[
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 3,
    "text": "Mas\nsac\nhus\netts,\nAm\nhers\nt\nKEIT\nH W.\nROS\nS\nNYU\nand\nNYU\nSha\nngh\nai"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 6,
    "text": "About the Authors\nJim Kurose\nJim Kurose is a Distinguished University Professor in the College of Information and\nComputer Sciences at the University of Massachusetts Amherst, where he has been on the\nfaculty since receiving his PhD in computer science from Columbia University. He received\na BA in physics from Wesleyan University. He has held a number of visiting scientist\npositions in the United States and abroad, including IBM Research, INRIA, and the\nSorbonne University in France. He recently completed a five-year term as Assistant Director\nat the US National Science Foundation, where he led the Directorate of Computer and\nInformation Science and Engineering in its mission to uphold the nation’s leadership in\nscientific discovery and engineering innovation. Jim is proud to have mentored and taught an amazing group of students, and to have\nreceived a number of awards for his research, teaching, and service, including the IEEE\nInfocom Award, the ACM SIGCOMM Lifetime Achievement Award, the ACM Sigcomm Test\nof Time Award, and the IEEE Computer Society Taylor Booth Education Medal. Dr. Kurose\nis a former Editor-in-Chief of IEEE Transactions on Communications and of IEEE/ACM"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 7,
    "text": "Transactions on Networking. He has served as Technical Program co-Chair for IEEE\nInfocom, ACM SIGCOMM, ACM Internet Measurement Conference, and ACM\nSIGMETRICS. He is a Fellow of the IEEE, the ACM and a member of the National Academy\nof Engineering. His research interests include network protocols and architecture, network\nmeasurement, multimedia communication, and modeling and performance evaluation. Keith Ross\nKeith Ross is the Dean of Engineering and Computer Science at NYU Shanghai and the\nLeonard J. Shustek Chair Professor in the Computer Science and Engineering Department\nat NYU. Previously he was at University of Pennsylvania (13 years), Eurecom Institute (5\nyears) and NYU-Poly (10 years). He received a B.S.E.E from Tufts University, a M.S.E.E. from Columbia University, and a Ph.D. in Computer and Control Engineering from The\nUniversity of Michigan. Keith Ross is also the co-founder and original CEO of Wimba, which\ndevelops online multimedia applications for e-learning and was acquired by Blackboard in\n2010. Professor Ross’s research interests have been in modeling and meaurement of\ncomputer networks, peer-to-peer systems, content distribution networks, social networks,\nand privacy. He is currently working in deep reinforcement learning. He is an ACM Fellow,\nan IEEE Fellow, recipient of the Infocom 2009 Best Paper Award, and recipient of 2011 and\n2008 Best Paper Awards for Multimedia Communications (awarded by IEEE"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 8,
    "text": "Communications Society). He has served on numerous journal editorial boards and\nconference program committees, including IEEE/ACM Transactions on Networking, ACM\nSIGCOMM, ACM CoNext, and ACM Internet Measurement Conference. He also has served\nas an advisor to the Federal Trade Commission on P2P file sharing."
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 9,
    "text": "To Julie and our three precious ones—Chris, Charlie,\nand Nina\nJFK\nA big THANKS to my professors, colleagues, and\nstudents all over the world. KWR"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 15,
    "text": "experience has been that such a layered approach indeed works well. Nevertheless, we have found that the traditional approach of teaching—\nbottom up; that is, from the physical layer toward the application layer—is\nnot the best approach for a modern course on computer networking. A Top-Down Approach\nOur book broke new ground 20 years ago by treating networking in a top-\ndown ­manner—that is, by beginning at the application layer and working its\nway down toward the physical layer. The feedback we received from\nteachers and students alike have confirmed that this top-down approach has\nmany advantages and does indeed work well pedagogically. First, it places\nemphasis on the application layer (a “high growth area” in networking). Indeed, many of the recent revolutions in computer networking—including\nthe Web, and media streaming—have taken place at the ­application layer. An early emphasis on application-layer issues differs from the ­approaches\ntaken in most other texts, which have only a small amount of material on\nnetwork applications, their requirements, application-layer paradigms (e.g.,\nclient-server and peer-to-peer), and application programming interfaces. Second, our experience as instructors (and that of many instructors who\nhave used this text) has been that teaching networking applications near the\nbeginning of the course is a powerful motivational tool. Students are\nthrilled to learn about how networking applications work—applications\nsuch as e-mail, streaming video, and the Web, which most students use on a\ndaily basis. Once a student understands the applications, the student can\nthen understand the network services needed to support these applications. The student can then, in turn, examine the various ways in which such"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 17,
    "text": "Another benefit of spotlighting the Internet is that most computer\nscience and electrical engineering students are eager to learn about the\nInternet and its protocols. They know that the Internet has been a\nrevolutionary and disruptive technology and can see that it is profoundly\nchanging our world. Given the enormous relevance of the Internet, students\nare naturally curious about what is “under the hood.” Thus, it is easy for an\ninstructor to get students excited about basic principles when using the\nInternet as the guiding focus. Teaching Networking Principles\nTwo of the unique features of the book—its top-down approach and its\nfocus on the Internet—have appeared in the titles of our book. If we could\nhave squeezed a third phrase into the subtitle, it would have contained the\nword principles. The field of networking is now mature enough that a\nnumber of fundamentally important issues can be identified. For example,\nin the transport layer, the fundamental issues include reliable\ncommunication over an unreliable network layer, connection establishment/\nteardown and handshaking, congestion and flow control, and multiplexing. Three fundamentally important network-layer issues are determining\n“good” paths between two routers, interconnecting a large number of\nheterogeneous networks, and managing the complexity of a modern\nnetwork. In the link layer, a fundamental problem is sharing a multiple\naccess \nchannel. In \nnetwork \nsecurity, \ntechniques \nfor \nproviding\nconfidentiality, authentication, and message integrity are all based on\ncryptographic fundamentals. This text identifies fundamental networking\nissues and studies approaches toward ­addressing these issues. The student\nlearning these principles will gain knowledge with a long “shelf life”—long"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 19,
    "text": "transport protocol, programming a distributed routing algorithm, and\nmore. •\nWireshark labs. One’s understanding of network protocols can be\ngreatly ­deepened by seeing them in action. The Website provides\nnumerous Wireshark assignments that enable students to actually\nobserve the sequence of messages exchanged between two protocol\nentities. The Website includes separate Wireshark labs on HTTP, DNS,\nTCP, UDP, IP, ICMP, Ethernet, ARP, WiFi, TLS and on tracing all\nprotocols involved in satisfying a request to fetch a Web page. We’ll\ncontinue to add new labs over time. Pedagogical Features\nWe have each been teaching computer networking for more than 30 years. Together, we bring more than 60 years of teaching experience to this text,\nduring which time we have taught many thousands of students. We have\nalso been active researchers in computer networking during this time. (In\nfact, Jim and Keith first met each other as master’s students in a computer\nnetworking course taught by Mischa Schwartz in 1979 at Columbia\nUniversity.) We think all this gives us a good perspective on where\nnetworking has been and where it is likely to go in the future. Nevertheless,\nwe have resisted temptations to bias the material in this book toward our\nown pet research projects. We figure you can visit our personal Websites if\nyou are interested in our research. Thus, this book is about modern\ncomputer networking—it is about contemporary protocols and technologies\nas well as the underlying principles behind these protocols and\ntechnologies. We also believe that learning (and teaching!) about"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 23,
    "text": "Steven Bellovin (Columbia University)\nPravin Bhagwat (Wibhu)\nSupratik Bhattacharyya (Amazon)\nErnst Biersack (Eurécom Institute)\nShahid Bokhari (University of Engineering & Technology, Lahore)\nJean Bolot (Technicolor Research)\nDaniel Brushteyn (former University of Pennsylvania student)\nKen Calvert (University of Kentucky)\nEvandro Cantu (Federal University of Santa Catarina)\nJeff Case (SNMP Research International)\nJeff Chaltas (Sprint)\nVinton Cerf (Google)\nByung Kyu Choi (Michigan Technological University)\nBram Cohen (BitTorrent, Inc.)\nConstantine Coutras (Pace University)\nJohn Daigle (University of Mississippi)\nEdmundo A. de Souza e Silva (Federal University of Rio de Janeiro)\nPhilippe Decuetos (former Eurecom Institute student)\nChristophe Diot (Google)\nPrithula Dhunghel (Akamai)\nDeborah Estrin (Cornell University)\nMichalis Faloutsos (University of California at Riverside)\nWu-chi Feng (Oregon Graduate Institute)\nSally Floyd (ICIR, University of California at Berkeley)\nPaul Francis (Max Planck Institute)\nDavid Fullager (Netflix)\nLixin Gao (University of Massachusetts)\nJJ Garcia-Luna-Aceves (University of California at Santa Cruz)"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 24,
    "text": "Mario Gerla (University of California at Los Angeles)\nDavid Goodman (NYU-Poly)\nYang Guo (Alcatel/Lucent Bell Labs)\nTim Griffin (Cambridge University)\nMax Hailperin (Gustavus Adolphus College)\nBruce Harvey (Florida A&M University, Florida State University)\nCarl Hauser (Washington State University)\nRachelle Heller (George Washington University)\nPhillipp Hoschka (INRIA/W3C)\nWen Hsin (Park University)\nAlbert Huang (former University of Pennsylvania student)\nCheng Huang (Microsoft Research)\nEsther A. Hughes (Virginia Commonwealth University)\nVan Jacobson (Google)\nPinak Jain (former NYU-Poly student)\nJobin James (University of California at Riverside)\nSugih Jamin (University of Michigan)\nShivkumar Kalyanaraman (IBM Research, India)\nJussi Kangasharju (University of Helsinki)\nSneha Kasera (University of Utah)\nParviz Kermani (U. Massachusetts)\nHyojin Kim (former University of Pennsylvania student)\nLeonard Kleinrock (University of California at Los Angeles)\nDavid Kotz (Dartmouth College)\nBeshan Kulapala (Arizona State University)\nRakesh Kumar (Bloomberg)\nMiguel A. Labrador (University of South Florida)\nSimon Lam (University of Texas)"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 25,
    "text": "Steve Lai (Ohio State University)\nTom LaPorta (Penn State University)\nTim-Berners Lee (World Wide Web Consortium)\nArnaud Legout (INRIA)\nLee Leitner (Drexel University)\nBrian Levine (University of Massachusetts)\nChunchun Li (former NYU-Poly student)\nYong Liu (NYU-Poly)\nWilliam Liang (former University of Pennsylvania student)\nWillis Marti (Texas A&M University)\nNick McKeown (Stanford University)\nJosh McKinzie (Park University)\nDeep Medhi (University of Missouri, Kansas City)\nBob Metcalfe (International Data Group)\nVishal Misra (Columbia University)\nSue Moon (KAIST)\nJenni Moyer (Comcast)\nErich Nahum (IBM Research)\nChristos Papadopoulos (Colorado Sate University)\nGuru Parulkar (Open Networking Foundation)\nCraig Partridge (Colorado State University)\nRadia Perlman (Dell EMC)\nJitendra Padhye (Microsoft Research)\nVern Paxson (University of California at Berkeley)\nKevin Phillips (Sprint)\nGeorge Polyzos (Athens University of Economics and Business)\nSriram Rajagopalan (Arizona State University)\nRamachandran Ramjee (Microsoft Research)"
  },
  {
    "unit": "Unit 1",
    "topic": "General",
    "source": "kurose",
    "page": 26,
    "text": "Ken Reek (Rochester Institute of Technology)\nMartin Reisslein (Arizona State University)\nJennifer Rexford (Princeton University)\nLeon Reznik (Rochester Institute of Technology)\nPablo Rodrigez (Telefonica)\nSumit Roy (University of Washington)\nCatherine Rosenberg (University of Waterloo)\nDan Rubenstein (Columbia University)\nAvi Rubin (Johns Hopkins University)\nDouglas Salane (John Jay College)\nDespina Saparilla (Cisco Systems)\nJohn Schanz (Comcast)\nHenning Schulzrinne (Columbia University)\nMischa Schwartz (Columbia University)\nArdash Sethi (University of Delaware)\nHarish Sethu (Drexel University)\nK. Sam Shanmugan (University of Kansas)\nPrashant Shenoy (University of Massachusetts)\nClay Shields (Georgetown University)\nSubin Shrestra (University of Pennsylvania)\nBojie Shu (former NYU-Poly student)\nMihail L. Sichitiu (NC State University)\nPeter Steenkiste (Carnegie Mellon University)\nTatsuya Suda (University of California at Irvine)\nKin Sun Tam (State University of New York at Albany)\nDon Towsley (University of Massachusetts)\nDavid Turner (California State University, San Bernardino)\nNitin Vaidya (Georgetown University)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 30,
    "text": "Brief Contents\nChapter 1 Computer Networks and the Internet\nChapter 2 Application Layer\nChapter 3 Transport Layer\nChapter 4 The Network Layer: Data Plane\nChapter 5 The Network Layer: Control Plane\nChapter 6 The Link Layer and LANs\nChapter 7 Wireless and Mobile Networks\nChapter 8 Security in Computer Networks"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 32,
    "text": "1.7.1\nThe Development of Packet Switching:\n1961–1972\n1.7.2\nProprietary Networks and Internetworking:\n1972–1980\n1.7.3\nA Proliferation of Networks: 1980–1990\n1.7.4\nThe Internet Explosion: The 1990s\n1.7.5\nThe New Millennium\n1.8\nSummary\nHomework Problems and Questions\nWireshark Lab\nInterview: Leonard Kleinrock\nChapter 2 Application Layer\n2.1\nPrinciples of Network Applications\n2.1.1\nNetwork Application Architectures\n2.1.2\nProcesses Communicating\n2.1.3\nTransport Services Available to Applications\n2.1.4\nTransport Services Provided by the Internet\n2.1.5\nApplication-Layer Protocols\n2.1.6\nNetwork Applications Covered in This Book\n2.2\nThe Web and HTTP\n2.2.1\nOverview of HTTP\n2.2.2\nNon-Persistent and Persistent Connections\n2.2.3\nHTTP Message Format\n2.2.4\nUser-Server Interaction: Cookies\n2.2.5\nWeb Caching\n2.2.6\nHTTP/2\n2.3\nElectronic Mail in the Internet"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 33,
    "text": "2.3.1\nSMTP\n2.3.2\nMail Message Formats\n2.3.3\nMail Access Protocols\n2.4\nDNS—The Internet’s Directory Service\n2.4.1\nServices Provided by DNS\n2.4.2\nOverview of How DNS Works\n2.4.3\nDNS Records and Messages\n2.5\nPeer-to-Peer File Distribution\n2.6\nVideo Streaming and Content Distribution\nNetworks\n2.6.1\nInternet Video\n2.6.2\nHTTP Streaming and DASH\n2.6.3\nContent Distribution Networks\n2.6.4\nCase Studies: Netflix and YouTube\n2.7\nSocket Programming: Creating Network\nApplications\n2.7.1\nSocket Programming with UDP\n2.7.2\nSocket Programming with TCP\n2.8\nSummary\nHomework Problems and Questions\nSocket Programming Assignments\nWireshark Labs: HTTP, DNS\nInterview: Tim Berners-Lee\nChapter 3 Transport Layer\n3.1\nIntroduction and Transport-Layer Services\n3.1.1\nRelationship Between Transport and\nNetwork Layers"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 34,
    "text": "3.1.2\nOverview of the Transport Layer in the\nInternet\n3.2\nMultiplexing and Demultiplexing\n3.3\nConnectionless Transport: UDP\n3.3.1\nUDP Segment Structure\n3.3.2\nUDP Checksum\n3.4\nPrinciples of Reliable Data Transfer\n3.4.1\nBuilding a Reliable Data Transfer Protocol\n3.4.2\nPipelined Reliable Data Transfer Protocols\n3.4.3\nGo-Back-N (GBN)\n3.4.4\nSelective Repeat (SR)\n3.5\nConnection-Oriented Transport: TCP\n3.5.1\nThe TCP Connection\n3.5.2\nTCP Segment Structure\n3.5.3\nRound-Trip Time Estimation and Timeout\n3.5.4\nReliable Data Transfer\n3.5.5\nFlow Control\n3.5.6\nTCP Connection Management\n3.6\nPrinciples of Congestion Control\n3.6.1\nThe Causes and the Costs of Congestion\n3.6.2\nApproaches to Congestion Control\n3.7\nTCP Congestion Control\n3.7.1\nClassic TCP Congestion Control\n3.7.2\nNetwork-Assisted Explicit Congestion\nNotification and Delayed-based Congestion\nControl\n3.7.3\nFairness\n3.8\nEvolution of Transport-Layer Functionality"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 35,
    "text": "3.9\nSummary\nHomework Problems and Questions\nProgramming Assignments\nWireshark Labs: Exploring TCP, UDP\nInterview: Van Jacobson\nChapter 4 The Network Layer: Data Plane\n4.1\nOverview of Network Layer\n4.1.1\nForwarding and Routing: The Data and\nControl Planes\n4.1.2\nNetwork Service Model\n4.2\nWhat’s Inside a Router? 4.2.1\nInput Port Processing and Destination-\nBased Forwarding\n4.2.2\nSwitching\n4.2.3\nOutput Port Processing\n4.2.4\nWhere Does Queuing Occur? 4.2.5\nPacket Scheduling\n4.3\nThe Internet Protocol (IP): IPv4, Addressing, IPv6,\nand More\n4.3.1\nIPv4 Datagram Format\n4.3.2\nIPv4 Addressing\n4.3.3\nNetwork Address Translation (NAT)\n4.3.4\nIPv6\n4.4\nGeneralized Forwarding and SDN\n4.4.1\nMatch\n4.4.2\nAction"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 36,
    "text": "4.4.3\nOpenFlow Examples of Match-plus-action\nin Action\n4.5\nMiddleboxes\n4.6\nSummary\nHomework Problems and Questions\nWireshark Lab: IP\nInterview: Vinton G. Cerf\nChapter 5 The Network Layer: Control Plane\n5.1\nIntroduction\n5.2\nRouting Algorithms\n5.2.1\nThe Link-State (LS) Routing Algorithm\n5.2.2\nThe Distance-Vector (DV) Routing\nAlgorithm\n5.3\nIntra-AS Routing in the Internet: OSPF\n5.4\nRouting Among the ISPs: BGP\n5.4.1\nThe Role of BGP\n5.4.2\nAdvertising BGP Route Information\n5.4.3\nDetermining the Best Routes\n5.4.4\nIP-Anycast\n5.4.5\nRouting Policy\n5.4.6\nPutting the Pieces Together: Obtaining\nInternet Presence\n5.5\nThe SDN Control Plane\n5.5.1\nThe SDN Control Plane: SDN Controller\nand SDN Network-control Applications\n5.5.2\nOpenFlow Protocol"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 37,
    "text": "5.5.3\nData and Control Plane Interaction: An\nExample\n5.5.4\nSDN: Past and Future\n5.6\nICMP: The Internet Control Message Protocol\n5.7\nNetwork Management and SNMP,\nNETCONF/YANG\n5.7.1\nThe Network Management Framework\n5.7.2\nThe Simple Network Management Protocol\n(SNMP) and the Management Information\nBase (MIB)\n5.7.3\nThe Network Configuration Protocol\n(NETCONF) and YANG\n5.8\nSummary\nHomework Problems and Questions\nSocket Programming Assignment 5: ICMP Ping\nProgramming Assignment: Routing\nWireshark Lab: ICMP\nInterview: Jennifer Rexford\nChapter 6 The Link Layer and LANs\n6.1\nIntroduction to the Link Layer\n6.1.1\nThe Services Provided by the Link Layer\n6.1.2\nWhere Is the Link Layer Implemented? 6.2\nError-Detection and -Correction Techniques\n6.2.1\nParity Checks\n6.2.2\nChecksumming Methods\n6.2.3\nCyclic Redundancy Check (CRC)\n6.3\nMultiple Access Links and Protocols"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 38,
    "text": "6.3.1\nChannel Partitioning Protocols\n6.3.2\nRandom Access Protocols\n6.3.3\nTaking-Turns Protocols\n6.3.4\nDOCSIS: The Link-Layer Protocol for\nCable Internet Access\n6.4\nSwitched Local Area Networks\n6.4.1\nLink-Layer Addressing and ARP\n6.4.2\nEthernet\n6.4.3\nLink-Layer Switches\n6.4.4\nVirtual Local Area Networks (VLANs)\n6.5\nLink Virtualization: A Network as a Link Layer\n6.5.1\nMultiprotocol Label Switching (MPLS)\n6.6\nData Center Networking\n6.6.1\nData Center Architectures\n6.6.2\nTrends in Data Center Networking\n6.7\nRetrospective: A Day in the Life of a Web Page\nRequest\n6.7.1\nGetting Started: DHCP, UDP, IP, and\nEthernet\n6.7.2\nStill Getting Started: DNS and ARP\n6.7.3\nStill Getting Started: Intra-Domain Routing\nto the DNS Server\n6.7.4\nWeb Client-Server Interaction: TCP and\nHTTP\n6.8\nSummary\nHomework Problems and Questions\nWireshark Labs: 802.11 Ethernet\nInterview: Albert Greenberg"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 39,
    "text": "Chapter 7 Wireless and Mobile Networks\n7.1\nIntroduction\n7.2\nWireless Links and Network Characteristics\n7.2.1\nCDMA\n7.3\nWiFi: 802.11 Wireless LANs\n7.3.1\nThe 802.11 Wireless LAN Architecture\n7.3.2\nThe 802.11 MAC Protocol\n7.3.3\nThe IEEE 802.11 Frame\n7.3.4\nMobility in the Same IP Subnet\n7.3.5\nAdvanced Features in 802.11\n7.3.6\nPersonal Area Networks: Bluetooth\n7.4\nCellular Networks: 4G and 5G\n7.4.1\n4G LTE Cellular Networks: Architecture\nand Elements\n7.4.2\nLTE Protocols Stacks\n7.4.3\nLTE Radio Access Network\n7.4.4\nAdditional LTE Functions: Network\nAttachment and Power Management\n7.4.5\nThe Global Cellular Network: A Network of\nNetworks\n7.4.6\n5G Cellular Networks\n7.5\nMobility Management: Principles\n7.5.1\nDevice Mobility: a Network-layer\nPerspective\n7.5.2\nHome Networks and Roaming on Visited\nNetworks\n7.5.3\nDirect and Indirect Routing to/from a\nMobile Device"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 40,
    "text": "7.6\nMobility Management in Practice\n7.6.1\nMobility Management in 4G/5G Networks\n7.6.2\nMobile IP\n7.7\nWireless and Mobility: Impact on Higher-Layer\nProtocols\n7.8\nSummary\nHomework Problems and Questions\nWireshark Lab: WiFi\nInterview: Deborah Estrin\nChapter 8 Security in Computer Networks\n8.1\nWhat Is Network Security? 8.2\nPrinciples of Cryptography\n8.2.1\nSymmetric Key Cryptography\n8.2.2\nPublic Key Encryption\n8.3\nMessage Integrity and Digital Signatures\n8.3.1\nCryptographic Hash Functions\n8.3.2\nMessage Authentication Code\n8.3.3\nDigital Signatures\n8.4\nEnd-Point Authentication\n8.5\nSecuring E-Mail\n8.5.1\nSecure E-Mail\n8.5.2\nPGP\n8.6\nSecuring TCP Connections: TLS\n8.6.1\nThe Big Picture\n8.6.2\nA More Complete Picture\n8.7\nNetwork-Layer Security: IPsec and Virtual Private\nNetworks"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 41,
    "text": "8.7.1\nIPsec and Virtual Private Networks (VPNs)\n8.7.2\nThe AH and ESP Protocols\n8.7.3\nSecurity Associations\n8.7.4\nThe IPsec Datagram\n8.7.5\nIKE: Key Management in IPsec\n8.8\nSecuring Wireless LANs and 4G/5G Cellular\nNetworks\n8.8.1\nAuthentication and Key Agreement in\n802.11 Wireless LANs\n8.8.2\nAuthentication and Key Agreement in\n4G/5G Cellular Networks\n8.9\nOperational Security: Firewalls and Intrusion\nDetection Systems\n8.9.1\nFirewalls\n8.9.2\nIntrusion Detection Systems\n8.10\nSummary\nHomework Problems and Questions\nWireshark Lab: SSL\nIPsec Lab\nInterview: Steven M. Bellovin"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 45,
    "text": "Computer Networks\nand the Internet\nToday’s Internet is arguably the largest\nengineered system ever created by ­mankind,\nwith hundreds of millions of connected\ncomputers, \ncommunication \nlinks, \nand\nswitches; with billions of users who connect\nvia laptops, tablets, and smartphones; and\nwith an array of new Internet-connected\n“things” \nincluding \ngame \nconsoles,\nsurveillance systems, watches, eye glasses,\nthermostats, and cars. Given that the Internet\nis so large and has so many diverse\ncomponents and uses, is there any hope of\nunderstanding how it works? Are there\nguiding principles and structure that can\nprovide a foundation for understanding such\nan amazingly large and complex system? And\nif so, is it possible that it actually could be\nboth interesting and fun to learn about\ncomputer networks? Fortunately, the answer\nto all of these questions is a resounding YES!"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 46,
    "text": "Indeed, it’s our aim in this book to provide\nyou with a modern introduction to the\ndynamic field of computer networking, giving\nyou the principles and practical insights\nyou’ll need to understand not only today’s\nnetworks, but tomorrow’s as well. This first chapter presents a broad\noverview of computer networking and the\nInternet. Our goal here is to paint a broad\npicture and set the context for the rest of this\nbook, to see the forest through the trees. We’ll\ncover a lot of ground in this introductory\nchapter and discuss a lot of the pieces of a\ncomputer network, without losing sight of the\nbig picture. We’ll structure our overview of computer\nnetworks in this chapter as follows. After\nintroducing some basic terminology and\nconcepts, we’ll first examine the basic\nhardware and software components that make\nup a network. We’ll begin at the network’s\nedge and look at the end systems and network\napplications running in the network. We’ll\nthen explore the core of a computer network,\nexamining the links and the switches that\ntransport data, as well as the access networks\nand physical media that connect end systems\nto the network core. We’ll learn that the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 47,
    "text": "Internet is a network of networks, and we’ll\nlearn how these networks connect with each\nother. After having completed this overview of the edge and core of a\ncomputer network, we’ll take the broader and more abstract view in the\nsecond half of this chapter. We’ll examine delay, loss, and throughput of\ndata in a computer network and provide simple quantitative models for end-\nto-end throughput and delay: models that take into account transmission,\npropagation, and queuing delays. We’ll then introduce some of the key\narchitectural principles in computer networking, namely, protocol layering\nand service models. We’ll also learn that computer networks are vulnerable\nto many different types of attacks; we’ll survey some of these attacks and\nconsider how computer networks can be made more secure. Finally, we’ll\nclose this chapter with a brief history of computer networking."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 48,
    "text": "1.1 What Is the Internet? In this book, we’ll use the public Internet, a specific computer network, as\nour principal vehicle for discussing computer networks and their protocols. But what is the Internet? There are a couple of ways to answer this\nquestion. First, we can describe the nuts and bolts of the Internet, that is, the\nbasic hardware and software components that make up the Internet. Second,\nwe can describe the Internet in terms of a networking infrastructure that\nprovides services to distributed applications. Let’s begin with the nuts-and-\nbolts description, using Figure 1.1 to illustrate our discussion."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 50,
    "text": "Figure 1.1 ♦Some pieces of the Internet\n1.1.1 A Nuts-and-Bolts Description\nThe Internet is a computer network that interconnects billions of computing\ndevices throughout the world. Not too long ago, these computing devices\nwere primarily traditional desktop computers, Linux workstations, and so-\ncalled servers that store and transmit information such as Web pages and e-\nmail messages. Increasingly, however, users connect to the Internet with\nsmartphones and tablets—today, close to half of the world’s population are\nactive mobile Internet users with the percentage expected to increase to\n75% by 2025 [Statista 2019]. Furthermore, nontraditional Internet “things”\nsuch as TVs, gaming consoles, thermostats, home security systems, home\nappliances, watches, eye glasses, cars, traffic control systems, and more are\nbeing connected to the Internet. Indeed, the term computer network is\nbeginning to sound a bit dated, given the many nontraditional devices that\nare being hooked up to the Internet. In Internet jargon, all of these devices\nare called hosts or end systems. By some estimates, there were about 18\nbillion devices connected to the Internet in 2017, and the number will reach\n28.5 billion by 2022 [Cisco VNI 2020]. End systems are connected together by a network of communication\nlinks and packet switches. We’ll see in Section 1.2 that there are many\ntypes of communication links, which are made up of different types of\nphysical media, including coaxial cable, copper wire, optical fiber, and\nradio spectrum. Different links can transmit data at different rates, with the\ntransmission rate of a link measured in bits/second. When one end system\nhas data to send to another end system, the sending end system segments"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 51,
    "text": "the data and adds header bytes to each segment. The resulting packages of\ninformation, known as packets in the jargon of computer networks, are then\nsent through the network to the destination end system, where they are\nreassembled into the original data. A packet switch takes a packet arriving on one of its incoming\ncommunication links and forwards that packet on one of its outgoing\ncommunication links. Packet switches come in many shapes and flavors,\nbut the two most prominent types in today’s Internet are routers and link-\nlayer switches. Both types of switches forward packets toward their\nultimate destinations. Link-layer switches are typically used in access\nnetworks, while routers are typically used in the network core. The\nsequence of communication links and packet switches traversed by a packet\nfrom the sending end system to the receiving end system is known as a\nroute or path through the network. Cisco predicts annual global IP traffic\nwill reach nearly five zettabytes (10  bytes) by 2022 [Cisco VNI 2020]. Packet-switched networks (which transport packets) are in many ways\nsimilar to transportation networks of highways, roads, and intersections\n(which transport vehicles). Consider, for example, a factory that needs to\nmove a large amount of cargo to some destination warehouse located\nthousands of kilometers away. At the factory, the cargo is segmented and\nloaded into a fleet of trucks. Each of the trucks then independently travels\nthrough the network of highways, roads, and intersections to the destination\nwarehouse. At the destination warehouse, the cargo is unloaded and\ngrouped with the rest of the cargo arriving from the same shipment. Thus,\nin many ways, packets are analogous to trucks, communication links are\nanalogous to highways and roads, packet switches are analogous to\nintersections, and end systems are analogous to buildings. Just as a truck"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 52,
    "text": "takes a path through the transportation network, a packet takes a path\nthrough a computer network. End systems access the Internet through Internet Service Providers\n(ISPs), including residential ISPs such as local cable or telephone\ncompanies; corporate ISPs; university ISPs; ISPs that provide WiFi access\nin airports, hotels, coffee shops, and other public places; and cellular data\nISPs, providing mobile access to our ­smartphones and other devices. Each\nISP is in itself a network of packet switches and communication links. ISPs\nprovide a variety of types of network access to the end systems, including\nresidential broadband access such as cable modem or DSL, high-speed local\narea network access, and mobile wireless access. ISPs also ­provide Internet\naccess to content providers, connecting servers directly to the ­Internet. The\nInternet is all about connecting end systems to each other, so the ISPs that ­-\nprovide access to end systems must also be interconnected. These lower-tier\nISPs are thus interconnected through national and international upper-tier\nISPs and these upper-tier ISPs are connected directly to each other. An\nupper-tier ISP consists of high-speed routers interconnected with high-\nspeed fiber-optic links. Each ISP network, whether upper-tier or lower-tier,\nis managed independently, runs the IP protocol (see below), and conforms\nto certain naming and address conventions. We’ll examine ISPs and their\ninterconnection more closely in Section 1.3. End systems, packet switches, and other pieces of the Internet run\nprotocols that control the sending and receiving of information within the\nInternet. The Transmission Control Protocol (TCP) and the Internet\nProtocol (IP) are two of the most important protocols in the Internet. The\nIP protocol specifies the format of the packets that are sent and received\namong routers and end systems. The Internet’s principal protocols are\ncollectively known as TCP/IP. We’ll begin looking into protocols in this"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 53,
    "text": "introductory chapter. But that’s just a start—much of this book is concerned\nwith networking protocols! Given the importance of protocols to the Internet, it’s important that\neveryone agree on what each and every protocol does, so that people can\ncreate systems and products that interoperate. This is where standards come\ninto play. Internet ­standards are developed by the Internet Engineering\nTask Force (IETF) [IETF 2020]. The IETF standards documents are called\nrequests for comments (RFCs). RFCs started out as general requests for\ncomments (hence the name) to resolve network and protocol design\nproblems that faced the precursor to the Internet [Allman 2011]. RFCs tend\nto be quite technical and detailed. They define protocols such as TCP, IP,\nHTTP (for the Web), and SMTP (for e-mail). There are currently nearly\n9000 RFCs. Other bodies also specify standards for network components,\nmost notably for network links. The IEEE 802 LAN Standards Committee\n[IEEE 802 2020], for example, specifies the Ethernet and wireless WiFi\nstandards. 1.1.2 A Services Description\nOur discussion above has identified many of the pieces that make up the\nInternet. But we can also describe the Internet from an entirely different\nangle—namely, as an infrastructure that provides services to applications. In addition to traditional applications such as e-mail and Web surfing,\nInternet applications include mobile smartphone and tablet applications,\nincluding Internet messaging, mapping with real-time road-traffic\ninformation, music streaming movie and television streaming, online social\nmedia, video conferencing, multi-person games, and location-based\nrecommendation systems. The applications are said to be distributed"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 54,
    "text": "applications, since they involve multiple end systems that exchange data\nwith each other. Importantly, Internet applications run on end systems—\nthey do not run in the packet switches in the network core. Although packet\nswitches facilitate the exchange of data among end systems, they are not\nconcerned with the application that is the source or sink of data. Let’s explore a little more what we mean by an infrastructure that\nprovides ­services to applications. To this end, suppose you have an exciting\nnew idea for a distributed Internet application, one that may greatly benefit\nhumanity or one that may simply make you rich and famous. How might\nyou go about transforming this idea into an actual Internet application? Because applications run on end systems, you are going to need to write\nprograms that run on the end systems. You might, for example, write your\nprograms in Java, C, or Python. Now, because you are developing a\ndistributed Internet application, the programs running on the different end\nsystems will need to send data to each other. And here we get to a central\nissue—one that leads to the alternative way of describing the Internet as a\nplatform for applications. How does one program running on one end\nsystem instruct the Internet to deliver data to another program running on\nanother end system? End systems attached to the Internet provide a socket interface that\nspecifies how a program running on one end system asks the Internet\ninfrastructure to deliver data to a specific destination program running on\nanother end system. This Internet socket interface is a set of rules that the\nsending program must follow so that the Internet can deliver the data to the\ndestination program. We’ll discuss the Internet socket interface in detail in\nChapter 2. For now, let’s draw upon a simple analogy, one that we will\nfrequently use in this book. Suppose Alice wants to send a letter to Bob\nusing the postal service. Alice, of course, can’t just write the letter (the data)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 55,
    "text": "and drop the letter out her window. Instead, the postal service requires that\nAlice put the letter in an envelope; write Bob’s full name, address, and zip\ncode in the center of the envelope; seal the envelope; put a stamp in the\nupper-right-hand corner of the envelope; and finally, drop the envelope into\nan official postal service mailbox. Thus, the postal service has its own\n“postal service interface,” or set of rules, that Alice must follow to have the\npostal service deliver her letter to Bob. In a similar manner, the Internet has\na socket interface that the program sending data must follow to have the\nInternet deliver the data to the program that will receive the data. The postal service, of course, provides more than one service to its\ncustomers. It provides express delivery, reception confirmation, ordinary\nuse, and many more services. In a similar manner, the Internet provides\nmultiple services to its applications. When you develop an Internet\napplication, you too must choose one of the Internet’s services for your\napplication. We’ll describe the Internet’s services in Chapter 2. We have just given two descriptions of the Internet; one in terms of its\nhardware and software components, the other in terms of an infrastructure\nfor providing services to distributed applications. But perhaps you are still\nconfused as to what the Internet is. What are packet switching and TCP/IP? What are routers? What kinds of communication links are present in the\nInternet? What is a distributed application? How can a thermostat or body\nscale be attached to the Internet? If you feel a bit overwhelmed by all of this\nnow, don’t worry—the purpose of this book is to introduce you to both the\nnuts and bolts of the Internet and the principles that govern how and why it\nworks. We’ll explain these important terms and questions in the following\nsections and chapters."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 56,
    "text": "1.1.3 What Is a Protocol? Now that we’ve got a bit of a feel for what the Internet is, let’s consider\nanother important buzzword in computer networking: protocol. What is a\nprotocol? What does a protocol do? A Human Analogy\nIt is probably easiest to understand the notion of a computer network\nprotocol by first considering some human analogies, since we humans\nexecute protocols all of the time. Consider what you do when you want to\nask someone for the time of day. A typical exchange is shown in Figure 1.2. Human protocol (or good manners, at least) dictates that one first offer a\ngreeting (the first “Hi” in Figure 1.2) to initiate communication with\nsomeone else. The typical response to a “Hi” is a returned “Hi” message. Implicitly, one then takes a cordial “Hi” response as an indication that one\ncan proceed and ask for the time of day. A different response to the initial\n“Hi” (such as “Don’t bother me!” or “I don’t speak English,” or some\nunprintable reply) might indicate an unwillingness or inability to\ncommunicate. In this case, the human protocol would be not to ask for the\ntime of day. Sometimes one gets no response at all to a question, in which\ncase one typically gives up asking that person for the time. Note that in our\nhuman protocol, there are specific messages we send, and specific actions\nwe take in response to the received reply messages or other events (such as\nno reply within some given amount of time). Clearly, transmitted and\nreceived messages, and actions taken when these messages are sent or\nreceived or other events occur, play a central role in a human protocol. If\npeople run different protocols (for example, if one person has manners but\nthe other does not, or if one understands the concept of time and the other"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 57,
    "text": "does not) the protocols do not interoperate and no useful work can be\naccomplished. The same is true in networking—it takes two (or more)\ncommunicating entities running the same protocol in order to accomplish a\ntask. Figure 1.2 ♦A human protocol and a computer network protocol\nLet’s consider a second human analogy. Suppose you’re in a college\nclass (a computer networking class, for example!). The teacher is droning\non about protocols and you’re confused. The teacher stops to ask, “Are\nthere any questions?” (a message that is transmitted to, and received by, all\nstudents who are not sleeping). You raise your hand (transmitting an\nimplicit message to the teacher). Your teacher acknowledges you with a\nsmile, saying “Yes . . .” (a transmitted message encouraging you to ask your"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 58,
    "text": "question—teachers love to be asked questions), and you then ask your\nquestion (that is, transmit your message to your teacher). Your teacher hears\nyour question (receives your question message) and answers (transmits a\nreply to you). Once again, we see that the transmission and receipt of\nmessages, and a set of conventional actions taken when these messages are\nsent and received, are at the heart of this question-and-answer protocol. Network Protocols\nA network protocol is similar to a human protocol, except that the entities\nexchanging messages and taking actions are hardware or software\ncomponents of some device (for example, computer, smartphone, tablet,\nrouter, or other network-capable device). All activity in the Internet that\ninvolves two or more communicating remote entities is governed by a\nprotocol. For example, hardware-implemented protocols in two physically\nconnected computers control the flow of bits on the “wire” between the two\nnetwork interface cards; congestion-control protocols in end systems\ncontrol the rate at which packets are transmitted between sender and\nreceiver; protocols in routers determine a packet’s path from source to\ndestination. Protocols are running everywhere in the Internet, and\nconsequently much of this book is about computer network protocols. As an example of a computer network protocol with which you are\nprobably familiar, consider what happens when you make a request to a\nWeb server, that is, when you type the URL of a Web page into your Web\nbrowser. The scenario is illustrated in the right half of Figure 1.2. First, your\ncomputer will send a connection request message to the Web server and\nwait for a reply. The Web server will eventually receive your connection\nrequest message and return a connection reply message. Knowing that it is\nnow OK to request the Web document, your computer then sends the name"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 59,
    "text": "of the Web page it wants to fetch from that Web server in a GET message. Finally, the Web server returns the Web page (file) to your computer. Given the human and networking examples above, the exchange of\nmessages and the actions taken when these messages are sent and received\nare the key defining elements of a protocol:\nA protocol defines the format and the order of messages exchanged\nbetween two or more communicating entities, as well as the actions\ntaken on the transmission and/or receipt of a message or other event. The Internet, and computer networks in general, make extensive use of\nprotocols. Different \nprotocols \nare \nused \nto \naccomplish \ndifferent\ncommunication tasks. As you read through this book, you will learn that\nsome protocols are simple and straightforward, while others are complex\nand intellectually deep. Mastering the field of computer networking is\nequivalent to understanding the what, why, and how of networking\nprotocols."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 60,
    "text": "1.2 The Network Edge\nIn the previous section, we presented a high-level overview of the Internet\nand ­networking protocols. We are now going to delve a bit more deeply into\nthe components of the Internet. We begin in this section at the edge of the\nnetwork and look at the components with which we are most ­familiar—\nnamely, the computers, smartphones and other devices that we use on a\ndaily basis. In the next section, we’ll move from the network edge to the\nnetwork core and examine switching and routing in computer networks. Recall from the previous section that in computer networking jargon,\nthe computers and other devices connected to the Internet are often referred\nto as end systems. They are referred to as end systems because they sit at\nthe edge of the Internet, as shown in Figure 1.3. The Internet’s end systems\ninclude desktop computers (e.g., desktop PCs, Macs, and Linux boxes),\nservers (e.g., Web and e-mail servers), and mobile devices (e.g., laptops,\nsmartphones, and tablets). Furthermore, an increasing number of non-\ntraditional “things” are being attached to the Internet as end ­systems (see\nthe Case History feature)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 61,
    "text": "Figure 1.3 ♦End-system interaction\nEnd systems are also referred to as hosts because they host (that is, run)\napplication programs such as a Web browser program, a Web server\nprogram, an e-mail client program, or an e-mail server program."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 62,
    "text": "Throughout this book we will use the terms hosts and end systems\ninterchangeably; that is, host = end system. Hosts are sometimes further\ndivided into two categories: clients and servers. Informally, clients tend to\nbe desktops, laptops, smartphones, and so on, whereas servers tend to be\nmore powerful machines that store and distribute Web pages, stream video,\nrelay e-mail, and so on. Today, most of the servers from which we receive\nsearch results, e-mail, Web pages, videos and mobile app content reside in\nlarge data centers. For example, as of 2020, Google has 19 data centers on\nfour continents, collectively containing several million servers. Figure 1.3\nincludes two such data centers, and the Case History sidebar describes data\ncenters in more detail. CASE HISTORY\nDATA CENTERS AND CLOUD COMPUTING\nInternet companies such as Google, Microsoft, Amazon, and Alibaba have built\nmassive data centers, each housing tens to hundreds of thousands of hosts. These\ndata centers are not only connected to the Internet, as shown in Figure 1.1, but also\ninternally include complex computer networks that interconnect the datacenter’s hosts. The data centers are the engines behind the Internet applications that we use on a\ndaily basis. Broadly speaking, data centers serve three purposes, which we describe here in the\ncontext of Amazon for concreteness. First, they serve Amazon e-commerce pages to\nusers, for example, pages describing products and purchase information. Second, they\nserve as massively parallel computing infrastructures for Amazon-specific data\nprocessing tasks. Third, they provide cloud computing to other companies. Indeed,\ntoday a major trend in computing is for companies to use a cloud provider such as\nAmazon to handle essentially all of their IT needs. For example, Airbnb and many other"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 63,
    "text": "Internet-based companies do not own and manage their own data centers but instead\nrun their entire Web-based services in the Amazon cloud, called Amazon Web Services\n(AWS). The worker bees in a data center are the hosts. They serve content (e.g., Web\npages and videos), store e-mails and documents, and collectively perform massively\ndistributed computations. The hosts in data centers, called blades and resembling\npizza boxes, are generally commodity hosts that include CPU, memory, and disk\nstorage. The hosts are stacked in racks, with each rack typically having 20 to\n40 blades. The racks are then interconnected using sophisticated and evolving data\ncenter network designs. Data center networks are discussed in greater detail in\nChapter 6. 1.2.1 Access Networks\nHaving considered the applications and end systems at the “edge of the\nnetwork,” let’s next consider the access network—the network that\nphysically connects an end system to the first router (also known as the\n“edge router”) on a path from the end system to any other distant end\nsystem. Figure 1.4 shows several types of access networks with thick,\nshaded lines and the settings (home, enterprise, and wide-area mobile\nwireless) in which they are used."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 64,
    "text": "Figure 1.4 ♦Access networks\nHome Access: DSL, Cable, FTTH, and 5G Fixed Wireless"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 65,
    "text": "As of 2020, more than 80% of the households in Europe and the USA have\nInternet access [Statista 2019]. Given this widespread use of home access\nnetworks let’s begin our overview of access networks by considering how\nhomes connect to the Internet. Today, the two most prevalent types of broadband residential access are\ndigital subscriber line (DSL) and cable. A residence typically obtains DSL\nInternet access from the same local telephone company (telco) that provides\nits wired local phone access. Thus, when DSL is used, a customer’s telco is\nalso its ISP. As shown in Figure 1.5, each customer’s DSL modem uses the\nexisting telephone line exchange data with a digital subscriber line access\nmultiplexer (DSLAM) located in the telco’s local central office (CO). The\nhome’s DSL modem takes digital data and translates it to high-­frequency\ntones for transmission over telephone wires to the CO; the analog signals\nfrom many such houses are translated back into digital format at the\nDSLAM. Figure 1.5 ♦DSL Internet access"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 66,
    "text": "The residential telephone line carries both data and traditional\ntelephone signals simultaneously, which are encoded at different\nfrequencies:\n•\nA high-speed downstream channel, in the 50 kHz to 1 MHz band\n•\nA medium-speed upstream channel, in the 4 kHz to 50 kHz band\n•\nAn ordinary two-way telephone channel, in the 0 to 4 kHz band\nThis approach makes the single DSL link appear as if there were three\nseparate links, so that a telephone call and an Internet connection can share\nthe DSL link at the same time. (We’ll describe this technique of frequency-\ndivision multiplexing in Section 1.3.1.) On the customer side, a splitter\nseparates the data and telephone signals arriving to the home and forwards\nthe data signal to the DSL modem. On the telco side, in the CO, the\nDSLAM separates the data and phone signals and sends the data into the\nInternet. Hundreds or even thousands of households connect to a single\nDSLAM. The DSL standards define multiple transmission rates, including\ndownstream transmission rates of 24 Mbs and 52 Mbs, and upstream rates\nof 3.5 Mbps and 16  Mbps; the newest standard provides for aggregate\nupstream plus downstream rates of 1 Gbps [ITU 2014]. Because the\ndownstream and upstream rates are different, the access is said to be\nasymmetric. The actual downstream and upstream transmission rates\nachieved may be less than the rates noted above, as the DSL provider may\npurposefully limit a residential rate when tiered service (different rates,\navailable at different prices) are offered. The maximum rate is also limited\nby the distance between the home and the CO, the gauge of the twisted-pair\nline and the degree of electrical interference. Engineers have expressly\ndesigned DSL for short distances between the home and the CO; generally,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 67,
    "text": "if the residence is not located within 5 to 10 miles of the CO, the residence\nmust resort to an alternative form of Internet access. While DSL makes use of the telco’s existing local telephone\ninfrastructure, cable Internet access makes use of the cable television\ncompany’s existing cable television infrastructure. A residence obtains cable\nInternet access from the same company that provides its cable television. As\nillustrated in Figure 1.6, fiber optics connect the cable head end to\nneighborhood-level junctions, from which traditional coaxial cable is then\nused to reach individual houses and apartments. Each neighborhood\njunction typically supports 500 to 5,000 homes. Because both fiber and\ncoaxial cable are employed in this system, it is often referred to as hybrid\nfiber coax (HFC). Figure 1.6 ♦A hybrid fiber-coaxial access network\nCable internet access requires special modems, called cable modems. As with a DSL modem, the cable modem is typically an external device and\nconnects to the home PC through an Ethernet port. (We will discuss"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 68,
    "text": "Ethernet in great detail in Chapter 6.) At the cable head end, the cable\nmodem termination system (CMTS) serves a similar function as the DSL\nnetwork’s DSLAM—turning the analog signal sent from the cable modems\nin many downstream homes back into digital format. Cable modems divide\nthe HFC network into two channels, a downstream and an upstream\nchannel. As with DSL, access is typically asymmetric, with the downstream\nchannel typically allocated a higher transmission rate than the upstream\nchannel. The DOCSIS 2.0 and 3.0 standards define downstream bitrates of\n40 Mbps and 1.2 Gbps, and upstream rates of  30  Mbps and 100 Mbps,\nrespectively. As in the case of DSL networks, the ­maximum achievable rate\nmay not be realized due to lower contracted data rates or media\nimpairments. One important characteristic of cable Internet access is that it is a\nshared broadcast medium. In particular, every packet sent by the head end\ntravels downstream on every link to every home and every packet sent by a\nhome travels on the upstream channel to the head end. For this reason, if\nseveral users are simultaneously downloading a video file on the\ndownstream channel, the actual rate at which each user receives its video\nfile will be significantly lower than the aggregate cable downstream rate. On the other hand, if there are only a few active users and they are all Web\nsurfing, then each of the users may actually receive Web pages at the full\ncable downstream rate, because the users will rarely request a Web page at\nexactly the same time. Because the upstream channel is also shared, a\ndistributed multiple access protocol is needed to coordinate transmissions\nand avoid collisions. (We’ll discuss this collision issue in some detail in\nChapter 6.) Although DSL and cable networks currently represent the majority of\nresidential broadband access in the United States, an up-and-coming"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 69,
    "text": "technology that provides even higher speeds is fiber to the home (FTTH)\n[Fiber Broadband 2020]. As the name suggests, the FTTH concept is simple\n—provide an optical fiber path from the CO directly to the home. FTTH\ncan potentially provide Internet access rates in the gigabits per second\nrange. There are several competing technologies for optical distribution from\nthe CO to the homes. The simplest optical distribution network is called\ndirect fiber, with one fiber leaving the CO for each home. More commonly,\neach fiber leaving the central office is actually shared by many homes; it is\nnot until the fiber gets relatively close to the homes that it is split into\nindividual customer-specific fibers. There are two competing optical-\ndistribution network architectures that perform this splitting: active optical\nnetworks (AONs) and passive optical networks (PONs). AON is essentially\nswitched Ethernet, which is discussed in Chapter 6. Here, we briefly discuss PON, which is used in Verizon’s FiOS service. Figure 1.7 shows FTTH using the PON distribution architecture. Each\nhome has an optical network terminator (ONT), which is connected by\ndedicated optical fiber to a neighborhood splitter. The splitter combines a\nnumber of homes (typically less than 100) onto a single, shared optical\nfiber, which connects to an optical line ­terminator (OLT) in the telco’s CO. The OLT, providing conversion between optical and electrical signals,\nconnects to the Internet via a telco router. At home, users connect a home\nrouter (typically a wireless router) to the ONT and access the ­Internet via\nthis home router. In the PON architecture, all packets sent from OLT to the\nsplitter are replicated at the splitter (similar to a cable head end)."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 70,
    "text": "Figure 1.7 ♦FTTH Internet access\nIn addition to DSL, Cable, and FTTH, 5G fixed wireless is beginning\nto be deployed. 5G fixed wireless not only promises high-speed residential\naccess, but will do so without installing costly and failure-prone cabling\nfrom the telco’s CO to the home. With 5G fixed wireless, using beam-\nforming technology, data is sent wirelessly from a provider’s base station to\nthe a modem in the home. A WiFi wireless router is connected to the\nmodem (possibly bundled together), similar to how a WiFi wireless router\nis connected to a cable or DSL modem. 5G cellular networks are covered in\nChapter 7. Access in the Enterprise (and the Home): Ethernet and WiFi\nOn corporate and university campuses, and increasingly in home settings, a\nlocal area  network (LAN) is used to connect an end system to the edge\nrouter. Although there are many types of LAN technologies, Ethernet is by\nfar the most prevalent access technology in corporate, university, and home\nnetworks. As shown in Figure 1.8, Ethernet users use twisted-pair copper\nwire to connect to an Ethernet switch, a technology discussed in detail in"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 71,
    "text": "Chapter 6. The Ethernet switch, or a network of such interconnected\nswitches, is then in turn connected into the larger Internet. With Ethernet\naccess, users typically have 100 Mbps to tens of Gbps access to the\nEthernet switch, whereas servers may have 1 Gbps 10 Gbps access. Figure 1.8 ♦Ethernet Internet access\nIncreasingly, however, people are accessing the Internet wirelessly from\nlaptops, smartphones, tablets, and other “things”. In a wireless LAN setting,\nwireless users transmit/receive packets to/from an access point that is\nconnected into the enterprise’s network (most likely using wired Ethernet),\nwhich in turn is connected to the wired Internet. A wireless LAN user must\ntypically be within a few tens of meters of the access point. Wireless LAN\naccess based on IEEE 802.11 technology, more colloquially known as WiFi,\nis now just about everywhere—universities, business offices, cafes, airports,\nhomes, and even in airplanes. As discussed in detail in Chapter 7, 802.11\ntoday provides a shared transmission rate of up to more than 100 Mbps."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 72,
    "text": "Even though Ethernet and WiFi access networks were initially\ndeployed in enterprise (corporate, university) settings, they are also\ncommon components of home networks. Many homes combine broadband\nresidential access (that is, cable modems or DSL) with these inexpensive\nwireless LAN technologies to create powerful home networks Figure 1.9\nshows a typical home network. This home network consists of a roaming\nlaptop, multiple Internet-connected home appliances, as well as a wired PC;\na base station (the wireless access point), which communicates with the\nwireless PC and other wireless devices in the home; and a home router that\nconnects the wireless access point, and any other wired home devices, to\nthe Internet. This network allows household members to have broadband\naccess to the Internet with one member roaming from the kitchen to the\nbackyard to the bedrooms. Figure 1.9 ♦A typical home network\nWide-Area Wireless Access: 3G and LTE 4G and 5G\nMobile devices such as iPhones and Android devices are being used to\nmessage, share photos in social networks, make mobile payments, watch\nmovies, stream music, and much more while on the run. These devices"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 73,
    "text": "employ the same wireless infrastructure used for cellular telephony to\nsend/receive packets through a base station that is operated by the cellular\nnetwork provider. Unlike WiFi, a user need only be within a few tens of\nkilometers (as opposed to a few tens of meters) of the base station. Telecommunications companies have made enormous investments in\nso-called fourth-generation (4G) wireless, which provides real-world\ndownload speeds of up to 60 Mbps. But even higher-speed wide-area access\ntechnologies—a fifth-generation (5G) of wide-area wireless networks—are\nalready being deployed. We’ll cover the basic principles of wireless\nnetworks and mobility, as well as WiFi, 4G and 5G technologies (and\nmore!) in Chapter 7. 1.2.2 Physical Media\nIn the previous subsection, we gave an overview of some of the most\nimportant network access technologies in the Internet. As we described\nthese technologies, we also indicated the physical media used. For example,\nwe said that HFC uses a combination of fiber cable and coaxial cable. We\nsaid that DSL and Ethernet use copper wire. And we said that mobile access\nnetworks use the radio spectrum. In this subsection, we provide a brief\noverview of these and other transmission media that are commonly used in\nthe Internet. In order to define what is meant by a physical medium, let us reflect on\nthe brief life of a bit. Consider a bit traveling from one end system, through\na series of links and routers, to another end system. This poor bit gets\nkicked around and transmitted many, many times! The source end system\nfirst transmits the bit, and shortly thereafter the first router in the series\nreceives the bit; the first router then transmits the bit, and shortly thereafter"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 74,
    "text": "the second router receives the bit; and so on. Thus our bit, when traveling\nfrom source to destination, passes through a series of transmitter-receiver\npairs. For each transmitter-receiver pair, the bit is sent by propagating\nelectromagnetic waves or optical pulses across a physical medium. The\nphysical medium can take many shapes and forms and does not have to be\nof the same type for each transmitter-receiver pair along the path. Examples\nof physical media include twisted-pair copper wire, coaxial cable,\nmultimode fiber-optic cable, terrestrial radio spectrum, and satellite radio\nspectrum. Physical media fall into two categories: guided media and\nunguided media. With guided media, the waves are guided along a solid\nmedium, such as a fiber-optic cable, a twisted-pair copper wire, or a coaxial\ncable. With unguided media, the waves propagate in the atmosphere and in\nouter space, such as in a wireless LAN or a digital satellite channel. But before we get into the characteristics of the various media types, let\nus say a few words about their costs. The actual cost of the physical link\n(copper wire, fiber-optic cable, and so on) is often relatively minor\ncompared with other networking costs. In particular, the labor cost\nassociated with the installation of the physical link can be orders of\nmagnitude higher than the cost of the material. For this reason, many\nbuilders install twisted pair, optical fiber, and coaxial cable in every room in\na building. Even if only one medium is initially used, there is a good chance\nthat another medium could be used in the near future, and so money is\nsaved by not having to lay additional wires in the future. Twisted-Pair Copper Wire\nThe least expensive and most commonly used guided transmission medium\nis twisted-pair copper wire. For over a hundred years it has been used by\ntelephone networks. In fact, more than 99 percent of the wired connections"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 75,
    "text": "from the telephone handset to the local telephone switch use twisted-pair\ncopper wire. Most of us have seen twisted pair in our homes (or those of\nour parents or grandparents!) and work environments. Twisted pair consists\nof two insulated copper wires, each about 1 mm thick, arranged in a regular\nspiral pattern. The wires are twisted together to reduce the electrical\ninterference from similar pairs close by. Typically, a number of pairs are\nbundled together in a cable by wrapping the pairs in a protective shield. A\nwire pair constitutes a single communication link. Unshielded twisted pair\n(UTP) is commonly used for computer networks within a building, that is,\nfor LANs. Data rates for LANs using twisted pair today range from 10\nMbps to 10 Gbps. The data rates that can be achieved depend on the\nthickness of the wire and the distance between transmitter and receiver. When fiber-optic technology emerged in the 1980s, many people\ndisparaged twisted pair because of its relatively low bit rates. Some people\neven felt that fiber-optic technology would completely replace twisted pair. But twisted pair did not give up so easily. Modern twisted-pair technology,\nsuch as category 6a cable, can achieve data rates of 10 Gbps for distances\nup to a hundred meters. In the end, twisted pair has emerged as the\ndominant solution for high-speed LAN networking. As discussed earlier, twisted pair is also commonly used for residential\nInternet access. We saw that dial-up modem technology enables access at\nrates of up to 56  kbps over twisted pair. We also saw that DSL (digital\nsubscriber line) technology has enabled residential users to access the\nInternet at tens of Mbps over twisted pair (when users live close to the ISP’s\ncentral office). Coaxial Cable"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 51",
    "source": "kurose",
    "page": 76,
    "text": "Like twisted pair, coaxial cable consists of two copper conductors, but the\ntwo conductors are concentric rather than parallel. With this construction\nand special insulation and shielding, coaxial cable can achieve high data\ntransmission rates. Coaxial cable is quite common in cable television\nsystems. As we saw earlier, cable television systems have recently been\ncoupled with cable modems to provide residential users with Internet access\nat rates of hundreds of Mbps. In cable television and cable Internet access,\nthe transmitter shifts the digital signal to a specific frequency band, and the\nresulting analog signal is sent from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically, a\nnumber of end systems can be connected directly to the cable, with each of\nthe end systems receiving whatever is sent by the other end systems. Fiber Optics\nAn optical fiber is a thin, flexible medium that conducts pulses of light,\nwith each pulse representing a bit. A single optical fiber can support\ntremendous bit rates, up to tens or even hundreds of gigabits per second. They are immune to electromagnetic interference, have very low signal\nattenuation up to 100 kilometers, and are very hard to tap. These\ncharacteristics have made fiber optics the preferred long-haul guided\ntransmission media, particularly for overseas links. Many of the long-\ndistance telephone networks in the United States and elsewhere now use\nfiber optics exclusively. Fiber optics is also prevalent in the backbone of the\nInternet. However, the high cost of optical devices—such as transmitters,\nreceivers, and switches—has hindered their deployment for short-haul\ntransport, such as in a LAN or into the home in a residential access\nnetwork. The Optical Carrier (OC) standard link speeds range from\n51.8 Mbps to 39.8 Gbps; these specifications are often referred to as OC-n,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 77,
    "text": "where the link speed equals n × 51.8 Mbps. Standards in use today include\nOC-1, OC-3, OC-12, OC-24, OC-48, OC-96, OC-192, OC-768. Terrestrial Radio Channels\nRadio channels carry signals in the electromagnetic spectrum. They are an\nattractive medium because they require no physical wire to be installed, can\npenetrate walls, provide connectivity to a mobile user, and can potentially\ncarry a signal for long distances. The characteristics of a radio channel\ndepend significantly on the propagation environment and the distance over\nwhich a signal is to be carried. Environmental considerations determine\npath loss and shadow fading (which decrease the signal strength as the\nsignal travels over a distance and around/through obstructing objects),\nmultipath fading (due to signal reflection off of interfering objects), and\ninterference (due to other transmissions and electromagnetic signals). Terrestrial radio channels can be broadly classified into three groups:\nthose that operate over very short distance (e.g., with one or two meters);\nthose that operate in local areas, typically spanning from ten to a few\nhundred meters; and those that operate in the wide area, spanning tens of\nkilometers. Personal devices such as wireless headsets, keyboards, and\nmedical devices operate over short distances; the wireless LAN\ntechnologies described in Section 1.2.1 use local-area radio channels; the\ncellular access technologies use wide-area radio channels. We’ll discuss\nradio channels in detail in Chapter 7. Satellite Radio Channels\nA communication satellite links two or more Earth-based microwave\ntransmitter/receivers, known as ground stations. The satellite receives\ntransmissions on one frequency band, regenerates the signal using a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 78,
    "text": "repeater (discussed below), and transmits the signal on another frequency. Two types of satellites are used in  communications: geostationary\nsatellites and low-earth orbiting (LEO) satellites. Geostationary satellites permanently remain above the same spot on\nEarth. This stationary presence is achieved by placing the satellite in orbit at\n36,000 kilo­meters above Earth’s surface. This huge distance from ground\nstation through satellite back to ground station introduces a substantial\nsignal propagation delay of 280 milliseconds. Nevertheless, satellite links,\nwhich can operate at speeds of hundreds of Mbps, are often used in areas\nwithout access to DSL or cable-based Internet access. LEO satellites are placed much closer to Earth and do not remain\npermanently above one spot on Earth. They rotate around Earth (just as the\nMoon does) and may communicate with each other, as well as with ground\nstations. To provide continuous coverage to an area, many satellites need to\nbe placed in orbit. There are currently many low-altitude communication\nsystems in development. LEO satellite ­technology may be used for Internet\naccess sometime in the future."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 79,
    "text": "1.3 The Network Core\nHaving examined the Internet’s edge, let us now delve more deeply inside\nthe network core—the mesh of packet switches and links that interconnects\nthe Internet’s end systems. Figure 1.10 highlights the network core with\nthick, shaded lines."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 80,
    "text": "Figure 1.10 ♦The network core\n1.3.1 Packet Switching"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 81,
    "text": "In a network application, end systems exchange messages with each other. Messages can contain anything the application designer wants. Messages\nmay perform a control function (for example, the “Hi” messages in our\nhandshaking example in Figure 1.2) or can contain data, such as an e-mail\nmessage, a JPEG image, or an MP3 audio file. To send a message from a\nsource end system to a destination end system, the source breaks long\nmessages into smaller chunks of data known as packets. Between source\nand destination, each packet travels through communication links and\npacket switches (for which there are two predominant types, routers and\nlink-layer switches). Packets are transmitted over each communication link\nat a rate equal to the full transmission rate of the link. So, if a source end\nsystem or a packet switch is sending a packet of L bits over a link with\ntransmission rate R bits/sec, then the time to transmit the packet is L / R\nseconds. Store-and-Forward Transmission\nMost packet switches use store-and-forward transmission at the inputs to\nthe links. Store-and-forward transmission means that the packet switch\nmust receive the entire packet before it can begin to transmit the first bit of\nthe packet onto the outbound link. To explore store-and-forward\ntransmission in more detail, consider a simple network consisting of two\nend systems connected by a single router, as shown in Figure 1.11. A router\nwill typically have many incident links, since its job is to switch an\nincoming packet onto an outgoing link; in this simple example, the router\nhas the rather simple task of transferring a packet from one (input) link to\nthe only other attached link. In this example, the source has three packets,\neach consisting of L bits, to send to the destination. At the snapshot of time\nshown in Figure 1.11, the source has transmitted some of packet 1, and the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 82,
    "text": "front of packet 1 has already arrived at the router. Because the router\nemploys store-and-forwarding, at this instant of time, the router cannot\ntransmit the bits it has received; instead it must first buffer (i.e., “store”) the\npacket’s bits. Only after the router has received all of the packet’s bits can it\nbegin to transmit (i.e., “forward”) the packet onto the outbound link. To\ngain some insight into store-and-forward transmission, let’s now calculate\nthe amount of time that elapses from when the source begins to send the\npacket until the destination has received the entire packet. (Here we will\nignore propagation delay—the time it takes for the bits to travel across the\nwire at near the speed of light—which will be discussed in Section 1.4.) The source begins to transmit at time 0; at time L/R seconds, the source has\ntransmitted the entire packet, and the entire packet has been received and\nstored at the router (since there is no propagation delay). At time L/R\nseconds, since the router has just received the entire packet, it can begin to\ntransmit the packet onto the outbound link towards the destination; at time\n2L/R, the router has transmitted the entire packet, and the entire packet has\nbeen received by the destination. Thus, the total delay is 2L/R. If the switch\ninstead forwarded bits as soon as they arrive (without first receiving the\nentire packet), then the total delay would be L/R since bits are not held up at\nthe router. But, as we will discuss in Section 1.4, routers need to receive,\nstore, and process the entire packet before forwarding."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 83,
    "text": "Figure 1.11 ♦Store-and-forward packet switching\nNow let’s calculate the amount of time that elapses from when the\nsource begins to send the first packet until the destination has received all\nthree packets. As before, at time L/R, the router begins to forward the first\npacket. But also at time L/R the source will begin to send the second packet,\nsince it has just finished sending the entire first packet. Thus, at time 2L/R,\nthe destination has received the first packet and the router has received the\nsecond packet. Similarly, at time 3L/R, the destination has received the first\ntwo packets and the router has received the third packet. Finally, at time\n4L/R the destination has received all three packets! Let’s now consider the general case of sending one packet from source\nto destination over a path consisting of N links each of rate R (thus, there\nare N-1 routers between source and destination). Applying the same logic as\nabove, we see that the end-to-end delay is:\nYou may now want to try to determine what the delay would be for P\npackets sent over a series of N links. Queuing Delays and Packet Loss\nEach packet switch has multiple links attached to it. For each attached link,\nthe packet switch has an output buffer (also called an output queue),\nwhich stores packets that the router is about to send into that link. The\noutput buffers play a key role in packet switching. If an arriving packet\nneeds to be transmitted onto a link but finds the link busy with the\ntransmission of another packet, the arriving packet must wait in the output\nbuffer. Thus, in addition to the store-and-forward delays, packets suffer\ndend-to-end = N L\nR\n(1.1)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 84,
    "text": "output buffer queuing delays. These delays are variable and depend on the\nlevel of congestion in the network. Since the amount of buffer space is\nfinite, an arriving packet may find that the buffer is completely full with\nother packets waiting for transmission. In this case, packet loss will occur\n—either the arriving packet or one of the already-queued packets will be\ndropped. Figure 1.12 illustrates a simple packet-switched network. As in Figure\n1.11, packets are represented by three-dimensional slabs. The width of a\nslab represents the number of bits in the packet. In this figure, all packets\nhave the same width and hence the same length. Suppose Hosts A and B are\nsending packets to Host E. Hosts A and B first send their packets along 100\nMbps Ethernet links to the first router. The router then directs these packets\nto the 15 Mbps link. If, during a short interval of time, the arrival rate of\npackets to the router (when converted to bits per second) exceeds 15 Mbps,\ncongestion will occur at the router as packets queue in the link’s output\nbuffer before being transmitted onto the link. For example, if Host A and B\neach send a burst of five packets back-to-back at the same time, then most\nof these packets will spend some time waiting in the queue. The situation is,\nin fact, entirely analogous to many common-day situations—for example,\nwhen we wait in line for a bank teller or wait in front of a tollbooth. We’ll\nexamine this queuing delay in more detail in Section 1.4."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 85,
    "text": "Figure 1.12 ♦Packet switching\nForwarding Tables and Routing Protocols\nEarlier, we said that a router takes a packet arriving on one of its attached\ncommunication links and forwards that packet onto another one of its\nattached communication links. But how does the router determine which\nlink it should forward the packet onto? Packet forwarding is actually done\nin different ways in different types of computer networks. Here, we briefly\ndescribe how it is done in the Internet. In the Internet, every end system has an address called an IP address. When a source end system wants to send a packet to a destination end\nsystem, the source includes the destination’s IP address in the packet’s\nheader. As with postal addresses, this address has a hierarchical structure. When a packet arrives at a router in the network, the router examines a"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 86,
    "text": "portion of the packet’s destination address and forwards the packet to an\nadjacent router. More specifically, each router has a forwarding table that\nmaps destination addresses (or portions of the destination addresses) to that\nrouter’s outbound links. When a packet arrives at a router, the router\nexamines the address and searches its forwarding table, using this\ndestination address, to find the appropriate outbound link. The router then\ndirects the packet to this outbound link. The end-to-end routing process is analogous to a car driver who does\nnot use maps but instead prefers to ask for directions. For example, suppose\nJoe is driving from Philadelphia to 156 Lakeside Drive in Orlando, Florida. Joe first drives to his neighborhood gas station and asks how to get to 156\nLakeside Drive in Orlando, Florida. The gas station attendant extracts the\nFlorida portion of the address and tells Joe that he needs to get onto the\ninterstate highway I-95 South, which has an entrance just next to the gas\nstation. He also tells Joe that once he enters Florida, he should ask someone\nelse there. Joe then takes I-95 South until he gets to Jacksonville, Florida, at\nwhich point he asks another gas station attendant for directions. The\nattendant extracts the Orlando portion of the address and tells Joe that he\nshould continue on I-95 to Daytona Beach and then ask someone else. In\nDaytona Beach, another gas station attendant also extracts the Orlando\nportion of the address and tells Joe that he should take I-4 directly to\nOrlando. Joe takes I-4 and gets off at the Orlando exit. Joe goes to another\ngas station attendant, and this time the attendant extracts the Lakeside Drive\nportion of the address and tells Joe the road he must follow to get to\nLakeside Drive. Once Joe reaches Lakeside Drive, he asks a kid on a\nbicycle how to get to his destination. The kid extracts the 156 portion of the\naddress and points to the house. Joe finally reaches his ultimate destination."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 87,
    "text": "In the above analogy, the gas station attendants and kids on bicycles are\nanalogous to routers. We just learned that a router uses a packet’s destination address to\nindex a forwarding table and determine the appropriate outbound link. But\nthis statement begs yet another question: How do forwarding tables get set? Are they configured by hand in each and every router, or does the Internet\nuse a more automated procedure? This issue will be studied in depth in\nChapter 5. But to whet your appetite here, we’ll note now that the Internet\nhas a number of special routing protocols that are used to automatically set\nthe forwarding tables. A routing protocol may, for example, determine the\nshortest path from each router to each destination and use the shortest path\nresults to configure the forwarding tables in the routers. 1.3.2 Circuit Switching\nThere are two fundamental approaches to moving data through a network of\nlinks and switches: circuit switching and packet switching. Having\ncovered packet-switched networks in the previous subsection, we now turn\nour attention to circuit-switched networks. In circuit-switched networks, the resources needed along a path\n(buffers, link transmission rate) to provide for communication between the\nend systems are reserved for the duration of the communication session\nbetween the end systems. In packet-switched networks, these resources are\nnot reserved; a session’s messages use the resources on demand and, as a\nconsequence, may have to wait (that is, queue) for access to a\ncommunication link. As a simple analogy, consider two restaurants, one that\nrequires reservations and another that neither requires reservations nor\naccepts them. For the restaurant that requires reservations, we have to go"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 88,
    "text": "through the hassle of calling before we leave home. But when we arrive at\nthe restaurant we can, in principle, immediately be seated and order our\nmeal. For the restaurant that does not require reservations, we don’t need to\nbother to reserve a table. But when we arrive at the restaurant, we may have\nto wait for a table before we can be seated. Traditional telephone networks are examples of circuit-switched\nnetworks. ­Consider what happens when one person wants to send\ninformation (voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a\nconnection between the sender and the receiver. This is a bona fide\nconnection for which the switches on the path between the sender and\nreceiver maintain connection state for that connection. In the jargon of\ntelephony, this connection is called a circuit. When the network establishes\nthe circuit, it also reserves a constant transmission rate in the network’s\nlinks (representing a fraction of each link’s transmission capacity) for the\nduration of the connection. Since a given transmission rate has been\nreserved for this sender-to-receiver connection, the sender can transfer the\ndata to the receiver at the guaranteed constant rate. Figure 1.13 illustrates a circuit-switched network. In this network, the\nfour circuit switches are interconnected by four links. Each of these links\nhas four circuits, so that each link can support four simultaneous\nconnections. The hosts (for example, PCs and workstations) are each\ndirectly connected to one of the switches. When two hosts want to\ncommunicate, the network establishes a dedicated end-to-end connection\nbetween the two hosts. Thus, in order for Host A to communicate with Host\nB, the network must first reserve one circuit on each of two links. In this\nexample, the dedicated end-to-end connection uses the second circuit in the\nfirst link and the fourth circuit in the second link. Because each link has"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 89,
    "text": "four circuits, for each link used by the end-to-end connection, the\nconnection gets one fourth of the link’s total transmission capacity for the\nduration of the connection. Thus, for example, if each link between adjacent\nswitches has a transmission rate of 1 Mbps, then each end-to-end circuit-\nswitch connection gets 250 kbps of dedicated transmission rate. Figure 1.13 ♦A simple circuit-switched network consisting of four\nswitches and four links\nIn contrast, consider what happens when one host wants to send a\npacket to another host over a packet-switched network, such as the Internet. As with circuit switching, the packet is transmitted over a series of\ncommunication links. But different from circuit switching, the packet is sent\ninto the network without reserving any link resources whatsoever. If one of\nthe links is congested because other packets need to be transmitted over the\nlink at the same time, then the packet will have to wait in a buffer at the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 90,
    "text": "sending side of the transmission link and suffer a delay. The Internet makes\nits best effort to deliver packets in a timely manner, but it does not make\nany guarantees. Multiplexing in Circuit-Switched Networks\nA circuit in a link is implemented with either frequency-division\nmultiplexing (FDM) or time-division multiplexing (TDM). With FDM,\nthe frequency spectrum of a link is divided up among the connections\nestablished across the link. Specifically, the link dedicates a frequency band\nto each connection for the ­duration of the connection. In telephone\nnetworks, this frequency band typically has a width of 4 kHz (that is, 4,000\nhertz or 4,000 cycles per second). The width of the band is called, not\nsurprisingly, the bandwidth. FM radio stations also use FDM to share the\nfrequency spectrum between 88 MHz and 108 MHz, with each station\nbeing allocated a specific frequency band. For a TDM link, time is divided into frames of fixed duration, and each\nframe is divided into a fixed number of time slots. When the network\nestablishes a connection across a link, the network dedicates one time slot\nin every frame to this connection. These slots are dedicated for the sole use\nof that connection, with one time slot available for use (in every frame) to\ntransmit the connection’s data. Figure 1.14 illustrates FDM and TDM for a specific network link\nsupporting up to four circuits. For FDM, the frequency domain is\nsegmented into four bands, each of bandwidth 4 kHz. For TDM, the time\ndomain is segmented into frames, with four time slots in each frame; each\ncircuit is assigned the same dedicated slot in the revolving TDM frames. For TDM, the transmission rate of a circuit is equal to the frame rate\nmultiplied by the number of bits in a slot. For example, if the link transmits"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 91,
    "text": "8,000 frames per second and each slot consists of 8 bits, then the\ntransmission rate of each circuit is 64 kbps. Figure 1.14 ♦With FDM, each circuit continuously gets a fraction of\nthe bandwidth. With TDM, each circuit gets all of the\nbandwidth periodically during brief intervals of time\n(that is, during slots)\nProponents of packet switching have always argued that circuit\nswitching is wasteful because the dedicated circuits are idle during silent\nperiods. For example, when one person in a telephone call stops talking,\nthe idle network resources (frequency bands or time slots in the links along\nthe connection’s route) cannot be used by other ongoing connections. As"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 92,
    "text": "another example of how these resources can be underutilized, consider a\nradiologist who uses a circuit-switched network to remotely access a series\nof x-rays. The radiologist sets up a connection, requests an image,\ncontemplates the image, and then requests a new image. Network resources\nare allocated to the connection but are not used (i.e., are wasted) during the\nradiologist’s contemplation periods. Proponents of packet switching also\nenjoy pointing out that establishing end-to-end circuits and reserving end-\nto-end transmission capacity is complicated and requires complex signaling\nsoftware to coordinate the operation of the switches along the end-to-end\npath. Before we finish our discussion of circuit switching, let’s work through\na numerical example that should shed further insight on the topic. Let us\nconsider how long it takes to send a file of 640,000 bits from Host A to Host\nB over a circuit-switched network. Suppose that all links in the network use\nTDM with 24 slots and have a bit rate of 1.536 Mbps. Also suppose that it\ntakes 500 msec to establish an end-to-end circuit before Host A can begin to\ntransmit the file. How long does it take to send the file? Each circuit has a\ntransmission rate of (1.536 Mbps)/24 = 64 kbps, so it takes (640,000\nbits)/(64 kbps) = 10 seconds to transmit the file. To this 10 seconds we add\nthe circuit establishment time, giving 10.5 seconds to send the file. Note\nthat the transmission time is independent of the number of links: The\ntransmission time would be 10 seconds if the end-to-end circuit passed\nthrough one link or a hundred links. (The actual end-to-end delay also\nincludes a propagation delay; see Section 1.4.) Packet Switching Versus Circuit Switching\nHaving described circuit switching and packet switching, let us compare the\ntwo. Critics of packet switching have often argued that packet switching is"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 93,
    "text": "not suitable for real-time services (for example, telephone calls and video\nconference calls) because of its variable and unpredictable end-to-end\ndelays (due primarily to variable and unpredictable queuing delays). Proponents of packet switching argue that (1) it offers better sharing of\ntransmission capacity than circuit switching and (2) it is simpler, more\nefficient, and less costly to implement than circuit switching. An interesting\ndiscussion of packet switching versus circuit switching is [Molinero-\nFernandez 2002]. Generally speaking, people who do not like to hassle with\n­restaurant reservations prefer packet switching to circuit switching. Why is packet switching more efficient? Let’s look at a simple\nexample. Suppose users share a 1 Mbps link. Also suppose that each user\nalternates between periods of activity, when a user generates data at a\nconstant rate of 100 kbps, and periods of inactivity, when a user generates\nno data. Suppose further that a user is active only 10 percent of the time\n(and is idly drinking coffee during the remaining 90 percent of the time). With circuit switching, 100 kbps must be reserved for each user at all times. For example, with circuit-switched TDM, if a one-second frame is divided\ninto 10 time slots of 100 ms each, then each user would be allocated one\ntime slot per frame. Thus, the circuit-switched link can support only 10 ( = 1 Mbps/100\nkbps) simultaneous users. With packet switching, the probability that a\nspecific user is active is 0.1 (that is, 10 percent). If there are 35 users, the\nprobability that there are 11 or more simultaneously active users is\napproximately 0.0004. (Homework Problem P8 outlines how this\nprobability is obtained.) When there are 10 or fewer simultaneously active\nusers (which happens with probability 0.9996), the aggregate arrival rate of\ndata is less than or equal to 1 Mbps, the output rate of the link. Thus, when\nthere are 10 or fewer active users, users’ packets flow through the link"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 94,
    "text": "essentially without delay, as is the case with circuit switching. When there\nare more than 10 simultaneously active users, then the aggregate arrival rate\nof packets exceeds the output capacity of the link, and the output queue will\nbegin to grow. (It continues to grow until the aggregate input rate falls back\nbelow 1 Mbps, at which point the queue will begin to diminish in length.) Because the probability of having more than 10 simultaneously active users\nis minuscule in this example, packet switching provides essentially the\nsame performance as circuit switching, but does so while allowing for more\nthan three times the number of users. Let’s now consider a second simple example. Suppose there are 10\nusers and that one user suddenly generates one thousand 1,000-bit packets,\nwhile other users remain quiescent and do not generate packets. Under\nTDM circuit switching with 10 slots per frame and each slot consisting of\n1,000 bits, the active user can only use its one time slot per frame to\ntransmit data, while the remaining nine time slots in each frame remain idle. It will be 10 seconds before all of the active user’s one million bits of data\nhas been transmitted. In the case of packet switching, the active user can\ncontinuously send its packets at the full link rate of 1 Mbps, since there are\nno other users generating packets that need to be multiplexed with the\nactive user’s packets. In this case, all of the active user’s data will be\ntransmitted within 1 second. The above examples illustrate two ways in which the performance of\npacket switching can be superior to that of circuit switching. They also\nhighlight the crucial difference between the two forms of sharing a link’s\ntransmission rate among multiple data streams. Circuit switching pre-\nallocates use of the transmission link regardless of demand, with allocated\nbut unneeded link time going unused. Packet switching on the other hand\nallocates link use on demand. Link transmission capacity will be shared on"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 95,
    "text": "a packet-by-packet basis only among those users who have packets that\nneed to be transmitted over the link. Although packet switching and circuit switching are both prevalent in\ntoday’s telecommunication networks, the trend has certainly been in the\ndirection of packet switching. Even many of today’s circuit-switched\ntelephone networks are slowly migrating toward packet switching. In\nparticular, telephone networks often use packet switching for the expensive\noverseas portion of a telephone call. 1.3.3 A Network of Networks\nWe saw earlier that end systems (PCs, smartphones, Web servers, mail\nservers, and so on) connect into the Internet via an access ISP. The access\nISP can provide either wired or wireless connectivity, using an array of\naccess technologies including DSL, cable, FTTH, Wi-Fi, and cellular. Note\nthat the access ISP does not have to be a telco or a cable company; instead it\ncan be, for example, a university (providing Internet access to students,\nstaff, and faculty), or a company (providing access for its employees). But\nconnecting end users and content providers into an access ISP is only a\nsmall piece of solving the puzzle of connecting the billions of end systems\nthat make up the Internet. To complete this puzzle, the access ISPs\nthemselves must be interconnected. This is done by creating a network of\nnetworks—understanding this phrase is the key to understanding the\nInternet. Over the years, the network of networks that forms the Internet has\nevolved into a very complex structure. Much of this evolution is driven by\neconomics and national policy, rather than by performance considerations. In order to understand today’s Internet network structure, let’s"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 96,
    "text": "incrementally build a series of network structures, with each new structure\nbeing a better approximation of the complex Internet that we have today. Recall that the overarching goal is to interconnect the access ISPs so that all\nend systems can send packets to each other. One naive approach would be\nto have each access ISP directly connect with every other access ISP. Such a\nmesh design is, of course, much too costly for the access ISPs, as it would\nrequire each access ISP to have a separate communication link to each of\nthe hundreds of thousands of other access ISPs all over the world. Our first network structure, Network Structure 1, interconnects all of\nthe access ISPs with a single global transit ISP. Our (imaginary) global\ntransit ISP is a network of routers and communication links that not only\nspans the globe, but also has at least one router near each of the hundreds of\nthousands of access ISPs. Of course, it would be very costly for the global\nISP to build such an extensive network. To be profitable, it would naturally\ncharge each of the access ISPs for connectivity, with the pricing reflecting\n(but not necessarily directly proportional to) the amount of traffic an access\nISP exchanges with the global ISP. Since the access ISP pays the global\ntransit ISP, the access ISP is said to be a customer and the global transit ISP\nis said to be a provider. Now if some company builds and operates a global transit ISP that is\nprofitable, then it is natural for other companies to build their own global\ntransit ISPs and compete with the original global transit ISP. This leads to\nNetwork Structure 2, which consists of the hundreds of thousands of access\nISPs and multiple global ­transit ISPs. The access ISPs certainly prefer\nNetwork Structure 2 over Network Structure 1 since they can now choose\namong the competing global transit providers as a function of their pricing\nand services. Note, however, that the global transit ISPs themselves must\ninterconnect: Otherwise access ISPs connected to one of the global transit"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 97,
    "text": "providers would not be able to communicate with access ISPs connected to\nthe other global transit providers. Network Structure 2, just described, is a two-tier hierarchy with global\ntransit providers residing at the top tier and access ISPs at the bottom tier. This assumes that global transit ISPs are not only capable of getting close to\neach and every access ISP, but also find it economically desirable to do so. In reality, although some ISPs do have impressive global coverage and do\ndirectly connect with many access ISPs, no ISP has presence in each and\nevery city in the world. Instead, in any given region, there may be a\nregional ISP to which the access ISPs in the region connect. Each regional\nISP then connects to tier-1 ISPs. Tier-1 ISPs are similar to our (imaginary)\nglobal transit ISP; but tier-1 ISPs, which actually do exist, do not have a\npresence in every city in the world. There are approximately a dozen tier-1\nISPs, including Level 3 Communications, AT&T, Sprint, and NTT. Interestingly, no group officially sanctions tier-1 status; as the saying goes\n—if you have to ask if you’re a member of a group, you’re probably not. Returning to this network of networks, not only are there multiple\ncompeting tier-1 ISPs, there may be multiple competing regional ISPs in a\nregion. In such a hierarchy, each access ISP pays the regional ISP to which\nit connects, and each regional ISP pays the tier-1 ISP to which it connects. (An access ISP can also connect directly to a tier-1 ISP, in which case it\npays the tier-1 ISP). Thus, there is customer-provider relationship at each\nlevel of the hierarchy. Note that the tier-1 ISPs do not pay anyone as they\nare at the top of the hierarchy. To further complicate matters, in some\nregions, there may be a larger regional ISP (possibly spanning an entire\ncountry) to which the smaller regional ISPs in that region connect; the\nlarger regional ISP then connects to a tier-1 ISP. For example, in China,\nthere are access ISPs in each city, which connect to provincial ISPs, which"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 98,
    "text": "in turn connect to national ISPs, which finally connect to tier-1 ISPs [Tian\n2012]. We refer to this multi-tier hierarchy, which is still only a crude\napproximation of today’s Internet, as Network Structure 3. To build a network that more closely resembles today’s Internet, we\nmust add points of presence (PoPs), multi-homing, peering, and Internet\nexchange points (IXPs) to the hierarchical Network Structure 3. PoPs exist\nin all levels of the hierarchy, except for the bottom (access ISP) level. A\nPoP is simply a group of one or more routers (at the same location) in the\nprovider’s network where customer ISPs can connect into the provider ISP. For a customer network to connect to a provider’s PoP, it can lease a high-\nspeed link from a third-party telecommunications provider to directly\nconnect one of its routers to a router at the PoP. Any ISP (except for tier-1\nISPs) may choose to multi-home, that is, to connect to two or more\nprovider ISPs. So, for example, an access ISP may multi-home with two\nregional ISPs, or it may multi-home with two regional ISPs and also with a\ntier-1 ISP. Similarly, a regional ISP may multi-home with multiple tier-1\nISPs. When an ISP multi-homes, it can continue to send and receive packets\ninto the Internet even if one of its providers has a failure. As we just learned, customer ISPs pay their provider ISPs to obtain\nglobal Internet interconnectivity. The amount that a customer ISP pays a\nprovider ISP reflects the amount of traffic it exchanges with the provider. To reduce these costs, a pair of nearby ISPs at the same level of the\nhierarchy can peer, that is, they can directly connect their networks together\nso that all the traffic between them passes over the direct connection rather\nthan through upstream intermediaries. When two ISPs peer, it is typically\nsettlement-free, that is, neither ISP pays the other. As noted earlier, tier-1\nISPs also peer with one another, settlement-free. For a readable discussion\nof peering and customer-provider relationships, see [Van der Berg 2008]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 99,
    "text": "Along these same lines, a third-party company can create an Internet\nExchange Point (IXP), which is a meeting point where multiple ISPs can\npeer together. An IXP is typically in a stand-alone building with its own\nswitches [Ager 2012]. There are over 600 IXPs in the Internet today\n[PeeringDB 2020]. We refer to this ecosystem—consisting of access ISPs,\nregional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs—as\nNetwork Structure 4. We now finally arrive at Network Structure 5, which describes today’s\nInternet. Network Structure 5, illustrated in Figure 1.15, builds on top of\nNetwork Structure 4 by adding content-provider networks. Google is\ncurrently one of the leading examples of such a content-provider network. As of this writing, it Google has 19 major data centers distributed across\nNorth America, Europe, Asia, South America, and Australia with each data\ncenter having tens or hundreds of thousands of servers. Additionally,\nGoogle has smaller data centers, each with a few hundred servers; these\nsmaller data centers are often located within IXPs. The Google data centers\nare all interconnected via Google’s private TCP/IP network, which spans\nthe entire globe but is nevertheless separate from the public Internet. Importantly, the Google private network only carries traffic to/from Google\nservers. As shown in Figure 1.15, the Google private network attempts to\n“bypass” the upper tiers of the Internet by peering (settlement free) with\nlower-tier ISPs, either by directly connecting with them or by connecting\nwith them at IXPs [Labovitz 2010]. However, because many access ISPs\ncan still only be reached by transiting through tier-1 networks, the Google\nnetwork also connects to tier-1 ISPs, and pays those ISPs for the traffic it\nexchanges with them. By creating its own network, a content provider not\nonly reduces its payments to upper-tier ISPs, but also has greater control of"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 100,
    "text": "how its services are ultimately delivered to end users. Google’s network\ninfrastructure is described in greater detail in Section 2.6. Figure 1.15 ♦Interconnection of ISPs\nIn summary, today’s Internet—a network of networks—is complex,\nconsisting of a dozen or so tier-1 ISPs and hundreds of thousands of lower-\ntier ISPs. The ISPs are diverse in their coverage, with some spanning\nmultiple continents and oceans, and others limited to narrow geographic\nregions. The lower-tier ISPs connect to the higher-tier ISPs, and the higher-\ntier ISPs interconnect with one another. Users and content providers are\ncustomers of lower-tier ISPs, and lower-tier ISPs are customers of higher-\ntier ISPs. In recent years, major content providers have also created their\nown networks and connect directly into lower-tier ISPs where possible."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 101,
    "text": "1.4 Delay, Loss, and Throughput in Packet-Switched Networks\nBack in Section 1.1 we said that the Internet can be viewed as an infrastructure that provides\nservices to distributed applications running on end systems. Ideally, we would like Internet\nservices to be able to move as much data as we want between any two end systems,\ninstantaneously, without any loss of data. Alas, this is a lofty goal, one that is unachievable\nin reality. Instead, computer networks necessarily constrain throughput (the amount of data\nper second that can be transferred) between end systems, introduce delays between end\nsystems, and can actually lose packets. On one hand, it is unfortunate that the physical laws\nof reality introduce delay and loss as well as constrain throughput. On the other hand,\nbecause computer networks have these problems, there are many fascinating issues\nsurrounding how to deal with the problems—more than enough issues to fill a course on\ncomputer networking and to motivate thousands of PhD theses! In this section, we’ll begin\nto examine and quantify delay, loss, and throughput in computer networks. 1.4.1 Overview of Delay in Packet-Switched Networks\nRecall that a packet starts in a host (the source), passes through a series of routers, and ends\nits journey in another host (the destination). As a packet travels from one node (host or\nrouter) to the subsequent node (host or router) along this path, the packet suffers from\nseveral types of delays at each node along the path. The most important of these delays are\nthe nodal processing delay, queuing delay, transmission delay, and propagation delay;\ntogether, these delays accumulate to give a total nodal delay. The performance of many\nInternet applications—such as search, Web browsing, e-mail, maps, instant messaging, and\nvoice-over-IP—are greatly affected by network delays. In order to acquire a deep\nunderstanding of packet switching and computer networks, we must understand the nature\nand importance of these delays. Types of Delay\nLet’s explore these delays in the context of Figure 1.16. As part of its end-to-end route\nbetween source and destination, a packet is sent from the upstream node through router A to\nrouter B. Our goal is to characterize the nodal delay at router A. Note that router A has an\noutbound link leading to router B. This link is preceded by a queue (also known as a buffer)."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 102,
    "text": "When the packet arrives at router A from the upstream node, router A examines the packet’s\nheader to determine the appropriate outbound link for the packet and then directs the packet\nto this link. In this example, the outbound link for the packet is the one that leads to router B. A packet can be transmitted on a link only if there is no other packet currently being\ntransmitted on the link and if there are no other packets preceding it in the queue; if the link\nis ­currently busy or if there are other packets already queued for the link, the newly arriving\npacket will then join the queue. Figure 1.16 ♦The nodal delay at router A\nProcessing Delay\nThe time required to examine the packet’s header and determine where to direct the packet is\npart of the processing delay. The processing delay can also include other factors, such as the\ntime needed to check for bit-level errors in the packet that occurred in transmitting the\npacket’s bits from the upstream node to router A. Processing delays in high-speed routers are\ntypically on the order of microseconds or less. After this nodal processing, the router directs\nthe packet to the queue that precedes the link to router B. (In Chapter 4 we’ll study the\ndetails of how a router operates.) Queuing Delay\nAt the queue, the packet experiences a queuing delay as it waits to be transmitted onto the\nlink. The length of the queuing delay of a specific packet will depend on the number of\nearlier-arriving packets that are queued and waiting for transmission onto the link. If the\nqueue is empty and no other packet is currently being transmitted, then our packet’s queuing\ndelay will be zero. On the other hand, if the traffic is heavy and many other packets are also\nwaiting to be transmitted, the queuing delay will be long. We will see shortly that the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 103,
    "text": "number of packets that an arriving packet might expect to find is a function of the intensity\nand nature of the traffic arriving at the queue. ­Queuing delays can be on the order of\nmicroseconds to milliseconds in practice. Transmission Delay\nAssuming that packets are transmitted in a first-come-first-served manner, as is common in\npacket-switched networks, our packet can be transmitted only after all the packets that have\narrived before it have been transmitted. Denote the length of the packet by L bits, and denote\nthe transmission rate of the link from router A to router B by R bits/sec. For example, for a\n10 Mbps Ethernet link, the rate is R = 10 Mbps; for a 100 Mbps Ethernet link, the rate is R =\n100 Mbps. The transmission delay is L/R. This is the amount of time required to push (that\nis, transmit) all of the packet’s bits into the link. Transmission delays are typically on the\norder of microseconds to milliseconds in practice. Propagation Delay\nOnce a bit is pushed into the link, it needs to propagate to router B. The time required to\npropagate from the beginning of the link to router B is the propagation delay. The bit\npropagates at the propagation speed of the link. The propagation speed depends on the\nphysical medium of the link (that is, fiber optics, twisted-pair copper wire, and so on) and is\nin the range of\n2  ⋅ 108 meters/sec to 3  ⋅ 108 meters/sec\nwhich is equal to, or a little less than, the speed of light. The propagation delay is the\ndistance between two routers divided by the propagation speed. That is, the propagation\ndelay is d/s, where d is the distance between router A and router B and s is the propagation\nspeed of the link. Once the last bit of the packet propagates to node B, it and all the\npreceding bits of the packet are stored in router B. The whole process then continues with\nrouter B now performing the forwarding. In wide-area networks, propagation delays are on\nthe order of milliseconds. Comparing Transmission and Propagation Delay"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 104,
    "text": "VideoNote\nExploring propagation delay and transmission delay\nNewcomers to the field of computer networking sometimes have difficulty understanding\nthe difference between transmission delay and propagation delay. The difference is subtle\nbut important. The transmission delay is the amount of time required for the router to push\nout the packet; it is a function of the packet’s length and the transmission rate of the link, but\nhas nothing to do with the distance between the two routers. The propagation delay, on the\nother hand, is the time it takes a bit to propagate from one router to the next; it is a function\nof the distance between the two routers, but has nothing to do with the packet’s length or the\ntransmission rate of the link. An analogy might clarify the notions of transmission and propagation delay. Consider a\nhighway that has a tollbooth every 100 kilometers, as shown in Figure 1.17. You can think of\nthe highway segments between tollbooths as links and the tollbooths as routers. Suppose that\ncars travel (that is, propagate) on the highway at a rate of 100 km/hour (that is, when a car\nleaves a tollbooth, it instantaneously accelerates to 100 km/hour and maintains that speed\nbetween tollbooths). Suppose next that 10 cars, traveling together as a caravan, follow each\nother in a fixed order. You can think of each car as a bit and the caravan as a packet. Also\nsuppose that each tollbooth services (that is, transmits) a car at a rate of one car per 12\nseconds, and that it is late at night so that the caravan’s cars are the only cars on the highway. Finally, suppose that whenever the first car of the caravan arrives at a tollbooth, it waits at\nthe entrance until the other nine cars have arrived and lined up behind it. (Thus, the entire\ncaravan must be stored at the tollbooth before it can begin to be forwarded.) The time\nrequired for the tollbooth to push the entire caravan onto the highway is (10 cars)/(5\ncars/minute) = 2 minutes. This time is analogous to the transmission delay in a router. The\ntime required for a car to travel from the exit of one tollbooth to the next tollbooth is 100\nkm/(100 km/hour) = 1 hour. This time is analogous to propagation delay. Therefore, the time\nfrom when the caravan is stored in front of a tollbooth until the caravan is stored in front of\nthe next tollbooth is the sum of transmission delay and propagation delay—in this example,\n62 minutes."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 105,
    "text": "Figure 1.17 ♦Caravan analogy\nLet’s explore this analogy a bit more. What would happen if the tollbooth service time\nfor a caravan were greater than the time for a car to travel between tollbooths? For example,\nsuppose now that the cars travel at the rate of 1,000 km/hour and the tollbooth services cars\nat the rate of one car per minute. Then the traveling delay between two tollbooths is 6\nminutes and the time to serve a caravan is 10 minutes. In this case, the first few cars in the\ncaravan will arrive at the second tollbooth before the last cars in the caravan leave the first\ntollbooth. This situation also arises in packet-switched networks—the first bits in a packet\ncan arrive at a router while many of the remaining bits in the packet are still waiting to be\ntransmitted by the preceding router. If a picture speaks a thousand words, then an animation must speak a million words. The\nWeb site for this textbook provides an interactive animation that nicely illustrates and\ncontrasts transmission delay and propagation delay. The reader is highly encouraged to visit\nthat animation. [Smith 2009] also provides a very readable discussion of propagation,\nqueuing, and transmission delays. If we let d\n, d\n, d\n, and d\n denote the processing, queuing, transmission, and\npropagation delays, then the total nodal delay is given by\ndnodal = dproc + dqueue + dtrans + dprop\nThe contribution of these delay components can vary significantly. For example, d\n can be\nnegligible (for example, a couple of microseconds) for a link connecting two routers on the\nsame university campus; however, d\n is hundreds of milliseconds for two routers\ninterconnected by a geostationary satellite link, and can be the dominant term in d\n. Similarly, d\n can range from negligible to significant. Its contribution is typically\nnegligible for transmission rates of 10 Mbps and higher (for example, for LANs); however,\nit can be hundreds of milliseconds for large Internet packets sent over low-speed dial-up\nmodem links. The processing delay, d\n, is often negligible; however, it strongly influences\na router’s maximum throughput, which is the maximum rate at which a router can forward\npackets. 1.4.2 Queuing Delay and Packet Loss\nproc\nqueue\ntrans\nprop\nprop\nprop\nnodal\ntrans\nproc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 106,
    "text": "The most complicated and interesting component of nodal delay is the queuing delay, d\n. In fact, queuing delay is so important and interesting in computer networking that thousands\nof papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975,\nKleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the\nmore curious reader may want to browse through some of the books (or even eventually\nwrite a PhD thesis on the subject!). Unlike the other three delays (namely, d\n, d\n, and\nd\n), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at\nan empty queue at the same time, the first packet transmitted will suffer no queuing delay,\nwhile the last packet transmitted will suffer a relatively large queuing delay (while it waits\nfor the other nine packets to be transmitted). Therefore, when characterizing queuing delay,\none typically uses statistical measures, such as average queuing delay, variance of queuing\ndelay, and the probability that the queuing delay exceeds some specified value. When is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission rate of the\nlink, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or\narrives in bursts. To gain some insight here, let a denote the average rate at which packets\narrive at the queue (a is in units of packets/sec). Recall that R is the transmission rate; that is,\nit is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for\nsimplicity, that all packets consist of L bits. Then the average rate at which bits arrive at the\nqueue is La bits/sec. Finally, assume that the queue is very big, so that it can hold essentially\nan infinite number of bits. The ratio La/R, called the traffic intensity, often plays an\nimportant role in estimating the extent of the queuing delay. If La/R > 1, then the average\nrate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted\nfrom the queue. In this unfortunate situation, the queue will tend to increase without bound\nand the queuing delay will approach infinity! Therefore, one of the golden rules in traffic\nengineering is: Design your system so that the traffic intensity is no greater than 1. Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts the\nqueuing delay. For example, if packets arrive periodically—that is, one packet arrives every\nL/R seconds—then every packet will arrive at an empty queue and there will be no queuing\ndelay."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 106,
    "text": "The most complicated and interesting component of nodal delay is the queuing delay, d\n. In fact, queuing delay is so important and interesting in computer networking that thousands\nof papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975,\nKleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the\nmore curious reader may want to browse through some of the books (or even eventually\nwrite a PhD thesis on the subject!). Unlike the other three delays (namely, d\n, d\n, and\nd\n), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at\nan empty queue at the same time, the first packet transmitted will suffer no queuing delay,\nwhile the last packet transmitted will suffer a relatively large queuing delay (while it waits\nfor the other nine packets to be transmitted). Therefore, when characterizing queuing delay,\none typically uses statistical measures, such as average queuing delay, variance of queuing\ndelay, and the probability that the queuing delay exceeds some specified value. When is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission rate of the\nlink, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or\narrives in bursts. To gain some insight here, let a denote the average rate at which packets\narrive at the queue (a is in units of packets/sec). Recall that R is the transmission rate; that is,\nit is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for\nsimplicity, that all packets consist of L bits. Then the average rate at which bits arrive at the\nqueue is La bits/sec. Finally, assume that the queue is very big, so that it can hold essentially\nan infinite number of bits. The ratio La/R, called the traffic intensity, often plays an\nimportant role in estimating the extent of the queuing delay. If La/R > 1, then the average\nrate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted\nfrom the queue. In this unfortunate situation, the queue will tend to increase without bound\nand the queuing delay will approach infinity! Therefore, one of the golden rules in traffic\nengineering is: Design your system so that the traffic intensity is no greater than 1. Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts the\nqueuing delay. For example, if packets arrive periodically—that is, one packet arrives every\nL/R seconds—then every packet will arrive at an empty queue and there will be no queuing\ndelay. On the other hand, if packets arrive in bursts but periodically, there can be a\nsignificant average queuing delay."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 106,
    "text": "The most complicated and interesting component of nodal delay is the queuing delay, d\n. In fact, queuing delay is so important and interesting in computer networking that thousands\nof papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975,\nKleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the\nmore curious reader may want to browse through some of the books (or even eventually\nwrite a PhD thesis on the subject!). Unlike the other three delays (namely, d\n, d\n, and\nd\n), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at\nan empty queue at the same time, the first packet transmitted will suffer no queuing delay,\nwhile the last packet transmitted will suffer a relatively large queuing delay (while it waits\nfor the other nine packets to be transmitted). Therefore, when characterizing queuing delay,\none typically uses statistical measures, such as average queuing delay, variance of queuing\ndelay, and the probability that the queuing delay exceeds some specified value. When is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission rate of the\nlink, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or\narrives in bursts. To gain some insight here, let a denote the average rate at which packets\narrive at the queue (a is in units of packets/sec). Recall that R is the transmission rate; that is,\nit is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for\nsimplicity, that all packets consist of L bits. Then the average rate at which bits arrive at the\nqueue is La bits/sec. Finally, assume that the queue is very big, so that it can hold essentially\nan infinite number of bits. The ratio La/R, called the traffic intensity, often plays an\nimportant role in estimating the extent of the queuing delay. If La/R > 1, then the average\nrate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted\nfrom the queue. In this unfortunate situation, the queue will tend to increase without bound\nand the queuing delay will approach infinity! Therefore, one of the golden rules in traffic\nengineering is: Design your system so that the traffic intensity is no greater than 1. Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts the\nqueuing delay. For example, if packets arrive periodically—that is, one packet arrives every\nL/R seconds—then every packet will arrive at an empty queue and there will be no queuing\ndelay. On the other hand, if packets arrive in bursts but periodically, there can be a\nsignificant average queuing delay. For example, suppose N packets arrive simultaneously\nevery (L/R)N seconds."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 106,
    "text": "The most complicated and interesting component of nodal delay is the queuing delay, d\n. In fact, queuing delay is so important and interesting in computer networking that thousands\nof papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975,\nKleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the\nmore curious reader may want to browse through some of the books (or even eventually\nwrite a PhD thesis on the subject!). Unlike the other three delays (namely, d\n, d\n, and\nd\n), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at\nan empty queue at the same time, the first packet transmitted will suffer no queuing delay,\nwhile the last packet transmitted will suffer a relatively large queuing delay (while it waits\nfor the other nine packets to be transmitted). Therefore, when characterizing queuing delay,\none typically uses statistical measures, such as average queuing delay, variance of queuing\ndelay, and the probability that the queuing delay exceeds some specified value. When is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission rate of the\nlink, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or\narrives in bursts. To gain some insight here, let a denote the average rate at which packets\narrive at the queue (a is in units of packets/sec). Recall that R is the transmission rate; that is,\nit is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for\nsimplicity, that all packets consist of L bits. Then the average rate at which bits arrive at the\nqueue is La bits/sec. Finally, assume that the queue is very big, so that it can hold essentially\nan infinite number of bits. The ratio La/R, called the traffic intensity, often plays an\nimportant role in estimating the extent of the queuing delay. If La/R > 1, then the average\nrate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted\nfrom the queue. In this unfortunate situation, the queue will tend to increase without bound\nand the queuing delay will approach infinity! Therefore, one of the golden rules in traffic\nengineering is: Design your system so that the traffic intensity is no greater than 1. Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts the\nqueuing delay. For example, if packets arrive periodically—that is, one packet arrives every\nL/R seconds—then every packet will arrive at an empty queue and there will be no queuing\ndelay. On the other hand, if packets arrive in bursts but periodically, there can be a\nsignificant average queuing delay. For example, suppose N packets arrive simultaneously\nevery (L/R)N seconds. Then the first packet transmitted has no queuing delay; the second\npacket transmitted has a queuing delay of L/R seconds; and more generally, the nth packet\nqueue\nproc\ntrans\nprop"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 106,
    "text": "The most complicated and interesting component of nodal delay is the queuing delay, d\n. In fact, queuing delay is so important and interesting in computer networking that thousands\nof papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975,\nKleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the\nmore curious reader may want to browse through some of the books (or even eventually\nwrite a PhD thesis on the subject!). Unlike the other three delays (namely, d\n, d\n, and\nd\n), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at\nan empty queue at the same time, the first packet transmitted will suffer no queuing delay,\nwhile the last packet transmitted will suffer a relatively large queuing delay (while it waits\nfor the other nine packets to be transmitted). Therefore, when characterizing queuing delay,\none typically uses statistical measures, such as average queuing delay, variance of queuing\ndelay, and the probability that the queuing delay exceeds some specified value. When is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission rate of the\nlink, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or\narrives in bursts. To gain some insight here, let a denote the average rate at which packets\narrive at the queue (a is in units of packets/sec). Recall that R is the transmission rate; that is,\nit is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for\nsimplicity, that all packets consist of L bits. Then the average rate at which bits arrive at the\nqueue is La bits/sec. Finally, assume that the queue is very big, so that it can hold essentially\nan infinite number of bits. The ratio La/R, called the traffic intensity, often plays an\nimportant role in estimating the extent of the queuing delay. If La/R > 1, then the average\nrate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted\nfrom the queue. In this unfortunate situation, the queue will tend to increase without bound\nand the queuing delay will approach infinity! Therefore, one of the golden rules in traffic\nengineering is: Design your system so that the traffic intensity is no greater than 1. Now consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts the\nqueuing delay. For example, if packets arrive periodically—that is, one packet arrives every\nL/R seconds—then every packet will arrive at an empty queue and there will be no queuing\ndelay. On the other hand, if packets arrive in bursts but periodically, there can be a\nsignificant average queuing delay. For example, suppose N packets arrive simultaneously\nevery (L/R)N seconds. Then the first packet transmitted has no queuing delay; the second\npacket transmitted has a queuing delay of L/R seconds; and more generally, the nth packet\nqueue\nproc\ntrans\nprop"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 107,
    "text": "transmitted has a queuing delay of (n − 1)L/R We leave it as an exercise for you to calculate\nthe average queuing delay in this example. The two examples of periodic arrivals described above are a bit academic. ­Typically, the\narrival process to a queue is random; that is, the arrivals do not follow any pattern and the\npackets are spaced apart by random amounts of time. In this more realistic case, the quantity\nLa/R is not usually sufficient to fully characterize the queuing delay statistics. Nonetheless,\nit is useful in gaining an intuitive understanding of the extent of the queuing delay. In\nparticular, if the traffic intensity is close to zero, then packet arrivals are few and far between\nand it is unlikely that an arriving packet will find another packet in the queue. Hence, the\naverage queuing delay will be close to zero. On the other hand, when the traffic intensity is\nclose to 1, there will be intervals of time when the arrival rate exceeds the transmission\ncapacity (due to variations in packet arrival rate), and a queue will form during these periods\nof time; when the arrival rate is less than the transmission capacity, the length of the queue\nwill shrink. Nonetheless, as the traffic intensity approaches 1, the average queue length gets\nlarger and larger. The qualitative dependence of average queuing delay on the traffic\nintensity is shown in Figure 1.18. Figure 1.18 ♦Dependence of average queuing delay on traffic intensity"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 108,
    "text": "One important aspect of Figure 1.18 is the fact that as the traffic intensity approaches 1,\nthe average queuing delay increases rapidly. A small percentage increase in the intensity will\nresult in a much larger percentage-wise increase in delay. Perhaps you have experienced this\nphenomenon on the highway. If you regularly drive on a road that is typically congested, the\nfact that the road is typically congested means that its traffic intensity is close to 1. If some\nevent causes an even slightly larger-than-usual amount of traffic, the delays you experience\ncan be huge. To really get a good feel for what queuing delays are about, you are encouraged once\nagain to visit the textbook Web site, which provides an interactive animation for a queue. If\nyou set the packet arrival rate high enough so that the traffic intensity exceeds 1, you will\nsee the queue slowly build up over time. Packet Loss\nIn our discussions above, we have assumed that the queue is capable of holding an infinite\nnumber of packets. In reality a queue preceding a link has finite capacity, although the\nqueuing capacity greatly depends on the router design and cost. Because the queue capacity\nis finite, packet delays do not really approach infinity as the traffic intensity approaches 1. Instead, a packet can arrive to find a full queue. With no place to store such a packet, a\nrouter will drop that packet; that is, the packet will be lost. This overflow at a queue can\nagain be seen in the interactive animation when the traffic intensity is greater than 1. From an end-system viewpoint, a packet loss will look like a packet having been\ntransmitted into the network core but never emerging from the network at the destination. The fraction of lost packets increases as the traffic intensity increases. Therefore,\nperformance at a node is often measured not only in terms of delay, but also in terms of the\nprobability of packet loss. As we’ll discuss in the subsequent chapters, a lost packet may be\nretransmitted on an end-to-end basis in order to ensure that all data are eventually transferred\nfrom source to destination. 1.4.3 End-to-End Delay\nOur discussion up to this point has focused on the nodal delay, that is, the delay at a single\nrouter. Let’s now consider the total delay from source to destination. To get a handle on this\nconcept, suppose there are N − 1 routers between the source host and the destination host. Let’s also suppose for the moment that the network is uncongested (so that queuing delays"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 109,
    "text": "are negligible), the processing delay at each router and at the source host is d\n, the\ntransmission rate out of each router and out of the source host is R bits/sec, and the\npropagation on each link is d\n. The nodal delays accumulate and give an end-to-end delay,\nwhere, once again, d\n = L/R, where L is the packet size. Note that Equation 1.2 is a\ngeneralization of Equation 1.1, which did not take into account processing and propagation\ndelays. We leave it to you to generalize Equation 1.2 to the case of ­heterogeneous delays at\nthe nodes and to the presence of an average queuing delay at each node. Traceroute\nVideoNote\nUsing Traceroute to discover network paths and measure network delay\nTo get a hands-on feel for end-to-end delay in a computer network, we can make use of the\nTraceroute program. Traceroute is a simple program that can run in any Internet host. When\nthe user specifies a destination hostname, the program in the source host sends multiple,\nspecial packets toward that destination. As these packets work their way toward the\ndestination, they pass through a series of routers. When a router receives one of these special\npackets, it sends back to the source a short message that contains the name and address of\nthe router. More specifically, suppose there are N − 1 routers between the source and the\ndestination. Then the source will send N special packets into the network, with each packet\naddressed to the ultimate destination. These N special packets are marked 1 through N, with\nthe first packet marked 1 and the last packet marked N. When the nth router receives the nth\npacket marked n, the router does not forward the packet toward its destination, but instead\nsends a message back to the source. When the destination host receives the Nth packet, it too\nreturns a message back to the source. The source records the time that elapses between when\nit sends a packet and when it receives the corresponding return message; it also records the\nname and address of the router (or the destination host) that returns the message. In this\nmanner, the source can reconstruct the route taken by packets flowing from source to\ndestination, and the source can determine the round-trip delays to all the intervening routers. proc\nprop\ndend-end = N(dproc + dtrans + dprop)\n(1.2)\ntrans"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 110,
    "text": "Traceroute actually repeats the experiment just described three times, so the source actually\nsends 3 • N packets to the destination. RFC 1393 describes Traceroute in detail. Here is an example of the output of the Traceroute program, where the route was being\ntraced from the source host gaia.cs.umass.edu (at the University of ­Massachusetts) to a host\nin the computer science department at the University of Sorbonne in Paris (formerly the\nuniversity was known as UPMC). The output has six columns: the first column is the n value\ndescribed above, that is, the number of the router along the route; the second column is the\nname of the router; the third column is the address of the router (of the form\nxxx.xxx.xxx.xxx); the last three columns are the round-trip delays for three experiments. If\nthe source receives fewer than three messages from any given router (due to packet loss in\nthe network), Traceroute places an asterisk just after the router number and reports fewer\nthan three round-trip times for that router. gw-vlan-2451.cs.umass.edu (128.119.245.1) 1.899 ms 3.266 ms\n3.280 ms\nj-cs-gw-int-10-240.cs.umass.edu (10.119.240.254) 1.296 ms\n1.276 ms 1.245 ms\nn5-rt-1-1-xe-2-1-0.gw.umass.edu (128.119.3.33) 2.237 ms\n2.217 ms 2.187 ms\ncore1-rt-et-5-2-0.gw.umass.edu (128.119.0.9) 0.351 ms 0.392\nms 0.380 ms\nborder1-rt-et-5-0-0.gw.umass.edu (192.80.83.102) 0.345 ms\n0.345 ms 0.344 ms\nnox300gw1-umass-re.nox.org (192.5.89.101) 3.260 ms 0.416 ms\n3.127 ms\nnox300gw1-umass-re.nox.org (192.5.89.101) 3.165 ms 7.326 ms\n7.311 ms\n198.71.45.237 (198.71.45.237) 77.826 ms 77.246 ms 77.744 ms\nrenater-lb1-gw.mx1.par.fr.geant.net (62.40.124.70) 79.357\nms 77.729 79.152 ms\n193.51.180.109 (193.51.180.109) 78.379 ms 79.936 80.042 ms\n* 193.51.180.109 (193.51.180.109) 80.640 ms *\n* 195.221.127.182 (195.221.127.182) 78.408 ms *\n195.221.127.182 (195.221.127.182) 80.686 ms 80.796 ms\n78.434 ms"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 111,
    "text": "4\nr-upmc1.reseau.jussieu.fr (134.157.254.10) 78.399 ms *\n81.353 ms\nIn the trace above, there are 14 routers between the source and the destination. Most of these\nrouters have a name, and all of them have addresses. For example, the name of Router 4 is\ncore1-rt-et-5-2-0.gw.umass.edu and its address is 128.119.0.9. Looking at\nthe data provided for this same router, we see that in the first of the three trials the round-trip\ndelay between the source and the router was 0.351 msec. The round-trip delays for the\nsubsequent two trials were 0.392 and 0.380 msec. These round-trip delays include all of the\ndelays just discussed, including transmission delays, propagation delays, router processing\ndelays, and queuing delay. Because the queuing delay is varying with time, the round-trip delay of packet n sent to\na router n can sometimes be longer than the round-trip delay of packet n+1 sent to router\nn+1. Indeed, we observe this phenomenon in the above example: the delay to Router 12 is\nsmaller than the delay to Router 11! Also note the big increase in the round-trip delay when\ngoing from router 7 to router 8. This is due to a transatlantic fiber-optic link between routers\n7 and 8, giving rise to a relatively large propagation delay. There are a number of free\nsoftware programs that provide a graphical interface to Traceroute; one of our favorites is\nPingPlotter [PingPlotter 2020]. End System, Application, and Other Delays\nIn addition to processing, transmission, and propagation delays, there can be additional\nsignificant delays in the end systems. For example, an end system wanting to transmit a\npacket into a shared medium (e.g., as in a WiFi or cable modem scenario) may purposefully\ndelay its transmission as part of its protocol for sharing the medium with other end systems;\nwe’ll consider such protocols in detail in Chapter 6. Another important delay is media\npacketization delay, which is present in Voice-over-IP (VoIP) applications. In VoIP, the\nsending side must first fill a packet with encoded digitized speech before passing the packet\nto the Internet. This time to fill a packet—called the packetization delay—can be significant\nand can impact the user-perceived quality of a VoIP call. This issue will be further explored\nin a homework problem at the end of this chapter. 1.4.4 Throughput in Computer Networks"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 112,
    "text": "In addition to delay and packet loss, another critical performance measure in computer\nnetworks is end-to-end throughput. To define throughput, consider transferring a large file\nfrom Host A to Host B across a computer network. This transfer might be, for example, a\nlarge video clip from one computer to another. The instantaneous throughput at any instant\nof time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications\ndisplay the instantaneous throughput during downloads in the user interface—perhaps you\nhave observed this before! You might like to try measuring the end-to-end delay and\ndownload throughput between your and servers around the Internet using the speedtest\napplication [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds\nfor Host B to receive all F bits, then the average throughput of the file transfer is F/T\nbits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay\nand an instantaneous throughput consistently above some threshold (for example, over 24\nkbps for some Internet telephony applications and over 256 kbps for some real-time video\napplications). For other applications, including those involving file transfers, delay is not\ncritical, but it is desirable to have the highest possible throughput. To gain further insight into the important concept of throughput, let’s consider a few\nexamples. Figure 1.19(a) shows two end systems, a server and a client, connected by two\ncommunication links and a router. Consider the throughput for a file transfer from the server\nto the client. Let R  denote the rate of the link between the server and the router; and R\ndenote the rate of the link between the router and the client. Suppose that the only bits being\nsent in the entire network are those from the server to the client. We now ask, in this ideal\nscenario, what is the server-to-client throughput? To answer this question, we may think of\nbits as fluid and communication links as pipes. Clearly, the server cannot pump bits through\nits link at a rate faster than R  bps; and the router cannot forward bits at a rate faster than R\nbps. If R  < R , then the bits pumped by the server will “flow” right through the router and\narrive at the client at a rate of R  bps, giving a throughput of R  bps. If, on the other hand, R\n< R , then the router will not be able to forward bits as quickly as it receives them. In this\ncase, bits will only leave the router at rate R , giving an end-to-end throughput of R . (Note\nalso that if bits continue to arrive at the router at rate R , and continue to leave the router at\nR , the backlog of bits at the router waiting for transmission to the client will grow and grow\n—a most undesirable situation!)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 112,
    "text": "In addition to delay and packet loss, another critical performance measure in computer\nnetworks is end-to-end throughput. To define throughput, consider transferring a large file\nfrom Host A to Host B across a computer network. This transfer might be, for example, a\nlarge video clip from one computer to another. The instantaneous throughput at any instant\nof time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications\ndisplay the instantaneous throughput during downloads in the user interface—perhaps you\nhave observed this before! You might like to try measuring the end-to-end delay and\ndownload throughput between your and servers around the Internet using the speedtest\napplication [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds\nfor Host B to receive all F bits, then the average throughput of the file transfer is F/T\nbits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay\nand an instantaneous throughput consistently above some threshold (for example, over 24\nkbps for some Internet telephony applications and over 256 kbps for some real-time video\napplications). For other applications, including those involving file transfers, delay is not\ncritical, but it is desirable to have the highest possible throughput. To gain further insight into the important concept of throughput, let’s consider a few\nexamples. Figure 1.19(a) shows two end systems, a server and a client, connected by two\ncommunication links and a router. Consider the throughput for a file transfer from the server\nto the client. Let R  denote the rate of the link between the server and the router; and R\ndenote the rate of the link between the router and the client. Suppose that the only bits being\nsent in the entire network are those from the server to the client. We now ask, in this ideal\nscenario, what is the server-to-client throughput? To answer this question, we may think of\nbits as fluid and communication links as pipes. Clearly, the server cannot pump bits through\nits link at a rate faster than R  bps; and the router cannot forward bits at a rate faster than R\nbps. If R  < R , then the bits pumped by the server will “flow” right through the router and\narrive at the client at a rate of R  bps, giving a throughput of R  bps. If, on the other hand, R\n< R , then the router will not be able to forward bits as quickly as it receives them. In this\ncase, bits will only leave the router at rate R , giving an end-to-end throughput of R . (Note\nalso that if bits continue to arrive at the router at rate R , and continue to leave the router at\nR , the backlog of bits at the router waiting for transmission to the client will grow and grow\n—a most undesirable situation!) Thus, for this simple two-link network, the throughput is\nmin{R , R }, that is, it is the transmission rate of the bottleneck link."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 112,
    "text": "In addition to delay and packet loss, another critical performance measure in computer\nnetworks is end-to-end throughput. To define throughput, consider transferring a large file\nfrom Host A to Host B across a computer network. This transfer might be, for example, a\nlarge video clip from one computer to another. The instantaneous throughput at any instant\nof time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications\ndisplay the instantaneous throughput during downloads in the user interface—perhaps you\nhave observed this before! You might like to try measuring the end-to-end delay and\ndownload throughput between your and servers around the Internet using the speedtest\napplication [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds\nfor Host B to receive all F bits, then the average throughput of the file transfer is F/T\nbits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay\nand an instantaneous throughput consistently above some threshold (for example, over 24\nkbps for some Internet telephony applications and over 256 kbps for some real-time video\napplications). For other applications, including those involving file transfers, delay is not\ncritical, but it is desirable to have the highest possible throughput. To gain further insight into the important concept of throughput, let’s consider a few\nexamples. Figure 1.19(a) shows two end systems, a server and a client, connected by two\ncommunication links and a router. Consider the throughput for a file transfer from the server\nto the client. Let R  denote the rate of the link between the server and the router; and R\ndenote the rate of the link between the router and the client. Suppose that the only bits being\nsent in the entire network are those from the server to the client. We now ask, in this ideal\nscenario, what is the server-to-client throughput? To answer this question, we may think of\nbits as fluid and communication links as pipes. Clearly, the server cannot pump bits through\nits link at a rate faster than R  bps; and the router cannot forward bits at a rate faster than R\nbps. If R  < R , then the bits pumped by the server will “flow” right through the router and\narrive at the client at a rate of R  bps, giving a throughput of R  bps. If, on the other hand, R\n< R , then the router will not be able to forward bits as quickly as it receives them. In this\ncase, bits will only leave the router at rate R , giving an end-to-end throughput of R . (Note\nalso that if bits continue to arrive at the router at rate R , and continue to leave the router at\nR , the backlog of bits at the router waiting for transmission to the client will grow and grow\n—a most undesirable situation!) Thus, for this simple two-link network, the throughput is\nmin{R , R }, that is, it is the transmission rate of the bottleneck link. Having determined the\nthroughput, we can now approximate the time it takes to transfer a large file of F bits from\nserver to client as F/min{R , R }."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 112,
    "text": "In addition to delay and packet loss, another critical performance measure in computer\nnetworks is end-to-end throughput. To define throughput, consider transferring a large file\nfrom Host A to Host B across a computer network. This transfer might be, for example, a\nlarge video clip from one computer to another. The instantaneous throughput at any instant\nof time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications\ndisplay the instantaneous throughput during downloads in the user interface—perhaps you\nhave observed this before! You might like to try measuring the end-to-end delay and\ndownload throughput between your and servers around the Internet using the speedtest\napplication [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds\nfor Host B to receive all F bits, then the average throughput of the file transfer is F/T\nbits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay\nand an instantaneous throughput consistently above some threshold (for example, over 24\nkbps for some Internet telephony applications and over 256 kbps for some real-time video\napplications). For other applications, including those involving file transfers, delay is not\ncritical, but it is desirable to have the highest possible throughput. To gain further insight into the important concept of throughput, let’s consider a few\nexamples. Figure 1.19(a) shows two end systems, a server and a client, connected by two\ncommunication links and a router. Consider the throughput for a file transfer from the server\nto the client. Let R  denote the rate of the link between the server and the router; and R\ndenote the rate of the link between the router and the client. Suppose that the only bits being\nsent in the entire network are those from the server to the client. We now ask, in this ideal\nscenario, what is the server-to-client throughput? To answer this question, we may think of\nbits as fluid and communication links as pipes. Clearly, the server cannot pump bits through\nits link at a rate faster than R  bps; and the router cannot forward bits at a rate faster than R\nbps. If R  < R , then the bits pumped by the server will “flow” right through the router and\narrive at the client at a rate of R  bps, giving a throughput of R  bps. If, on the other hand, R\n< R , then the router will not be able to forward bits as quickly as it receives them. In this\ncase, bits will only leave the router at rate R , giving an end-to-end throughput of R . (Note\nalso that if bits continue to arrive at the router at rate R , and continue to leave the router at\nR , the backlog of bits at the router waiting for transmission to the client will grow and grow\n—a most undesirable situation!) Thus, for this simple two-link network, the throughput is\nmin{R , R }, that is, it is the transmission rate of the bottleneck link. Having determined the\nthroughput, we can now approximate the time it takes to transfer a large file of F bits from\nserver to client as F/min{R , R }. For a specific example, suppose that you are downloading\ns\nc\ns\nc\ns\nc\ns\ns\nc\ns\nc\nc\ns\nc\nc\ns\ns\nc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 112,
    "text": "In addition to delay and packet loss, another critical performance measure in computer\nnetworks is end-to-end throughput. To define throughput, consider transferring a large file\nfrom Host A to Host B across a computer network. This transfer might be, for example, a\nlarge video clip from one computer to another. The instantaneous throughput at any instant\nof time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications\ndisplay the instantaneous throughput during downloads in the user interface—perhaps you\nhave observed this before! You might like to try measuring the end-to-end delay and\ndownload throughput between your and servers around the Internet using the speedtest\napplication [Speedtest 2020].) If the file consists of F bits and the transfer takes T seconds\nfor Host B to receive all F bits, then the average throughput of the file transfer is F/T\nbits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay\nand an instantaneous throughput consistently above some threshold (for example, over 24\nkbps for some Internet telephony applications and over 256 kbps for some real-time video\napplications). For other applications, including those involving file transfers, delay is not\ncritical, but it is desirable to have the highest possible throughput. To gain further insight into the important concept of throughput, let’s consider a few\nexamples. Figure 1.19(a) shows two end systems, a server and a client, connected by two\ncommunication links and a router. Consider the throughput for a file transfer from the server\nto the client. Let R  denote the rate of the link between the server and the router; and R\ndenote the rate of the link between the router and the client. Suppose that the only bits being\nsent in the entire network are those from the server to the client. We now ask, in this ideal\nscenario, what is the server-to-client throughput? To answer this question, we may think of\nbits as fluid and communication links as pipes. Clearly, the server cannot pump bits through\nits link at a rate faster than R  bps; and the router cannot forward bits at a rate faster than R\nbps. If R  < R , then the bits pumped by the server will “flow” right through the router and\narrive at the client at a rate of R  bps, giving a throughput of R  bps. If, on the other hand, R\n< R , then the router will not be able to forward bits as quickly as it receives them. In this\ncase, bits will only leave the router at rate R , giving an end-to-end throughput of R . (Note\nalso that if bits continue to arrive at the router at rate R , and continue to leave the router at\nR , the backlog of bits at the router waiting for transmission to the client will grow and grow\n—a most undesirable situation!) Thus, for this simple two-link network, the throughput is\nmin{R , R }, that is, it is the transmission rate of the bottleneck link. Having determined the\nthroughput, we can now approximate the time it takes to transfer a large file of F bits from\nserver to client as F/min{R , R }. For a specific example, suppose that you are downloading\ns\nc\ns\nc\ns\nc\ns\ns\nc\ns\nc\nc\ns\nc\nc\ns\ns\nc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 113,
    "text": "an MP3 file of F = 32 million bits, the server has a transmission rate of R  = 2 Mbps, and\nyou have an access link of R  = 1 Mbps. The time needed to transfer the file is then 32\nseconds. Of course, these expressions for throughput and transfer time are only\napproximations, as they do not account for store-and-forward and processing delays as well\nas protocol issues. Figure 1.19 ♦Throughput for a file transfer from server to client\nFigure 1.19(b) now shows a network with N links between the server and the client, with\nthe transmission rates of the N links being R , R , ..., R . Applying the same analysis as for\nthe two-link network, we find that the throughput for a file transfer from server to client is\nmin{R , R , ..., R }, which is once again the transmission rate of the bottleneck link along the\npath between server and client. Now consider another example motivated by today’s Internet. Figure 1.20(a) shows two\nend systems, a server and a client, connected to a computer network. Consider the\nthroughput for a file transfer from the server to the client. The server is connected to the\nnetwork with an access link of rate R  and the client is connected to the network with an\naccess link of rate R . Now suppose that all the links in the core of the communication\nnetwork have very high transmission rates, much higher than R  and R . Indeed, today, the\ncore of the Internet is over-provisioned with high speed links that experience little\ncongestion. Also suppose that the only bits being sent in the entire network are those from\nthe server to the client. Because the core of the computer network is like a wide pipe in this\nexample, the rate at which bits can flow from source to destination is again the minimum of\ns\nc\n2\nN\n2\nN\ns\nc\ns\nc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 114,
    "text": "R  and R , that is, throughput = min{R , R }. Therefore, the constraining factor for throughput\nin today’s Internet is typically the access network. Figure 1.20 ♦End-to-end throughput: (a) Client downloads a file from ­server; (b)\n10 clients ­downloading with 10 servers\nFor a final example, consider Figure 1.20(b) in which there are 10 servers and 10 clients\nconnected to the core of the computer network. In this example, there are 10 simultaneous\ndownloads taking place, involving 10 client-server pairs. Suppose that these 10 downloads\nare the only traffic in the network at the current time. As shown in the figure, there is a link\nin the core that is traversed by all 10 downloads. Denote R for the transmission rate of this\nlink R. Let’s suppose that all server access links have the same rate R , all client access links\nhave the same rate R , and the transmission rates of all the links in the core—except the one\ncommon link of rate R—are much larger than R , R , and R. Now we ask, what are the\ns\nc\ns\nc\ns\nc\ns\nc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 115,
    "text": "throughputs of the downloads? Clearly, if the rate of the common link, R, is large—say a\nhundred times larger than both R  and R —then the throughput for each download will once\nagain be min{R , R }. But what if the rate of the common link is of the same order as R  and\nR ? What will the throughput be in this case? Let’s take a look at a specific example. Suppose R  = 2 Mbps, R  = 1 Mbps, R = 5 Mbps, and the common link divides its\ntransmission rate equally among the 10 downloads. Then the bottleneck for each download\nis no longer in the access network, but is now instead the shared link in the core, which only\nprovides each download with 500 kbps of throughput. Thus, the end-to-end throughput for\neach download is now reduced to 500 kbps. The examples in Figure 1.19 and Figure 1.20(a) show that throughput depends on the\ntransmission rates of the links over which the data flows. We saw that when there is no other\nintervening traffic, the throughput can simply be approximated as the minimum transmission\nrate along the path between source and destination. The example in Figure 1.20(b) shows\nthat more generally the throughput depends not only on the transmission rates of the links\nalong the path, but also on the intervening traffic. In particular, a link with a high\ntransmission rate may nonetheless be the bottleneck link for a file transfer if many other data\nflows are also passing through that link. We will examine throughput in computer networks\nmore closely in the homework problems and in the subsequent chapters. s\nc\ns\nc\ns\nc\ns\nc"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 116,
    "text": "1.5 Protocol Layers and Their Service Models\nFrom our discussion thus far, it is apparent that the Internet is an extremely\ncomplicated system. We have seen that there are many pieces to the\nInternet: numerous applications and protocols, various types of end\nsystems, packet switches, and various types of link-level media. Given this\nenormous complexity, is there any hope of organizing a network\narchitecture, or at least our discussion of network architecture? Fortunately,\nthe answer to both questions is yes. 1.5.1 Layered Architecture\nBefore attempting to organize our thoughts on Internet architecture, let’s\nlook for a human analogy. Actually, we deal with complex systems all the\ntime in our everyday life. Imagine if someone asked you to describe, for\nexample, the airline system. How would you find the structure to describe\nthis complex system that has ticketing agents, baggage checkers, gate\npersonnel, pilots, airplanes, air traffic control, and a worldwide system for\nrouting airplanes? One way to describe this system might be to describe the\nseries of actions you take (or others take for you) when you fly on an\nairline. You purchase your ticket, check your bags, go to the gate, and\neventually get loaded onto the plane. The plane takes off and is routed to its\ndestination. After your plane lands, you deplane at the gate and claim your\nbags. If the trip was bad, you complain about the flight to the ticket agent\n(getting nothing for your effort). This scenario is shown in Figure 1.21."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 117,
    "text": "Figure 1.21 ♦Taking an airplane trip: actions\nAlready, we can see some analogies here with computer networking:\nYou are being shipped from source to destination by the airline; a packet is\nshipped from source host to destination host in the Internet. But this is not\nquite the analogy we are after. We are looking for some structure in Figure\n1.21. Looking at Figure 1.21, we note that there is a ticketing function at\neach end; there is also a baggage function for already-ticketed passengers,\nand a gate function for already-ticketed and already-baggage-checked\npassengers. For passengers who have made it through the gate (that is,\npassengers who are already ticketed, baggage-checked, and through the\ngate), there is a takeoff and landing function, and while in flight, there is an\nairplane-routing function. This suggests that we can look at the\nfunctionality in Figure 1.21 in a horizontal manner, as shown in Figure\n1.22."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 118,
    "text": "Figure 1.22 ♦Horizontal layering of airline functionality\nFigure 1.22 has divided the airline functionality into layers, providing a\nframework in which we can discuss airline travel. Note that each layer,\ncombined with the layers below it, implements some functionality, some\nservice. At the ticketing layer and below, airline-counter-to-airline-counter\ntransfer of a person is accomplished. At the baggage layer and below,\nbaggage-check-to-baggage-claim transfer of a person and bags is\naccomplished. Note that the baggage layer provides this service only to an\nalready-ticketed person. At the gate layer, departure-gate-to-arrival-gate\ntransfer of a person and bags is accomplished. At the takeoff/landing layer,\nrunway-to-runway transfer of people and their bags is accomplished. Each\nlayer provides its service by (1) performing certain actions within that layer\n(for example, at the gate layer, loading and unloading people from an\nairplane) and by (2) using the services of the layer directly below it (for\nexample, in the gate layer, using the runway-to-runway passenger transfer\nservice of the takeoff/landing layer). A layered architecture allows us to discuss a well-defined, specific part\nof a large and complex system. This simplification itself is of considerable\nvalue by providing modularity, making it much easier to change the\nimplementation of the service provided by the layer. As long as the layer"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 119,
    "text": "provides the same service to the layer above it, and uses the same services\nfrom the layer below it, the remainder of the system remains unchanged\nwhen a layer’s implementation is changed. (Note that changing the\nimplementation of a service is very different from changing the service\nitself!) For example, if the gate functions were changed (for instance, to\nhave people board and disembark by height), the remainder of the airline\nsystem would remain unchanged since the gate layer still provides the same\nfunction (loading and unloading people); it simply implements that function\nin a different manner after the change. For large and complex systems that\nare constantly being updated, the ability to change the implementation of a\nservice without affecting other components of the system is another\nimportant advantage of layering. Protocol Layering\nBut enough about airlines. Let’s now turn our attention to network\nprotocols. To provide structure to the design of network protocols, network\ndesigners organize protocols—and the network hardware and software that\nimplement the protocols—in layers. Each protocol belongs to one of the\nlayers, just as each function in the airline architecture in Figure 1.22\nbelonged to a layer. We are again interested in the services that a layer\noffers to the layer above—the so-called service model of a layer. Just as in\nthe case of our airline example, each layer provides its service by (1)\nperforming certain actions within that layer and by (2) using the services of\nthe layer directly below it. For example, the services provided by layer n\nmay include reliable delivery of messages from one edge of the network to\nthe other. This might be implemented by using an unreliable edge-to-edge\nmessage delivery service of layer n − 1, and adding layer n functionality to\ndetect and retransmit lost messages."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 121,
    "text": "have roughly organized this book using the layers of the Internet protocol\nstack. We take a top-down approach, first covering the application layer\nand then proceeding downward. Figure 1.23 ♦The Internet protocol stack\nApplication Layer\nThe application layer is where network applications and their application-\nlayer protocols reside. The Internet’s application layer includes many\nprotocols, such as the HTTP protocol (which provides for Web document\nrequest and transfer), SMTP (which provides for the transfer of e-mail\nmessages), and FTP (which provides for the transfer of files between two\nend systems). We’ll see that certain network functions, such as the\ntranslation of human-friendly names for Internet end systems like\nwww.ietf.org to a 32-bit network address, are also done with the help of a"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 122,
    "text": "specific application-layer protocol, namely, the domain name system\n(DNS). We’ll see in Chapter 2 that it is very easy to create and deploy our\nown new application-layer protocols. An application-layer protocol is distributed over multiple end systems,\nwith the application in one end system using the protocol to exchange\npackets of information with the application in another end system. We’ll\nrefer to this packet of information at the application layer as a message. Transport Layer\nThe Internet’s transport layer transports application-layer messages between\napplication endpoints. In the Internet, there are two transport protocols,\nTCP and UDP, either of which can transport application-layer messages. TCP provides a ­connection-oriented service to its applications. This service\nincludes guaranteed delivery of application-layer messages to the\ndestination and flow control (that is, sender/receiver speed matching). TCP\nalso breaks long messages into shorter ­segments and provides a congestion-\ncontrol mechanism, so that a source throttles its transmission rate when the\nnetwork is congested. The UDP protocol provides a connectionless service\nto its applications. This is a no-frills service that provides no reliability, no\nflow control, and no congestion control. In this book, we’ll refer to a\ntransport-layer packet as a segment. Network Layer\nThe Internet’s network layer is responsible for moving network-layer\npackets known as datagrams from one host to another. The Internet\ntransport-layer protocol (TCP or UDP) in a source host passes a transport-\nlayer segment and a destination address to the network layer, just as you\nwould give the postal service a letter with a destination address. The"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 123,
    "text": "network layer then provides the service of delivering the segment to the\ntransport layer in the destination host. The Internet’s network layer includes the celebrated IP protocol, which\ndefines the fields in the datagram as well as how the end systems and\nrouters act on these fields. There is only one IP protocol, and all Internet\ncomponents that have a network layer must run the IP protocol. The\nInternet’s network layer also contains routing protocols that determine the\nroutes that datagrams take between sources and destinations. The Internet\nhas many routing protocols. As we saw in Section 1.3, the Internet is a\nnetwork of networks, and within a network, the network administrator can\nrun any routing protocol desired. Although the network layer contains both\nthe IP protocol and numerous routing protocols, it is often simply referred\nto as the IP layer, reflecting the fact that IP is the glue that binds the Internet\ntogether. Link Layer\nThe Internet’s network layer routes a datagram through a series of routers\nbetween the source and destination. To move a packet from one node (host\nor router) to the next node in the route, the network layer relies on the\nservices of the link layer. In particular, at each node, the network layer\npasses the datagram down to the link layer, which delivers the datagram to\nthe next node along the route. At this next node, the link layer passes the\ndatagram up to the network layer. The services provided by the link layer depend on the specific link-\nlayer protocol that is employed over the link. For example, some link-layer\nprotocols provide reliable delivery, from transmitting node, over one link, to\nreceiving node. Note that this reliable delivery service is different from the\nreliable delivery service of TCP, which provides reliable delivery from one"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 124,
    "text": "end system to another. Examples of link-layer protocols include Ethernet,\nWiFi, and the cable access network’s DOCSIS protocol. As datagrams\ntypically need to traverse several links to travel from source to destination,\na datagram may be handled by different link-layer protocols at different\nlinks along its route. For example, a datagram may be handled by Ethernet\non one link and by PPP on the next link. The network layer will receive a\ndifferent service from each of the different link-layer protocols. In this\nbook, we’ll refer to the link-layer packets as frames. Physical Layer\nWhile the job of the link layer is to move entire frames from one network\nelement to an adjacent network element, the job of the physical layer is to\nmove the individual bits within the frame from one node to the next. The\nprotocols in this layer are again link dependent and further depend on the\nactual transmission medium of the link (for example, twisted-pair copper\nwire, single-mode fiber optics). For example, Ethernet has many physical-\nlayer protocols: one for twisted-pair copper wire, another for coaxial cable,\nanother for fiber, and so on. In each case, a bit is moved across the link in a\ndifferent way. 1.5.2 Encapsulation\nFigure 1.24 shows the physical path that data takes down a sending end\nsystem’s protocol stack, up and down the protocol stacks of an intervening\nlink-layer switch and router, and then up the protocol stack at the receiving\nend system. As we discuss later in this book, routers and link-layer switches\nare both packet switches. Similar to end systems, routers and link-layer\nswitches organize their networking hardware and software into layers. But"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 125,
    "text": "routers and link-layer switches do not implement all of the layers in the\nprotocol stack; they typically implement only the bottom layers. As shown\nin Figure 1.24, link-layer switches implement layers 1 and 2; routers\nimplement layers 1 through 3. This means, for example, that Internet routers\nare capable of implementing the IP protocol (a layer 3 protocol), while link-\nlayer switches are not. We’ll see later that while link-layer switches do not\nrecognize IP addresses, they are capable of recognizing layer 2 addresses,\nsuch as Ethernet addresses. Note that hosts implement all five layers; this is\nconsistent with the view that the Internet architecture puts much of its\ncomplexity at the edges of the network. Figure 1.24 ♦Hosts, routers, and link-layer switches; each contains\na ­different set of layers, reflecting their differences in\nfunctionality"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 126,
    "text": "Figure 1.24 also illustrates the important concept of encapsulation. At\nthe sending host, an application-layer message (M in Figure 1.24) is\npassed to the transport layer. In the simplest case, the transport layer takes\nthe message and appends additional information (so-called transport-layer\nheader information, H  in Figure 1.24) that will be used by the receiver-side\ntransport layer. The application-layer message and the transport-layer\nheader information together constitute the transport-layer segment. The\ntransport-layer segment thus encapsulates the application-layer message. The added information might include information allowing the receiver-side\ntransport layer to deliver the message up to the appropriate application, and\nerror-detection bits that allow the receiver to determine whether bits in the\nmessage have been changed in route. The transport layer then passes the\nsegment to the network layer, which adds network-layer header information\n(H  in Figure 1.24) such as source and destination end system addresses,\ncreating a network-layer datagram. The datagram is then passed to the\nlink layer, which (of course!) will add its own link-layer header information\nand create a link-layer frame. Thus, we see that at each layer, a packet has\ntwo types of fields: header fields and a payload field. The payload is\ntypically a packet from the layer above. A useful analogy here is the sending of an interoffice memo from one\ncorporate branch office to another via the public postal service. Suppose\nAlice, who is in one branch office, wants to send a memo to Bob, who is in\nanother branch office. The memo is analogous to the application-layer\nmessage. Alice puts the memo in an interoffice envelope with Bob’s name\nand department written on the front of the envelope. The interoffice\nenvelope is analogous to a transport-layer segment—it contains header\ninformation (Bob’s name and department number) and it encapsulates the\napplication-layer message (the memo). When the sending branch-office\nt\nn"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 127,
    "text": "mailroom receives the interoffice envelope, it puts the interoffice envelope\ninside yet another envelope, which is suitable for sending through the\npublic postal service. The sending mailroom also writes the postal address\nof the sending and receiving branch offices on the postal envelope. Here,\nthe postal envelope is analogous to the datagram—it encapsulates the\ntransport-layer segment (the interoffice envelope), which encapsulates the\noriginal message (the memo). The postal service delivers the postal\nenvelope to the receiving branch-office mailroom. There, the process of de-\nencapsulation is begun. The mailroom extracts the interoffice memo and\nforwards it to Bob. Finally, Bob opens the envelope and removes the memo. The process of encapsulation can be more complex than that described\nabove. For example, a large message may be divided into multiple\ntransport-layer segments (which might themselves each be divided into\nmultiple network-layer datagrams). At the receiving end, such a segment\nmust then be reconstructed from its constituent datagrams."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 128,
    "text": "1.6 Networks Under Attack\nThe Internet has become mission critical for many institutions today,\nincluding large and small companies, universities, and government\nagencies. Many individuals also rely on the Internet for many of their\nprofessional, social, and personal activities. Billions of “things,” including\nwearables and home devices, are currently being connected to the Internet. But behind all this utility and excitement, there is a dark side, a side where\n“bad guys” attempt to wreak havoc in our daily lives by damaging our\nInternet-connected computers, violating our privacy, and rendering\ninoperable the Internet services on which we depend. The field of network security is about how the bad guys can attack\ncomputer networks and about how we, soon-to-be experts in computer\nnetworking, can defend networks against those attacks, or better yet, design\nnew architectures that are immune to such attacks in the first place. Given\nthe frequency and variety of existing attacks as well as the threat of new\nand more destructive future attacks, network security has become a central\ntopic in the field of computer networking. One of the features of this\ntextbook is that it brings network security issues to the forefront. Since we don’t yet have expertise in computer networking and Internet\nprotocols, we’ll begin here by surveying some of today’s more prevalent\nsecurity-related problems. This will whet our appetite for more substantial\ndiscussions in the upcoming chapters. So we begin here by simply asking,\nwhat can go wrong? How are computer networks vulnerable? What are\nsome of the more prevalent types of attacks today? The Bad Guys Can Put Malware into Your Host Via the Internet"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 129,
    "text": "We attach devices to the Internet because we want to receive/send data\nfrom/to the Internet. This includes all kinds of good stuff, including\nInstagram posts, Internet search results, streaming music, video conference\ncalls, streaming movies, and so on. But, unfortunately, along with all that\ngood stuff comes malicious stuff—­collectively known as malware—that\ncan also enter and infect our devices. Once malware infects our device it\ncan do all kinds of devious things, including deleting our files and installing\nspyware that collects our private information, such as  social ­security\nnumbers, passwords, and keystrokes, and then sends this (over the Internet,\nof course!) back to the bad guys. Our compromised host may also\nbe enrolled in a network of thousands of similarly compromised devices,\ncollectively known as a botnet, which the bad guys control and leverage for\nspam e-mail distribution or distributed denial-of-service attacks (soon to be\ndiscussed) against targeted hosts. Much of the malware out there today is self-replicating: once it infects\none host, from that host it seeks entry into other hosts over the Internet, and\nfrom ­the newly infected hosts, it seeks entry into yet more hosts. In this\nmanner, self-­replicating malware can spread exponentially fast. The Bad Guys Can Attack Servers and Network Infrastructure\nAnother broad class of security threats are known as denial-of-service\n(DoS) attacks. As the name suggests, a DoS attack renders a network, host,\nor other piece of infrastructure unusable by legitimate users. Web servers, e-\nmail servers, DNS servers (discussed in Chapter 2), and institutional\nnetworks can all be subject to DoS attacks. The site Digital Attack Map\nallows use to visualize the top daily DoS attacks worldwide [DAM 2020]. Most Internet DoS attacks fall into one of three categories:"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 130,
    "text": "•\nVulnerability attack. This involves sending a few well-crafted messages\nto a vulnerable application or operating system running on a targeted\nhost. If the right sequence of packets is sent to a vulnerable application\nor operating system, the service can stop or, worse, the host can crash. •\nBandwidth flooding. The attacker sends a deluge of packets to the\ntargeted host—so many packets that the target’s access link becomes\nclogged, preventing legitimate packets from reaching the server. •\nConnection flooding. The attacker establishes a large number of half-\nopen or fully open TCP connections (TCP connections are discussed in\nChapter 3) at the target host. The host can become so bogged down with\nthese bogus connections that it stops accepting legitimate connections. Let’s now explore the bandwidth-flooding attack in more detail. Recalling\nour delay and loss analysis discussion in Section 1.4.2, it’s evident that if\nthe server has an access rate of R bps, then the attacker will need to send\ntraffic at a rate of approximately R bps to cause damage. If R is very large, a\nsingle attack source may not be able to generate enough traffic to harm the\nserver. Furthermore, if all the traffic emanates from a single source, an\nupstream router may be able to detect the attack and block all traffic from\nthat source before the traffic gets near the server. In a distributed DoS\n(DDoS) attack, illustrated in Figure 1.25, the attacker controls multiple\nsources and has each source blast traffic at the target. With this approach,\nthe aggregate traffic rate across all the controlled sources needs to be\napproximately R to cripple the ­service. DDoS attacks leveraging botnets\nwith thousands of comprised hosts are a common occurrence today [DAM\n2020]. DDos attacks are much harder to detect and defend against than a\nDoS attack from a single host."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 131,
    "text": "Figure 1.25 ♦A distributed denial-of-service attack\nWe encourage you to consider the following question as you work your\nway through this book: What can computer network designers do to defend\nagainst DoS attacks? We will see that different defenses are needed for the\nthree types of DoS attacks. The Bad Guys Can Sniff Packets\nMany users today access the Internet via wireless devices, such as WiFi-\nconnected laptops or handheld devices with cellular Internet connections\n(covered in Chapter 7). While ubiquitous Internet access is extremely\nconvenient and enables marvelous new applications for mobile users, it also\ncreates a major security vulnerability—by placing a passive receiver in the\nvicinity of the wireless transmitter, that receiver can obtain a copy of every\npacket that is transmitted! These packets can contain all kinds of sensitive\ninformation, including passwords, social security numbers, trade secrets,"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 132,
    "text": "and private personal messages. A passive receiver that records a copy of\nevery packet that flies by is called a packet sniffer. Sniffers can be deployed in wired environments as well. In wired\nbroadcast environments, as in many Ethernet LANs, a packet sniffer can\nobtain copies of broadcast packets sent over the LAN. As described in\nSection 1.2, cable access technologies also broadcast packets and are thus\nvulnerable to sniffing. Furthermore, a bad guy who gains access to an\ninstitution’s access router or access link to the Internet may be able to plant\na sniffer that makes a copy of every packet going to/from the organization. Sniffed packets can then be analyzed offline for sensitive information. Packet-sniffing software is freely available at various Web sites and as\ncommercial products. Professors teaching a networking course have been\nknown to assign lab exercises that involve writing a packet-sniffing and\napplication-layer data reconstruction program. Indeed, the Wireshark\n[Wireshark 2020] labs associated with this text (see the introductory\nWireshark lab at the end of this chapter) use exactly such a packet sniffer! Because packet sniffers are passive—that is, they do not inject packets\ninto the channel—they are difficult to detect. So, when we send packets into\na wireless channel, we must accept the possibility that some bad guy may\nbe recording copies of our packets. As you may have guessed, some of the\nbest defenses against packet sniffing involve cryptography. We will\nexamine cryptography as it applies to network security in Chapter 8. The Bad Guys Can Masquerade as Someone You Trust\nIt is surprisingly easy (you will have the knowledge to do so shortly as you\nproceed through this text!) to create a packet with an arbitrary source\naddress, packet content, and destination address and then transmit this\nhand-crafted packet into the Internet, which will dutifully forward the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 133,
    "text": "packet to its destination. Imagine the unsuspecting receiver (say an Internet\nrouter) who receives such a packet, takes the (false) source address as being\ntruthful, and then performs some command embedded in the packet’s\ncontents (say modifies its forwarding table). The ability to inject packets\ninto the Internet with a false source address is known as IP spoofing, and is\nbut one of many ways in which one user can masquerade as another user. To solve this problem, we will need end-point authentication, that is, a\nmechanism that will allow us to determine with certainty if a message\noriginates from where we think it does. Once again, we encourage you to\nthink about how this can be done for network applications and protocols as\nyou progress through the chapters of this book. We will explore\nmechanisms for end-point authentication in Chapter 8. In closing this section, it’s worth considering how the Internet got to be\nsuch an insecure place in the first place. The answer, in essence, is that the\nInternet was originally designed to be that way, based on the model of “a\ngroup of mutually trusting users attached to a transparent network”\n[Blumenthal 2001]—a model in which (by definition) there is no need for\nsecurity. Many aspects of the original Internet architecture deeply reflect\nthis notion of mutual trust. For example, the ability for one user to send a\npacket to any other user is the default rather than a requested/granted\ncapability, and user identity is taken at declared face value, rather than\nbeing authenticated by default. But today’s Internet certainly does not involve “mutually trusting\nusers.” Nonetheless, today’s users still need to communicate when they\ndon’t necessarily trust each other, may wish to communicate anonymously,\nmay communicate indirectly through third parties (e.g., Web caches, which\nwe’ll study in Chapter 2, or mobility-assisting agents, which we’ll study in\nChapter 7), and may distrust the hardware, software, and even the air"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 134,
    "text": "through which they communicate. We now have many security-related\nchallenges before us as we progress through this book: We should seek\ndefenses against sniffing, end-point masquerading, man-in-the-middle\nattacks, DDoS attacks, malware, and more. We should keep in mind that\ncommunication among mutually trusted users is the exception rather than\nthe rule. Welcome to the world of modern computer networking!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 135,
    "text": "1.7 History of Computer Networking and the\nInternet\nSections 1.1 through 1.6 presented an overview of the technology of\ncomputer networking and the Internet. You should know enough now to\nimpress your family and friends! However, if you really want to be a big hit\nat the next cocktail party, you should sprinkle your discourse with tidbits\nabout the fascinating history of the Internet [Segaller 1998]. 1.7.1 The Development of Packet Switching: 1961–\nThe field of computer networking and today’s Internet trace their\nbeginnings back to the early 1960s, when the telephone network was the\nworld’s dominant communication network. Recall from Section 1.3 that the\ntelephone network uses circuit switching to transmit information from a\nsender to a receiver—an appropriate choice given that voice is transmitted\nat a constant rate between sender and receiver. Given the increasing\nimportance of computers in the early 1960s and the advent of timeshared\ncomputers, it was perhaps natural to consider how to hook computers\ntogether so that they could be shared among geographically distributed\nusers. The traffic generated by such users was likely to be bursty—intervals\nof activity, such as the sending of a command to a remote computer,\nfollowed by periods of inactivity while waiting for a reply or while\ncontemplating the received response."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 136,
    "text": "Three research groups around the world, each unaware of the others’\nwork [Leiner 1998], began inventing packet switching as an efficient and\nrobust alternative to circuit switching. The first published work on packet-\nswitching techniques was that of Leonard Kleinrock [Kleinrock 1961;\nKleinrock 1964], then a graduate student at MIT. Using queuing theory,\nKleinrock’s work elegantly demonstrated the effectiveness of the packet-\nswitching approach for bursty traffic sources. In 1964, Paul Baran [Baran\n1964] at the Rand Institute had begun investigating the use of packet\nswitching for secure voice over military networks, and at the National\nPhysical Laboratory in England, Donald Davies and Roger Scantlebury\nwere also developing their ideas on packet switching. The work at MIT, Rand, and the NPL laid the foundations for today’s\nInternet. But the Internet also has a long history of a let’s-build-it-and-\ndemonstrate-it attitude that also dates back to the 1960s. J. C. R. Licklider\n[DEC 1990] and Lawrence Roberts, both colleagues of Kleinrock’s at MIT,\nwent on to lead the computer science program at the Advanced Research\nProjects Agency (ARPA) in the United States. Roberts published an overall\nplan for the ARPAnet [Roberts 1967], the first packet-switched computer\nnetwork and a direct ancestor of today’s public Internet. On Labor Day in\n1969, the first packet switch was installed at UCLA under Kleinrock’s\nsupervision, and three additional packet switches were installed shortly\nthereafter at the Stanford Research Institute (SRI), UC Santa Barbara, and\nthe University of Utah (Figure 1.26). The fledgling precursor to the Internet\nwas four nodes large by the end of 1969. Kleinrock recalls the very first use\nof the network to perform a remote login from UCLA to SRI, crashing the\nsystem [Kleinrock 2004]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 137,
    "text": "Figure 1.26 ♦An early packet switch\nMark J. Terrill/AP Photo"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 138,
    "text": "By 1972, ARPAnet had grown to approximately 15 nodes and was given\nits first public demonstration by Robert Kahn. The first host-to-host\nprotocol between ARPAnet end systems, known as the network-control\nprotocol (NCP), was completed [RFC 001]. With an end-to-end protocol\navailable, applications could now be written. Ray Tomlinson wrote the first\ne-mail program in 1972. 1.7.2 Proprietary Networks and Internetworking:\n1972–1980\nThe initial ARPAnet was a single, closed network. In order to communicate\nwith an ARPAnet host, one had to be actually attached to another ARPAnet\nIMP. In the early to mid-1970s, additional stand-alone packet-switching\nnetworks besides ARPAnet came into being: ALOHANet, a microwave\nnetwork linking universities on the Hawaiian islands [Abramson 1970], as\nwell as DARPA’s packet-satellite [RFC 829] and packet-radio networks\n[Kahn 1978]; Telenet, a BBN commercial packet-switching network based\non ARPAnet technology; Cyclades, a French packet-switching network\npioneered by Louis Pouzin [Think 2012]; Time-sharing networks such as\nTymnet and the GE Information Services network, among others, in the late\n1960s and early 1970s [Schwartz 1977]; IBM’s SNA (1969–1974), which\nparalleled the ARPAnet work [Schwartz 1977]. The number of networks was growing. With perfect hindsight we can\nsee that the time was ripe for developing an encompassing architecture for\nconnecting networks together. Pioneering work on interconnecting\nnetworks (under the sponsorship of the Defense Advanced Research\nProjects Agency (DARPA)), in essence creating a network of networks, was"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 139,
    "text": "done by Vinton Cerf and Robert Kahn [Cerf 1974]; the term internetting\nwas coined to describe this work. These architectural principles were embodied in TCP. The early\nversions of TCP, however, were quite different from today’s TCP. The early\nversions of TCP combined a reliable in-sequence delivery of data via end-\nsystem retransmission (still part of today’s TCP) with forwarding functions\n(which today are performed by IP). Early experimentation with TCP,\ncombined with the recognition of the importance of an unreliable, non-\nflow-controlled, end-to-end transport service for applications such as\npacketized voice, led to the separation of IP out of TCP and the\ndevelopment of the UDP protocol. The three key Internet protocols that we\nsee today—TCP, UDP, and IP—were conceptually in place by the end of\nthe 1970s. In addition to the DARPA Internet-related research, many other\nimportant networking activities were underway. In Hawaii, Norman\nAbramson was developing ALOHAnet, a packet-based radio network that\nallowed multiple remote sites on the Hawaiian Islands to communicate with\neach other. The ALOHA protocol [Abramson 1970] was the first multiple-\naccess protocol, allowing geographically distributed users to share a single\nbroadcast communication medium (a radio ­frequency). Metcalfe and Boggs\nbuilt on Abramson’s multiple-access protocol work when they developed\nthe Ethernet protocol [Metcalfe 1976] for wire-based shared broadcast\nnetworks. Interestingly, Metcalfe and Boggs’ Ethernet protocol was\nmotivated by the need to connect multiple PCs, printers, and shared disks\n[Perkins 1994]. Twenty-five years ago, well before the PC revolution and\nthe explosion of networks, Metcalfe and Boggs were laying the foundation\nfor today’s PC LANs."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 140,
    "text": "1.7.3 A Proliferation of Networks: 1980–1990\nBy the end of the 1970s, approximately two hundred hosts were connected\nto the ARPAnet. By the end of the 1980s the number of hosts connected to\nthe public ­Internet, a confederation of networks looking much like today’s\nInternet, would reach a hundred thousand. The 1980s would be a time of\ntremendous growth. Much of that growth resulted from several distinct efforts to create\ncomputer networks linking universities together. BITNET provided e-mail\nand file transfers among several universities in the Northeast. CSNET\n(computer science network) was formed to link university researchers who\ndid not have access to ARPAnet. In 1986, NSFNET was created to provide\naccess to NSF-sponsored supercomputing centers. Starting with an initial\nbackbone speed of 56 kbps, NSFNET’s backbone would be running at 1.5\nMbps by the end of the decade and would serve as a primary backbone\nlinking regional networks. In the ARPAnet community, many of the final pieces of today’s Internet\narchitecture were falling into place. January 1, 1983 saw the official\ndeployment of TCP/IP as the new standard host protocol for ARPAnet\n(replacing the NCP pro­tocol). The transition [RFC 801] from NCP to\nTCP/IP was a flag day event—all hosts were required to transfer over to\nTCP/IP as of that day. In the late 1980s, important extensions were made to\nTCP to implement host-based congestion control [Jacobson 1988]. The\nDNS, used to map between a human-readable Internet name (for example,\ngaia.cs.umass.edu) and its 32-bit IP address, was also developed [RFC\n1034]. Paralleling this development of the ARPAnet (which was for the most\npart a US effort), in the early 1980s the French launched the Minitel project,\nan ambitious plan to bring data networking into everyone’s home."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 141,
    "text": "Sponsored by the French government, the Minitel system consisted of a\npublic packet-switched network (based on the X.25 protocol suite), Minitel\nservers, and inexpensive terminals with built-in low-speed modems. The\nMinitel became a huge success in 1984 when the French government gave\naway a free Minitel terminal to each French household that wanted one. Minitel sites included free sites—such as a telephone directory site—as\nwell as private sites, which collected a usage-based fee from each user. At\nits peak in the mid 1990s, it offered more than 20,000 services, ranging\nfrom home banking to specialized research databases. The Minitel was in a\nlarge proportion of French homes 10 years before most Americans had ever\nheard of the Internet. 1.7.4 The Internet Explosion: The 1990s\nThe 1990s were ushered in with a number of events that symbolized the\ncontinued evolution and the soon-to-arrive commercialization of the\nInternet. ARPAnet, the progenitor of the Internet, ceased to exist. In 1991,\nNSFNET lifted its restrictions on the use of NSFNET for commercial\npurposes. NSFNET itself would be decommissioned in 1995, with Internet\nbackbone traffic being carried by commercial Internet Service Providers. The main event of the 1990s was to be the emergence of the World\nWide Web application, which brought the Internet into the homes and\nbusinesses of millions of people worldwide. The Web served as a platform\nfor enabling and deploying hundreds of new applications that we take for\ngranted today, including search (e.g., Google and Bing) Internet commerce\n(e.g., Amazon and eBay) and social networks (e.g., Facebook). The Web was invented at CERN by Tim Berners-Lee between 1989 and\n1991 [Berners-Lee 1989], based on ideas originating in earlier work on"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 142,
    "text": "hypertext from the 1940s by Vannevar Bush [Bush 1945] and since the\n1960s by Ted Nelson [Xanadu 2012]. Berners-Lee and his associates\ndeveloped initial versions of HTML, HTTP, a Web server, and a browser—\nthe four key components of the Web. Around the end of 1993 there were\nabout two hundred Web servers in operation, this collection of servers being\njust a harbinger of what was about to come. At about this time several\nresearchers were developing Web browsers with GUI interfaces, including\nMarc Andreessen, who along with Jim Clark, formed Mosaic\nCommunications, \nwhich \nlater \nbecame \nNetscape \nCommunications\nCorporation [Cusumano 1998; Quittner 1998]. By 1995, university students\nwere using Netscape browsers to surf the Web on a daily basis. At about this\ntime companies—big and small—began to operate Web servers and transact\ncommerce over the Web. In 1996, Microsoft started to make browsers,\nwhich started the browser war between Netscape and Microsoft, which\nMicrosoft won a few years later [Cusumano 1998]. The second half of the 1990s was a period of tremendous growth and\ninnovation for the Internet, with major corporations and thousands of\nstartups creating Internet products and services. By the end of the\nmillennium the Internet was supporting hundreds of popular applications,\nincluding four killer applications:\n•\nE-mail, including attachments and Web-accessible e-mail\n•\nThe Web, including Web browsing and Internet commerce\n•\nInstant messaging, with contact lists\n•\nPeer-to-peer file sharing of MP3s, pioneered by Napster\nInterestingly, the first two killer applications came from the research\ncommunity, whereas the last two were created by a few young\nentrepreneurs."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 143,
    "text": "The period from 1995 to 2001 was a roller-coaster ride for the Internet\nin the financial markets. Before they were even profitable, hundreds of\nInternet startups made initial public offerings and started to be traded in a\nstock market. Many companies were valued in the billions of dollars\nwithout having any significant revenue streams. The Internet stocks\ncollapsed in 2000–2001, and many startups shut down. Nevertheless, a\nnumber of companies emerged as big winners in the Internet space,\nincluding Microsoft, Cisco, Yahoo, eBay, Google, and Amazon. 1.7.5 The New Millennium\nIn the first two decades of the 21st century, perhaps no other technology has\ntransformed society more than the Internet along with Internet-connected\nsmartphones. And innovation in computer networking continues at a rapid\npace. Advances are being made on all fronts, including deployments of\nfaster routers and higher transmission speeds in both access networks and in\nnetwork backbones. But the following developments merit special attention:\n•\nSince the beginning of the millennium, we have been seeing aggressive\ndeployment of broadband Internet access to homes—not only cable\nmodems and DSL but also fiber to the home, and now 5G fixed wireless\nas discussed in Section 1.2. This high-speed Internet access has set the\nstage for a wealth of video applications, including the distribution of\nuser-generated video (for example, YouTube), on-demand streaming of\nmovies and television shows (e.g., Netflix), and multi-person video\nconference (e.g., Skype, Facetime, and Google Hangouts). •\nThe increasing ubiquity of high-speed wireless Internet access is not\nonly making it possible to remain constantly connected while on the\nmove, but also enabling new location-specific applications such as Yelp,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 144,
    "text": "Tinder, and Waz. The number of wireless devices connecting to the\nInternet surpassed the number of wired devices in 2011. This high-\nspeed wireless access has set the stage for the rapid emergence of hand-\nheld computers (iPhones, Androids, iPads, and so on), which enjoy\nconstant and untethered access to the Internet. •\nOnline social networks—such as Facebook, Instagram, Twitter, and\nWeChat (hugely popular in China)—have created massive people\nnetworks on top of the Internet. Many of these social networks are\nextensively used for messaging as well as photo sharing. Many Internet\nusers today “live” primarily within one or more social networks. Through their APIs, the online social networks create platforms for new\nnetworked applications, including mobile payments and distributed\ngames. •\nAs discussed in Section 1.3.3, online service providers, such as Google\nand Microsoft, have deployed their own extensive private networks,\nwhich not only connect together their globally distributed data centers,\nbut are used to bypass the Internet as much as possible by peering\ndirectly with lower-tier ISPs. As a result, Google provides search results\nand e-mail access almost instantaneously, as if their data centers were\nrunning within one’s own computer. •\nMany Internet commerce companies are now running their applications\nin the “cloud”—such as in Amazon’s EC2, in Microsoft’s Azure, or in\nthe Alibaba Cloud. Many companies and universities have also\nmigrated their Internet applications (e.g., e-mail and Web hosting) to the\ncloud. Cloud companies not only provide applications scalable\ncomputing and storage environments, but also provide the applications\nimplicit access to their high-performance private networks."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 145,
    "text": "1.8 Summary\nIn this chapter, we’ve covered a tremendous amount of material! We’ve\nlooked at the various pieces of hardware and software that make up the\nInternet in particular and computer networks in general. We started at the\nedge of the network, looking at end systems and applications, and at the\ntransport service provided to the applications running on the end systems. We also looked at the link-layer technologies and physical media typically\nfound in the access network. We then dove deeper inside the network, into\nthe network core, identifying packet switching and circuit switching as the\ntwo basic approaches for transporting data through a telecommunication\nnetwork, and we examined the strengths and weaknesses of each approach. We also examined the structure of the global Internet, learning that the\nInternet is a network of networks. We saw that the Internet’s hierarchical\nstructure, consisting of higher- and lower-tier ISPs, has allowed it to scale\nto include thousands of networks. In the second part of this introductory chapter, we examined several\ntopics central to the field of computer networking. We first examined the\ncauses of delay, throughput and packet loss in a packet-switched network. We developed simple quantitative models for transmission, propagation,\nand queuing delays as well as for throughput; we’ll make extensive use of\nthese delay models in the homework problems throughout this book. Next\nwe examined protocol layering and service models, key architectural\nprinciples in networking that we will also refer back to throughout this\nbook. We also surveyed some of the more prevalent security attacks in the\nInternet day. We finished our introduction to networking with a brief history"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 146,
    "text": "of computer networking. The first chapter in itself constitutes a mini-course\nin computer networking. So, we have indeed covered a tremendous amount of ground in this first\nchapter! If you’re a bit overwhelmed, don’t worry. In the following\nchapters, we’ll revisit all of these ideas, covering them in much more detail\n(that’s a promise, not a threat!). At this point, we hope you leave this\nchapter with a still-developing intuition for the pieces that make up a\nnetwork, a still-developing command of the vocabulary of networking\n(don’t be shy about referring back to this chapter), and an ever-growing\ndesire to learn more about networking. That’s the task ahead of us for the\nrest of this book. Road-Mapping This Book\nBefore starting any trip, you should always glance at a road map in order to\nbecome familiar with the major roads and junctures that lie ahead. For the\ntrip we are about to embark on, the ultimate destination is a deep\nunderstanding of the how, what, and why of computer networks. Our road\nmap is the sequence of chapters of this book:\n1. Computer Networks and the Internet\n2. Application Layer\n3. Transport Layer\n4. Network Layer: Data Plane\n5. Network Layer: Control Plane\n6. The Link Layer and LANs\n7. Wireless and Mobile Networks\n8. Security in Computer Networks"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 147,
    "text": "Chapters 2 through 6 are the five core chapters of this book. You should\nnotice that these chapters are organized around the top four layers of the\nfive-layer Internet protocol. Further note that our journey will begin at the\ntop of the Internet protocol stack, namely, the application layer, and will\nwork its way downward. The rationale behind this top-down journey is that\nonce we understand the applications, we can understand the network\nservices needed to support these applications. We can then, in turn, examine\nthe various ways in which such services might be implemented by a\nnetwork architecture. Covering applications early thus provides motivation\nfor the remainder of the text. The second half of the book—Chapters 7 and 8—zooms in on two\nenormously important (and somewhat independent) topics in modern\ncomputer networking. In Chapter 7, we examine wireless and mobile\nnetworks, including wireless LANs (including WiFi and Bluetooth),\nCellular networks (including 4G and 5G), and mobility. Chapter 8, which\naddresses security in computer networks, first looks at the underpinnings of\nencryption and network security, and then we examine how the basic theory\nis being applied in a broad range of Internet contexts."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 148,
    "text": "Homework Problems and Questions\nChapter 1 Review Questions\nSECTION 1.1\nR1. What is the difference between a host and an end system? List several\ndifferent types of end systems. Is a Web server an end system? R2. Describe the protocol that might be used by two people having a\ntelephonic conversation to initiate and end the conversation, i.e., the\nway that they talk. R3. Why are standards important for protocols? SECTION 1.2\nR4. List four access technologies. Classify each one as home access,\nenterprise access, or wide-area wireless access. R5. Is HFC transmission rate dedicated or shared among users? Are\ncollisions possible in a downstream HFC channel? Why or why not? R6. What access network technologies would be most suitable for\nproviding internet access in rural areas? R7. Dial-up modems and DSL both use the telephone line (a twisted-pair\ncopper cable) as their transmission medium. Why then is DSL much\nfaster than dial-up access? R8. What are some of the physical media that Ethernet can run over? R9. HFC, DSL, and FTTH are all used for residential access. For each of\nthese access technologies, provide a range of ­transmission rates and\ncomment on whether the transmission rate is shared or dedicated."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 149,
    "text": "R10. Describe the different wireless technologies you use during the day\nand their characteristics. If you have a choice between multiple\ntechnologies, why do you prefer one over another? SECTION 1.3\nR11. Suppose there is exactly one packet switch between a sending host\nand a receiving host. The transmission rates between the sending host\nand the switch and between the switch and the receiving host are R\nand R , respectively. Assuming that the switch uses store-and-forward\npacket switching, what is the total end-to-end delay to send a packet\nof length L? (Ignore queuing, propagation delay, and processing\ndelay.) R12. What advantage does a circuit-switched network have over a packet-\nswitched network? What advantages does TDM have over FDM in a\ncircuit-switched network? R13. Suppose users share a 2 Mbps link. Also suppose each user transmits\ncontinuously at 1 Mbps when transmitting, but each user transmits\nonly 20 percent of the time. (See the discussion of statistical\nmultiplexing in Section 1.3.) a. When circuit switching is used, how many users can be\nsupported? b. For the remainder of this problem, suppose packet switching is\nused. Why will there be essentially no queuing delay before the\nlink if two or fewer users transmit at the same time? Why will\nthere be a queuing delay if three users transmit at the same time? c. Find the probability that a given user is transmitting. d. Suppose now there are three users. Find the probability that at\nany given time, all three users are transmitting simultaneously. Find the fraction of time during which the queue grows. 2"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 150,
    "text": "R14. Why will two ISPs at the same level of the hierarchy often peer with\neach other? How does an IXP earn money? R15. Why is a content provider considered a different Internet entity\ntoday? How does a content provider connect to other ISPs? Why? SECTION 1.4\nR16. Consider sending a packet from a source host to a destination host\nover a fixed route. List the delay components in the end-to-end delay. Which of these delays are constant and which are variable? R17. Visit the Transmission Versus Propagation Delay interactive\nanimation at the Companion Website. Among the rates, propagation\ndelay, and packet sizes available, find a combination for which the\nsender finishes transmitting before the first bit of the packet reaches\nthe receiver. Find another combination for which the first bit of the\npacket reaches the receiver before the sender finishes transmitting. R18. A user can directly connect to a server through either long-range\nwireless or a twisted-pair cable for transmitting a 1500-bytes file. The\ntransmission rates of the wireless and wired media are 2 and 100\nMbps, respectively. Assume that the propagation speed in air is 3 ×\n10  m/s, while the speed in the twisted pair is 2 × 10  m/s. If the user\nis located 1 km away from the server, what is the nodal delay when\nusing each of the two technologies? R19. Suppose Host A wants to send a large file to Host B. The path from\nHost A to Host B has three links, of rates R  = 500 kbps, R  = 2 Mbps,\nand R  = 1 Mbps. a. Assuming no other traffic in the network, what is the throughput\nfor the file transfer? 8\n2"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 151,
    "text": "b. Suppose the file is 4 million bytes. Dividing the file size by the\nthroughput, roughly how long will it take to transfer the file to\nHost B? c. Repeat (a) and (b), but now with R  reduced to 100 kbps. R20. Suppose end system A wants to send a large file to end system B. At a\nvery high level, describe how end system A creates packets from the\nfile. When one of these packets arrives to a router, what information\nin the packet does the router use to determine the link onto which the\npacket is forwarded? Why is packet switching in the Internet\nanalogous to driving from one city to another and asking directions\nalong the way? R21. Visit the Queuing and Loss interactive animation at the Companion\nWebsite. What is the maximum emission rate and the minimum\ntransmission rate? With those rates, what is the traffic intensity? Run\nthe interactive animation with these rates and determine how long it\ntakes for packet loss to occur. Then repeat the experiment a second\ntime and determine again how long it takes for packet loss to occur. Are the values different? Why or why not? SECTION 1.5\nR22. If two end-systems are connected through multiple routers and the\ndata-link level between them ensures reliable data delivery, is a\ntransport protocol ­offering reliable data delivery between these two\nend-systems necessary? Why? R23. What are the five layers in the Internet protocol stack? What are the\nprincipal responsibilities of each of these layers? R24. What do encapsulation and de-encapsulation mean? Why are they\nneeded in a layered protocol stack?"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 152,
    "text": "R25. Which layers in the Internet protocol stack does a router process? Which layers does a link-layer switch process? Which layers does a\nhost process? SECTION 1.6\nR26. What is self-replicating malware? R27. Describe how a botnet can be created and how it can be used for a\nDDoS attack. R28. Suppose Alice and Bob are sending packets to each other over a\ncomputer network. Suppose Trudy positions herself in the network so\nthat she can capture all the packets sent by Alice and send whatever\nshe wants to Bob; she can also capture all the packets sent by Bob\nand send whatever she wants to Alice. List some of the malicious\nthings Trudy can do from this position. Problems\nP1. Design and describe an application-level protocol to be used between\nan automatic teller machine and a bank’s centralized computer. Your\nprotocol should allow a user’s card and password to be verified, the\naccount balance (which is maintained at the centralized computer) to\nbe queried, and an account withdrawal to be made (that is, money\ndisbursed to the user). Your protocol entities should be able to handle\nthe all-too-common case in which there is not enough money in the\naccount to cover the withdrawal. Specify your protocol by listing the\nmessages exchanged and the action taken by the automatic teller\nmachine or the bank’s centralized computer on transmission and\nreceipt of messages. Sketch the operation of your protocol for the\ncase of a simple withdrawal with no errors, using a diagram similar to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 153,
    "text": "that in Figure 1.2. Explicitly state the assumptions made by your\nprotocol about the underlying end-to-end transport service. P2. Equation 1.1 gives a formula for the end-to-end delay of sending one\npacket of length L over N links of transmission rate R. Generalize this\nformula for sending P such packets back-to-back over the N links. P3. Consider an application that transmits data at a steady rate (for\nexample, the sender generates an N-bit unit of data every k time units,\nwhere k is small and fixed). Also, when such an application starts, it\nwill continue running for a relatively long period of time. Answer the\nfollowing questions, briefly justifying your answer:\na. Would a packet-switched network or a circuit-switched network\nbe more appropriate for this application? Why? b. Suppose that a packet-switched network is used and the only\ntraffic in this network comes from such applications as described\nabove. Furthermore, assume that the sum of the application data\nrates is less than the capacities of each and every link. Is some\nform of congestion control needed? Why? P4. Consider the circuit-switched network in Figure 1.13. Recall that\nthere are four circuits on each link. Label the four switches A, B, C,\nand D, going in the clockwise direction. a. What is the maximum number of simultaneous connections that\ncan be in progress at any one time in this network? b. Suppose that all connections are between switches A and C. What\nis the maximum number of simultaneous connections that can be\nin progress? c. Suppose we want to make four connections between switches A\nand C, and another four connections between switches B and D."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 154,
    "text": "Can we route these calls through the four links to accommodate\nall eight ­connections? P5. Review the car-caravan analogy in Section 1.4. Assume a propagation\nspeed of 100 km/hour. a. Suppose the caravan travels 175 km, beginning in front of one\ntollbooth, passing through a second tollbooth, and finishing just\nafter a third tollbooth. What is the end-to-end delay? b. Repeat (a), now assuming that there are eight cars in the caravan\ninstead of ten. P6. This elementary problem begins to explore propagation delay and\ntransmission delay, two central concepts in data networking. Consider\ntwo hosts, A and B, connected by a single link of rate R bps. Suppose\nthat the two hosts are separated by m meters, and suppose the\npropagation speed along the link is s meters/sec. Host A is to send a\npacket of size L bits to Host B.\nVideoNote\nExploring propagation delay and transmission delay\na. Express the propagation delay, d\n, in terms of m and s.\nb. Determine the transmission time of the packet, d\n, in terms of L\nand R.\nc. Ignoring processing and queuing delays, obtain an expression for\nthe end-to-end delay. d. Suppose Host A begins to transmit the packet at time t = 0. At\ntime t = d\n, where is the last bit of the packet? e. Suppose d\n is greater than d\n. At time t = d\n, where is the\nfirst bit of the packet? prop\ntrans\ntrans\nprop\ntrans\ntrans"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 155,
    "text": "f. Suppose d\n is less than d\n. At time t = d\n, where is the first\nbit of the packet? g. Suppose s = 2.5 · 10 , L = 1500 bytes, and R = 10 Mbps. Find the\ndistance m so that d\n equals d\n. P7. In this problem, we consider sending real-time voice from Host A to\nHost B over a packet-switched network (VoIP). Host A converts\nanalog voice to a digital 64 kbps bit stream on the fly. Host A then\ngroups the bits into 56-byte packets. There is one link between Hosts\nA and B; its transmission rate is 10 Mbps and its propagation delay is\n10 msec. As soon as Host A gathers a packet, it sends it to Host B. As\nsoon as Host B receives an entire packet, it converts the packet’s bits\nto an analog signal. How much time elapses from the time a bit is\ncreated (from the original analog signal at Host A) until the bit is\ndecoded (as part of the analog signal at Host B)? P8. Suppose users share a 10 Mbps link. Also suppose each user requires\n200 kbps when transmitting, but each user transmits only 10 percent\nof the time. (See the discussion of packet switching versus circuit\nswitching in Section 1.3.) a. When circuit switching is used, how many users can be\nsupported? b. For the remainder of this problem, suppose packet switching is\nused. Find the probability that a given user is transmitting. c. Suppose there are 120 users. Find the probability that at any\ngiven time, exactly n users are transmitting simultaneously. (Hint: Use the binomial distribution.) d. Find the probability that there are 51 or more users transmitting ­-\nsimultaneously. prop\ntrans\ntrans\nprop\ntrans"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 156,
    "text": "P9. Consider the discussion in Section 1.3 of packet switching versus\ncircuit switching in which an example is provided with a 1 Mbps link. Users are generating data at a rate of 100 kbps when busy, but are\nbusy generating data only with probability p = 0.1. Suppose that the 1\nMbps link is replaced by a 1 Gbps link. a. What is N, the maximum number of users that can be supported\nsimultaneously under circuit switching? b. Now consider packet switching and a user population of M users. Give a formula (in terms of p, M, N) for the probability that more\nthan N users are sending data. P10. Consider the network illustrated in Figure 1.16. Assume the two hosts\non the left of the figure start transmitting packets of 1500 bytes at the\nsame time towards Router B. Suppose the link rates between the hosts\nand Router A is 4-Mbps. One link has a 6-ms propagation delay and\nthe other has a 2-ms propagation delay. Will queuing delay occur at\nRouter A? P11. Consider the scenario in Problem P10 again, but now assume the links\nbetween the hosts and Router A have different rates R  and R  byte/s\nin addition to different propagation delays d  and d . Assume the\npacket lengths for the two hosts are of L bytes. For what values of the\npropagation delay will no queuing delay occur at Router A? P12. Consider a client and a server connected through one router. Assume\nthe router can start transmitting an incoming packet after receiving its\nfirst h bytes instead of the whole packet. Suppose that the link rates\nare R byte/s and that the client transmits one packet with a size of L\nbytes to the server. What is the end-to-end delay? Assume the\npropagation, processing, and queuing delays are negligible. 2\n2"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 157,
    "text": "Generalize the previous result to a scenario where the client and the\nserver are interconnected by N routers. P13. (a) Suppose N packets arrive simultaneously to a link at which no\npackets are currently being transmitted or queued. Each packet is\nof length L and the link has transmission rate R. What is the\naverage queuing delay for the N packets? (b) Now suppose that N such packets arrive to the link every LN/R\nseconds. What is the average queuing delay of a packet? P14. Consider the queuing delay in a router buffer. Let I denote traffic\nintensity; that is, I = La/R. Suppose that the queuing delay takes the\nform IL/R (1 − I) for I < 1.\na. Provide a formula for the total delay, that is, the queuing delay\nplus the transmission delay. b. Plot the total delay as a function of L /R. P15. Let a denote the rate of packets arriving at a link in packets/sec, and\nlet µ denote the link’s transmission rate in packets/sec. Based on the\nformula for the total delay (i.e., the queuing delay plus the\ntransmission delay) derived in the previous problem, derive a formula\nfor the total delay in terms of a and µ.\nP16. Consider a router buffer preceding an outbound link. In this problem,\nyou will use Little’s formula, a famous formula from queuing theory. Let N denote the average number of packets in the buffer plus the\npacket being transmitted. Let a denote the rate of packets arriving at\nthe link. Let d denote the average total delay (i.e., the queuing delay\nplus the transmission delay) experienced by a packet. Little’s formula\nis N = a · d. Suppose that on average, the buffer contains 100 packets,\nand the average packet queuing delay is 20 msec. The link’s"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 158,
    "text": "transmission rate is 100 packets/sec. Using Little’s formula, what is\nthe average packet arrival rate, assuming there is no packet loss? P17. Consider the network illustrated in Figure 1.12. Would Equation 1.2\nhold in such a scenario? If so, under which conditions? If not, why? (Assume N is the number of links between a source and a destination\nin the figure.) P18. Perform a Traceroute between source and destination on the same\ncontinent at three different hours of the day. VideoNote\nUsing Traceroute to discover network paths and measure network delay\na. Find the average and standard deviation of the round-trip delays\nat each of the three hours. b. Find the number of routers in the path at each of the three hours. Did the paths change during any of the hours? c. Try to identify the number of ISP networks that the Traceroute\npackets pass through from source to destination. Routers with\nsimilar names and/or similar IP addresses should be considered\nas part of the same ISP. In your experiments, do the largest delays\noccur at the peering interfaces between adjacent ISPs? d. Repeat the above for a source and destination on different\ncontinents. Compare the intra-continent and inter-continent\nresults. P19. Metcalfe’s law states the value of a computer network is proportional\nto the square of the number of connected users of the system. Let n\ndenote the number of users in a computer network. Assuming each"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 159,
    "text": "user sends one message to each of the other users, how many\nmessages will be sent? Does your answer support Metcalfe’s law? P20. Consider the throughput example corresponding to Figure 1.20(b). Now suppose that there are M client-server pairs rather than 10. Denote R , R , and R for the rates of the server links, client links, and\nnetwork link. Assume all other links have abundant capacity and that\nthere is no other traffic in the network besides the traffic generated by\nthe M client-server pairs. Derive a general expression for throughput\nin terms of R , R , R, and M.\nP21. Assume a client and a server can connect through either network (a)\nor (b) in Figure 1.19. Assume that R  = (R  + R ) / i, for i = 1, 2, ..., N.\nIn what case will network (a) have a higher throughput than network\n(b)? P22. Consider Figure 1.19(b). Suppose that each link between the server\nand the client has a packet loss probability p, and the packet loss\nprobabilities for these links are independent. What is the probability\nthat a packet (sent by the server) is successfully received by the\nreceiver? If a packet is lost in the path from the server to the client,\nthen the server will re-transmit the packet. On average, how many\ntimes will the server re-transmit the packet in order for the client to\nsuccessfully receive the packet? P23. Consider Figure 1.19(a). Assume that we know the bottleneck link\nalong the path from the server to the client is the first link with rate R\nbits/sec. Suppose we send a pair of packets back to back from the\nserver to the client, and there is no other traffic on this path. Assume\neach packet of size L bits, and both links have the same propagation\ndelay d\n. s\nc\ns\nc\ni\nc\ns\ns\nprop"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 160,
    "text": "a. What is the packet inter-arrival time at the destination? That is,\nhow much time elapses from when the last bit of the first packet\narrives until the last bit of the second packet arrives? b. Now assume that the second link is the bottleneck link (i.e., R  <\nR ). Is it possible that the second packet queues at the input queue\nof the second link? Explain. Now suppose that the server sends\nthe second packet T seconds after sending the first packet. How\nlarge must T be to ensure no queuing before the second link? Explain. P24. Consider a user who needs to transmit 1.5 gigabytes of data to a\nserver. The user lives in a village where only dial-up access is\navailable. As an alternative, a bus collects data from users in rural\nareas and transfer them to the Internet through a 1 Gbps link once it\ngets back to the city. The bus visits the village once a day and stops in\nfront of the user’s house just long enough to receive the data. The bus\nhas a 100 Mbps WiFi connection. Suppose the average speed of the\nbus is 60 km/h and that the distance between the village and the city\nis 150 km. What is the fastest way the user can transfer the data to the\nserver? P25. Suppose two hosts, A and B, are separated by 20,000 kilometers and\nare connected by a direct link of R = 5 Mbps. Suppose the\npropagation speed over the link is 2.5 · 10  meters/sec. a. Calculate the bandwidth-delay product, R · d\n. b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose the file is sent continuously as one large message. What\nis the maximum number of bits that will be in the link at any\ngiven time? c. Provide an interpretation of the bandwidth-delay product. c\ns\nprop"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 161,
    "text": "d. What is the width (in meters) of a bit in the link? Is it longer than\na ­football field? e. Derive a general expression for the width of a bit in terms of the\npropagation speed s, the transmission rate R, and the length of the\nlink m.\nP26. Consider problem P25 but now with a link of R = 1 Gbps. a. Calculate the bandwidth-delay product, R · d\n. b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose the file is sent continuously as one big message. What is\nthe maximum number of bits that will be in the link at any given\ntime? c. What is the width (in meters) of a bit in the link? P27. Consider the scenario illustrated in Figure 1.19(a). Assume R  is 20\nMbps, R  is 10 Mbps, and the server is continuously sending traffic to\nthe client. Also assume the router between the server and the client\ncan buffer at most four messages. After how many messages sent by\nthe server will packet loss starts occurring at the router? P28. Generalize the result obtained in Problem P27 for the case where the\nrouter can buffer m messages. P29. Suppose there is a 10 Mbps microwave link between a geostationary\nsatellite and its base station on Earth. Every minute the satellite takes\na digital photo and sends it to the base station. Assume a propagation\nspeed of 2.4 · 10  meters/sec. a. What is the propagation delay of the link? b. What is the bandwidth-delay product, R · d\n? c. Let x denote the size of the photo. What is the minimum value of\nx for the microwave link to be continuously transmitting? prop\ns\nc\nprop"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 162,
    "text": "P30. Consider the airline travel analogy in our discussion of layering in\nSection 1.5, and the addition of headers to protocol data units as they\nflow down the protocol stack. Is there an equivalent notion of header\ninformation that is added to passengers and baggage as they move\ndown the airline protocol stack? P31. In modern packet-switched networks, including the Internet, the\nsource host segments long, application-layer messages (for example,\nan image or a music file) into smaller packets and sends the packets\ninto the network. The receiver then reassembles the packets back into\nthe original message. We refer to this process as message\nsegmentation. Figure 1.27 illustrates the end-to-end transport of a\nmessage with and without message segmentation. Consider a message\nthat is 10  bits long that is to be sent from source to destination in\nFigure 1.27. Suppose each link in the figure is 5 Mbps. Ignore\npropagation, queuing, and processing delays. Figure 1.27 ♦End-to-end message transport: (a) without\nmessage segmentation; (b) with message\nsegmentation"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 163,
    "text": "a. Consider sending the message from source to destination without\nmessage segmentation. How long does it take to move the\nmessage from the source host to the first packet switch? Keeping\nin mind that each switch uses store-and-forward packet\nswitching, what is the total time to move the message from\nsource host to destination host? b. Now suppose that the message is segmented into 100 packets,\nwith each packet being 10,000 bits long. How long does it take to\nmove the first packet from source host to the first switch? When\nthe first packet is being sent from the first switch to the second\nswitch, the second packet is being sent from the source host to\nthe first switch. At what time will the second packet be fully\nreceived at the first switch? c. How long does it take to move the file from source host to\ndestination host when message segmentation is used? Compare\nthis result with your answer in part (a) and comment. d. In addition to reducing delay, what are reasons to use message ­-\nsegmentation? e. Discuss the drawbacks of message segmentation. P32. Consider Problem P31 and assume that the propagation delay is 250\nms. Recalculate the total time needed to transfer the source data with\nand without segmentation. Is segmentation more beneficial or less if\nthere is propagation delay? P33. Consider sending a large file of F bits from Host A to Host B. There\nare three links (and two switches) between A and B, and the links are\nuncongested (that is, no queuing delays). Host A segments the file\ninto segments of S bits each and adds 80 bits of header to each\nsegment, forming packets of L = 80 + S bits. Each link has a"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 164,
    "text": "transmission rate of R bps. Find the value of S that minimizes the\ndelay of moving the file from Host A to Host B. Disregard\npropagation delay. P34. Early versions of TCP combined functions for both forwarding and\nreliable delivery. How are these TCP variants located in the ISO/OSI\nprotocol stack? Why were forwarding functions later separated from\nTCP? What were the consequences?"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 165,
    "text": "Wireshark Lab\n“Tell me and I forget. Show me and I remember. Involve me and I\nunderstand.”\nChinese proverb\nOne’s understanding of network protocols can often be greatly deepened by\nseeing them in action and by playing around with them—observing the\nsequence of messages exchanged between two protocol entities, delving\ninto the details of protocol operation, causing protocols to perform certain\nactions, and observing these actions and their consequences. This can be\ndone in simulated scenarios or in a real network environment such as the\nInternet. The interactive animations at the textbook Web site take the first\napproach. In the Wireshark labs, we’ll take the latter approach. You’ll run\nnetwork applications in various scenarios using a computer on your desk, at\nhome, or in a lab. You’ll observe the network protocols in your computer,\ninteracting and exchanging messages with protocol entities executing\nelsewhere in the Internet. Thus, you and your computer will be an integral\npart of these live labs. You’ll observe—and you’ll learn—by doing. The basic tool for observing the messages exchanged between\nexecuting protocol entities is called a packet sniffer. As the name suggests,\na packet sniffer passively copies (sniffs) messages being sent from and\nreceived by your computer; it also displays the contents of the various\nprotocol fields of these captured messages. A screenshot of the Wireshark\npacket sniffer is shown in Figure 1.28. Wireshark is a free packet sniffer\nthat runs on Windows, Linux/Unix, and Mac computers. Throughout the\ntextbook, you will find Wireshark labs that allow you to explore a number\nof the protocols studied in the chapter. In this first Wireshark lab, you’ll"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 167,
    "text": "AN INTERVIEW WITH…\nLeonard Kleinrock\nLeonard Kleinrock is a professor of computer science at the\nUniversity of California, Los Angeles. In 1969, his computer at\nUCLA became the first node of the Internet. His creation of\nthe mathematical theory of packet-switching principles in\n1961 became the technology behind the Internet. He received\nhis B.E.E. from the City College of New York (CCNY) and his\nmasters and PhD in electrical engineering from MIT. Courtesy of Leonard Kleinrock\nWhat made you decide to specialize in\nnetworking/Internet technology?"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 168,
    "text": "As a PhD student at MIT in 1959, I looked around\nand found that most of my classmates were doing\nresearch in the area of information theory and\ncoding theory that had been established by the\ngreat researcher, Claude Shannon. I judged that he\nhad solved most of the important problems already. The research problems that were left were hard and\nseemed to me to be of lesser consequence. So I\ndecided to launch out in a new area that no one\nelse had yet conceived of. Happily, at MIT I was\nsurrounded by many computers, and it was clear to\nme that, sooner or later, these machines would\nneed to communicate with each other. At the time,\nthere was no effective way for them to do so and\nthat the solution to this important problem would\nhave impact. I had an approach to this problem and\nso, for my PhD research, I decided to create a\nmathematical theory to model, evaluate, design\nand optimize efficient and reliable data networks. What was your first job in the computer\nindustry? What did it entail? I went to the evening session at CCNY from 1951\nto 1957 for my bachelor’s degree in electrical\nengineering. During the day, I worked first as a\ntechnician and then as an electrical engineer at a\nsmall, industrial electronics firm called Photobell. While there, I introduced digital technology to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 169,
    "text": "their product line. Essentially, we were using\nphotoelectric devices to detect the presence of\ncertain items (boxes, people, etc.) and the use of a\ncircuit known then as a bistable multivibrator was\njust what we needed to bring digital processing\ninto this field of detection. These circuits happen to\nbe the building blocks for computers, and have\ncome to be known as flip-flops or switches in\ntoday’s vernacular. What was going through your mind when\nyou sent the first host-to-host message\n(from UCLA to the Stanford Research\nInstitute)? Frankly, we had no idea of the importance of that\nevent. We had not prepared a special message of\nhistoric significance, as did so many inventors of\nthe past (Samuel Morse with “What hath God\nwrought.” or Alexander Graham Bell with\n“Watson, come here! I want you.” or Neal\nArmstrong with “That’s one small step for a man,\none giant leap for mankind.”) Those guys were\nsmart! They understood media and public\nrelations. All we wanted to do was to demonstrate\nour ability to remotely login to the SRI computer. So we typed the “L”, which was correctly\nreceived, we typed the “o” which was correctly\nreceived, and then we typed the “g” which caused"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 170,
    "text": "the SRI host computer to crash! So, it turned out\nthat our message was the shortest and perhaps the\nmost prophetic message ever, namely “Lo!” as in\n“Lo and behold!”\nEarlier that year, I was quoted in a UCLA\npress release saying that once the network was up\nand running, it would be possible to gain access to\ncomputer utilities from our homes and offices as\neasily as we gain access to electricity and\ntelephone connectivity. So my vision at that time\nwas that the Internet would be ubiquitous, always\non, always available, anyone with any device could\nconnect from any location, and it would be\ninvisible. However, I never anticipated that my 99-\nyear-old mother would use the Internet at the same\ntime that my 5 year-old granddaughter was—and\nindeed she did! What is your vision for the future of\nnetworking? The easy part of the vision is to predict the\ninfrastructure itself. I anticipate that we will see\nconsiderable deployment of wireless and mobile\ndevices in smart spaces to produce what I like to\nrefer to as the Invisible Internet. This step will\nenable us to move out from the netherworld of\ncyberspace to the physical world of smart spaces. Our environments (desks, walls, vehicles, watches,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 171,
    "text": "belts, fingernails, bodies and so on) will come\nalive with technology, through actuators, sensors,\nlogic, processing, storage, cameras, microphones,\nspeakers, displays, and communication. This\nembedded technology will allow our environment\nto provide the IP services wherever and whenever\nwe want. When I walk into a room, the room will\nknow I entered. I will be able to communicate with\nmy environment naturally, as in spoken English,\nhaptics, gestures, and eventually through brain-\nInternet interfaces; my requests will generate\nreplies that present Web pages to me from wall\ndisplays, through my eyeglasses, as speech,\nholograms, and so forth. Looking a bit further out,\nI see a networking future that includes the\nfollowing additional key components. I see\ncustomized intelligent software agents deployed\nacross the network whose function it is to mine\ndata, act on that data, observe trends, and carry out\ntasks dynamically and adaptively. I see the\ndeployment of blockchain technology that provides\nirrefutable, immutable distributed ledgers coupled\nwith reputation systems that provide credibility to\nthe contents and functionality. I see considerably\nmore network traffic generated not so much by\nhumans, but by the embedded devices, the\nintelligent software agents and the distributed\nledgers. I see large collections of self-organizing"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 172,
    "text": "systems controlling this vast, fast network. I see\nhuge amounts of information flashing across this\nnetwork instantaneously with this information\nundergoing enormous processing and filtering. The\nInvisible Internet will essentially be a pervasive\nglobal nervous system . I see all these things and\nmore as we move headlong through the twenty-\nfirst century. The harder part of the vision is to predict the\napplications and services, which have consistently\nsurprised us in dramatic ways (e-mail, search\ntechnologies, the World Wide Web, blogs, peer-to-\npeer networks, social networks, user generated\ncontent, sharing of music, photos, and videos, etc.). These applications have “come of the blue”,\nsudden, unanticipated and explosive. What a\nwonderful world for the next generation to\nexplore! What people have inspired you\nprofessionally? By far, it was Claude Shannon from MIT, a\nbrilliant researcher who had the ability to relate his\nmathematical ideas to the physical world in highly\nintuitive ways. He was a superb member of my\nPhD thesis committee."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 173,
    "text": "Do you have any advice for students\nentering the networking/Internet field? The Internet and all that it enables is a vast new\nfrontier, continuously full of amazing challenges. There is room for great innovation. Don’t be\nconstrained by today’s technology. Reach out and\nimagine what could be and then make it happen."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 174,
    "text": "Application Layer\nNetwork applications are the raisons d’être of\na computer network—if we couldn’t conceive\nof any useful applications, there wouldn’t be\nany need for networking infrastructure and\nprotocols to support them. Since the Internet’s\ninception, numerous useful and entertaining\napplications have indeed been created. These\napplications have been the driving force\nbehind the Internet’s success, motivating\npeople in homes, schools, governments, and\nbusinesses to make the Internet an integral\npart of their daily activities. Internet applications include the classic\ntext-based applications that became popular\nin the 1970s and 1980s: text e-mail, remote\naccess to computers, file transfers, and\nnewsgroups. They \ninclude \nthe \nkiller\napplication of the mid-1990s, the World Wide\nWeb, encompassing Web surfing, search, and\nelectronic commerce. Since the beginning of\nnew millennium, new and highly compelling\napplications continue to emerge, including"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 175,
    "text": "voice over IP and video conferencing such as\nSkype, Facetime, and Google Hangouts; user\ngenerated video such as YouTube and movies\non demand such as Netflix; and multiplayer\nonline games such as Second Life and World\nof Warcraft. During this same period, we have\nseen the emergence of a new generation of\nsocial networking applications—such as\nFacebook, Instagram, and Twitter—which\nhave created human networks on top of the\nInternet’s \nnetwork \nor \nrouters \nand\ncommunication links. And most recently,\nalong with the arrival of the smartphone and\nthe ubiquity of 4G/5G wireless Internet\naccess, there has been a profusion of location\nbased mobile apps, including popular check-\nin, dating, and road-traffic forecasting apps\n(such as Yelp, Tinder, and Waz), mobile\npayment apps (such as WeChat and Apple\nPay) and messaging apps (such as WeChat\nand WhatsApp). Clearly, there has been no\nslowing down of new and exciting Internet\napplications. Perhaps some of the readers of\nthis text will create the next generation of\nkiller Internet applications!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 176,
    "text": "In this chapter, we study the conceptual and implementation aspects of\nnetwork applications. We begin by defining key application-layer concepts,\nincluding network services required by applications, clients and servers,\nprocesses, and transport-layer interfaces. We examine several network\napplications in detail, including the Web, e-mail, DNS, peer-to-peer (P2P)\nfile distribution, and video streaming. We then cover network application\ndevelopment, over both TCP and UDP. In particular, we study the socket\ninterface and walk through some simple client-server applications in\nPython. We also provide several fun and interesting socket programming\nassignments at the end of the chapter. The application layer is a particularly good place to start our study of\nprotocols. It’s familiar ground. We’re acquainted with many of the\napplications that rely on the protocols we’ll study. It will give us a good feel\nfor what protocols are all about and will introduce us to many of the same\nissues that we’ll see again when we study transport, network, and link layer\nprotocols."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 177,
    "text": "2.1 Principles of Network Applications\nSuppose you have an idea for a new network application. Perhaps this\napplication will be a great service to humanity, or will please your\nprofessor, or will bring you great wealth, or will simply be fun to develop. Whatever the motivation may be, let’s now examine how you transform the\nidea into a real-world network application. At the core of network application development is writing programs\nthat run on different end systems and communicate with each other over the\nnetwork. For example, in the Web application there are two distinct\nprograms that communicate with each other: the browser program running\nin the user’s host (desktop, laptop, tablet, smartphone, and so on); and the\nWeb server program running in the Web server host. As another example, in\na Video on Demand application such as Netflix (see Section 2.6), there is a\nNetflix-provided program running on the user’s smartphone, tablet, or\ncomputer; and a Netflix server program running on the Netflix server host. Servers often (but certainly not always) are housed in a data center, as\nshown in Figure 2.1."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 178,
    "text": "Figure 2.1 ♦Communication for a network application takes place\nbetween end systems at the application layer\nThus, when developing your new application, you need to write\nsoftware that will run on multiple end systems. This software could be\nwritten, for example, in C, Java, or Python. Importantly, you do not need to\nwrite software that runs on network-core devices, such as routers or link-"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 179,
    "text": "layer switches. Even if you wanted to write application software for these\nnetwork-core devices, you wouldn’t be able to do so. As we learned in\nChapter 1, and as shown earlier in Figure 1.24, network-core devices do not\nfunction at the application layer but instead function at lower layers—\nspecifically at the network layer and below. This basic design—namely,\nconfining application software to the end systems—as shown in Figure 2.1,\nhas facilitated the rapid development and deployment of a vast array of\nnetwork applications. 2.1.1 Network Application Architectures\nBefore diving into software coding, you should have a broad architectural\nplan for your application. Keep in mind that an application’s architecture is\ndistinctly different from the network architecture (e.g., the five-layer\nInternet architecture discussed in Chapter 1). From the application\ndeveloper’s perspective, the network architecture is fixed and provides a\nspecific set of services to applications. The application architecture, on\nthe other hand, is designed by the application developer and dictates how\nthe application is structured over the various end systems. In choosing the\napplication architecture, an application developer will likely draw on one of\nthe two predominant architectural paradigms used in modern network\napplications: the client-server architecture or the peer-to-peer (P2P)\narchitecture. In a client-server architecture, there is an always-on host, called the\nserver, which services requests from many other hosts, called clients. A\nclassic example is the Web application for which an always-on Web server\nservices requests from browsers running on client hosts. When a Web server\nreceives a request for an object from a client host, it responds by sending"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 180,
    "text": "the requested object to the client host. Note that with the client-server\narchitecture, clients do not directly communicate with each other; for\nexample, in the Web application, two browsers do not directly\ncommunicate. Another characteristic of the client-server architecture is that\nthe server has a fixed, well-known address, called an IP address (which\nwe’ll discuss soon). Because the server has a fixed, well-known address,\nand because the server is always on, a client can always contact the server\nby sending a packet to the server’s IP address. Some of the better-known\napplications with a client-server architecture include the Web, FTP, Telnet,\nand e-mail. The client-server architecture is shown in Figure 2.2(a). Figure 2.2 ♦(a) Client-server architecture; (b) P2P architecture\nOften in a client-server application, a single-server host is incapable of\nkeeping up with all the requests from clients. For example, a popular social-"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 181,
    "text": "networking site can quickly become overwhelmed if it has only one server\nhandling all of its requests. For this reason, a data center, housing a large\nnumber of hosts, is often used to create a powerful virtual server. The most\npopular Internet services—such as search engines (e.g., Google, Bing,\nBaidu), Internet commerce (e.g., Amazon, eBay, Alibaba), Web-based e-\nmail (e.g., Gmail and Yahoo Mail), social media (e.g., Facebook, Instagram,\nTwitter, and WeChat)—run in one or more data centers. As discussed in\nSection 1.3.3, Google has 19 data centers distributed around the world,\nwhich collectively handle search, YouTube, Gmail, and other services. A\ndata center can have hundreds of thousands of servers, which must be\npowered and maintained. Additionally, the service providers must pay\nrecurring interconnection and bandwidth costs for sending data from their\ndata centers. In a P2P architecture, there is minimal (or no) reliance on dedicated\nservers in data centers. Instead the application exploits direct\ncommunication between pairs of intermittently connected hosts, called\npeers. The peers are not owned by the service provider, but are instead\ndesktops and laptops controlled by users, with most of the peers residing in\nhomes, universities, and offices. Because the peers communicate without\npassing through a dedicated server, the architecture is called peer-to-peer. An example of a popular P2P application is the file-sharing application\nBitTorrent. One of the most compelling features of P2P architectures is their self-\nscalability. For example, in a P2P file-sharing application, although each\npeer ­generates workload by requesting files, each peer also adds service\ncapacity to the system by distributing files to other peers. P2P architectures\nare also cost effective, since they normally don’t require significant server\ninfrastructure and server bandwidth (in contrast with clients-server designs"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 182,
    "text": "with datacenters). However, P2P applications face challenges of security,\nperformance, and reliability due to their highly ­decentralized structure. 2.1.2 Processes Communicating\nBefore building your network application, you also need a basic\nunderstanding of how the programs, running in multiple end systems,\ncommunicate with each other. In the jargon of operating systems, it is not\nactually programs but processes that communicate. A process can be\nthought of as a program that is running within an end system. When\nprocesses are running on the same end system, they can communicate with\neach other with interprocess communication, using rules that are governed\nby the end system’s operating system. But in this book, we are not\nparticularly interested in how processes in the same host communicate, but\ninstead in how processes running on different hosts (with potentially\ndifferent operating systems) communicate. Processes on two different end systems communicate with each other\nby exchanging messages across the computer network. A sending process\ncreates and sends messages into the network; a receiving process receives\nthese messages and possibly responds by sending messages back. Figure\n2.1 illustrates that processes communicating with each other reside in the\napplication layer of the five-layer protocol stack. Client and Server Processes\nA network application consists of pairs of processes that send messages to\neach other over a network. For example, in the Web application a client\nbrowser process exchanges messages with a Web server process. In a P2P\nfile-sharing system, a file is transferred from a process in one peer to a"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 183,
    "text": "process in another peer. For each pair of communicating processes, we\ntypically label one of the two processes as the client and the other process\nas the server. With the Web, a browser is a client process and a Web server\nis a server process. With P2P file sharing, the peer that is downloading the\nfile is labeled as the client, and the peer that is uploading the file is labeled\nas the server. You may have observed that in some applications, such as in P2P file\nsharing, a process can be both a client and a server. Indeed, a process in a\nP2P file-sharing system can both upload and download files. Nevertheless,\nin the context of any given communication session between a pair of\nprocesses, we can still label one process as the client and the other process\nas the server. We define the client and server processes as follows:\nIn the context of a communication session between a pair of processes,\nthe process that initiates the communication (that is, initially contacts\nthe other process at the beginning of the session) is labeled as the\nclient. The process that waits to be contacted to begin the session is the\nserver. In the Web, a browser process initializes contact with a Web server\nprocess; hence the browser process is the client and the Web server process\nis the server. In P2P file sharing, when Peer A asks Peer B to send a specific\nfile, Peer A is the client and Peer B is the server in the context of this\nspecific communication session. When there’s no confusion, we’ll\nsometimes also use the terminology “client side and server side of an\napplication.” At the end of this chapter, we’ll step through simple code for\nboth the client and server sides of network applications. The Interface Between the Process and the Computer Network"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 184,
    "text": "As noted above, most applications consist of pairs of communicating\nprocesses, with the two processes in each pair sending messages to each\nother. Any message sent from one process to another must go through the\nunderlying network. A process sends messages into, and receives messages\nfrom, the network through a software interface called a socket. Let’s\nconsider an analogy to help us understand processes and sockets. A process\nis analogous to a house and its socket is analogous to its door. When a\nprocess wants to send a message to another process on another host, it\nshoves the message out its door (socket). This sending process assumes that\nthere is a transportation infrastructure on the other side of its door that will\ntransport the message to the door of the destination process. Once the\nmessage arrives at the destination host, the message passes through the\nreceiving process’s door (socket), and the receiving process then acts on the\nmessage. Figure 2.3 illustrates socket communication between two processes that\ncommunicate over the Internet. (Figure 2.3 assumes that the underlying\ntransport protocol used by the processes is the Internet’s TCP protocol.) As\nshown in this figure, a socket is the interface between the application layer\nand the transport layer within a host. It is also referred to as the Application\nProgramming Interface (API) between the application and the network,\nsince the socket is the programming interface with which network\napplications are built. The application developer has control of everything\non the application-layer side of the socket but has little control of the\ntransport-layer side of the socket. The only control that the application\ndeveloper has on the transport-layer side is (1) the choice of transport\nprotocol and (2) perhaps the ability to fix a few transport-layer parameters\nsuch as maximum buffer and maximum segment sizes (to be covered in\nChapter 3). Once the application developer chooses a transport protocol (if"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 185,
    "text": "a choice is available), the application is built using the transport-layer\nservices provided by that protocol. We’ll explore sockets in some detail in\nSection 2.7. Figure 2.3 ♦Application processes, sockets, and underlying\ntransport protocol\nAddressing Processes\nIn order to send postal mail to a particular destination, the destination needs\nto have an address. Similarly, in order for a process running on one host to\nsend packets to a process running on another host, the receiving process\nneeds to have an address. To identify the receiving process, two pieces of\ninformation need to be specified: (1)  the address of the host and (2) an\nidentifier that specifies the receiving process in the destination host. In the Internet, the host is identified by its IP address. We’ll discuss IP\naddresses in great detail in Chapter 4. For now, all we need to know is that\nan IP address is a 32-bit quantity that we can think of as uniquely"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 186,
    "text": "identifying the host. In addition to knowing the address of the host to which\na message is destined, the sending process must also identify the receiving\nprocess (more specifically, the receiving socket) running in the host. This\ninformation is needed because in general a host could be running many\nnetwork applications. A destination port number serves this purpose. Popular applications have been assigned specific port numbers. For\nexample, a Web server is identified by port number 80. A mail server\nprocess (using the SMTP protocol) is identified by port number 25. A list of\nwell-known port numbers for all Internet standard protocols can be found at\nwww.iana.org. We’ll examine port numbers in detail in Chapter 3. 2.1.3 Transport Services Available to Applications\nRecall that a socket is the interface between the application process and the\ntransport-layer protocol. The application at the sending side pushes\nmessages through the socket. At the other side of the socket, the transport-\nlayer protocol has the responsibility of getting the messages to the socket of\nthe receiving process. Many networks, including the Internet, provide more than one\ntransport-layer protocol. When you develop an application, you must\nchoose one of the available transport-layer protocols. How do you make\nthis choice? Most likely, you would study the services provided by the\navailable transport-layer protocols, and then pick the protocol with the\nservices that best match your application’s needs. The situation is similar to\nchoosing either train or airplane transport for travel between two cities. You\nhave to choose one or the other, and each transportation mode offers\ndifferent services. (For example, the train offers downtown pickup and\ndrop-off, whereas the plane offers shorter travel time.)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 187,
    "text": "What are the services that a transport-layer protocol can offer to\napplications invoking it? We can broadly classify the possible services\nalong four dimensions: reliable data transfer, throughput, timing, and\nsecurity. Reliable Data Transfer\nAs discussed in Chapter 1, packets can get lost within a computer network. For example, a packet can overflow a buffer in a router, or can be discarded\nby a host or router after having some of its bits corrupted. For many\napplications—such as electronic mail, file transfer, remote host access, Web\ndocument transfers, and financial applications—data loss can have\ndevastating consequences (in the latter case, for either the bank or the\ncustomer!). Thus, to support these applications, something has to be done to\nguarantee that the data sent by one end of the application is delivered\ncorrectly and completely to the other end of the application. If a protocol\nprovides such a guaranteed data delivery service, it is said to provide\nreliable data transfer. One important service that a transport-layer\nprotocol can potentially provide to an application is process-to-process\nreliable data transfer. When a transport protocol provides this service, the\nsending process can just pass its data into the socket and know with\ncomplete confidence that the data will arrive without errors at the receiving\nprocess. When a transport-layer protocol doesn’t provide reliable data transfer,\nsome of the data sent by the sending process may never arrive at the\nreceiving process. This may be acceptable for loss-tolerant applications,\nmost notably multimedia applications such as conversational audio/video\nthat can tolerate some amount of data loss. In these multimedia"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 188,
    "text": "applications, lost data might result in a small glitch in the audio/video—not\na crucial impairment. Throughput\nIn Chapter 1, we introduced the concept of available throughput, which, in\nthe context of a communication session between two processes along a\nnetwork path, is the rate at which the sending process can deliver bits to the\nreceiving process. Because other sessions will be sharing the bandwidth\nalong the network path, and because these other sessions will be coming\nand going, the available throughput can fluctuate with time. These\nobservations lead to another natural service that a transport-layer protocol\ncould provide, namely, guaranteed available throughput at some specified\nrate. With such a service, the application could request a guaranteed\nthroughput of r bits/sec, and the transport protocol would then ensure that\nthe available throughput is always at least r bits/sec. Such a guaranteed\nthroughput service would appeal to many applications. For example, if an\nInternet telephony application encodes voice at 32 kbps, it needs to send\ndata into the network and have data delivered to the receiving application at\nthis rate. If the transport protocol cannot provide this throughput, the\napplication would need to encode at a lower rate (and receive enough\nthroughput to sustain this lower coding rate) or may have to give up, since\nreceiving, say, half of the needed throughput is of little or no use to this\nInternet telephony application. Applications that have throughput\nrequirements are said to be bandwidth-sensitive applications. Many\ncurrent multimedia applications are bandwidth sensitive, although some\nmultimedia applications may use adaptive coding techniques to encode\ndigitized voice or video at a rate that matches the currently available\nthroughput."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 189,
    "text": "While bandwidth-sensitive applications have specific throughput\nrequirements, elastic applications can make use of as much, or as little,\nthroughput as happens to be available. Electronic mail, file transfer, and\nWeb transfers are all elastic applications. Of course, the more throughput,\nthe better. There’s an adage that says that one cannot be too rich, too thin, or\nhave too much throughput! Timing\nA transport-layer protocol can also provide timing guarantees. As with\nthroughput guarantees, timing guarantees can come in many shapes and\nforms. An example guarantee might be that every bit that the sender pumps\ninto the socket arrives at the receiver’s socket no more than 100 msec later. Such a service would be appealing to interactive real-time applications,\nsuch as Internet telephony, virtual environments, teleconferencing, and\nmultiplayer games, all of which require tight timing constraints on data\ndelivery in order to be effective, see [Gauthier 1999; Ramjee 1994]. Long\ndelays in Internet telephony, for example, tend to result in unnatural pauses\nin the conversation; in a multiplayer game or virtual interactive\nenvironment, a long delay between taking an action and seeing the response\nfrom the environment (for example, from another player at the end of an\nend-to-end connection) makes the application feel less realistic. For non-\nreal-time applications, lower delay is always preferable to higher delay, but\nno tight constraint is placed on the end-to-end delays. Security\nFinally, a transport protocol can provide an application with one or more\nsecurity services. For example, in the sending host, a transport protocol can\nencrypt all data transmitted by the sending process, and in the receiving"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 190,
    "text": "host, the transport-layer protocol can decrypt the data before delivering the\ndata to the receiving process. Such a service would provide confidentiality\nbetween the two processes, even if the data is somehow observed between\nsending and receiving processes. A transport protocol can also provide other\nsecurity services in addition to confidentiality, including data integrity and\nend-point authentication, topics that we’ll cover in detail in Chapter 8. 2.1.4 Transport Services Provided by the Internet\nUp until this point, we have been considering transport services that a\ncomputer network could provide in general. Let’s now get more specific\nand examine the type of transport services provided by the Internet. The\nInternet (and, more generally, TCP/IP networks) makes two transport\nprotocols available to applications, UDP and TCP. When you (as an\napplication developer) create a new network application for the Internet,\none of the first decisions you have to make is whether to use UDP or TCP. Each of these protocols offers a different set of services to the invoking\napplications. Figure 2.4 shows the service requirements for some selected\napplications."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 191,
    "text": "Figure 2.4 ♦Requirements of selected network applications\nTCP Services\nThe TCP service model includes a connection-oriented service and a\nreliable data transfer service. When an application invokes TCP as its\ntransport protocol, the application receives both of these services from TCP. •\nConnection-oriented service. TCP has the client and server exchange\ntransport-layer control information with each other before the\napplication-level messages begin to flow. This so-called handshaking\nprocedure alerts the client and server, allowing them to prepare for an\nonslaught of packets. After the handshaking phase, a TCP connection\nis said to exist between the sockets of the two processes. The\nconnection is a full-duplex connection in that the two processes can\nsend messages to each other over the connection at the same time. When the application finishes sending messages, it must tear down the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 192,
    "text": "connection. In Chapter 3, we’ll discuss connection-oriented service in\ndetail and examine how it is implemented. •\nReliable data transfer service. The communicating processes can rely\non TCP to deliver all data sent without error and in the proper order. When one side of the application passes a stream of bytes into a socket,\nit can count on TCP to deliver the same stream of bytes to the receiving\nsocket, with no missing or duplicate bytes. TCP also includes a congestion-control mechanism, a service for the ­-\ngeneral welfare of the Internet rather than for the direct benefit of the\ncommunicating processes. The TCP congestion-control mechanism throttles\na sending process (client or server) when the network is congested between\nsender and receiver. As we will see in Chapter 3, TCP congestion control\nalso attempts to limit each TCP connection to its fair share of network\nbandwidth. UDP Services\nUDP is a no-frills, lightweight transport protocol, providing minimal\nservices. UDP is connectionless, so there is no handshaking before the two\nprocesses start to communicate. UDP provides an unreliable data transfer\nservice—that is, when a process sends a message into a UDP socket, UDP\nprovides no guarantee that the message will ever reach the receiving\nprocess. Furthermore, messages that do arrive at the receiving process may\narrive out of order. FOCUS ON\nSECURITY"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 193,
    "text": "SECURING TCP\nNeither TCP nor UDP provides any encryption—the data that the sending process\npasses into its socket is the same data that travels over the network to the destination\nprocess. So, for example, if the sending process sends a password in cleartext (i.e.,\nunencrypted) into its socket, the cleartext password will travel over all the links\nbetween sender and receiver, potentially getting sniffed and discovered at any of the\nintervening links. Because privacy and other security issues have become critical for\nmany applications, the Internet community has developed an enhancement for TCP,\ncalled Transport Layer Security (TLS) [RFC 5246]. TCP-enhanced-with-TLS not only\ndoes everything that traditional TCP does but also provides critical process-to-process\nsecurity services, including encryption, data integrity, and end-point authentication. We\nemphasize that TLS is not a third Internet transport protocol, on the same level as TCP\nand UDP, but instead is an enhancement of TCP, with the enhancements being\nimplemented in the application layer. In particular, if an application wants to use the\nservices of TLS, it needs to include TLS code (existing, highly optimized libraries and\nclasses) in both the client and server sides of the application. TLS has its own socket\nAPI that is similar to the traditional TCP socket API. When an application uses TLS, the\nsending process passes cleartext data to the TLS socket; TLS in the sending host then\nencrypts the data and passes the encrypted data to the TCP socket. The encrypted\ndata travels over the Internet to the TCP socket in the receiving process. The receiving\nsocket passes the encrypted data to TLS, which decrypts the data. Finally, TLS passes\nthe cleartext data through its TLS socket to the receiving process. We’ll cover TLS in\nsome detail in Chapter 8. UDP does not include a congestion-control mechanism, so the sending\nside of UDP can pump data into the layer below (the network layer) at any\nrate it pleases. (Note, however, that the actual end-to-end throughput may"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 194,
    "text": "be less than this rate due to the limited transmission capacity of intervening\nlinks or due to congestion). Services Not Provided by Internet Transport Protocols\nWe have organized transport protocol services along four dimensions:\nreliable data transfer, throughput, timing, and security. Which of these\nservices are provided by TCP and UDP? We have already noted that TCP\nprovides reliable end-to-end data transfer. And we also know that TCP can\nbe easily enhanced at the application layer with TLS to provide security\nservices. But in our brief description of TCP and UDP, conspicuously\nmissing was any mention of throughput or timing guarantees—services not\nprovided by today’s Internet transport protocols. Does this mean that time-\nsensitive applications such as Internet telephony cannot run in today’s\nInternet? The answer is clearly no—the Internet has been hosting time-\nsensitive applications for many years. These applications often work fairly\nwell because they have been designed to cope, to the greatest extent\npossible, with this lack of guarantee. Nevertheless, clever design has its\nlimitations when delay is excessive, or the end-to-end throughput is limited. In summary, today’s Internet can often provide satisfactory service to time-\nsensitive applications, but it cannot provide any timing or throughput\nguarantees. Figure 2.5 indicates the transport protocols used by some popular\nInternet applications. We see that e-mail, remote terminal access, the Web,\nand file transfer all use TCP. These applications have chosen TCP primarily\nbecause TCP provides reliable data transfer, guaranteeing that all data will\neventually get to its destination. Because Internet telephony applications\n(such as Skype) can often tolerate some loss but require a minimal rate to\nbe effective, developers of Internet telephony applications usually prefer to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 195,
    "text": "run their applications over UDP, thereby circumventing TCP’s congestion\ncontrol mechanism and packet overheads. But because many firewalls are\nconfigured to block (most types of) UDP traffic, Internet telephony\napplications often are designed to use TCP as a backup if UDP\ncommunication fails. Figure 2.5 ♦Popular Internet applications, their application-layer\nprotocols, and their underlying transport protocols\n2.1.5 Application-Layer Protocols\nWe have just learned that network processes communicate with each other\nby sending messages into sockets. But how are these messages structured? What are the meanings of the various fields in the messages? When do the\nprocesses send the messages? These questions bring us into the realm of\napplication-layer protocols. An application-layer protocol defines how an\napplication’s processes, running on different end systems, pass messages to\neach other. In particular, an application-layer protocol defines:"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 196,
    "text": "•\nThe types of messages exchanged, for example, request messages and\nresponse messages\n•\nThe syntax of the various message types, such as the fields in the\nmessage and how the fields are delineated\n•\nThe semantics of the fields, that is, the meaning of the information in\nthe fields\n•\nRules for determining when and how a process sends messages and\nresponds to messages\nSome application-layer protocols are specified in RFCs and are therefore in\nthe public domain. For example, the Web’s application-layer protocol,\nHTTP (the HyperText Transfer Protocol [RFC 7230]), is available as an\nRFC. If a browser developer follows the rules of the HTTP RFC, the\nbrowser will be able to retrieve Web pages from any Web server that has\nalso followed the rules of the HTTP RFC. Many other application-layer\nprotocols are proprietary and intentionally not available in the public\ndomain. For example, Skype uses proprietary application-layer protocols. It is important to distinguish between network applications and\napplication-layer protocols. An application-layer protocol is only one piece\nof a network application (albeit, a very important piece of the application\nfrom our point of view!). Let’s look at a couple of examples. The Web is a\nclient-server application that allows users to obtain documents from Web\nservers on demand. The Web application consists of many components,\nincluding a standard for document formats (that is, HTML), Web browsers\n(for example, Chrome and Microsoft Internet Explorer), Web servers\n(for  example, Apache and Microsoft servers), and an application-layer\nprotocol. The Web’s application-layer protocol, HTTP, defines the format\nand sequence of  messages exchanged between browser and Web server. Thus, HTTP is only one  piece (albeit, an important piece) of the Web"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 197,
    "text": "application. As another example, we’ll see in Section 2.6 that Netflix’s\nvideo service also has many components, including servers that store and\ntransmit videos, other servers that manage billing and other ­client functions,\nclients (e.g., the Netflix app on your smartphone, tablet, or ­computer), and\nan application-level DASH protocol defines the format and sequence of\nmessages exchanged between a Netflix server and client. Thus, DASH is\nonly one piece (albeit, an important piece) of the Netflix application. 2.1.6 Network Applications Covered in This Book\nNew applications are being developed every day. Rather than covering a\nlarge number of Internet applications in an encyclopedic manner, we have\nchosen to focus on a small number of applications that are both pervasive\nand important. In this chapter, we discuss five important applications: the\nWeb, electronic mail, directory service, video streaming, and P2P\napplications. We first discuss the Web, not only because it is an enormously\npopular application, but also because its application-layer protocol, HTTP,\nis straightforward and easy to understand. We then discuss electronic mail,\nthe Internet’s first killer application. E-mail is more complex than the Web\nin the sense that it makes use of not one but several application-layer\nprotocols. After e-mail, we cover DNS, which provides a directory service\nfor the Internet. Most users do not interact with DNS directly; instead, users\ninvoke DNS indirectly through other applications (including the Web, file\ntransfer, and electronic mail). DNS illustrates nicely how a piece of core\nnetwork functionality (network-name to network-address translation) can be\nimplemented at the application layer in the Internet. We then discuss P2P\nfile sharing applications, and complete our application study by discussing"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 198,
    "text": "video streaming on demand, including distributing stored video over\ncontent distribution networks."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 199,
    "text": "2.2 The Web and HTTP\nUntil the early 1990s, the Internet was used primarily by researchers,\nacademics, and university students to log in to remote hosts, to transfer files\nfrom local hosts to remote hosts and vice versa, to receive and send news,\nand to receive and send electronic mail. Although these applications were\n(and continue to be) extremely useful, the Internet was essentially unknown\noutside of the academic and research communities. Then, in the early\n1990s, a major new application arrived on the scene—the World Wide Web\n[Berners-Lee 1994]. The Web was the first Internet application that caught\nthe general public’s eye. It dramatically changed how people interact inside\nand outside their work environments. It elevated the Internet from just one\nof many data networks to essentially the one and only data network. Perhaps what appeals the most to users is that the Web operates on\ndemand. Users receive what they want, when they want it. This is unlike\ntraditional broadcast radio and television, which force users to tune in when\nthe content provider makes the content available. In addition to being\navailable on demand, the Web has many other wonderful features that\npeople love and cherish. It is enormously easy for any individual to make\ninformation available over the Web—everyone can become a publisher at\nextremely low cost. Hyperlinks and search engines help us navigate through\nan ocean of information. Photos and videos stimulate our senses. Forms,\nJavaScript, video, and many other devices enable us to interact with pages\nand sites. And the Web and its protocols serve as a platform for YouTube,\nWeb-based e-mail (such as Gmail), and most mobile Internet applications,\nincluding Instagram and Google Maps."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 200,
    "text": "2.2.1 Overview of HTTP\nThe HyperText Transfer Protocol (HTTP), the Web’s application-layer\nprotocol, is at the heart of the Web. It is defined in [RFC 1945], [RFC 7230]\nand [RFC 7540]. HTTP is implemented in two programs: a client program\nand a server program. The client program and server program, executing on\ndifferent end systems, talk to each other by exchanging HTTP messages. HTTP defines the structure of these messages and how the client and server\nexchange the messages. Before explaining HTTP in detail, we should\nreview some Web terminology. A Web page (also called a document) consists of objects. An object is ­-\nsimply a file—such as an HTML file, a JPEG image, a Javascrpt file, a CCS\nstyle sheet file, or a video clip—that is addressable by a single URL. Most\nWeb pages consist of a base HTML file and several referenced objects. For\nexample, if a Web page contains HTML text and five JPEG images, then\nthe Web page has six objects: the base HTML file plus the five images. The\nbase HTML file references the other objects in the page with the objects’\nURLs. Each URL has two components: the hostname of the server that\nhouses the object and the object’s path name. For example, the URL\nhttp://www.someSchool.edu/someDepartment/picture.g\nif\nhas \nwww.someSchool.edu \nfor \na \nhostname \nand\n/someDepartment/picture.gif for a path name. Because Web\nbrowsers (such as Internet Explorer and Chrome) implement the client side\nof HTTP, in the context of the Web, we will use the words browser and\nclient interchangeably. Web servers, which implement the server side of"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 201,
    "text": "HTTP, house Web objects, each addressable by a URL. Popular Web servers\ninclude Apache and Microsoft Internet Information Server. HTTP defines how Web clients request Web pages from Web servers\nand how servers transfer Web pages to clients. We discuss the interaction\nbetween client and server in detail later, but the general idea is illustrated in\nFigure 2.6. When a user requests a Web page (for example, clicks on a\nhyperlink), the browser sends HTTP request messages for the objects in the\npage to the server. The server receives the requests and responds with\nHTTP response messages that contain the objects. Figure 2.6 ♦HTTP request-response behavior\nHTTP uses TCP as its underlying transport protocol (rather than\nrunning on top of UDP). The HTTP client first initiates a TCP connection\nwith the server. Once the connection is established, the browser and the\nserver processes access TCP through their socket interfaces. As described in\nSection 2.1, on the client side the socket interface is the door between the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 202,
    "text": "client process and the TCP connection; on the server side it is the door\nbetween the server process and the TCP connection. The client sends HTTP\nrequest messages into its socket interface and receives HTTP response\nmessages from its socket interface. Similarly, the HTTP server receives\nrequest messages from its socket interface and sends response messages\ninto its socket interface. Once the client sends a message into its socket\ninterface, the message is out of the client’s hands and is “in the hands” of\nTCP. Recall from Section 2.1 that TCP provides a reliable data transfer\nservice to HTTP. This implies that each HTTP request message sent by a\nclient process eventually arrives intact at the server; similarly, each HTTP\nresponse message sent by the server process eventually arrives intact at the\nclient. Here we see one of the great advantages of a layered architecture—\nHTTP need not worry about lost data or the details of how TCP recovers\nfrom loss or reordering of data within the network. That is the job of TCP\nand the protocols in the lower layers of the protocol stack. It is important to note that the server sends requested files to clients\nwithout storing any state information about the client. If a particular client\nasks for the same object twice in a period of a few seconds, the server does\nnot respond by saying that it just served the object to the client; instead, the\nserver resends the object, as it has completely forgotten what it did earlier. Because an HTTP server maintains no information about the clients, HTTP\nis said to be a stateless protocol. We also remark that the Web uses the\nclient-server application architecture, as described in Section 2.1. A Web\nserver is always on, with a fixed IP address, and it services requests from\npotentially millions of different browsers. The original version of HTTP is called HTTP/1.0 and dates back to the\nearly 1990’s [RFC 1945]. As of 2020, the majority of HTTP transactions\ntake place over HTTP/1.1 [RFC 7230]. However, increasingly browsers and"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 203,
    "text": "Web servers also support a new version of HTTP called HTTP/2 [RFC\n7540]. At the end of this section, we’ll provide an introduction to HTTP/2. 2.2.2 Non-Persistent and Persistent Connections\nIn many Internet applications, the client and server communicate for an\nextended period of time, with the client making a series of requests and the\nserver responding to each of the requests. Depending on the application and\non how the application is being used, the series of requests may be made\nback-to-back, periodically at regular intervals, or intermittently. When this\nclient-server interaction is taking place over TCP, the application developer\nneeds to make an important decision—should each request/response pair be\nsent over a separate TCP connection, or should all of the requests and their\ncorresponding responses be sent over the same TCP connection? In the\nformer approach, the application is said to use non-persistent connections;\nand in the latter approach, persistent connections. To gain a deep\nunderstanding of this design issue, let’s examine the advantages and\ndisadvantages of persistent connections in the context of a specific\napplication, namely, HTTP, which can use both non-persistent connections\nand persistent connections. Although HTTP uses persistent connections in\nits default mode, HTTP clients and servers can be configured to use non-\npersistent connections instead. HTTP with Non-Persistent Connections\nLet’s walk through the steps of transferring a Web page from server to client\nfor the case of non-persistent connections. Let’s suppose the page consists\nof a base HTML file and 10 JPEG images, and that all 11 of these objects"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 204,
    "text": "reside on the same server. Further suppose the URL for the base HTML file\nis\nhttp://www.someSchool.edu/someDepartment/home.inde\nx\nHere is what happens:\n1. The HTTP client process initiates a TCP connection to the server\nwww.someSchool.edu on port number 80, which is the default port\nnumber for HTTP. Associated with the TCP connection, there will be a\nsocket at the client and a socket at the server. 2. The HTTP client sends an HTTP request message to the server via its\nsocket. The request message includes the path name\n/someDepartment/home.index. (We will discuss HTTP\nmessages in some detail below.) 3. The HTTP server process receives the request message via its socket,\nretrieves the object /someDepartment/home.index from its\nstorage (RAM or disk), encapsulates the object in an HTTP response\nmessage, and sends the response message to the client via its socket. 4. The HTTP server process tells TCP to close the TCP connection. (But\nTCP doesn’t actually terminate the connection until it knows for sure\nthat the client has received the response message intact.) 5. The HTTP client receives the response message. The TCP connection\nterminates. The message indicates that the encapsulated object is an\nHTML file. The client extracts the file from the response message,\nexamines the HTML file, and finds references to the 10 JPEG objects. 6. The first four steps are then repeated for each of the referenced JPEG\nobjects."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 205,
    "text": "As the browser receives the Web page, it displays the page to the user. Two different browsers may interpret (that is, display to the user) a Web\npage in somewhat different ways. HTTP has nothing to do with how a Web\npage is interpreted by a client. The HTTP specifications ([RFC 1945] and\n[RFC 7540]) define only the communication protocol between the client\nHTTP program and the server HTTP program. The steps above illustrate the use of non-persistent connections, where\neach TCP connection is closed after the server sends the object—the\nconnection does not persist for other objects. HTTP/1.0 employes non-\npersistent TCP connections. Note that each non-persistent TCP connection\ntransports exactly one request message and one response message. Thus, in\nthis example, when a user requests the Web page, 11 TCP connections are\ngenerated. In the steps described above, we were intentionally vague about\nwhether the client obtains the 10 JPEGs over 10 serial TCP connections, or\nwhether some of the JPEGs are obtained over parallel TCP connections. Indeed, users can configure some browsers to control the degree of\nparallelism. Browsers may open multiple TCP connections and request\ndifferent parts of the Web page over the multiple connections. As we’ll see\nin the next chapter, the use of parallel connections shortens the response\ntime. Before continuing, let’s do a back-of-the-envelope calculation to\nestimate the amount of time that elapses from when a client requests the\nbase HTML file until the entire file is received by the client. To this end, we\ndefine the round-trip time (RTT), which is the time it takes for a small\npacket to travel from client to server and then back to the client. The RTT\nincludes packet-propagation delays, packet-queuing delays in intermediate\nrouters and switches, and packet-processing delays. (These delays were"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 206,
    "text": "discussed in Section 1.4.) Now consider what happens when a user clicks\non a hyperlink. As shown in Figure 2.7, this causes the browser to initiate a\nTCP connection between the browser and the Web server; this involves a\n“three-way handshake”—the client sends a small TCP segment to the\nserver, the server acknowledges and responds with a small TCP segment,\nand, finally, the client acknowledges back to the server. The first two parts\nof the three-way handshake take one RTT. After completing the first two\nparts of the handshake, the client sends the HTTP request message\ncombined with the third part of the three-way handshake (the\nacknowledgment) into the TCP connection. Once the request message\narrives at the server, the server sends the HTML file into the TCP\nconnection. This HTTP request/response eats up another RTT. Thus,\nroughly, the total response time is two RTTs plus the transmission time at\nthe server of the HTML file."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 207,
    "text": "Figure 2.7 ♦Back-of-the-envelope calculation for the time needed\nto request and receive an HTML file\nHTTP with Persistent Connections\nNon-persistent connections have some shortcomings. First, a brand-new\nconnection must be established and maintained for each requested object. For each of these connections, TCP buffers must be allocated and TCP\nvariables must be kept in both the client and server. This can place a\nsignificant burden on the Web server, which may be serving requests from\nhundreds of different clients simultaneously. Second, as we just described,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 208,
    "text": "each object suffers a delivery delay of two RTTs—one RTT to establish the\nTCP connection and one RTT to request and receive an object. With HTTP/1.1 persistent connections, the server leaves the TCP\nconnection open after sending a response. Subsequent requests and\nresponses between the same client and server can be sent over the same\nconnection. In particular, an entire Web page (in the example above, the\nbase HTML file and the 10 images) can be sent over a single persistent TCP\nconnection. Moreover, multiple Web pages residing on the same server can\nbe sent from the server to the same client over a single persistent TCP\nconnection. These requests for objects can be made back-to-back, without\nwaiting for replies to pending requests (pipelining). Typically, the HTTP\nserver closes a connection when it isn’t used for a certain time (a\nconfigurable timeout interval). When the server receives the back-to-back\nrequests, it sends the objects back-to-back. The default mode of HTTP uses\npersistent connections with pipelining. We’ll quantitatively compare the\nperformance of non-persistent and persistent connections in the homework\nproblems of Chapters 2 and 3. You are also encouraged to see [Heidemann\n1997; Nielsen 1997; RFC 7540]. 2.2.3 HTTP Message Format\nThe HTTP specifications [RFC 1945; RFC 7230; RFC 7540] include the\ndefinitions of the HTTP message formats. There are two types of HTTP\nmessages, request messages and response messages, both of which are\ndiscussed below. HTTP Request Message\nBelow we provide a typical HTTP request message:"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 209,
    "text": "GET /somedir/page.html HTTP/1.1\nHost: www.someschool.edu\nConnection: close\nUser-agent: Mozilla/5.0\nAccept-language: fr\nWe can learn a lot by taking a close look at this simple request message. First of all, we see that the message is written in ordinary ASCII text, so\nthat your ordinary computer-literate human being can read it. Second, we\nsee that the message consists of five lines, each followed by a carriage\nreturn and a line feed. The last line is followed by an additional carriage\nreturn and line feed. Although this particular request message has five lines,\na request message can have many more lines or as few as one line. The first\nline of an HTTP request message is called the request line; the subsequent\nlines are called the header lines. The request line has three fields: the\nmethod field, the URL field, and the HTTP version field. The method field\ncan take on several different values, including GET, POST, HEAD, PUT,\nand DELETE. The great majority of HTTP request messages use the GET\nmethod. The GET method is used when the browser requests an object, with\nthe requested object identified in the URL field. In this example, the\nbrowser is requesting the object /somedir/page.html. The version is\nself-explanatory; in this example, the browser implements version\nHTTP/1.1. Now let’s look at the header lines in the example. The header line\nHost: www.someschool.edu specifies the host on which the object\nresides. You might think that this header line is unnecessary, as there is\nalready a TCP connection in place to the host. But, as we’ll see in Section\n2.2.5, the information provided by the host header line is required by Web"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 210,
    "text": "proxy caches. By including the Connection: close header line, the\nbrowser is telling the server that it doesn’t want to bother with persistent\nconnections; it wants the server to close the connection after sending the\nrequested object. The User-agent: header line specifies the user agent,\nthat is, the browser type that is making the request to the server. Here the\nuser agent is Mozilla/5.0, a Firefox browser. This header line is useful\nbecause the server can actually send different versions of the same object to\ndifferent types of user agents. (Each of the versions is addressed by the\nsame URL.) Finally, the Accept-language: header indicates that the\nuser prefers to receive a French version of the object, if such an object\nexists on the server; otherwise, the server should send its default version. The Accept-language: header is just one of many content negotiation\nheaders available in HTTP. Having looked at an example, let’s now look at the general format of a\nrequest message, as shown in Figure 2.8. We see that the general format\nclosely follows our earlier example. You may have noticed, however, that\nafter the header lines (and the additional carriage return and line feed) there\nis an “entity body.” The entity body is empty with the GET method, but is\nused with the POST method. An HTTP client often uses the POST method\nwhen the user fills out a form—for example, when a user provides search\nwords to a search engine. With a POST message, the user is still requesting\na Web page from the server, but the specific contents of the Web page\ndepend on what the user entered into the form fields. If the value of the\nmethod field is POST, then the entity body contains what the user entered\ninto the form fields."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 211,
    "text": "Figure 2.8 ♦General format of an HTTP request message\nWe would be remiss if we didn’t mention that a request generated with\na form does not necessarily have to use the POST method. Instead, HTML\nforms often use the GET method and include the inputted data (in the form\nfields) in the requested URL. For example, if a form uses the GET method,\nhas two fields, and the inputs to the two fields are monkeys and\nbananas, \nthen \nthe \nURL \nwill \nhave \nthe \nstructure\nwww.somesite.com/animalsearch?monkeys&bananas. In your\nday-to-day Web surfing, you have probably noticed extended URLs of this\nsort. The HEAD method is similar to the GET method. When a server\nreceives a request with the HEAD method, it responds with an HTTP\nmessage but it leaves out the requested object. Application developers often\nuse the HEAD method for debugging. The PUT method is often used in\nconjunction with Web publishing tools. It allows a user to upload an object"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 212,
    "text": "to a specific path (directory) on a specific Web server. The PUT method is\nalso used by applications that need to upload objects to Web servers. The\nDELETE method allows a user, or an application, to delete an object on a\nWeb server. HTTP Response Message\nBelow we provide a typical HTTP response message. This response\nmessage could be the response to the example request message just\ndiscussed. HTTP/1.1 200 OK\nConnection: close\nDate: Tue, 18 Aug 2015 15:44:04 GMT\nServer: Apache/2.2.3 (CentOS)\nLast-Modified: Tue, 18 Aug 2015 15:11:03 GMT\nContent-Length: 6821\nContent-Type: text/html\n(data data data data data ...)\nLet’s take a careful look at this response message. It has three sections:\nan initial status line, six header lines, and then the entity body. The entity\nbody is the meat of the message—it contains the requested object itself\n(represented by data data data data data ...). The status line\nhas three fields: the protocol version field, a status code, and a\ncorresponding status message. In this example, the status line indicates that\nthe server is using HTTP/1.1 and that everything is OK (that is, the server\nhas found, and is sending, the requested object)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 213,
    "text": "Now let’s look at the header lines. The server uses the Connection:\nclose header line to tell the client that it is going to close the TCP\nconnection after sending the message. The Date: header line indicates the\ntime and date when the HTTP response was created and sent by the server. Note that this is not the time when the object was created or last modified; it\nis the time when the server retrieves the object from its file system, inserts\nthe object into the response message, and sends the response message. The\nServer: header line indicates that the message was generated by an\nApache Web server; it is analogous to the User-agent: header line in\nthe HTTP request message. The Last-Modified: header line indicates\nthe time and date when the object was created or last modified. The Last-\nModified: header, which we will soon cover in more detail, is critical for\nobject caching, both in the local client and in network cache servers (also\nknown as proxy servers). The Content-Length: header line indicates\nthe number of bytes in the object being sent. The Content-Type: header\nline indicates that the object in the entity body is HTML text. (The object\ntype is officially indicated by the Content-Type: header and not by the\nfile extension.) Having looked at an example, let’s now examine the general format of\na response message, which is shown in Figure 2.9. This general format of\nthe response message matches the previous example of a response message. Let’s say a few additional words about status codes and their phrases. The\nstatus code and associated phrase indicate the result of the request. Some\ncommon status codes and associated phrases include:\n•\n200 OK: Request succeeded and the information is returned in the\nresponse."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 214,
    "text": "•\nMoved \nPermanently: \nRequested \nobject \nhas \nbeen\npermanently moved; the new URL is specified in Location: header of\nthe response message. The client software will automatically retrieve\nthe new URL. •\n400 Bad Request: This is a generic error code indicating that the\nrequest could not be understood by the server. •\n404 Not Found: The requested document does not exist on this\nserver. •\n505 HTTP Version Not Supported: The requested HTTP\nprotocol version is not supported by the server. Figure 2.9 ♦General format of an HTTP response message\nHow would you like to see a real HTTP response message? This is\nhighly recommended and very easy to do! First Telnet into your favorite\nWeb server. Then type in a one-line request message for some object that is"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 215,
    "text": "housed on the server. For example, if you have access to a command\nprompt, type:\ntelnet gaia.cs.umass.edu 80 \nGET /kurose_ross/interactive/index.php HTTP/1.1\nHost: gaia.cs.umass.edu\n(Press the carriage return twice after typing the last line.) This opens a TCP\nconnection to port 80 of the host gaia.cs.umass.edu and then sends\nthe HTTP request message. You should see a response message that\nincludes the base HTML file for the interactive homework problems for this\ntextbook. If you’d rather just see the HTTP message lines and not receive\nthe object itself, replace GET with HEAD. VideoNote\nUsing Wireshark to investigate the HTTP protocol\nIn this section, we discussed a number of header lines that can be used\nwithin HTTP request and response messages. The HTTP specification\ndefines many, many more header lines that can be inserted by browsers,\nWeb servers, and network cache servers. We have covered only a small\nnumber of the totality of header lines. We’ll cover a few more below and\nanother small number when we discuss network Web caching in Section\n2.2.5. A highly readable and comprehensive discussion of the HTTP\nprotocol, including its headers and status codes, is given in [Krishnamurthy\n2001]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 216,
    "text": "How does a browser decide which header lines to include in a request\nmessage? How does a Web server decide which header lines to include in a\nresponse message? A browser will generate header lines as a function of the\nbrowser type and version, the user configuration of the browser and\nwhether the browser currently has a cached, but possibly out-of-date,\nversion of the object. Web servers behave similarly: There are different\nproducts, versions, and configurations, all of which influence which header\nlines are included in response messages. 2.2.4 User-Server Interaction: Cookies\nWe mentioned above that an HTTP server is stateless. This simplifies server\ndesign and has permitted engineers to develop high-performance Web\nservers that can handle thousands of simultaneous TCP connections. However, it is often desirable for a Web site to identify users, either because\nthe server wishes to restrict user access or because it wants to serve content\nas a function of the user identity. For these purposes, HTTP uses cookies. Cookies, defined in [RFC 6265], allow sites to keep track of users. Most\nmajor commercial Web sites use cookies today. As shown in Figure 2.10, cookie technology has four components: (1) a\ncookie header line in the HTTP response message; (2) a cookie header line\nin the HTTP request message; (3) a cookie file kept on the user’s end\nsystem and managed by the user’s browser; and (4) a back-end database at\nthe Web site. Using Figure 2.10, let’s walk through an example of how\ncookies work. Suppose Susan, who always accesses the Web using Internet\nExplorer from her home PC, contacts Amazon.com for the first time. Let us\nsuppose that in the past she has already visited the eBay site. When the\nrequest comes into the Amazon Web server, the server creates a unique"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 217,
    "text": "identification number and creates an entry in its back-end database that is\nindexed by the identification number. The Amazon Web server then\nresponds to Susan’s browser, including in the HTTP response a Set-\ncookie: header, which contains the identification number. For example,\nthe header line might be:\nSet-cookie: 1678"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 218,
    "text": "Figure 2.10 ♦Keeping user state with cookies\nWhen Susan’s browser receives the HTTP response message, it sees the\nSet-cookie: header. The browser then appends a line to the special\ncookie file that it manages. This line includes the hostname of the server\nand the identification number in the Set-cookie: header. Note that the\ncookie file already has an entry for eBay, since Susan has visited that site in\nthe past. As Susan continues to browse the Amazon site, each time she\nrequests a Web page, her browser consults her cookie file, extracts her\nidentification number for this site, and puts a cookie header line that\nincludes the identification number in the HTTP request. Specifically, each\nof her HTTP requests to the Amazon server includes the header line:\nCookie: 1678\nIn this manner, the Amazon server is able to track Susan’s activity at the\nAmazon site. Although the Amazon Web site does not necessarily know\nSusan’s name, it knows exactly which pages user 1678 visited, in which\norder, and at what times! Amazon uses cookies to provide its shopping cart\nservice—Amazon can maintain a list of all of Susan’s intended purchases,\nso that she can pay for them collectively at the end of the session. If Susan returns to Amazon’s site, say, one week later, her browser will\ncontinue to put the header line Cookie: 1678 in the request messages. Amazon also recommends products to Susan based on Web pages she has\nvisited at Amazon in the past. If Susan also registers herself with Amazon—\nproviding full name, e-mail address, postal address, and credit card\ninformation—Amazon can then include this information in its database,\nthereby associating Susan’s name with her identification number (and all of\nthe pages she has visited at the site in the past!). This is how Amazon and"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 219,
    "text": "other e-commerce sites provide “one-click shopping”—when Susan\nchooses to purchase an item during a subsequent visit, she doesn’t need to\nre-enter her name, credit card number, or address. From this discussion, we see that cookies can be used to identify a user. The first time a user visits a site, the user can provide a user identification\n(possibly his or her name). During the subsequent sessions, the browser\npasses a cookie header to the server, thereby identifying the user to the\nserver. Cookies can thus be used to create a user session layer on top of\nstateless HTTP. For example, when a user logs in to a Web-based e-mail\napplication (such as Hotmail), the browser sends cookie information to the\nserver, permitting the server to identify the user throughout the user’s\nsession with the application. Although cookies often simplify the Internet shopping experience for\nthe user, they are controversial because they can also be considered as an\ninvasion of privacy. As we just saw, using a combination of cookies and\nuser-supplied account information, a Web site can learn a lot about a user\nand potentially sell this information to a third party. 2.2.5 Web Caching\nA Web cache—also called a proxy server—is a network entity that\nsatisfies HTTP requests on the behalf of an origin Web server. The Web\ncache has its own disk storage and keeps copies of recently requested\nobjects in this storage. As shown in Figure 2.11, a user’s browser can be\nconfigured so that all of the user’s HTTP requests are first directed to the\nWeb cache [RFC 7234]. Once a browser is configured, each browser\nrequest for an object is first directed to the Web cache. As an example,\nsuppose \na \nbrowser \nis \nrequesting \nthe \nobject"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 220,
    "text": "http://www.someschool.edu/campus.gif. Here \nis \nwhat\nhappens:\n1. The browser establishes a TCP connection to the Web cache and sends\nan HTTP request for the object to the Web cache. 2. The Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response\nmessage to the client browser. 3. If the Web cache does not have the object, the Web cache opens a TCP\nconnection to the origin server, that is, to www.someschool.edu. The Web cache then sends an HTTP request for the object into the\ncache-to-server TCP connection. After receiving this request, the origin\nserver sends the object within an HTTP response to the Web cache. 4. When the Web cache receives the object, it stores a copy in its local\nstorage and sends a copy, within an HTTP response message, to the\nclient browser (over the existing TCP connection between the client\nbrowser and the Web cache)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 221,
    "text": "Figure 2.11 ♦Clients requesting objects through a Web cache\nNote that a cache is both a server and a client at the same time. When it\nreceives requests from and sends responses to a browser, it is a server. When it sends requests to and receives responses from an origin server, it is\na client. Typically a Web cache is purchased and installed by an ISP. For\nexample, a university might install a cache on its campus network and\nconfigure all of the campus browsers to point to the cache. Or a major\nresidential ISP (such as Comcast) might install one or more caches in its\nnetwork and preconfigure its shipped browsers to point to the installed\ncaches. Web caching has seen deployment in the Internet for two reasons. First,\na Web cache can substantially reduce the response time for a client request,\nparticularly if the bottleneck bandwidth between the client and the origin\nserver is much less than the bottleneck bandwidth between the client and"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 222,
    "text": "the cache. If there is a high-speed connection between the client and the\ncache, as there often is, and if the cache has the requested object, then the\ncache will be able to deliver the object rapidly to the client. Second, as we\nwill soon illustrate with an example, Web caches can substantially reduce\ntraffic on an institution’s access link to the Internet. By reducing traffic, the\ninstitution (for example, a company or a university) does not have to\nupgrade bandwidth as quickly, thereby reducing costs. Furthermore, Web\ncaches can substantially reduce Web traffic in the Internet as a whole,\nthereby improving performance for all applications. To gain a deeper understanding of the benefits of caches, let’s consider\nan example in the context of Figure 2.12. This figure shows two networks—\nthe institutional network and the rest of the public Internet. The institutional\nnetwork is a high-speed LAN. A router in the institutional network and a\nrouter in the Internet are connected by a 15 Mbps link. The origin servers\nare attached to the Internet but are located all over the globe. Suppose that\nthe average object size is 1 Mbits and that the average request rate from the\ninstitution’s browsers to the origin servers is 15 requests per second. Suppose that the HTTP request messages are negligibly small and thus\ncreate no traffic in the networks or in the access link (from institutional\nrouter to Internet router). Also suppose that the amount of time it takes from\nwhen the router on the Internet side of the access link in Figure 2.12\nforwards an HTTP request (within an IP datagram) until it receives the\nresponse (typically within many IP datagrams) is two seconds on average. Informally, we refer to this last delay as the “Internet delay.”"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 223,
    "text": "Figure 2.12 ♦Bottleneck between an institutional network and the\nInternet"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 224,
    "text": "The total response time—that is, the time from the browser’s request of\nan object until its receipt of the object—is the sum of the LAN delay, the\naccess delay (that is, the delay between the two routers), and the Internet\ndelay. Let’s now do a very crude calculation to estimate this delay. The\ntraffic intensity on the LAN (see Section 1.4.2) is\n(15 requests/sec)  ⋅ (1 Mbits/request)/(100 Mbps) = 0.15\nwhereas the traffic intensity on the access link (from the Internet router to\ninstitution router) is\n(15 requests/sec)  ⋅ (1 Mbits/request)/(15 Mbps) = 1\nA traffic intensity of 0.15 on a LAN typically results in, at most, tens of\nmilliseconds of delay; hence, we can neglect the LAN delay. However, as\ndiscussed in Section 1.4.2, as the traffic intensity approaches 1 (as is the\ncase of the access link in Figure 2.12), the delay on a link becomes very\nlarge and grows without bound. Thus, the average response time to satisfy\nrequests is going to be on the order of minutes, if not more, which is\nunacceptable for the institution’s users. Clearly something must be done. One possible solution is to increase the access rate from 15 Mbps to,\nsay, 100 Mbps. This will lower the traffic intensity on the access link to\n0.15, which translates to negligible delays between the two routers. In this\ncase, the total response time will roughly be two seconds, that is, the\nInternet delay. But this solution also means that the institution must upgrade\nits access link from 15 Mbps to 100 Mbps, a costly proposition. Now consider the alternative solution of not upgrading the access link\nbut instead installing a Web cache in the institutional network. This solution\nis illustrated in Figure 2.13. Hit rates—the fraction of requests that are\nsatisfied by a cache—typically range from 0.2 to 0.7 in practice. For"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 225,
    "text": "illustrative purposes, let’s suppose that the cache provides a hit rate of 0.4\nfor this institution. Because the clients and the cache are connected to the\nsame high-speed LAN, 40 percent of the requests will be satisfied almost\nimmediately, say, within 10 milliseconds, by the cache. Nevertheless, the\nremaining 60 percent of the requests still need to be satisfied by the origin\nservers. But with only 60 percent of the requested objects passing through\nthe access link, the traffic intensity on the access link is reduced from 1.0 to\n0.6. Typically, a traffic intensity less than 0.8 corresponds to a small delay,\nsay, tens of milliseconds, on a 15 Mbps link. This delay is negligible\ncompared with the two-second Internet delay. Given these considerations,\naverage delay therefore is\n0.4  ⋅ (0.01 seconds) + 0.6  ⋅ (2.01 seconds)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 226,
    "text": "Figure 2.13 ♦Adding a cache to the institutional network\nwhich is just slightly greater than 1.2 seconds. Thus, this second solution\nprovides an even lower response time than the first solution, and it doesn’t\nrequire the institution to upgrade its link to the Internet. The institution\ndoes, of course, have to purchase and install a Web cache. But this cost is\nlow—many caches use public-domain software that runs on inexpensive\nPCs."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 227,
    "text": "Through the use of Content Distribution Networks (CDNs), Web\ncaches are increasingly playing an important role in the Internet. A CDN\ncompany installs many geographically distributed caches throughout the\nInternet, thereby localizing much of the traffic. There are shared CDNs\n(such as Akamai and Limelight) and dedicated CDNs (such as Google and\nNetflix). We will discuss CDNs in more detail in Section 2.6. The Conditional GET\nAlthough caching can reduce user-perceived response times, it introduces a\nnew problem—the copy of an object residing in the cache may be stale. In\nother words, the object housed in the Web server may have been modified\nsince the copy was cached at the client. Fortunately, HTTP has a\nmechanism that allows a cache to verify that its objects are up to date. This\nmechanism is called the conditional GET [RFC 7232]. An HTTP request\nmessage is a so-called conditional GET message if (1) the request message\nuses the GET method and (2) the request message includes an If-\nModified-Since: header line. To illustrate how the conditional GET operates, let’s walk through an\nexample. First, on the behalf of a requesting browser, a proxy cache sends a\nrequest message to a Web server:\nGET /fruit/kiwi.gif HTTP/1.1\nHost: www.exotiquecuisine.com\nSecond, the Web server sends a response message with the requested object\nto the cache:\nHTTP/1.1 200 OK\nDate: Sat, 3 Oct 2015 15:39:29"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 228,
    "text": "Server: Apache/1.3.0 (Unix)\nLast-Modified: Wed, 9 Sep 2015 09:23:24\nContent-Type: image/gif\n(data data data data data ...)\nThe cache forwards the object to the requesting browser but also caches the\nobject locally. Importantly, the cache also stores the last-modified date\nalong with the object. Third, one week later, another browser requests the\nsame object via the cache, and the object is still in the cache. Since this\nobject may have been modified at the Web server in the past week, the\ncache performs an up-to-date check by issuing a conditional GET. Specifically, the cache sends:\nGET /fruit/kiwi.gif HTTP/1.1\nHost: www.exotiquecuisine.com\nIf-modified-since: Wed, 9 Sep 2015 09:23:24\nNote that the value of the If-modified-since: header line is exactly\nequal to the value of the Last-Modified: header line that was sent by\nthe server one week ago. This conditional GET is telling the server to send\nthe object only if the object has been modified since the specified date. Suppose the object has not been modified since 9 Sep 2015 09:23:24. Then,\nfourth, the Web server sends a response message to the cache:\nHTTP/1.1 304 Not Modified\nDate: Sat, 10 Oct 2015 15:39:29\nServer: Apache/1.3.0 (Unix) \n(empty entity body)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 229,
    "text": "We see that in response to the conditional GET, the Web server still sends a\nresponse message but does not include the requested object in the response\nmessage. Including the requested object would only waste bandwidth and\nincrease user-perceived response time, particularly if the object is large. Note that this last response message has 304 Not Modified in the\nstatus line, which tells the cache that it can go ahead and forward its (the\nproxy cache’s) cached copy of the object to the requesting browser. 2.2.6 HTTP/2\nHTTP/2 [RFC 7540], standardized in 2015, was the first new version of\nHTTP since HTTP/1.1, which was standardized in 1997. Since\nstandardization, HTTP/2 has taken off, with over 40% of the top 10 million\nwebsites supporting HTTP/2 in 2020 [W3Techs]. Most browsers—\nincluding Google Chrome, Internet Explorer, Safari, Opera, and Firefox—\nalso support HTTP/2. The primary goals for HTTP/2 are to reduce perceived latency by\nenabling request and response multiplexing over a single TCP connection,\nprovide request prioritization and server push, and provide efficient\ncompression of HTTP header fields. HTTP/2 does not change HTTP\nmethods, status codes, URLs, or header fields. Instead, HTTP/2 changes\nhow the data is formatted and transported between the client and server. To motivate the need for HTTP/2, recall that HTTP/1.1 uses persistent\nTCP connections, allowing a Web page to be sent from server to client over\na single TCP connection. By having only one TCP connection per Web\npage, the number of sockets at the server is reduced and each transported\nWeb page gets a fair share of the network bandwidth (as discussed below). But developers of Web browsers quickly discovered that sending all the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 230,
    "text": "objects in a Web page over a single TCP connection has a Head of Line\n(HOL) blocking problem. To understand HOL blocking, consider a Web\npage that includes an HTML base page, a large video clip near the top of\nWeb page, and many small objects below the video. Further suppose there\nis a low-to-medium speed bottleneck link (for example, a low-speed\nwireless link) on the path between server and client. Using a single TCP\nconnection, the video clip will take a long time to pass through the\nbottleneck link, while the small objects are delayed as they wait behind the\nvideo clip; that is, the video clip at the head of the line blocks the small\nobjects behind it. HTTP/1.1 browsers typically work around this problem\nby opening multiple parallel TCP connections, thereby having objects in the\nsame web page sent in parallel to the browser. This way, the small objects\ncan arrive at and be rendered in the browser much faster, thereby reducing\nuser-perceived delay. TCP congestion control, discussed in detail in Chapter 3, also provides\nbrowsers an unintended incentive to use multiple parallel TCP connections\nrather than a single persistent connection. Very roughly speaking, TCP\ncongestion control aims to give each TCP connection sharing a bottleneck\nlink an equal share of the available bandwidth of that link; so if there are n\nTCP connections operating over a bottleneck link, then each connection\napproximately gets 1/nth of the bandwidth. By opening multiple parallel\nTCP connections to transport a single Web page, the browser can “cheat”\nand grab a larger portion of the link bandwidth. Many HTTP/1.1 browsers\nopen up to six parallel TCP connections not only to circumvent HOL\nblocking but also to obtain more bandwidth. One of the primary goals of HTTP/2 is to get rid of (or at least reduce\nthe number of) parallel TCP connections for transporting a single Web page. This not only reduces the number of sockets that need to be open and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 231,
    "text": "maintained at servers, but also allows TCP congestion control to operate as\nintended. But with only one TCP connection to transport a Web page,\nHTTP/2 requires carefully designed mechanisms to avoid HOL blocking. HTTP/2 Framing\nThe HTTP/2 solution for HOL blocking is to break each message into small\nframes, and interleave the request and response messages on the same TCP\nconnection. To understand this, consider again the example of a Web page\nconsisting of one large video clip and, say, 8 smaller objects. Thus the\nserver will receive 9 concurrent requests from any browser wanting to see\nthis Web page. For each of these requests, the server needs to send 9\ncompeting HTTP response messages to the browser. ­Suppose all frames are\nof fixed length, the video clip consists of 1000 frames, and each of the\nsmaller objects consists of two frames. With frame interleaving, after\nsending one frame from the video clip, the first frames of each of the small\nobjects are sent. Then after sending the second frame of the video clip, the\nlast frames of each of the small objects are sent. Thus, all of the smaller\nobjects are sent after sending a total of 18 frames. If interleaving were not\nused, the smaller objects would be sent only after sending 1016 frames. Thus the HTTP/2 framing mechanism can significantly decrease user-\nperceived delay. The ability to break down an HTTP message into independent frames,\ninterleave them, and then reassemble them on the other end is the single\nmost important enhancement of HTTP/2. The framing is done by the\nframing sub-layer of the HTTP/2 protocol. When a server wants to send an\nHTTP response, the response is processed by the framing sub-layer, where\nit is broken down into frames. The header field of the response becomes one\nframe, and the body of the message is broken down into one for more"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 232,
    "text": "additional frames. The frames of the response are then interleaved by the\nframing sub-layer in the server with the frames of other responses and sent\nover the single persistent TCP connection. As the frames arrive at the client,\nthey are first reassembled into the original response messages at the framing\nsub-layer and then processed by the browser as usual. Similarly, a client’s\nHTTP requests are broken into frames and interleaved. In addition to breaking down each HTTP message into independent\nframes, the framing sublayer also binary encodes the frames. Binary\nprotocols are more efficient to parse, lead to slightly smaller frames, and are\nless error-prone. Response Message Prioritization and Server Pushing\nMessage prioritization allows developers to customize the relative priority\nof requests to better optimize application performance. As we just learned,\nthe framing sub-layer organizes messages into parallel streams of data\ndestined to the same requestor. When a client sends concurrent requests to a\nserver, it can prioritize the responses it is requesting by assigning a weight\nbetween 1 and 256 to each message. The higher number indicates higher\npriority. Using these weights, the server can send first the frames for the\nresponses with the highest priority. In addition to this, the client also states\neach message’s dependency on other messages by specifying the ID of the\nmessage on which it depends. Another feature of HTTP/2 is the ability for a server to send multiple\nresponses for a single client request. That is, in addition to the response to\nthe original request, the server can push additional objects to the client,\nwithout the client having to request each one. This is possible since the\nHTML base page indicates the objects that will be needed to fully render\nthe Web page. So instead of waiting for the HTTP requests for these"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 233,
    "text": "objects, the server can analyze the HTML page, identify the objects that are\nneeded, and send them to the client before receiving explicit requests for\nthese objects. Server push eliminates the extra latency due to waiting for the\nrequests. HTTP/3\nQUIC, discussed in Chapter 3, is a new “transport” protocol that is\nimplemented in the application layer over the bare-bones UDP protocol. QUIC has several features that are desirable for HTTP, such as message\nmultiplexing (interleaving), per-stream flow control, and low-latency\nconnection establishment. HTTP/3 is yet a new HTTP protocol that is\ndesigned to operate over QUIC. As of 2020, HTTP/3 is described in\nInternet drafts and has not yet been fully standardized. Many of the HTTP/2\nfeatures (such as message interleaving) are subsumed by QUIC, allowing\nfor a simpler, streamlined design for HTTP/3."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 234,
    "text": "2.3 Electronic Mail in the Internet\nElectronic mail has been around since the beginning of the Internet. It was\nthe most popular application when the Internet was in its infancy [Segaller\n1998], and has become more elaborate and powerful over the years. It\nremains one of the Internet’s most important and utilized applications. As with ordinary postal mail, e-mail is an asynchronous communication\nmedium—people send and read messages when it is convenient for them,\nwithout having to coordinate with other people’s schedules. In contrast with\npostal mail, electronic mail is fast, easy to distribute, and inexpensive. Modern e-mail has many powerful features, including messages with\nattachments, hyperlinks, HTML-formatted text, and embedded photos. In this section, we examine the application-layer protocols that are at\nthe heart of Internet e-mail. But before we jump into an in-depth discussion\nof these protocols, let’s take a high-level view of the Internet mail system\nand its key components. Figure 2.14 presents a high-level view of the Internet mail system. We\nsee from this diagram that it has three major components: user agents, mail\nservers, and the Simple Mail Transfer Protocol (SMTP). We now\ndescribe each of these components in the context of a sender, Alice, sending\nan e-mail message to a recipient, Bob. User agents allow users to read,\nreply to, forward, save, and compose ­messages. Examples of user agents for\ne-mail include Microsoft Outlook, Apple Mail, Web-based Gmail, the\nGmail App running in a smartphone, and so on. When Alice is finished\ncomposing her message, her user agent sends the message to her mail\nserver, where the message is placed in the mail server’s outgoing message"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 235,
    "text": "queue. When Bob wants to read a message, his user agent retrieves the\nmessage from his mailbox in his mail server. Figure 2.14 ♦A high-level view of the Internet e-mail system\nMail servers form the core of the e-mail infrastructure. Each recipient,\nsuch as Bob, has a mailbox located in one of the mail servers. Bob’s\nmailbox manages and maintains the messages that have been sent to him. A\ntypical message starts its journey in the sender’s user agent, then travels to\nthe sender’s mail server, and then travels to the recipient’s mail server,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 236,
    "text": "where it is deposited in the recipient’s mailbox. When Bob wants to access\nthe messages in his mailbox, the mail server containing his mailbox\nauthenticates Bob (with his username and password). Alice’s mail server\nmust also deal with failures in Bob’s mail server. If Alice’s server cannot\ndeliver mail to Bob’s server, Alice’s server holds the message in a message\nqueue and attempts to transfer the message later. Reattempts are often done\nevery 30 minutes or so; if there is no success after several days, the server\nremoves the message and notifies the sender (Alice) with an e-mail\nmessage. SMTP is the principal application-layer protocol for Internet electronic\nmail. It uses the reliable data transfer service of TCP to transfer mail from\nthe sender’s mail server to the recipient’s mail server. As with most\napplication-layer protocols, SMTP has two sides: a client side, which\nexecutes on the sender’s mail server, and a server side, which executes on\nthe recipient’s mail server. Both the client and server sides of SMTP run on\nevery mail server. When a mail server sends mail to other mail servers, it\nacts as an SMTP client. When a mail server receives mail from other mail\nservers, it acts as an SMTP server. 2.3.1 SMTP\nSMTP, defined in RFC 5321, is at the heart of Internet electronic mail. As\nmentioned above, SMTP transfers messages from senders’ mail servers to\nthe recipients’ mail servers. SMTP is much older than HTTP. (The original\nSMTP RFC dates back to 1982, and SMTP was around long before that.) Although SMTP has numerous wonderful qualities, as evidenced by its\nubiquity in the Internet, it is nevertheless a legacy technology that possesses\ncertain archaic characteristics. For example, it restricts the body (not just"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 237,
    "text": "the headers) of all mail messages to simple 7-bit ASCII. This restriction\nmade sense in the early 1980s when transmission capacity was scarce and\nno one was e-mailing large attachments or large image, audio, or video\nfiles. But today, in the multimedia era, the 7-bit ASCII restriction is a bit of\na pain—it requires binary multimedia data to be encoded to ASCII before\nbeing sent over SMTP; and it requires the corresponding ASCII message to\nbe decoded back to binary after SMTP transport. Recall from Section 2.2\nthat HTTP does not require multimedia data to be ASCII encoded before\ntransfer. To illustrate the basic operation of SMTP, let’s walk through a common\nscenario. Suppose Alice wants to send Bob a simple ASCII message. 1. Alice invokes her user agent for e-mail, provides Bob’s e-mail address\n(for example, bob@someschool.edu), composes a message, and\ninstructs the user agent to send the message. 2. Alice’s user agent sends the message to her mail server, where it is\nplaced in a message queue. 3. The client side of SMTP, running on Alice’s mail server, sees the\nmessage in the message queue. It opens a TCP connection to an SMTP\nserver, running on Bob’s mail server. 4. After some initial SMTP handshaking, the SMTP client sends Alice’s\nmessage into the TCP connection. 5. At Bob’s mail server, the server side of SMTP receives the message. Bob’s mail server then places the message in Bob’s mailbox. 6. Bob invokes his user agent to read the message at his convenience. The scenario is summarized in Figure 2.15."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 238,
    "text": "Figure 2.15 ♦Alice sends a message to Bob\nIt is important to observe that SMTP does not normally use\nintermediate mail servers for sending mail, even when the two mail servers\nare located at opposite ends of the world. If Alice’s server is in Hong Kong\nand Bob’s server is in St. Louis, the TCP connection is a direct connection\nbetween the Hong Kong and St. Louis servers. In particular, if Bob’s mail\nserver is down, the message remains in Alice’s mail server and waits for a\nnew attempt—the message does not get placed in some intermediate mail\nserver. Let’s now take a closer look at how SMTP transfers a message from a\nsending mail server to a receiving mail server. We will see that the SMTP\nprotocol has many similarities with protocols that are used for face-to-face\nhuman interaction. First, the client SMTP (running on the sending mail\nserver host) has TCP establish a connection to port 25 at the server SMTP\n(running on the receiving mail server host). If the server is down, the client\ntries again later. Once this connection is established, the server and client\nperform some application-layer handshaking—just as humans often\nintroduce themselves before transferring information from one to another,\nSMTP clients and servers introduce themselves before transferring\ninformation. During this SMTP handshaking phase, the SMTP client"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 240,
    "text": "S:  250 Message accepted for delivery\nC:  QUIT\nS:  221 hamburger.edu closing connection\nIn the example above, the client sends a message (“Do you like\nketchup? How about pickles?”) from mail server crepes.fr\nto mail server hamburger.edu. As part of the dialogue, the client issued\nfive commands: HELO (an abbreviation for HELLO), MAIL FROM, RCPT\nTO, DATA, and QUIT. These commands are self-explanatory. The client\nalso sends a line consisting of a single period, which indicates the end of the\nmessage to the server. (In ASCII jargon, each message ends with\nCRLF.CRLF, where CR and LF stand for carriage return and line feed,\nrespectively.) The server issues replies to each command, with each reply\nhaving a reply code and some (optional) English-language explanation. We\nmention here that SMTP uses persistent connections: If the sending mail\nserver has several messages to send to the same receiving mail server, it can\nsend all of the messages over the same TCP connection. For each message,\nthe client begins the process with a new MAIL FROM: crepes.fr,\ndesignates the end of message with an isolated period, and issues QUIT\nonly after all messages have been sent. It is highly recommended that you use Telnet to carry out a direct\ndialogue with an SMTP server. To do this, issue\ntelnet serverName 25\nwhere serverName is the name of a local mail server. When you do this,\nyou are simply establishing a TCP connection between your local host and\nthe mail server. After typing this line, you should immediately receive the\n220 reply from the server. Then issue the SMTP commands HELO, MAIL"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 241,
    "text": "FROM, RCPT TO, DATA, CRLF.CRLF, and QUIT at the appropriate times. It is also highly recommended that you do Programming Assignment 3 at\nthe end of this chapter. In that assignment, you’ll build a simple user agent\nthat implements the client side of SMTP. It will allow you to send an e-mail\nmessage to an arbitrary recipient via a local mail server. 2.3.2 Mail Message Formats\nWhen Alice writes an ordinary snail-mail letter to Bob, she may include all\nkinds of peripheral header information at the top of the letter, such as Bob’s\naddress, her own return address, and the date. Similarly, when an e-mail\nmessage is sent from one person to another, a header containing peripheral\ninformation precedes the body of the message itself. This peripheral\ninformation is contained in a series of header lines, which are defined in\nRFC 5322. The header lines and the body of the message are separated by a\nblank line (that is, by CRLF). RFC 5322 specifies the exact format for mail\nheader lines as well as their semantic interpretations. As with HTTP, each\nheader line contains readable text, consisting of a keyword followed by a\ncolon followed by a value. Some of the keywords are required and others\nare optional. Every header must have a From: header line and a To:\nheader line; a header may include a Subject: header line as well as other\noptional header lines. It is important to note that these header lines are\ndifferent from the SMTP commands we studied in Section 2.3.1 (even\nthough they contain some common words such as “from” and “to”). The\ncommands in that section were part of the SMTP handshaking protocol; the\nheader lines examined in this section are part of the mail message itself. A typical message header looks like this:"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 242,
    "text": "From: alice@crepes.fr\nTo: bob@hamburger.edu\nSubject: Searching for the meaning of life. After the message header, a blank line follows; then the message body (in\nASCII) follows. You should use Telnet to send a message to a mail server\nthat contains some header lines, including the Subject: header line. To\ndo this, issue telnet serverName 25, as discussed in Section 2.3.1. 2.3.3 Mail Access Protocols\nOnce SMTP delivers the message from Alice’s mail server to Bob’s mail\nserver, the message is placed in Bob’s mailbox. Given that Bob (the\nrecipient) executes his user agent on his local host (e.g., smartphone or PC),\nit is natural to consider placing a mail server on his local host as well. With\nthis approach, Alice’s mail server would dialogue directly with Bob’s PC. There is a problem with this approach, however. Recall that a mail server\nmanages mailboxes and runs the client and server sides of SMTP. If Bob’s\nmail server were to reside on his local host, then Bob’s host would have to\nremain always on, and connected to the Internet, in order to receive new\nmail, which can arrive at any time. This is impractical for many Internet\nusers. Instead, a typical user runs a user agent on the local host but accesses\nits mailbox stored on an always-on shared mail server. This mail server is\nshared with other users. Now let’s consider the path an e-mail message takes when it is sent\nfrom Alice to Bob. We just learned that at some point along the path the e-\nmail message needs to be deposited in Bob’s mail server. This could be\ndone simply by having Alice’s user agent send the message directly to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 243,
    "text": "Bob’s mail server. However, typically the sender’s user agent does not\ndialogue directly with the recipient’s mail server. Instead, as shown in\nFigure 2.16, Alice’s user agent uses SMTP or HTTP to deliver the e-mail\nmessage into her mail server, then Alice’s mail server uses SMTP (as an\nSMTP client) to relay the e-mail message to Bob’s mail server. Why the\ntwo-step procedure? Primarily because without relaying through Alice’s\nmail server, Alice’s user agent doesn’t have any recourse to an unreachable\ndestination mail server. By having Alice first deposit the e-mail in her own\nmail server, Alice’s mail server can repeatedly try to send the message to\nBob’s mail server, say every 30 minutes, until Bob’s mail server becomes\noperational. (And if Alice’s mail server is down, then she has the recourse\nof complaining to her system administrator!) Figure 2.16 ♦E-mail protocols and their communicating entities\nBut there is still one missing piece to the puzzle! How does a recipient\nlike Bob, running a user agent on his local host , obtain his messages, which\nare sitting in a mail server? Note that Bob’s user agent can’t use SMTP to\nobtain the messages because obtaining the messages is a pull operation,\nwhereas SMTP is a push protocol. Today, there are two common ways for Bob to retrieve his e-mail from\na mail server. If Bob is using Web-based e-mail or a smartphone app (such\nas Gmail), then the user agent will use HTTP to retrieve Bob’s e-mail. This"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 244,
    "text": "case requires Bob’s mail server to have an HTTP interface as well as an\nSMTP interface (to communicate with Alice’s mail server). The alternative\nmethod, typically used with mail clients such as Microsoft Outlook, is to\nuse the Internet Mail Access Protocol (IMAP) defined in RFC 3501. Both\nthe HTTP and IMAP approaches allow Bob to manage folders, maintained\nin Bob’s mail server. Bob can move messages into the folders he creates,\ndelete messages, mark messages as important, and so on."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 245,
    "text": "2.4 DNS—The Internet’s Directory Service\nWe human beings can be identified in many ways. For example, we can be\nidentified by the names that appear on our birth certificates. We can be\nidentified by our social security numbers. We can be identified by our\ndriver’s license numbers. Although each can be used to identify people,\nwithin a given context one identifier may be more appropriate than another. For example, the computers at the IRS (the infamous tax-collecting agency\nin the United States) prefer to use fixed-length social security numbers\nrather than birth certificate names. On the other hand, ordinary people ­-\nprefer the more mnemonic birth certificate names rather than social security\nnumbers. (Indeed, can you imagine saying, “Hi. My name is 132-67-9875. Please meet my husband, 178-87-1146.”)\nJust as humans can be identified in many ways, so too can Internet\nhosts. One identifier for a host is its hostname. Hostnames—such as\nwww.facebook.com, www.google.com, gaia.cs.umass.edu\n—are mnemonic and are therefore appreciated by humans. However,\nhostnames provide little, if any, information about the location within the\nInternet of the host. (A hostname such as www.eurecom.fr, which ends\nwith the country code .fr, tells us that the host is probably in France, but\ndoesn’t say much more.) Furthermore, because hostnames can consist of\nvariable-length alphanumeric characters, they would be difficult to process\nby routers. For these reasons, hosts are also identified by so-called IP\naddresses. We discuss IP addresses in some detail in Chapter 4, but it is useful to\nsay a few brief words about them now. An IP address consists of four bytes\nand has a rigid hierarchical structure. An IP address looks like"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 121",
    "source": "kurose",
    "page": 246,
    "text": "121.7.106.83, where each period separates one of the bytes expressed\nin decimal notation from 0 to 255. An IP address is hierarchical because as\nwe scan the address from left to right, we obtain more and more specific\ninformation about where the host is located in the Internet (that is, within\nwhich network, in the network of networks). Similarly, when we scan a\npostal address from bottom to top, we obtain more and more specific\ninformation about where the addressee is located. 2.4.1 Services Provided by DNS\nWe have just seen that there are two ways to identify a host—by a hostname\nand by an IP address. People prefer the more mnemonic hostname\nidentifier, while routers prefer fixed-length, hierarchically structured IP\naddresses. In order to reconcile these preferences, we need a directory\nservice that translates hostnames to IP addresses. This is the main task of\nthe Internet’s domain name system (DNS). The DNS is (1) a distributed\ndatabase implemented in a hierarchy of DNS servers, and (2) an\napplication-layer protocol that allows hosts to query the distributed\ndatabase. The DNS servers are often UNIX machines running the Berkeley\nInternet Name Domain (BIND) software [BIND 2020]. The DNS protocol\nruns over UDP and uses port 53. DNS is commonly employed by other application-layer protocols,\nincluding HTTP and SMTP, to translate user-supplied hostnames to IP\naddresses. As an example, consider what happens when a browser (that is,\nan HTTP client), running on some user’s host, requests the URL\nwww.someschool.edu/index.html. In order for the user’s host to\nbe able to send an HTTP request message to the Web server"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 121",
    "source": "kurose",
    "page": 247,
    "text": "www.someschool.edu, the user’s host must first obtain the IP address\nof www.someschool.edu. This is done as follows. 1. The same user machine runs the client side of the DNS application. 2. The browser extracts the hostname, www.someschool.edu, from the\nURL and passes the hostname to the client side of the DNS application. 3. The DNS client sends a query containing the hostname to a DNS server. 4. The DNS client eventually receives a reply, which includes the IP\naddress for the hostname. 5. Once the browser receives the IP address from DNS, it can initiate a\nTCP connection to the HTTP server process located at port 80 at that IP\naddress. We see from this example that DNS adds an additional delay—sometimes\nsubstantial—to the Internet applications that use it. Fortunately, as we\ndiscuss below, the desired IP address is often cached in a “nearby” DNS\nserver, which helps to reduce DNS network traffic as well as the average\nDNS delay. DNS provides a few other important services in addition to translating\nhostnames to IP addresses:\n•\nHost aliasing. A host with a complicated hostname can have one or\nmore alias names. For example, a hostname such as relay1.west-\ncoast.enterprise.com could have, say, two aliases such as\nenterprise.com and www.enterprise.com. In this case, the\nhostname relay1.west-coast.enterprise.com is said to be a\ncanonical hostname. Alias hostnames, when present, are typically\nmore mnemonic than canonical hostnames. DNS can be invoked by an"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 121",
    "source": "kurose",
    "page": 248,
    "text": "application to obtain the canonical hostname for a supplied alias\nhostname as well as the IP address of the host. •\nMail server aliasing. For obvious reasons, it is highly desirable that e-\nmail addresses be mnemonic. For example, if Bob has an account with\nYahoo Mail, Bob’s e-mail address might be as simple as\nbob@yahoo.com. However, the hostname of the Yahoo mail server is\nmore complicated and much less mnemonic than simply yahoo.com\n(for example, the canonical hostname might be something like\nrelay1.west-coast.yahoo.com). DNS can be invoked by a\nmail application to obtain the canonical hostname for a supplied alias\nhostname as well as the IP address of the host. In fact, the MX record\n(see below) permits a company’s mail server and Web server to have\nidentical (aliased) hostnames; for example, a company’s Web server and\nmail server can both be called enterprise.com. •\nLoad distribution. DNS is also used to perform load distribution\namong replicated servers, such as replicated Web servers. Busy sites,\nsuch as cnn.com, are replicated over multiple servers, with each\nserver running on a different end system and each having a different IP\naddress. For replicated Web servers, a set of IP addresses is thus\nassociated with one alias hostname. The DNS database contains this set\nof IP addresses. When clients make a DNS query for a name mapped to\na set of addresses, the server responds with the entire set of IP\naddresses, but rotates the ordering of the addresses within each reply. Because a client typically sends its HTTP request message to the IP\naddress that is listed first in the set, DNS rotation distributes the traffic\namong the replicated servers. DNS rotation is also used for e-mail so\nthat multiple mail servers can have the same alias name. Also, content\ndistribution companies such as Akamai have used DNS in more"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 249,
    "text": "sophisticated ways [Dilley 2002] to provide Web content distribution\n(see Section 2.6.3). PRINCIPLES IN\nPRACTICE\nDNS: CRITICAL NETWORK FUNCTIONS VIA THE CLIENT-SERVER PARADIGM\nLike HTTP, FTP, and SMTP, the DNS protocol is an application-layer protocol since it\n(1) runs between communicating end systems using the client-server paradigm and\n(2) relies on an underlying end-to-end transport protocol to transfer DNS messages\nbetween communicating end systems. In another sense, however, the role of the DNS is\nquite different from Web, file transfer, and e-mail applications. Unlike these applications, the\nDNS is not an application with which a user directly interacts. Instead, the DNS provides a\ncore Internet function—namely, translating hostnames to their underlying IP addresses, for\nuser applications and other software in the Internet. We noted in Section 1.2 that much of\nthe complexity in the Internet architecture is located at the “edges” of the network. The\nDNS, which implements the critical name-to-address translation process using clients and\nservers located at the edge of the network, is yet another example of that design\nphilosophy. The DNS is specified in RFC 1034 and RFC 1035, and updated in\nseveral additional RFCs. It is a complex system, and we only touch upon\nkey aspects of its operation here. The interested reader is referred to these\nRFCs and the book by Albitz and Liu [Albitz 1993]; see also the\nretrospective paper [Mockapetris 1988], which provides a nice description\nof the what and why of DNS, and [Mockapetris 2005]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 250,
    "text": "2.4.2 Overview of How DNS Works\nWe now present a high-level overview of how DNS works. Our discussion\nwill focus on the hostname-to-IP-address translation service. Suppose that some application (such as a Web browser or a mail client)\nrunning in a user’s host needs to translate a hostname to an IP address. The\napplication will invoke the client side of DNS, specifying the hostname that\nneeds \nto \nbe \ntranslated. (On \nmany \nUNIX-based \nmachines,\ngethostbyname() is the function call that an application calls in order\nto perform the translation.) DNS in the user’s host then takes over, sending\na query message into the network. All DNS query and reply messages are\nsent within UDP datagrams to port 53. After a delay, ranging from\nmilliseconds to seconds, DNS in the user’s host receives a DNS reply\nmessage that provides the desired mapping. This mapping is then passed to\nthe invoking application. Thus, from the perspective of the invoking\napplication in the user’s host, DNS is a black box providing a simple,\nstraightforward translation service. But in fact, the black box that\nimplements the service is complex, consisting of a large number of DNS\nservers distributed around the globe, as well as an application-layer protocol\nthat specifies how the DNS servers and querying hosts communicate. A simple design for DNS would have one DNS server that contains all\nthe mappings. In this centralized design, clients simply direct all queries to\nthe single DNS server, and the DNS server responds directly to the\nquerying clients. Although the simplicity of this design is attractive, it is\ninappropriate for today’s Internet, with its vast (and growing) number of\nhosts. The problems with a centralized design include:\n•\nA single point of failure. If the DNS server crashes, so does the entire\nInternet!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 251,
    "text": "•\nTraffic volume. A single DNS server would have to handle all DNS\nqueries (for all the HTTP requests and e-mail messages generated from\nhundreds of millions of hosts). •\nDistant centralized database. A single DNS server cannot be “close\nto” all the querying clients. If we put the single DNS server in New\nYork City, then all queries from Australia must travel to the other side\nof the globe, perhaps over slow and congested links. This can lead to\nsignificant delays. •\nMaintenance. The single DNS server would have to keep records for\nall Internet hosts. Not only would this centralized database be huge, but\nit would have to be updated frequently to account for every new host. In summary, a centralized database in a single DNS server simply\ndoesn’t scale. Consequently, the DNS is distributed by design. In fact, the\nDNS is a wonderful example of how a distributed database can be\nimplemented in the Internet. A Distributed, Hierarchical Database\nIn order to deal with the issue of scale, the DNS uses a large number of\nservers, organized in a hierarchical fashion and distributed around the\nworld. No single DNS server has all of the mappings for all of the hosts in\nthe Internet. Instead, the mappings are distributed across the DNS servers. To a first approximation, there are three classes of DNS servers—root DNS\nservers, top-level domain (TLD) DNS servers, and authoritative DNS\nservers—organized in a hierarchy as shown in Figure 2.17. To understand\nhow these three classes of servers interact, suppose a DNS client wants to\ndetermine the IP address for the hostname www.amazon.com. To a first\napproximation, the following events will take place. The client first contacts"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 252,
    "text": "one of the root servers, which returns IP addresses for TLD servers for the\ntop-level domain com. The client then contacts one of these TLD servers,\nwhich returns the IP address of an authoritative server for amazon.com. Finally, the client contacts one of the authoritative servers for\namazon.com, which returns the IP address for the hostname\nwww.amazon.com. We’ll soon examine this DNS lookup process in more\ndetail. But let’s first take a closer look at these three classes of DNS servers:\nFigure 2.17 ♦Portion of the hierarchy of DNS servers\n•\nRoot DNS servers. There are more than 1000 root servers instances\nscattered all over the world, as shown in Figure 2.18. These root servers\nare copies of 13  different root servers, managed by 12 different\norganizations, and coordinated through the Internet Assigned Numbers\nAuthority [IANA 2020]. The full list of root name servers, along with\nthe organizations that manage them and their IP addresses can be found\nat [Root Servers 2020]. Root name servers provide the IP addresses of\nthe TLD servers. •\nTop-level domain (TLD) servers. For each of the top-level domains—\ntop-level domains such as com, org, net, edu, and gov, and all of the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 253,
    "text": "country top-level domains such as uk, fr, ca, and jp—there is TLD\nserver (or server cluster). The company Verisign Global Registry\nServices maintains the TLD servers for the com top-level domain, and\nthe company Educause maintains the TLD servers for the edu top-level\ndomain. The network infrastructure supporting a TLD can be large and\ncomplex; see [Osterweil 2012] for a nice overview of the Verisign\nnetwork. See [TLD list 2020] for a list of all top-level domains. TLD\nservers provide the IP addresses for authoritative DNS servers. •\nAuthoritative DNS servers. Every organization with publicly\naccessible hosts (such as Web servers and mail servers) on the Internet\nmust provide publicly accessible DNS records that map the names of\nthose hosts to IP addresses. An organization’s authoritative DNS server\nhouses these DNS records. An organization can choose to implement its\nown authoritative DNS server to hold these records; alternatively, the\norganization can pay to have these records stored in an authoritative\nDNS server of some service provider. Most universities and large\ncompanies implement and maintain their own primary and secondary\n(backup) authoritative DNS server."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 254,
    "text": "Figure 2.18 ♦DNS root servers in 2020\nThe root, TLD, and authoritative DNS servers all belong to the\nhierarchy of DNS servers, as shown in Figure 2.17. There is another\nimportant type of DNS server called the local DNS server. A local DNS\nserver does not strictly belong to the hierarchy of servers but is nevertheless\ncentral to the DNS architecture. Each ISP—such as a residential ISP or an\ninstitutional ISP—has a local DNS server (also called a default name\nserver). When a host connects to an ISP, the ISP provides the host with the\nIP addresses of one or more of its local DNS servers (typically through\nDHCP, which is discussed in Chapter 4). You can easily determine the IP\naddress of your local DNS server by accessing network status windows in\nWindows or UNIX. A host’s local DNS server is typically “close to” the\nhost. For an institutional ISP, the local DNS server may be on the same\nLAN as the host; for a residential ISP, it is typically separated from the host\nby no more than a few routers. When a host makes a DNS query, the query\nis sent to the local DNS server, which acts a proxy, ­forwarding the query\ninto the DNS server hierarchy, as we’ll discuss in more detail below."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 255,
    "text": "Let’s take a look at a simple example. Suppose the host\ncse.nyu.edu desires the IP address of gaia.cs.umass.edu. Also\nsuppose that NYU’s local DNS server for cse.nyu.edu is called\ndns.nyu.edu \nand \nthat \nan \nauthoritative \nDNS \nserver \nfor\ngaia.cs.umass.edu is called dns.umass.edu. As shown in ­Figure\n2.19, the host cse.nyu.edu first sends a DNS query message to its local\nDNS server, dns.nyu.edu. The query message contains the hostname to\nbe translated, namely, gaia.cs.umass.edu. The local DNS server\nforwards the query message to a root DNS server. The root DNS server\ntakes note of the edu suffix and returns to the local DNS server a list of IP\naddresses for TLD servers responsible for edu. The local DNS server then\nresends the query message to one of these TLD servers. The TLD server\ntakes note of the umass.edu suffix and responds with the IP address of\nthe authoritative DNS server for the University of Massachusetts, namely,\ndns.umass.edu. Finally, the local DNS server resends the query\nmessage directly to dns.umass.edu, which responds with the IP address\nof gaia.cs.umass.edu. Note that in this example, in order to obtain\nthe mapping for one hostname, eight DNS messages were sent: four query\nmessages and four reply messages! We’ll soon see how DNS caching\nreduces this query traffic."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 256,
    "text": "Figure 2.19 ♦Interaction of the various DNS servers\nOur previous example assumed that the TLD server knows the\nauthoritative DNS server for the hostname. In general, this is not always\ntrue. Instead, the TLD server may know only of an intermediate DNS\nserver, which in turn knows the authoritative DNS server for the hostname."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 257,
    "text": "For example, suppose again that the University of Massachusetts has a DNS\nserver for the university, called dns.umass.edu. Also suppose that each\nof the departments at the University of Massachusetts has its own DNS\nserver, and that each departmental DNS server is authoritative for all hosts\nin the department. In this case, when the intermediate DNS server,\ndns.umass.edu, receives a query for a host with a hostname ending\nwith cs.umass.edu, it returns to dns.nyu.edu the IP address of\ndns.cs.umass.edu, which is authoritative for all hostnames ending\nwith cs.umass.edu. The local DNS server dns.nyu.edu then sends\nthe query to the authoritative DNS server, which returns the desired\nmapping to the local DNS server, which in turn returns the mapping to the\nrequesting host. In this case, a total of 10 DNS messages are sent! The example shown in Figure 2.19 makes use of both recursive\nqueries and iterative queries. The query sent from cse.nyu.edu to\ndns.nyu.edu is a recursive query, since the query asks dns.nyu.edu\nto obtain the mapping on its behalf. However, the subsequent three queries\nare iterative since all of the replies are directly returned to dns.nyu.edu. In theory, any DNS query can be iterative or recursive. For example, Figure\n2.20 shows a DNS query chain for which all of the queries are recursive. In\npractice, the queries typically follow the pattern in Figure 2.19: The query\nfrom the requesting host to the local DNS server is recursive, and the\nremaining queries are iterative."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 258,
    "text": "Figure 2.20 ♦Recursive queries in DNS\nDNS Caching"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 259,
    "text": "Our discussion thus far has ignored DNS caching, a critically important\nfeature of the DNS system. In truth, DNS extensively exploits DNS caching\nin order to improve the delay performance and to reduce the number of\nDNS messages ricocheting around the Internet. The idea behind DNS\ncaching is very simple. In a query chain, when a DNS server receives a\nDNS reply (containing, for example, a mapping from a hostname to an IP\naddress), it can cache the mapping in its local memory. For example, in\nFigure 2.19, each time the local DNS server dns.nyu.edu receives a\nreply from some DNS server, it can cache any of the information contained\nin the reply. If a hostname/IP address pair is cached in a DNS server and\nanother query arrives to the DNS server for the same hostname, the DNS\nserver can provide the desired IP address, even if it is not authoritative for\nthe hostname. Because hosts and mappings between hostnames and IP\naddresses are by no means permanent, DNS servers discard cached\ninformation after a period of time (often set to two days). As an example, suppose that a host apricot.nyu.edu queries\ndns.nyu.edu for the IP address for the hostname cnn.com. Furthermore, ­suppose that a few hours later, another NYU host, say,\nkiwi.nyu.edu, also queries dns.nyu.edu with the same hostname. Because of caching, the local DNS server will be able to immediately return\nthe IP address of cnn.com to this second requesting host without having to\nquery any other DNS servers. A local DNS server can also cache the IP\naddresses of TLD servers, thereby allowing the local DNS server to bypass\nthe root DNS servers in a query chain. In fact, because of caching, root\nservers are bypassed for all but a very small fraction of DNS queries. 2.4.3 DNS Records and Messages"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 145",
    "source": "kurose",
    "page": 260,
    "text": "The DNS servers that together implement the DNS distributed database\nstore resource records (RRs), including RRs that provide hostname-to-IP\naddress mappings. Each DNS reply message carries one or more resource\nrecords. In this and the following subsection, we provide a brief overview\nof DNS resource records and messages; more details can be found in\n[Albitz 1993] or in the DNS RFCs [RFC 1034; RFC 1035]. A resource record is a four-tuple that contains the following fields:\n(Name, Value, Type, TTL)\nTTL is the time to live of the resource record; it determines when a resource\nshould be removed from a cache. In the example records given below, we\nignore the TTL field. The meaning of Name and Value depend on Type:\n•\nIf Type=A, then Name is a hostname and Value is the IP address for\nthe hostname. Thus, a Type A record provides the standard hostname-to-\nIP address mapping. As an example, (relay1.bar.foo.com,\n145.37.93.126, A) is a Type A record. •\nIf Type=NS, then Name is a domain (such as foo.com) and Value\nis the hostname of an authoritative DNS server that knows how to\nobtain the IP addresses for hosts in the domain. This record is used to\nroute DNS queries further along in the query chain. As an example,\n(foo.com, dns.foo.com, NS) is a Type NS record. •\nIf Type=CNAME, then Value is a canonical hostname for the alias\nhostname Name. This record can provide querying hosts the canonical\nname \nfor \na \nhostname. As \nan \nexample, \n(foo.com,\nrelay1.bar.foo.com, CNAME) is a CNAME record."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 128",
    "source": "kurose",
    "page": 261,
    "text": "•\nIf Type=MX, then Value is the canonical name of a mail server that\nhas an alias hostname Name. As an example, (foo.com,\nmail.bar.foo.com, MX) is an MX record. MX records allow the\nhostnames of mail servers to have simple aliases. Note that by using the\nMX record, a company can have the same aliased name for its mail\nserver and for one of its other servers (such as its Web server). To obtain\nthe canonical name for the mail server, a DNS client would query for an\nMX record; to obtain the canonical name for the other server, the DNS\nclient would query for the CNAME record. If a DNS server is authoritative for a particular hostname, then the DNS\nserver will contain a Type A record for the hostname. (Even if the DNS\nserver is not authoritative, it may contain a Type A record in its cache.) If a\nserver is not authoritative for a hostname, then the server will contain a\nType NS record for the domain that includes the hostname; it will also\ncontain a Type A record that provides the IP address of the DNS server in\nthe Value field of the NS record. As an example, suppose an edu TLD\nserver is not authoritative for the host gaia.cs.umass.edu. Then this\nserver will contain a record for a domain that includes the host\ngaia.cs.umass.edu, \nfor \nexample, \n(umass.edu,\ndns.umass.edu, NS). The edu TLD server would also contain a Type\nA record, which maps the DNS server dns.umass.edu to an IP address,\nfor example, (dns.umass.edu, 128.119.40.111, A). DNS Messages\nEarlier in this section, we referred to DNS query and reply messages. These\nare the only two kinds of DNS messages. Furthermore, both query and"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 262,
    "text": "reply messages have the same format, as shown in Figure 2.21.The\nsemantics of the various fields in a DNS message are as follows:\n•\nThe first 12 bytes is the header section, which has a number of fields. The first field is a 16-bit number that identifies the query. This identifier\nis copied into the reply message to a query, allowing the client to match\nreceived replies with sent queries. There are a number of flags in the\nflag field. A 1-bit query/reply flag indicates whether the message is a\nquery (0) or a reply (1). A 1-bit authoritative flag is set in a reply\nmessage when a DNS server is an authoritative server for a queried\nname. A 1-bit recursion-desired flag is set when a client (host or DNS\nserver) desires that the DNS server perform recursion when it doesn’t\nhave the record. A 1-bit recursion-available field is set in a reply if the\nDNS server supports recursion. In the header, there are also four\nnumber-of fields. These fields indicate the number of occurrences of the\nfour types of data sections that follow the header. •\nThe question section contains information about the query that is being\nmade. This section includes (1) a name field that contains the name that\nis being queried, and (2) a type field that indicates the type of question\nbeing asked about the name—for example, a host address associated\nwith a name (Type A) or the mail server for a name (Type MX)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 263,
    "text": "Figure 2.21 ♦DNS message format\n•\nIn a reply from a DNS server, the answer section contains the resource\nrecords for the name that was originally queried. Recall that in each\nresource record there is the Type (for example, A, NS, CNAME, and\nMX), the Value, and the TTL. A reply can return multiple RRs in the\nanswer, since a hostname can have multiple IP addresses (for example,\nfor replicated Web servers, as discussed earlier in this section). •\nThe authority section contains records of other authoritative servers. •\nThe additional section contains other helpful records. For example, the\nanswer field in a reply to an MX query contains a resource record\nproviding the canonical hostname of a mail server. The additional\nsection contains a Type A record providing the IP address for the\ncanonical hostname of the mail server. How would you like to send a DNS query message directly from the\nhost you’re working on to some DNS server? This can easily be done with"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 264,
    "text": "the nslookup program, which is available from most Windows and UNIX\nplatforms. For example, from a Windows host, open the Command Prompt\nand invoke the nslookup program by simply typing “nslookup.” After\ninvoking nslookup, you can send a DNS query to any DNS server (root,\nTLD, or authoritative). After receiving the reply message from the DNS\nserver, nslookup will display the records included in the reply (in a human-\nreadable format). As an alternative to running nslookup from your own\nhost, you can visit one of many Web sites that allow you to remotely\nemploy nslookup. (Just type “nslookup” into a search engine and you’ll be\nbrought to one of these sites.) The DNS Wireshark lab at the end of this\nchapter will allow you to explore the DNS in much more detail. Inserting Records into the DNS Database\nThe discussion above focused on how records are retrieved from the DNS\ndatabase. You might be wondering how records get into the database in the\nfirst place. Let’s look at how this is done in the context of a specific\nexample. Suppose you have just created an exciting new startup company\ncalled Network Utopia. The first thing you’ll surely want to do is register\nthe domain name networkutopia.com at a registrar. A registrar is a\ncommercial entity that verifies the uniqueness of the domain name, enters\nthe domain name into the DNS database (as discussed below), and collects\na small fee from you for its services. Prior to 1999, a single registrar,\nNetwork Solutions, had a monopoly on domain name registration for com,\nnet, and org domains. But now there are many registrars competing for\ncustomers, and the Internet Corporation for Assigned Names and Numbers\n(ICANN) accredits the various registrars. A complete list of accredited\nregistrars is available at http://www.internic.net."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 212",
    "source": "kurose",
    "page": 265,
    "text": "When you register the domain name networkutopia.com with\nsome registrar, you also need to provide the registrar with the names and IP\naddresses of your primary and secondary authoritative DNS servers. Suppose the names and IP addresses are dns1.networkutopia.com,\ndns2.networkutopia.com, \n212.2.212.1, \nand\n212.212.212.2. For each of these two authoritative DNS servers, the\nregistrar would then make sure that a Type NS and a Type A record are\nentered into the TLD com servers. Specifically, for the primary authoritative\nserver for networkutopia.com, the registrar would insert the following\ntwo resource records into the DNS system:\n(networkutopia.com, dns1.networkutopia.com, NS)\n(dns1.networkutopia.com, 212.212.212.1, A)\nFOCUS ON\nSECURITY\nDNS VULNERABILITIES\nWe have seen that DNS is a critical component of the Internet infrastructure, with many\nimportant services—including the Web and e-mail—simply incapable of functioning\nwithout it. We therefore naturally ask, how can DNS be attacked? Is DNS a sitting\nduck, waiting to be knocked out of service, while taking most Internet applications\ndown with it? The first type of attack that comes to mind is a DDoS bandwidth-flooding attack (see\nSection 1.6) against DNS servers. For example, an attacker could attempt to send to\neach DNS root server a deluge of packets, so many that the majority of legitimate DNS\nqueries never get answered. Such a large-scale DDoS attack against DNS root servers\nactually took place on October 21, 2002. In this attack, the attackers leveraged a"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 266,
    "text": "botnet to send truck loads of ICMP ping messages to each of the 13 DNS root IP\naddresses. (ICMP messages are discussed in Section 5.6. For now, it suffices to know\nthat ICMP packets are special types of IP datagrams.) Fortunately, this large-scale\nattack caused minimal damage, having little or no impact on users’ Internet experience. The attackers did succeed at directing a deluge of packets at the root servers. But\nmany of the DNS root servers were protected by packet filters, configured to always\nblock all ICMP ping messages directed at the root servers. These protected servers\nwere thus spared and functioned as normal. Furthermore, most local DNS servers\ncache the IP addresses of top-level-domain servers, allowing the query process to\noften bypass the DNS root servers. A potentially more effective DDoS attack against DNS is send a deluge of DNS\nqueries to top-level-domain servers, for example, to top-level-domain servers that\nhandle the .com domain. It is harder to filter DNS queries directed to DNS servers; and\ntop-level-domain servers are not as easily bypassed as are root servers. Such an\nattack took place against the top-level-domain service provider Dyn on October 21,\n2016. This DDoS attack was accomplished through a large number of DNS lookup\nrequests from a botnet consisting of about one hundred thousand IoT devices such as\nprinters, IP cameras, residential gateways and baby monitors that had been infected\nwith Mirai malware. For almost a full day, Amazon, Twitter, Netflix, Github and Spotify\nwere disturbed. DNS could potentially be attacked in other ways. In a man-in-the-middle attack, the\nattacker intercepts queries from hosts and returns bogus replies. In the DNS poisoning\nattack, the attacker sends bogus replies to a DNS server, tricking the server into\naccepting bogus records into its cache. Either of these attacks could be used, for\nexample, to redirect an unsuspecting Web user to the attacker’s Web site. The DNS\nSecurity Extensions (DNSSEC [Gieben 2004; RFC 4033] have been designed and\ndeployed to protect against such exploits. DNSSEC, a secured version of DNS,\naddresses many of these possible attacks and is gaining popularity in the Internet."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 212",
    "source": "kurose",
    "page": 267,
    "text": "You’ll also have to make sure that the Type A resource record for your Web\nserver www.networkutopia.com and the Type MX resource record for\nyour mail server mail.networkutopia.com are entered into your\nauthoritative DNS servers. (Until recently, the contents of each DNS server\nwere configured statically, for example, from a configuration file created by\na system manager. More recently, an UPDATE option has been added to the\nDNS protocol to allow data to be dynamically added or deleted from the\ndatabase via DNS messages. [RFC 2136] and [RFC 3007] specify DNS\ndynamic updates.) Once all of these steps are completed, people will be able to visit your\nWeb site and send e-mail to the employees at your company. Let’s conclude\nour discussion of DNS by verifying that this statement is true. This\nverification also helps to solidify what we have learned about DNS. Suppose \nAlice \nin \nAustralia \nwants \nto \nview \nthe \nWeb \npage\nwww.networkutopia.com. As discussed earlier, her host will first send\na DNS query to her local DNS server. The local DNS server will then\ncontact a TLD com server. (The local DNS server will also have to contact\na root DNS server if the address of a TLD com server is not cached.) This\nTLD server contains the Type NS and Type A resource records listed above,\nbecause the registrar had these resource records inserted into all of the TLD\ncom servers. The TLD com server sends a reply to Alice’s local DNS\nserver, with the reply containing the two resource records. The local DNS\nserver then sends a DNS query to 212.212.212.1, asking for the Type\nA record corresponding to www.networkutopia.com. This record\nprovides the IP address of the desired Web server, say, 212.212.71.4,\nwhich the local DNS server passes back to Alice’s host. Alice’s browser can\nnow initiate a TCP connection to the host 212.212.71.4 and send an"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 212",
    "source": "kurose",
    "page": 268,
    "text": "HTTP request over the connection. Whew! There’s a lot more going on than\nwhat meets the eye when one surfs the Web!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 269,
    "text": "2.5 Peer-to-Peer File Distribution\nThe applications described in this chapter thus far—including the Web, e-mail, and\nDNS—all employ client-server architectures with significant reliance on always-on\ninfrastructure servers. Recall from Section 2.1.1 that with a P2P architecture, there is\nminimal (or no) reliance on always-on infrastructure servers. Instead, pairs of\nintermittently connected hosts, called peers, communicate directly with each other. The peers are not owned by a service provider, but are instead PCs, laptops, and\nsmartpones controlled by users. In this section, we consider a very natural P2P application, namely, distributing a\nlarge file from a single server to a large number of hosts (called peers). The file might\nbe a new version of the Linux operating system, a software patch for an existing\noperating system or an MPEG video file. In client-server file distribution, the server\nmust send a copy of the file to each of the peers—placing an enormous burden on the\nserver and consuming a large amount of server bandwidth. In P2P file distribution,\neach peer can redistribute any portion of the file it has received to any other peers,\nthereby assisting the server in the distribution process. As of 2020, the most popular\nP2P file distribution protocol is BitTorrent. Originally developed by Bram Cohen,\nthere are now many different independent BitTorrent clients conforming to the\nBitTorrent protocol, just as there are a number of Web browser clients that conform to\nthe HTTP protocol. In this subsection, we first examine the self-scalability of P2P\narchitectures in the context of file distribution. We then describe BitTorrent in some\ndetail, highlighting its most important characteristics and features. Scalability of P2P Architectures\nTo compare client-server architectures with peer-to-peer architectures, and illustrate\nthe inherent self-scalability of P2P, we now consider a simple quantitative model for\ndistributing a file to a fixed set of peers for both architecture types. As shown in\nFigure 2.22, the server and the peers are connected to the Internet with access links. Denote the upload rate of the server’s access link by u , the upload rate of the ith\ns"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 270,
    "text": "peer’s access link by u . and the download rate of the ith peer’s access link by d . Also\ndenote the size of the file to be distributed (in bits) by F and the number of peers that\nwant to obtain a copy of the file by N. The distribution time is the time it takes to get\na copy of the file to all N peers. In our analysis of the distribution time below, for\nboth client-server and P2P architectures, we make the simplifying (and generally\naccurate [Akella 2003]) assumption that the Internet core has abundant bandwidth,\nimplying that all of the bottlenecks are in access networks. We also suppose that the\nserver and clients are not participating in any other network applications, so that all of\ntheir upload and download access bandwidth can be fully devoted to distributing this\nfile. Figure 2.22 ♦An illustrative file distribution problem\nLet’s first determine the distribution time for the client-server architecture, which\nwe denote by D . In the client-server architecture, none of the peers aids in\ndistributing the file. We make the following observations:\ni\ni\ncs"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 271,
    "text": "•\nThe server must transmit one copy of the file to each of the N peers. Thus, the\nserver must transmit NF bits. Since the server’s upload rate is u , the time to\ndistribute the file must be at least NF/u . •\nLet d\n denote the download rate of the peer with the lowest download rate, that\nis, d\n = min{d , d , ..., d }. The peer with the lowest download rate cannot obtain\nall F bits of the file in less than F/d\n seconds. Thus, the minimum distribution\ntime is at least F/d\n. Putting these two observations together, we obtain\nDcs ≥max{ NF\nus ,\nF\ndmin }. This provides a lower bound on the minimum distribution time for the client-server\narchitecture. In the homework problems, you will be asked to show that the server\ncan schedule its transmissions so that the lower bound is actually achieved. So let’s\ntake this lower bound provided above as the actual distribution time, that is,\nWe see from Equation 2.1 that for N large enough, the client-server distribution time\nis given by NF/u . Thus, the distribution time increases linearly with the number of\npeers N. So, for example, if the number of peers from one week to the next increases\na thousand-fold from a thousand to a million, the time required to distribute the file to\nall peers increases by 1,000. Let’s now go through a similar analysis for the P2P architecture, where each peer\ncan assist the server in distributing the file. In particular, when a peer receives some\nfile data, it can use its own upload capacity to redistribute the data to other peers. Calculating the distribution time for the P2P architecture is somewhat more\ncomplicated than for the client-server architecture, since the distribution time depends\non how each peer distributes portions of the file to the other peers. Nevertheless, a\nsimple expression for the minimal distribution time can be obtained [Kumar 2006]. To this end, we first make the following observations:\ns\ns\nmin\nmin\np\nN\nmin\nmin\nDcs = max{ NF\nus ,\nF\ndmin }\n(2.1)\ns"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 272,
    "text": "•\nAt the beginning of the distribution, only the server has the file. To get this file\ninto the community of peers, the server must send each bit of the file at least once\ninto its access link. Thus, the minimum distribution time is at least F/u . (Unlike\nthe client-server scheme, a bit sent once by the server may not have to be sent by\nthe server again, as the peers may redistribute the bit among themselves.) •\nAs with the client-server architecture, the peer with the lowest download rate\ncannot obtain all F bits of the file in less than F/d\n seconds. Thus, the minimum\ndistribution time is at least F/d\n. •\nFinally, observe that the total upload capacity of the system as a whole is equal to\nthe upload rate of the server plus the upload rates of each of the individual peers,\nthat is, u\n = u  + u  + ... + u . The system must deliver (upload) F bits to each of\nthe N peers, thus delivering a total of NF bits. This cannot be done at a rate faster\nthan u\n. Thus, the minimum distribution time is also at least NF/(u  + u  + ... +\nu ). Putting these three observations together, we obtain the minimum distribution\ntime for P2P, denoted by DP2P. Equation 2.2 provides a lower bound for the minimum distribution time for the P2P\narchitecture. It turns out that if we imagine that each peer can redistribute a bit as\nsoon as it receives the bit, then there is a redistribution scheme that actually achieves\nthis lower bound [Kumar 2006]. (We will prove a special case of this result in the\nhomework.) In reality, where chunks of the file are redistributed rather than\nindividual bits, Equation 2.2 serves as a good approximation of the actual minimum\ndistribution time. Thus, let’s take the lower bound provided by Equation 2.2 as the\nactual minimum distribution time, that is,\ns\nmin\nmin\ntotal\ns\nN\ntotal\ns\nN\nDP2P ≥max{ F\nus ,\nF\ndmin ,\nNF\nus +\nN\n∑\ni=1\nui\n}\n(2.2)\nDP2P = max{ F\nus ,\nF\ndmin ,\nNF\nus +\nN\n∑\ni=1\nui\n}\n(2.3)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 273,
    "text": "Figure 2.23 compares the minimum distribution time for the client-server and\nP2P architectures assuming that all peers have the same upload rate u. In Figure 2.23,\nwe have set F/u = 1 hour, u  = 10u, and d\n ≥ u . Thus, a peer can transmit the entire\nfile in one hour, the server transmission rate is 10 times the peer upload rate, and (for\nsimplicity) the peer download rates are set large enough so as not to have an effect. We see from Figure 2.23 that for the client-server architecture, the distribution time\nincreases linearly and without bound as the number of peers increases. However, for\nthe P2P architecture, the minimal distribution time is not only always less than the\ndistribution time of the client-server architecture; it is also less than one hour for any\nnumber of peers N. Thus, applications with the P2P architecture can be self-scaling. This scalability is a direct consequence of peers being redistributors as well as\nconsumers of bits. Figure 2.23 ♦Distribution time for P2P and client-server architectures\nBitTorrent\nBitTorrent is a popular P2P protocol for file distribution [Chao 2011]. In BitTorrent\nlingo, the collection of all peers participating in the distribution of a particular file is\ns\nmin\ns"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 274,
    "text": "called a torrent. Peers in a torrent download equal-size chunks of the file from one\nanother, with a typical chunk size of 256 KBytes. When a peer first joins a torrent, it\nhas no chunks. Over time it accumulates more and more chunks. While it downloads\nchunks it also uploads chunks to other peers. Once a peer has acquired the entire file,\nit may (selfishly) leave the torrent, or (altruistically) remain in the torrent and\ncontinue to upload chunks to other peers. Also, any peer may leave the torrent at any\ntime with only a subset of chunks, and later rejoin the torrent. Let’s now take a closer look at how BitTorrent operates. Since BitTorrent is a\nrather complicated protocol and system, we’ll only describe its most important\nmechanisms, sweeping some of the details under the rug; this will allow us to see the\nforest through the trees. Each torrent has an infrastructure node called a tracker. When a peer joins a torrent, it registers itself with the tracker and periodically informs\nthe tracker that it is still in the torrent. In this manner, the tracker keeps track of the\npeers that are participating in the torrent. A given torrent may have fewer than ten or\nmore than a thousand peers participating at any instant of time. As shown in Figure 2.24, when a new peer, Alice, joins the torrent, the tracker\nrandomly selects a subset of peers (for concreteness, say 50) from the set of\nparticipating peers, and sends the IP addresses of these 50 peers to Alice. Possessing\nthis list of peers, Alice attempts to establish concurrent TCP connections with all the\npeers on this list. Let’s call all the peers with which Alice succeeds in establishing a\nTCP connection “neighboring peers.” (In Figure 2.24, Alice is shown to have only\nthree neighboring peers. Normally, she would have many more.) As time evolves,\nsome of these peers may leave and other peers (outside the initial 50) may attempt to\nestablish TCP connections with Alice. So a peer’s neighboring peers will fluctuate\nover time."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 275,
    "text": "Figure 2.24 ♦File distribution with BitTorrent\nAt any given time, each peer will have a subset of chunks from the file, with\ndifferent peers having different subsets. Periodically, Alice will ask each of her\nneighboring peers (over the TCP connections) for the list of the chunks they have. If\nAlice has L different neighbors, she will obtain L lists of chunks. With this\nknowledge, Alice will issue requests (again over the TCP connections) for chunks she\ncurrently does not have. So at any given instant of time, Alice will have a subset of chunks and will know\nwhich chunks her neighbors have. With this information, Alice will have two\nimportant decisions to make. First, which chunks should she request first from her\nneighbors? And second, to which of her neighbors should she send requested chunks? In deciding which chunks to request, Alice uses a technique called rarest first. The\nidea is to determine, from among the chunks she does not have, the chunks that are"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 276,
    "text": "the rarest among her neighbors (that is, the chunks that have the fewest repeated\ncopies among her neighbors) and then request those rarest chunks first. In this\nmanner, the rarest chunks get more quickly redistributed, aiming to (roughly)\nequalize the numbers of copies of each chunk in the torrent. To determine which requests she responds to, BitTorrent uses a clever trading\nalgorithm. The basic idea is that Alice gives priority to the neighbors that are\ncurrently supplying her data at the highest rate. Specifically, for each of her\nneighbors, Alice continually measures the rate at which she receives bits and\ndetermines the four peers that are feeding her bits at the highest rate. She then\nreciprocates by sending chunks to these same four peers. Every 10 seconds, she\nrecalculates the rates and possibly modifies the set of four peers. In BitTorrent lingo,\nthese four peers are said to be unchoked. Importantly, every 30 seconds, she also\npicks one additional neighbor at random and sends it chunks. Let’s call the randomly\nchosen peer Bob. In BitTorrent lingo, Bob is said to be optimistically unchoked. Because Alice is sending data to Bob, she may become one of Bob’s top four\nuploaders, in which case Bob would start to send data to Alice. If the rate at which\nBob sends data to Alice is high enough, Bob could then, in turn, become one of\nAlice’s top four uploaders. In other words, every 30 seconds, Alice will randomly\nchoose a new trading partner and initiate trading with that partner. If the two peers are\nsatisfied with the trading, they will put each other in their top four lists and continue\ntrading with each other until one of the peers finds a better partner. The effect is that\npeers capable of uploading at compatible rates tend to find each other. The random\nneighbor selection also allows new peers to get chunks, so that they can have\nsomething to trade. All other neighboring peers besides these five peers (four “top”\npeers and one probing peer) are “choked,” that is, they do not receive any chunks\nfrom Alice. BitTorrent has a number of interesting mechanisms that are not discussed\nhere, including pieces (mini-chunks), pipelining, random first selection, endgame\nmode, and anti-snubbing [Cohen 2003]. The incentive mechanism for trading just described is often referred to as tit-for-\ntat [Cohen 2003]. It has been shown that this incentive scheme can be circumvented\n[Liogkas 2006; Locher 2006; Piatek 2008]. Nevertheless, the BitTorrent ecosystem is\nwildly successful, with millions of simultaneous peers actively sharing files in"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 277,
    "text": "hundreds of thousands of torrents. If BitTorrent had been designed without tit-for-tat\n(or a variant), but otherwise exactly the same, BitTorrent would likely not even exist\nnow, as the majority of the users would have been freeriders [Saroiu 2002]. We close our discussion on P2P by briefly mentioning another application of P2P,\nnamely, Distributed Hast Table (DHT). A distributed hash table is a simple database,\nwith the database records being distributed over the peers in a P2P system. DHTs\nhave been widely implemented (e.g., in BitTorrent) and have been the subject of\nextensive research. An overview is provided in a Video Note in the Companion\nWebsite. VideoNote\nWalking though distributed hash tables"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 278,
    "text": "2.6 Video Streaming and Content Distribution\nNetworks\nBy many estimates, streaming video—including Netflix, YouTube and\nAmazon Prime—account for about 80% of Internet traffic in 2020 [Cisco\n2020]. This section we will provide an overview of how popular video\nstreaming services are implemented in today’s Internet. We will see they are\nimplemented using application-level protocols and servers that function in\nsome ways like a cache. 2.6.1 Internet Video\nIn streaming stored video applications, the underlying medium is\nprerecorded video, such as a movie, a television show, a prerecorded\nsporting event, or a prerecorded user-generated video (such as those\ncommonly seen on YouTube). These prerecorded videos are placed on\nservers, and users send requests to the servers to view the videos on\ndemand. Many Internet companies today provide streaming video,\nincluding, Netflix, YouTube (Google), Amazon, and TikTok. But before launching into a discussion of video streaming, we should\nfirst get a quick feel for the video medium itself. A video is a sequence of\nimages, typically being displayed at a constant rate, for example, at 24 or 30\nimages per second. An uncompressed, digitally encoded image consists of\nan array of pixels, with each pixel encoded into a number of bits to\nrepresent luminance and color. An important characteristic of video is that it\ncan be compressed, thereby trading off video quality with bit rate. Today’s"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 279,
    "text": "off-the-shelf compression algorithms can compress a video to essentially\nany bit rate desired. Of course, the higher the bit rate, the better the image\nquality and the better the overall user viewing experience. From a networking perspective, perhaps the most salient characteristic\nof video is its high bit rate. Compressed Internet video typically ranges\nfrom 100 kbps for low-quality video to over 4 Mbps for streaming high-\ndefinition movies; 4K streaming envisions a bitrate of more than 10 Mbps. This can translate to huge amount of traffic and storage, particularly for\nhigh-end video. For example, a single 2 Mbps video with a duration of 67\nminutes will consume 1 gigabyte of storage and traffic. By far, the most\nimportant performance measure for streaming video is average end-to-end\nthroughput. In order to provide continuous playout, the network must\nprovide an average throughput to the streaming application that is at least as\nlarge as the bit rate of the compressed video. We can also use compression to create multiple versions of the same\nvideo, each at a different quality level. For example, we can use\ncompression to create, say, three versions of the same video, at rates of 300\nkbps, 1 Mbps, and 3 Mbps. Users can then decide which version they want\nto watch as a function of their current available bandwidth. Users with high-\nspeed Internet connections might choose the 3 Mbps version; users\nwatching the video over 3G with a smartphone might choose the 300 kbps\nversion. 2.6.2 HTTP Streaming and DASH\nIn HTTP streaming, the video is simply stored at an HTTP server as an\nordinary file with a specific URL. When a user wants to see the video, the\nclient establishes a TCP connection with the server and issues an HTTP"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 280,
    "text": "GET request for that URL. The server then sends the video file, within an\nHTTP response message, as quickly as the underlying network protocols\nand traffic conditions will allow. On the client side, the bytes are collected\nin a client application buffer. Once the number of bytes in this buffer\nexceeds a predetermined threshold, the client application begins playback—\nspecifically, the streaming video application periodically grabs video frames\nfrom the client application buffer, decompresses the frames, and displays\nthem on the user’s screen. Thus, the video streaming application is\ndisplaying video as it is receiving and buffering frames corresponding to\nlatter parts of the video. Although HTTP streaming, as described in the previous paragraph, has\nbeen extensively deployed in practice (for example, by YouTube since its\ninception), it has a major shortcoming: All clients receive the same\nencoding of the video, despite the large variations in the amount of\nbandwidth available to a client, both across different clients and also over\ntime for the same client. This has led to the development of a new type of\nHTTP-based streaming, often referred to as Dynamic Adaptive Streaming\nover HTTP (DASH). In DASH, the video is encoded into several different\nversions, with each version having a different bit rate and, correspondingly,\na different quality level. The client dynamically requests chunks of video\nsegments of a few seconds in length. When the amount of available\nbandwidth is high, the client naturally selects chunks from a high-rate\nversion; and when the available bandwidth is low, it naturally selects from a\nlow-rate version. The client selects different chunks one at a time with\nHTTP GET request messages [Akhshabi 2011]. DASH allows clients with different Internet access rates to stream in\nvideo at different encoding rates. Clients with low-speed 3G connections\ncan receive a low bit-rate (and low-quality) version, and clients with fiber"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 281,
    "text": "connections can receive a high-quality version. DASH also allows a client\nto adapt to the available bandwidth if the available end-to-end bandwidth\nchanges during the session. This feature is particularly important for mobile\nusers, who typically see their bandwidth availability fluctuate as they move\nwith respect to the base stations. With DASH, each video version is stored in the HTTP server, each with\na different URL. The HTTP server also has a manifest file, which provides\na URL for each version along with its bit rate. The client first requests the\nmanifest file and learns about the various versions. The client then selects\none chunk at a time by specifying a URL and a byte range in an HTTP GET\nrequest message for each chunk. While downloading chunks, the client also\nmeasures the received bandwidth and runs a rate determination algorithm to\nselect the chunk to request next. Naturally, if the client has a lot of video\nbuffered and if the measured receive bandwidth is high, it will choose a\nchunk from a high-bitrate version. And naturally if the client has little video\nbuffered and the measured received bandwidth is low, it will choose a\nchunk from a low-bitrate version. DASH therefore allows the client to\nfreely switch among different quality levels. 2.6.3 Content Distribution Networks\nToday, many Internet video companies are distributing on-demand multi-\nMbps streams to millions of users on a daily basis. YouTube, for example,\nwith a library of hundreds of millions of videos, distributes hundreds of\nmillions of video streams to users around the world every day. Streaming all\nthis traffic to locations all over the world while providing continuous\nplayout and high interactivity is clearly a challenging task."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 282,
    "text": "For an Internet video company, perhaps the most straightforward\napproach to providing streaming video service is to build a single massive\ndata center, store all of its videos in the data center, and stream the videos\ndirectly from the data center to clients worldwide. But there are three major\nproblems with this approach. First, if the client is far from the data center,\nserver-to-client packets will cross many communication links and likely\npass through many ISPs, with some of the ISPs possibly located on\ndifferent continents. If one of these links provides a throughput that is less\nthan the video consumption rate, the end-to-end throughput will also be\nbelow the consumption rate, resulting in annoying freezing delays for the\nuser. (Recall from Chapter 1 that the end-to-end throughput of a stream is\ngoverned by the throughput at the bottleneck link.) The likelihood of this\nhappening increases as the number of links in the end-to-end path increases. A second drawback is that a popular video will likely be sent many times\nover the same communication links. Not only does this waste network\nbandwidth, but the Internet video company itself will be paying its provider\nISP (connected to the data center) for sending the same bytes into the\nInternet over and over again. A third problem with this solution is that a\nsingle data center represents a single point of failure—if the data center or\nits links to the Internet goes down, it would not be able to distribute any\nvideo streams. In order to meet the challenge of distributing massive amounts of video\ndata to users distributed around the world, almost all major video-streaming\ncompanies make use of Content Distribution Networks (CDNs). A CDN\nmanages servers in multiple geographically distributed locations, stores\ncopies of the videos (and other types of Web content, including documents,\nimages, and audio) in its servers, and attempts to direct each user request to\na CDN location that will provide the best user experience. The CDN may be"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 283,
    "text": "a private CDN, that is, owned by the content provider itself; for example,\nGoogle’s CDN distributes YouTube videos and other types of content. The\nCDN may alternatively be a third-party CDN that distributes content on\nbehalf of multiple content providers; Akamai, Limelight and Level-3 all\noperate third-party CDNs. A very readable overview of modern CDNs is\n[Leighton 2009; Nygren 2010]. CDNs typically adopt one of two different server placement\nphilosophies [Huang 2008]:\n•\nEnter Deep. One philosophy, pioneered by Akamai, is to enter deep\ninto the access networks of Internet Service Providers, by deploying\nserver clusters in access ISPs all over the world. (Access networks are\ndescribed in Section 1.3.) Akamai takes this approach with clusters in\nthousands of locations. The goal is to get close to end users, thereby\nimproving user-perceived delay and throughput by decreasing the\nnumber of links and routers between the end user and the CDN server\nfrom which it receives content. Because of this highly distributed\ndesign, the task of maintaining and managing the clusters becomes\nchallenging. •\nBring Home. A second design philosophy, taken by Limelight and\nmany other CDN companies, is to bring the ISPs home by building\nlarge clusters at a smaller number (for example, tens) of sites. Instead of\ngetting inside the access ISPs, these CDNs typically place their clusters\nin Internet Exchange Points (IXPs) (see Section 1.3). Compared with\nthe enter-deep design philosophy, the bring-home design typically\nresults in lower maintenance and management overhead, possibly at the\nexpense of higher delay and lower throughput to end users."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 284,
    "text": "Once its clusters are in place, the CDN replicates content across its clusters. The CDN may not want to place a copy of every video in each cluster, since\nsome videos are rarely viewed or are only popular in some countries. In\nfact, many CDNs do not push videos to their clusters but instead use a\nsimple pull strategy: If a client requests a video from a cluster that is not\nstoring the video, then the cluster retrieves the video (from a central\nrepository or from another cluster) and stores a copy locally while\nstreaming the video to the client at the same time. Similar Web caching (see\nSection 2.2.5), when a cluster’s storage becomes full, it removes videos that\nare not frequently requested. CDN Operation\nHaving identified the two major approaches toward deploying a CDN, let’s\nnow dive down into the nuts and bolts of how a CDN operates. When a\nbrowser in a user’s host is instructed to retrieve a specific video (identified\nby a URL), the CDN must intercept the request so that it can (1) determine\na suitable CDN server cluster for that client at that time, and (2) redirect the\nclient’s request to a server in that cluster. We’ll shortly discuss how a CDN\ncan determine a suitable cluster. But first let’s examine the mechanics\nbehind intercepting and redirecting a request. CASE STUDY\nGOOGLE’S NETWORK INFRASTRUCTURE\nTo support its vast array of services—including search, Gmail, calendar, YouTube\nvideo, maps, documents, and social networks—Google has deployed an extensive"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 285,
    "text": "private network and CDN infrastructure. Google’s CDN infrastructure has three tiers of\nserver clusters:\n•\nNineteen “mega data centers” in North America, Europe, and Asia [Google\nLocations 2020], with each data center having on the order of 100,000 servers. These mega data centers are responsible for serving dynamic (and often\npersonalized) content, including search results and Gmail messages. •\nWith about 90 clusters in IXPs scattered throughout the world, with each cluster\nconsisting of hundreds of servers servers [Adhikari 2011a] [Google CDN 2020]. These clusters are responsible for serving static content, including YouTube videos. •\nMany hundreds of “enter-deep” clusters located within an access ISP. Here a\ncluster typically consists of tens of servers within a single rack. These enter-deep ­-\nservers perform TCP splitting (see Section 3.7) and serve static content [Chen\n2011], including the static portions of Web pages that embody search results. All of these data centers and cluster locations are networked together with Google’s\nown private network. When a user makes a search query, often the query is first sent\nover the local ISP to a nearby enter-deep cache, from where the static content is\nretrieved; while providing the static content to the client, the nearby cache also\nforwards the query over Google’s private network to one of the mega data centers,\nfrom where the personalized search results are retrieved. For a YouTube video, the\nvideo itself may come from one of the bring-home caches, whereas portions of the\nWeb page surrounding the video may come from the nearby enter-deep cache, and the\nadvertisements surrounding the video come from the data centers. In summary, except\nfor the local ISPs, the Google cloud services are largely provided by a network\ninfrastructure that is independent of the public Internet. Most CDNs take advantage of DNS to intercept and redirect requests;\nan interesting discussion of such a use of the DNS is [Vixie 2009]. Let’s"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 286,
    "text": "consider a simple example to illustrate how the DNS is typically involved. Suppose a content provider, NetCinema, employs the third-party CDN\ncompany, KingCDN, to distribute its videos to its customers. On the\nNetCinema Web pages, each of its videos is assigned a URL that includes\nthe string “video” and a unique identifier for the video itself; for example,\nTransformers 7 might be assigned http://video.netcinema.com/6Y7B23V. Six steps then occur, as shown in Figure 2.25:\nFigure 2.25 ♦DNS redirects a user’s request to a CDN server\n1. The user visits the Web page at NetCinema. 2. When the user clicks on the link http://video.netcinema.com/6Y7B23V,\nthe user’s host sends a DNS query for video.netcinema.com."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 287,
    "text": "3. The user’s Local DNS Server (LDNS) relays the DNS query to an\nauthoritative DNS server for NetCinema, which observes the string\n“video” in the hostname video.netcinema.com. To “hand over” the DNS\nquery to KingCDN, instead of returning an IP address, the NetCinema\nauthoritative DNS server returns to the LDNS a hostname in the\nKingCDN’s domain, for example, a1105.kingcdn.com. 4. From this point on, the DNS query enters into KingCDN’s private DNS\ninfrastructure. The user’s LDNS then sends a second query, now for\na1105.kingcdn.com, and KingCDN’s DNS system eventually returns the\nIP addresses of a KingCDN content server to the LDNS. It is thus here,\nwithin the KingCDN’s DNS system, that the CDN server from which\nthe client will receive its content is specified. 5. The LDNS forwards the IP address of the content-serving CDN node to\nthe user’s host. 6. Once the client receives the IP address for a KingCDN content server, it\nestablishes a direct TCP connection with the server at that IP address\nand issues an HTTP GET request for the video. If DASH is used, the\nserver will first send to the client a manifest file with a list of URLs, one\nfor each version of the video, and the client will dynamically select\nchunks from the different versions. Cluster Selection Strategies\nAt the core of any CDN deployment is a cluster selection strategy, that is,\na mechanism for dynamically directing clients to a server cluster or a data\ncenter within the CDN. As we just saw, the CDN learns the IP address of\nthe client’s LDNS server via the client’s DNS lookup. After learning this IP\naddress, the CDN needs to select an appropriate cluster based on this IP\naddress. CDNs generally employ proprietary cluster selection strategies. We"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 288,
    "text": "now briefly survey a few approaches, each of which has its own advantages\nand disadvantages. One simple strategy is to assign the client to the cluster that is\ngeographically closest. Using commercial geo-location databases (such as\nQuova [Quova 2020] and Max-Mind [MaxMind 2020]), each LDNS IP\naddress is mapped to a geographic location. When a DNS request is\nreceived from a particular LDNS, the CDN chooses the geographically\nclosest cluster, that is, the cluster that is the fewest kilometers from the\nLDNS “as the bird flies.” Such a solution can work reasonably well for a\nlarge fraction of the clients [Agarwal 2009]. However, for some clients, the\nsolution may perform poorly, since the geographically closest cluster may\nnot be the closest cluster in terms of the length or number of hops of the\nnetwork path. Furthermore, a problem inherent with all DNS-based\napproaches is that some end-users are configured to use remotely located\nLDNSs [Shaikh 2001; Mao 2002], in which case the LDNS location may be\nfar from the client’s location. Moreover, this simple strategy ignores the\nvariation in delay and available bandwidth over time of Internet paths,\nalways assigning the same cluster to a particular client. In order to determine the best cluster for a client based on the current\ntraffic conditions, CDNs can instead perform periodic real-time\nmeasurements of delay and loss performance between their clusters and\nclients. For instance, a CDN can have each of its clusters periodically send\nprobes (for example, ping messages or DNS queries) to all of the LDNSs\naround the world. One drawback of this approach is that many LDNSs are\nconfigured to not respond to such probes. 2.6.4 Case Studies: Netflix and YouTube"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 289,
    "text": "We conclude our discussion of streaming stored video by taking a look at\ntwo highly successful large-scale deployments: Netflix and YouTube. We’ll\nsee that each of these systems take a very different approach, yet employ\nmany of the underlying principles discussed in this section. Netflix\nAs of 2020, Netflix is the leading service provider for online movies and\nTV series in North America. As we discuss below, Netflix video distribution\nhas two major components: the Amazon cloud and its own private CDN\ninfrastructure. Netflix has a Web site that handles numerous functions, including user\nregistration and login, billing, movie catalogue for browsing and searching,\nand a movie recommendation system. As shown in Figure 2.26, this Web\nsite (and its associated backend databases) run entirely on Amazon servers\nin the Amazon cloud. Additionally, the Amazon cloud handles the following\ncritical functions:\n•\nContent ingestion. Before Netflix can distribute a movie to its\ncustomers, it must first ingest and process the movie. Netflix receives\nstudio master versions of movies and uploads them to hosts in the\nAmazon cloud. •\nContent processing. The machines in the Amazon cloud create many\ndifferent formats for each movie, suitable for a diverse array of client\nvideo players running on desktop computers, smartphones, and game\nconsoles connected to televisions. A different version is created for each\nof these formats and at multiple bit rates, allowing for adaptive\nstreaming over HTTP using DASH."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 290,
    "text": "•\nUploading versions to its CDN. Once all of the versions of a movie\nhave been created, the hosts in the Amazon cloud upload the versions to\nits CDN. Figure 2.26 ♦Netflix video streaming platform\nWhen Netflix first rolled out its video streaming service in 2007, it\nemployed three third-party CDN companies to distribute its video content. Netflix has since created its own private CDN, from which it now streams\nall of its videos. To create its own CDN, Netflix has installed server racks\nboth in IXPs and within residential ISPs themselves. Netflix currently has\nserver racks in over 200 IXP locations; see [Bottger 2018] [Netflix Open\nConnect 2020] for a current list of IXPs housing Netflix racks. There are"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 291,
    "text": "also hundreds of ISP locations housing Netflix racks; also see [Netflix Open\nConnect 2020], where Netflix provides to potential ISP partners instructions\nabout installing a (free) Netflix rack for their networks. Each server in the\nrack has several 10 Gbps Ethernet ports and over 100 terabytes of storage. The number of servers in a rack varies: IXP installations often have tens of\nservers and contain the entire Netflix streaming video library, including\nmultiple versions of the videos to support DASH. Netflix does not use pull-\ncaching (Section 2.2.5) to populate its CDN servers in the IXPs and ISPs. Instead, Netflix distributes by pushing the videos to its CDN servers during\noff-peak hours. For those locations that cannot hold the entire library,\nNetflix pushes only the most popular videos, which are determined on a\nday-to-day basis. The Netflix CDN design is described in some detail in the\nYouTube videos [Netflix Video 1] and [Netflix Video 2]; see also [Bottger\n2018]. Having described the components of the Netflix architecture, let’s take\na closer look at the interaction between the client and the various servers\nthat are involved in movie delivery. As indicated earlier, the Web pages for\nbrowsing the Netflix video library are served from servers in the Amazon\ncloud. When a user selects a movie to play, the Netflix software, running in\nthe Amazon cloud, first determines which of its CDN servers have copies of\nthe movie. Among the servers that have the movie, the software then\ndetermines the “best” server for that client request. If the client is using a\nresidential ISP that has a Netflix CDN server rack installed in that ISP, and\nthis rack has a copy of the requested movie, then a server in this rack is\ntypically selected. If not, a server at a nearby IXP is typically selected. Once Netflix determines the CDN server that is to deliver the content, it\nsends the client the IP address of the specific server as well as a manifest\nfile, which has the URLs for the different versions of the requested movie."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 292,
    "text": "The client and that CDN server then directly interact using a proprietary\nversion of DASH. Specifically, as described in Section 2.6.2, the client uses\nthe byte-range header in HTTP GET request messages, to request chunks\nfrom the different versions of the movie. Netflix uses chunks that are\napproximately four-seconds long [Adhikari 2012]. While the chunks are\nbeing downloaded, the client measures the received throughput and runs a\nrate-determination algorithm to determine the quality of the next chunk to\nrequest. Netflix embodies many of the key principles discussed earlier in this\nsection, including adaptive streaming and CDN distribution. However,\nbecause Netflix uses its own private CDN, which distributes only video\n(and not Web pages), Netflix has been able to simplify and tailor its CDN\ndesign. In particular, Netflix does not need to employ DNS redirect, as\ndiscussed in Section 2.6.3, to connect a particular client to a CDN server;\ninstead, the Netflix software (running in the Amazon cloud) directly tells\nthe client to use a particular CDN server. Furthermore, the Netflix CDN\nuses push caching rather than pull caching (Section 2.2.5): content is\npushed into the servers at scheduled times at off-peak hours, rather than\ndynamically during cache misses. YouTube\nWith hundreds of hours of video uploaded to YouTube every minute and\nseveral billion video views per day, YouTube is indisputably the world’s\nlargest video-sharing site. YouTube began its service in April 2005 and was\nacquired by Google in November 2006. Although the Google/YouTube\ndesign and protocols are proprietary, through several independent\nmeasurement efforts we can gain a basic understanding about how YouTube\noperates [Zink 2009; Torres 2011; Adhikari 2011a]. As with Netflix,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 293,
    "text": "YouTube makes extensive use of CDN technology to distribute its videos\n[Torres 2011]. Similar to Netflix, Google uses its own private CDN to\ndistribute YouTube videos, and has installed server clusters in many\nhundreds of different IXP and ISP locations. From these locations and\ndirectly from its huge data centers, Google distributes YouTube videos\n[Adhikari 2011a]. Unlike Netflix, however, Google uses pull caching, as\ndescribed in Section 2.2.5, and DNS redirect, as described in Section 2.6.3. Most of the time, Google’s cluster-selection strategy directs the client to the\ncluster for which the RTT between client and cluster is the lowest; however,\nin order to balance the load across clusters, sometimes the client is directed\n(via DNS) to a more distant cluster [Torres 2011]. YouTube employs HTTP streaming, often making a small number of\ndifferent versions available for a video, each with a different bit rate and\ncorresponding quality level. YouTube does not employ adaptive streaming\n(such as DASH), but instead requires the user to manually select a version. In order to save bandwidth and server resources that would be wasted by\nrepositioning or early termination, YouTube uses the HTTP byte range\nrequest to limit the flow of transmitted data after a target amount of video is\nprefetched. Several million videos are uploaded to YouTube every day. Not only\nare YouTube videos streamed from server to client over HTTP, but YouTube\nuploaders also upload their videos from client to server over HTTP. YouTube processes each video it receives, converting it to a YouTube video\nformat and creating multiple versions at different bit rates. This processing\ntakes place entirely within Google data centers. (See the case study on\nGoogle’s network infrastructure in Section 2.6.3.)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 294,
    "text": "2.7 Socket Programming: Creating Network\nApplications\nNow that we’ve looked at a number of important network applications, let’s\nexplore how network application programs are actually created. Recall from\nSection 2.1 that a typical network application consists of a pair of programs\n—a client program and a server program—residing in two different end\nsystems. When these two programs are executed, a client process and a\nserver process are created, and these processes communicate with each\nother by reading from, and writing to, sockets. When creating a network\napplication, the developer’s main task is therefore to write the code for both\nthe client and server programs. There are two types of network applications. One type is an\nimplementation whose operation is specified in a protocol standard, such as\nan RFC or some other standards document; such an application is\nsometimes referred to as “open,” since the rules specifying its operation are\nknown to all. For such an implementation, the client and server programs\nmust conform to the rules dictated by the RFC. For example, the client\nprogram could be an implementation of the client side of the HTTP\nprotocol, described in Section 2.2 and precisely defined in RFC 2616;\nsimilarly, the server program could be an implementation of the HTTP\nserver protocol, also precisely defined in RFC 2616. If one developer writes\ncode for the client program and another developer writes code for the server\nprogram, and both developers carefully follow the rules of the RFC, then\nthe two programs will be able to interoperate. Indeed, many of today’s\nnetwork applications involve communication between client and server"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 295,
    "text": "programs that have been created by independent developers—for example,\na Google Chrome browser communicating with an Apache Web server, or a\nBitTorrent client communicating with BitTorrent tracker. The other type of network application is a proprietary network\napplication. In this case, the client and server programs employ an\napplication-layer protocol that has not been openly published in an RFC or\nelsewhere. A single developer (or development team) creates both the client\nand server programs, and the developer has complete control over what\ngoes in the code. But because the code does not implement an open\nprotocol, other independent developers will not be able to develop code that\ninteroperates with the application. In this section, we’ll examine the key issues in developing a client-\nserver application, and we’ll “get our hands dirty” by looking at code that\nimplements a very simple client-server application. During the development\nphase, one of the first decisions the developer must make is whether the\napplication is to run over TCP or over UDP. Recall that TCP is connection\noriented and provides a reliable byte-stream channel through which data\nflows between two end systems. UDP is connectionless and sends\nindependent packets of data from one end system to the other, without any\nguarantees about delivery. Recall also that when a client or server program\nimplements a protocol defined by an RFC, it should use the well-known\nport number associated with the protocol; conversely, when developing a\nproprietary application, the developer must be careful to avoid using such\nwell-known port numbers. (Port numbers were briefly discussed in Section\n2.1. They are covered in more detail in Chapter 3.) We introduce UDP and TCP socket programming by way of a simple\nUDP application and a simple TCP application. We present the simple UDP\nand TCP applications in Python 3. We could have written the code in Java,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 296,
    "text": "C, or C++, but we chose Python mostly because Python clearly exposes the\nkey socket concepts. With Python there are fewer lines of code, and each\nline can be explained to the novice programmer without difficulty. But\nthere’s no need to be frightened if you are not familiar with Python. You\nshould be able to easily follow the code if you have experience\nprogramming in Java, C, or C++. If you are interested in client-server programming with Java, you are\nencouraged to see the Companion Website for this textbook; in fact, you can\nfind there all the examples in this section (and associated labs) in Java. For\nreaders who are interested in client-server programming in C, there are\nseveral good references available [Donahoo 2001; Stevens 1997; Frost\n1994]; our Python examples below have a similar look and feel to C.\n2.7.1 Socket Programming with UDP\nIn this subsection, we’ll write simple client-server programs that use UDP;\nin the following section, we’ll write similar programs that use TCP. Recall from Section 2.1 that processes running on different machines\ncommunicate with each other by sending messages into sockets. We said\nthat each process is analogous to a house and the process’s socket is\nanalogous to a door. The application resides on one side of the door in the\nhouse; the transport-layer protocol resides on the other side of the door in\nthe outside world. The application developer has control of everything on\nthe application-layer side of the socket; however, it has little control of the\ntransport-layer side. Now let’s take a closer look at the interaction between two\ncommunicating processes that use UDP sockets. Before the sending process\ncan push a packet of data out the socket door, when using UDP, it must first"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 297,
    "text": "attach a destination address to the packet. After the packet passes through\nthe sender’s socket, the Internet will use this destination address to route the\npacket through the Internet to the socket in the receiving process. When the\npacket arrives at the receiving socket, the receiving process will retrieve the\npacket through the socket, and then inspect the packet’s contents and take\nappropriate action. So you may be now wondering, what goes into the destination address\nthat is attached to the packet? As you might expect, the destination host’s IP\naddress is part of the destination address. By including the destination IP\naddress in the packet, the routers in the Internet will be able to route the\npacket through the Internet to the destination host. But because a host may\nbe running many network application processes, each with one or more\nsockets, it is also necessary to identify the particular socket in the\ndestination host. When a socket is created, an identifier, called a port\nnumber, is assigned to it. So, as you might expect, the packet’s destination\naddress also includes the socket’s port number. In summary, the sending\nprocess attaches to the packet a destination address, which consists of the\ndestination host’s IP address and the destination socket’s port number. Moreover, as we shall soon see, the sender’s source address—consisting of\nthe IP address of the source host and the port number of the source socket—\nare also attached to the packet. However, attaching the source address to the\npacket is typically not done by the UDP application code; instead it is\nautomatically done by the underlying operating system. We’ll use the following simple client-server application to demonstrate\nsocket programming for both UDP and TCP:\n1. The client reads a line of characters (data) from its keyboard and sends\nthe data to the server. 2. The server receives the data and converts the characters to uppercase."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 298,
    "text": "3. The server sends the modified data to the client. 4. The client receives the modified data and displays the line on its screen. Figure 2.27 highlights the main socket-related activity of the client and\nserver that communicate over the UDP transport service. Figure 2.27 ♦The client-server application using UDP\nNow let’s get our hands dirty and take a look at the client-server\nprogram pair for a UDP implementation of this simple application. We also\nprovide a detailed, line-by-line analysis after each program. We’ll begin"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 299,
    "text": "with the UDP client, which will send a simple application-level message to\nthe server. In order for the server to be able to receive and reply to the\nclient’s message, it must be ready and running—that is, it must be running\nas a process before the client sends its message. The client program is called UDPClient.py, and the server program is\ncalled UDPServer.py. In order to emphasize the key issues, we intentionally\nprovide code that is minimal. “Good code” would certainly have a few\nmore auxiliary lines, in particular for handling error cases. For this\napplication, we have arbitrarily chosen 12000 for the server port number. UDPClient.py\nHere is the code for the client side of the application:\nfrom socket import *\nserverName = ’hostname’\nserverPort = 12000\nclientSocket = socket(AF_INET, SOCK_DGRAM)\nmessage = input(’Input lowercase sentence:’)\nclientSocket.sendto(message.encode(),(serverName,\nserverPort))\nmodifiedMessage, serverAddress =\nclientSocket.recvfrom(2048)\nprint(modifiedMessage.decode())\nclientSocket.close()\nNow let’s take a look at the various lines of code in UDPClient.py. from socket import *"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 300,
    "text": "The socket module forms the basis of all network communications in\nPython. By including this line, we will be able to create sockets within our\nprogram. serverName = ’hostname’\nserverPort = 12000\nThe first line sets the variable serverName to the string ‘hostname’. Here, we provide a string containing either the IP address of the server (e.g.,\n“128.138.32.126”) or the hostname of the server (e.g., “cis.poly.edu”). If we\nuse the hostname, then a DNS lookup will automatically be performed to\nget the IP address.) The second line sets the integer variable serverPort\nto 12000.\nclientSocket = socket(AF_INET, SOCK_DGRAM)\nThis line creates the client’s socket, called clientSocket. The first\nparameter indicates the address family; in particular, AF_INET indicates\nthat the underlying network is using IPv4. (Do not worry about this now—\nwe will discuss IPv4 in Chapter 4.) The second parameter indicates that the\nsocket is of type SOCK_DGRAM, which means it is a UDP socket (rather\nthan a TCP socket). Note that we are not specifying the port number of the\nclient socket when we create it; we are instead letting the operating system\ndo this for us. Now that the client process’s door has been created, we will\nwant to create a message to send through the door. message = input(’Input lowercase sentence:’)\ninput() is a built-in function in Python. When this command is executed,\nthe user at the client is prompted with the words “Input lowercase"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 301,
    "text": "sentence:” The user then uses her keyboard to input a line, which is put into\nthe variable message. Now that we have a socket and a message, we will\nwant to send the message through the socket to the destination host. clientSocket.sendto(message.encode(), (serverName,\n serverPort))\nIn the above line, we first convert the message from string type to byte type,\nas we need to send bytes into a socket; this is done with the encode()\nmethod. The method sendto() attaches the destination address\n(serverName, serverPort) to the message and sends the resulting\npacket into the process’s socket, clientSocket. (As mentioned earlier,\nthe source address is also attached to the packet, although this is done\nautomatically rather than explicitly by the code.) Sending a client-to-server\nmessage via a UDP socket is that simple! After sending the packet, the\nclient waits to receive data from the server. modifiedMessage, serverAddress =\nclientSocket.recvfrom(2048)\nWith the above line, when a packet arrives from the Internet at the client’s\nsocket, the packet’s data is put into the variable modifiedMessage and\nthe packet’s source address is put into the variable serverAddress. The\nvariable serverAddress contains both the server’s IP address and the\nserver’s port number. The program UDPClient doesn’t actually need this\nserver address information, since it already knows the server address from\nthe outset; but this line of Python provides the server address nevertheless. The method recvfrom also takes the buffer size 2048 as input. (This\nbuffer size works for most purposes.)"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 302,
    "text": "print(modifiedMessage.decode())\nThis line prints out modifiedMessage on the user’s display, after converting\nthe message from bytes to string. It should be the original line that the user\ntyped, but now capitalized. clientSocket.close()\nThis line closes the socket. The process then terminates. UDPServer.py\nLet’s now take a look at the server side of the application:\nfrom socket import *\nserverPort = 12000\nserverSocket = socket(AF_INET, SOCK_DGRAM)\nserverSocket.bind((’’, serverPort))\nprint(”The server is ready to receive”)\nwhile True:\n    message, clientAddress =\nserverSocket.recvfrom(2048)\n    modifiedMessage = message.decode().upper()\n    serverSocket.sendto(modifiedMessage.encode(),\nclientAddress)\nNote that the beginning of UDPServer is similar to UDPClient. It also\nimports the socket module, also sets the integer variable serverPort to\n12000, and also creates a socket of type SOCK_DGRAM (a UDP socket). The first line of code that is significantly different from UDPClient is:"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 303,
    "text": "serverSocket.bind((’’, serverPort))\nThe above line binds (that is, assigns) the port number 12000 to the server’s\nsocket. Thus, in UDPServer, the code (written by the application developer)\nis explicitly assigning a port number to the socket. In this manner, when\nanyone sends a packet to port 12000 at the IP address of the server, that\npacket will be directed to this socket. UDPServer then enters a while loop;\nthe while loop will allow UDPServer to receive and process packets from\nclients indefinitely. In the while loop, UDPServer waits for a packet to\narrive. message, clientAddress =\nserverSocket.recvfrom(2048)\nThis line of code is similar to what we saw in UDPClient. When a packet\narrives at the server’s socket, the packet’s data is put into the variable\nmessage and the packet’s source address is put into the variable\nclientAddress. The variable ­clientAddress contains both the client’s IP\naddress and the client’s port number. Here, UDPServer will make use of this\naddress information, as it provides a return address, similar to the return\naddress with ordinary postal mail. With this source address information, the\nserver now knows to where it should direct its reply. modifiedMessage = message.decode().upper()\nThis line is the heart of our simple application. It takes the line sent by the\nclient and, after converting the message to a string, uses the method\nupper() to capitalize it."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 304,
    "text": "serverSocket.sendto(modifiedMessage.encode(),\nclientAddress)\nThis last line attaches the client’s address (IP address and port number) to\nthe capitalized message (after converting the string to bytes), and sends the\nresulting packet into the server’s socket. (As mentioned earlier, the server\naddress is also attached to the packet, although this is done automatically\nrather than explicitly by the code.) The Internet will then deliver the packet\nto this client address. After the server sends the packet, it remains in the\nwhile loop, waiting for another UDP packet to arrive (from any client\nrunning on any host). To test the pair of programs, you run UDPClient.py on one host and\nUDPServer.py on another host. Be sure to include the proper hostname or\nIP address of the server in UDPClient.py. Next, you execute UDPServer.py,\nthe compiled server program, in the server host. This creates a process in\nthe server that idles until it is contacted by some client. Then you execute\nUDPClient.py, the compiled client program, in the client. This creates a\nprocess in the client. Finally, to use the application at the client, you type a\nsentence followed by a carriage return. To develop your own UDP client-server application, you can begin by\nslightly modifying the client or server programs. For example, instead of\nconverting all the letters to uppercase, the server could count the number of\ntimes the letter s appears and return this number. Or you can modify the\nclient so that after receiving a capitalized sentence, the user can continue to\nsend more sentences to the server. 2.7.2 Socket Programming with TCP"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 305,
    "text": "Unlike UDP, TCP is a connection-oriented protocol. This means that before\nthe client and server can start to send data to each other, they first need to\nhandshake and establish a TCP connection. One end of the TCP connection\nis attached to the client socket and the other end is attached to a server\nsocket. When creating the TCP connection, we associate with it the client\nsocket address (IP address and port number) and the server socket address\n(IP address and port number). With the TCP connection established, when\none side wants to send data to the other side, it just drops the data into the\nTCP connection via its socket. This is different from UDP, for which the\nserver must attach a destination address to the packet before dropping it into\nthe socket. Now let’s take a closer look at the interaction of client and server\nprograms in TCP. The client has the job of initiating contact with the server. In order for the server to be able to react to the client’s initial contact, the\nserver has to be ready. This implies two things. First, as in the case of UDP,\nthe TCP server must be running as a process before the client attempts to\ninitiate contact. Second, the server program must have a special door—\nmore precisely, a special socket—that welcomes some initial contact from a\nclient process running on an arbitrary host. Using our house/door analogy\nfor a process/socket, we will sometimes refer to the client’s initial contact as\n“knocking on the welcoming door.”\nWith the server process running, the client process can initiate a TCP\nconnection to the server. This is done in the client program by creating a\nTCP socket. When the client creates its TCP socket, it specifies the address\nof the welcoming socket in the server, namely, the IP address of the server\nhost and the port number of the socket. After creating its socket, the client\ninitiates a three-way handshake and establishes a TCP connection with the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 306,
    "text": "server. The three-way handshake, which takes place within the transport\nlayer, is completely invisible to the client and server programs. During the three-way handshake, the client process knocks on the\nwelcoming door of the server process. When the server “hears” the\nknocking, it creates a new door—more precisely, a new socket that is\ndedicated to that particular ­client. In our example below, the welcoming\ndoor is a TCP socket object that we call ­serverSocket; the newly\ncreated socket dedicated to the client making the connection is called\nconnectionSocket. Students who are encountering TCP sockets for\nthe first time sometimes confuse the welcoming socket (which is the initial\npoint of contact for all clients wanting to communicate with the server), and\neach newly created server-side connection socket that is subsequently\ncreated for communicating with each client. From the application’s perspective, the client’s socket and the server’s\nconnection socket are directly connected by a pipe. As shown in Figure\n2.28, the client process can send arbitrary bytes into its socket, and TCP\nguarantees that the server process will receive (through the connection\nsocket) each byte in the order sent. TCP thus provides a reliable service\nbetween the client and server processes. Furthermore, just as people can go\nin and out the same door, the client process not only sends bytes into but\nalso receives bytes from its socket; similarly, the server process not only\nreceives bytes from but also sends bytes into its connection socket."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 307,
    "text": "Figure 2.28 ♦The TCPServer process has two sockets\nWe use the same simple client-server application to demonstrate socket\nprogramming with TCP: The client sends one line of data to the server, the\nserver capitalizes the line and sends it back to the client. Figure 2.29\nhighlights the main socket-related activity of the client and server that\ncommunicate over the TCP transport service."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 308,
    "text": "Figure 2.29 ♦The client-server application using TCP\nTCPClient.py\nHere is the code for the client side of the application:\nfrom socket import *"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 309,
    "text": "serverName = ’servername’\nserverPort = 12000\nclientSocket = socket(AF_INET, SOCK_STREAM)\nclientSocket.connect((serverName,serverPort))\nsentence = input(’Input lowercase sentence:’)\nclientSocket.send(sentence.encode())\nmodifiedSentence = clientSocket.recv(1024)\nprint(’From Server: ’, modifiedSentence.decode()) \nclientSocket.close()\nLet’s now take a look at the various lines in the code that differ significantly\nfrom the UDP implementation. The first such line is the creation of the\nclient socket. clientSocket = socket(AF_INET, SOCK_STREAM)\nThis line creates the client’s socket, called clientSocket. The first\nparameter again indicates that the underlying network is using IPv4. The\nsecond parameter indicates that the socket is of type SOCK_STREAM,\nwhich means it is a TCP socket (rather than a UDP socket). Note that we are\nagain not specifying the port number of the client socket when we create it;\nwe are instead letting the operating system do this for us. Now the next line\nof code is very different from what we saw in UDPClient:\nclientSocket.connect((serverName,serverPort))\nRecall that before the client can send data to the server (or vice versa) using\na TCP socket, a TCP connection must first be established between the client\nand server. The above line initiates the TCP connection between the client\nand server. The parameter of the connect() method is the address of the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 310,
    "text": "server side of the connection. After this line of code is executed, the three-\nway handshake is performed and a TCP connection is established between\nthe client and server. sentence = input(’Input lowercase sentence:’)\nAs with UDPClient, the above obtains a sentence from the user. The string\nsentence continues to gather characters until the user ends the line by\ntyping a carriage return. The next line of code is also very different from\nUDPClient:\nclientSocket.send(sentence.encode())\nThe above line sends the sentence through the client’s socket and into\nthe TCP connection. Note that the program does not explicitly create a\npacket and attach the destination address to the packet, as was the case with\nUDP sockets. Instead the client program simply drops the bytes in the string\nsentence into the TCP connection. The client then waits to receive bytes\nfrom the server. modifiedSentence = clientSocket.recv(2048)\nWhen characters arrive from the server, they get placed into the string\nmodifiedSentence. Characters \ncontinue \nto \naccumulate \nin\nmodifiedSentence until the line ends with a carriage return character. After printing the capitalized sentence, we close the client’s socket:\nclientSocket.close()\nThis last line closes the socket and, hence, closes the TCP connection\nbetween the client and the server. It causes TCP in the client to send a TCP"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 311,
    "text": "message to TCP in the server (see Section 3.5). TCPServer.py\nNow let’s take a look at the server program. from socket import *\nserverPort = 12000\nserverSocket = socket(AF_INET,SOCK_STREAM)\nserverSocket.bind((’’,serverPort))\nserverSocket.listen(1)\nprint(’The server is ready to receive’)\nwhile True:\n    connectionSocket, addr = serverSocket.accept()\n    sentence =\nconnectionSocket.recv(1024).decode()\n    capitalizedSentence = sentence.upper()\n    connectionSocket.send(capitalizedSentence.enco\nde()) \n    connectionSocket.close()\nLet’s now take a look at the lines that differ significantly from UDPServer\nand TCPClient. As with TCPClient, the server creates a TCP socket with:\nserverSocket=socket(AF_INET,SOCK_STREAM)\nSimilar to UDPServer, we associate the server port number, serverPort,\nwith this socket:\nserverSocket.bind((’’,serverPort))"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 312,
    "text": "But with TCP, serverSocket will be our welcoming socket. After\nestablishing this welcoming door, we will wait and listen for some client to\nknock on the door:\nserverSocket.listen(1)\nThis line has the server listen for TCP connection requests from the client. The parameter specifies the maximum number of queued connections (at\nleast 1). connectionSocket, addr = serverSocket.accept()\nWhen a client knocks on this door, the program invokes the accept()\nmethod for serverSocket, which creates a new socket in the server, called ­-\nconnectionSocket, dedicated to this particular client. The client and\nserver then complete the handshaking, creating a TCP connection between\nthe client’s clientSocket and the server’s connectionSocket. With the TCP connection established, the client and server can now send\nbytes to each other over the connection. With TCP, all bytes sent from one\nside are only guaranteed to arrive at the other side but also guaranteed to\narrive in order. connectionSocket.close()\nIn this program, after sending the modified sentence to the client, we close\nthe connection socket. But since serverSocket remains open, another\nclient can now knock on the door and send the server a sentence to modify. This completes our discussion of socket programming in TCP. You are\nencouraged to run the two programs in two separate hosts, and also to\nmodify them to achieve slightly different goals. You should compare the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 313,
    "text": "UDP program pair with the TCP program pair and see how they differ. You\nshould also do many of the socket programming assignments described at\nthe ends of Chapter 2 and 5. Finally, we hope someday, after mastering\nthese and more advanced socket programs, you will write your own popular\nnetwork application, become very rich and famous, and remember the\nauthors of this textbook!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 314,
    "text": "2.8 Summary\nIn this chapter, we’ve studied the conceptual and the implementation\naspects of network applications. We’ve learned about the ubiquitous client-\nserver architecture adopted by many Internet applications and seen its use in\nthe HTTP, SMTP, and DNS protocols. We’ve studied these important\napplication-level protocols, and their corresponding associated applications\n(the Web, file transfer, e-mail, and DNS) in some detail. We’ve learned\nabout the P2P architecture and contrasted it with the client-server\narchitecture. We’ve also learned about streaming video, and how modern\nvideo distribution systems leverage CDNs. We’ve examined how the socket\nAPI can be used to build network applications. We’ve walked through the\nuse of sockets for connection-oriented (TCP) and connectionless (UDP)\nend-to-end transport services. The first step in our journey down the layered\nnetwork architecture is now complete! At the very beginning of this book, in Section 1.1, we gave a rather\nvague, bare-bones definition of a protocol: “the format and the order of\nmessages exchanged between two or more communicating entities, as well\nas the actions taken on the transmission and/or receipt of a message or other\nevent.” The material in this chapter, and in particular our detailed study of\nthe HTTP, SMTP, and DNS protocols, has now added considerable\nsubstance to this definition. Protocols are a key concept in networking; our\nstudy of application protocols has now given us the opportunity to develop\na more intuitive feel for what protocols are all about. In Section 2.1, we described the service models that TCP and UDP\noffer to applications that invoke them. We took an even closer look at these\nservice models when we developed simple applications that run over TCP"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 315,
    "text": "and UDP in Section 2.7. However, we have said little about how TCP and\nUDP provide these service models. For example, we know that TCP\nprovides a reliable data service, but we haven’t said yet how it does so. In\nthe next chapter, we’ll take a careful look at not only the what, but also the\nhow and why of transport protocols. Equipped with knowledge about Internet application structure and\napplication-level protocols, we’re now ready to head further down the\nprotocol stack and examine the transport layer in Chapter 3."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 316,
    "text": "Homework Problems and Questions\nChapter 2 Review Questions\nSECTION 2.1\nR1. List five nonproprietary Internet applications and the application-\nlayer protocols that they use. R2. What is the difference between network architecture and application\narchitecture? R3. For a communication session between a pair of processes, which\nprocess is the client and which is the server? R4. Why are the terms client and server still used in peer-to-peer\napplications? R5. What information is used by a process running on one host to identify\na process running on another host? R6. What is the role of HTTP in a network application? What other\ncomponents are needed to complete a Web application? R7. Referring to Figure 2.4, we see that none of the applications listed in\nFigure 2.4 requires both no data loss and timing. Can you conceive of\nan application that requires no data loss and that is also highly time-\nsensitive? R8. List the four broad classes of services that a transport protocol can\nprovide. For each of the service classes, indicate if either UDP or\nTCP (or both) provides such a service. R9. Recall that TCP can be enhanced with TLS to provide process-to-\nprocess security services, including encryption. Does TLS operate at\nthe transport layer or the application layer? If the application"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 317,
    "text": "developer wants TCP to be enhanced with TLS, what does the\ndeveloper have to do? SECTIONS 2.2-2.5\nR10. What is meant by a handshaking protocol? R11. What does a stateless protocol mean? Is IMAP stateless? What about\nSMTP? R12. How can websites keep track of users? Do they always need to use\ncookies? R13. Describe how Web caching can reduce the delay in receiving a\nrequested object. Will Web caching reduce the delay for all objects\nrequested by a user or for only some of the objects? Why? R14. Telnet into a Web server and send a multiline request message. Include in the request message the If-modified-since: header\nline to force a response message with the 304 Not Modified\nstatus code. R15. Are there any constraints on the format of the HTTP body? What\nabout the email message body sent with SMTP? How can arbitrary\ndata be transmitted over SMTP? R16. Suppose Alice, with a Web-based e-mail account (such as Hotmail or\nGmail), sends a message to Bob, who accesses his mail from his mail\nserver using IMAP. Discuss how the message gets from Alice’s host\nto Bob’s host. Be sure to list the series of application-layer protocols\nthat are used to move the message between the two hosts. R17. Print out the header of an e-mail message you have recently received. How many Received: header lines are there? Analyze each of the\nheader lines in the message."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 318,
    "text": "R18. What is the HOL blocking issue in HTTP/1.1? How does HTTP/2\nattempt to solve it? R19. Why are MX records needed? Would it not be enough to use a\nCNAME record? (Assume the email client looks up email addresses\nthrough a Type A query and that the target host only runs an email\nserver.) R20. What is the difference between recursive and iterative DNS queries? SECTION 2.5\nR21. Under what circumstances is file downloading through P2P much\nfaster than through a centralized client-server approach? Justify your\nanswer using Equation 2.2. R22. Consider a new peer Alice that joins BitTorrent without possessing\nany chunks. Without any chunks, she cannot become a top-four\nuploader for any of the other peers, since she has nothing to upload. How then will Alice get her first chunk? R23. Assume a BitTorrent tracker suddenly becomes unavailable. What are\nits consequences? Can files still be downloaded? SECTION 2.6\nR24. CDNs typically adopt one of two different server placement\nphilosophies. Name and briefly describe them. R25. Besides network-related considerations such as delay, loss, and\nbandwidth performance, there are other important factors that go into\ndesigning a CDN server selection strategy. What are they? SECTION 2.7\nR26. In Section 2.7, the UDP server described needed only one socket,\nwhereas the TCP server needed two sockets. Why? If the TCP server"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 319,
    "text": "were to support n simultaneous connections, each from a different\nclient host, how many sockets would the TCP server need? R27. For the client-server application over TCP described in Section 2.7,\nwhy must the server program be executed before the client program? For the client-server application over UDP, why may the client\nprogram be executed before the server program? Problems\nP1. True or false? a. A user requests a Web page that consists of some text and three\nimages. For this page, the client will send one request message\nand receive four response messages. b. Two distinct Web pages (for example,\nwww.mit.edu/research.html and\nwww.mit.edu/students.html) can be sent over the same\npersistent connection. c. With nonpersistent connections between browser and origin\nserver, it is possible for a single TCP segment to carry two\ndistinct HTTP request messages. d. The Date: header in the HTTP response message indicates\nwhen the object in the response was last modified. e. HTTP response messages never have an empty message body. P2. SMS, iMessage, Wechat, and WhatsApp are all smartphone real-time\nmessaging systems. After doing some research on the Internet, for\neach of these systems write one paragraph about the protocols they\nuse. Then write a paragraph explaining how they differ."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 320,
    "text": "P3. Assume you open a browser and enter\nhttp://yourbusiness.com/about.html in the address bar. What happens until the webpage is ­displayed? Provide details about\nthe protocol(s) used and a high-level description of the messages\nexchanged. P4. Consider the following string of ASCII characters that were captured\nby Wireshark when the browser sent an HTTP GET message (i.e., this\nis the actual content of an HTTP GET message). The characters <cr>\n<lf> are carriage return and line-feed characters (that is, the italized\ncharacter string <cr> in the text below represents the single carriage-\nreturn character that was contained at that point in the HTTP header). Answer the following questions, indicating where in the HTTP GET\nmessage below you find the answer. GET /cs453/index.html HTTP/1.1<cr><lf>Host:\ngai a.cs.umass.edu<cr><lf>User-Agent:\nMozilla/5.0 (Windows;U; Windows NT 5.1; en-US;\nrv:1.7.2) Gec ko/20040804 Netscape/7.2 (ax)\n<cr><lf>Accept:ex t/xml, application/xml,\napplication/xhtml+xml, text /html;q=0.9,\ntext/plain;q=0.8,image/png,*/*;q=0.5 <cr>\n<lf>Accept-Language: en-us,en;q=0.5<cr>\n<lf>Accept-Encoding: zip,deflate<cr>\n<lf>Accept-Charset: ISO-8859-1,utf-\n8;q=0.7,*;q=0.7<cr><lf>Keep-Alive: 300<cr>\n<lf> Connection:keep-alive <cr><lf><cr><lf>\na. What is the URL of the document requested by the browser? b. What version of HTTP is the browser running?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 321,
    "text": "c. Does the browser request a non-persistent or a persistent\nconnection? d. What is the IP address of the host on which the browser is\nrunning? e. What type of browser initiates this message? Why is the browser\ntype needed in an HTTP request message? P5. The text below shows the reply sent from the server in response to the\nHTTP GET message in the question above. Answer the following\nquestions, indicating where in the message below you find the\nanswer. HTTP/1.1 200 OK<cr><lf>Date: Tue, 07 Mar 2008\n12:39:45GMT<cr><lf>Server: Apache/2.0.52\n(Fedora) <cr><lf>Last-Modified: Sat, 10\nDec2005 18:27:46 GMT<cr><lf>ETag: ”526c3-f22-\na88a4c80”<cr><lf>Accept-Ranges: bytes<cr>\n<lf>Content-Length: 3874<cr><lf> Keep-Alive:\ntimeout=max=100<cr><lf>Connection: Keep-\nAlive<cr><lf>Content-Type: text/html;\ncharset=ISO-8859-1<cr><lf><cr><lf><!doctype\nhtml public ”-//w3c//dtd html\n4.0transitional//en”><lf><html><lf> <head><lf>\n<meta http-equiv=”Content-Type”\ncontent=”text/html; charset=iso-8859-1”><lf>\n<meta name=”GENERATOR” content=”Mozilla/4.79\n[en] (Windows NT 5.0; U) Netscape]”><lf>\n<title>CMPSCI 453 / 591 / NTU-ST550ASpring\n2005 homepage</title><lf></head><lf> <much\nmore document text following here (not shown)>"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 322,
    "text": "a. Was the server able to successfully find the document or not? What time was the document reply provided? b. When was the document last modified? c. How many bytes are there in the document being returned? d. What are the first 5 bytes of the document being returned? Did\nthe server agree to a persistent connection? P6. Obtain the HTTP/1.1 specification (RFC 2616). Answer the following\nquestions:\na. Explain the mechanism used for signaling between the client and\nserver to indicate that a persistent connection is being closed. Can the client, the server, or both signal the close of a\nconnection? b. What encryption services are provided by HTTP? c. Can a client open three or more simultaneous connections with a\ngiven server? d. Either a server or a client may close a transport connection\nbetween them if either one detects the connection has been idle\nfor some time. Is it possible that one side starts closing a\nconnection while the other side is transmitting data via this\nconnection? Explain. P7. Suppose within your Web browser, you click on a link to obtain a\nWeb page. The IP address for the associated URL is not cached in\nyour local host, so a DNS lookup is necessary to obtain the IP\naddress. Suppose that n DNS servers are visited before your host\nreceives the IP address from DNS; the successive visits incur an RTT\nof RTT , . . . , RTT . Further suppose that the Web page associated\nwith the link contains exactly one object, consisting of a large amount\nof HTML text. Let RTT  denote the RTT between the local host and\nn"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 323,
    "text": "the server containing the object. Assuming transmission duration of\n0.002 × RTT  of the object, how much time elapses from when the\nclient clicks on the link until the client receives the object? P8. Consider Problem P7 again and assume RTT  = RTT  = RTT  = . . . RTT  = RTT, Furthermore, assume a new HTML file, small enough to\nhave negligible transmission time, which references nine equally\nsmall objects on the same server. How much time elapses with\na. non-persistent HTTP with no parallel TCP connections? b. non-persistent HTTP with the browser configured for 6 parallel ­-\nconnections? c. persistent HTTP? P9. Consider Figure 2.12, for which there is an institutional network\nconnected to the Internet. Moreover, assume the access link has been\nupgraded to 54 Mbps, and the institutional LAN is upgraded to 10\nGbps. Suppose that the average object size is 1,600,000 bits and that\nthe average request rate from the institution’s browsers to the origin\nservers is 24 requests per second. Also suppose that the amount of\ntime it takes from when the router on the Internet side of the access\nlink forwards an HTTP request until it receives the response is three\nseconds on average (see Section 2.2.5). Model the total average\nresponse time as the sum of the average access delay (that is, the\ndelay from Internet router to institution router) and the average\nInternet delay. For the average access delay, use ∆/(1 − ∆β), where ∆\nis the average time required to send an object over the access link and\nβ is the arrival rate of objects to the access link. a. Find the total average response time. b. Now suppose a cache is installed in the institutional LAN. Suppose the miss rate is 0.3. Find the total response time. 0\n2\nn"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 324,
    "text": "P10. Consider a 30-meter link, over which a sender can transmit at a rate of\n300 bits/sec in both directions. Suppose that packets containing data\nare 100,000 bits long, and packets containing only control (e.g., ACK\nor handshaking) are 200 bits long. Assume that N parallel connections\neach get 1/N of the link bandwidth. Now, consider the HTTP protocol\nand suppose that each downloaded object is 100 Kbits long, and that\nthe initial downloaded object contains 10 referenced objects from the\nsame sender. Would parallel downloads via parallel instances of non-\npersistent HTTP make sense in this case? Now consider persistent\nHTTP. Do you expect significant gains over the non-persistent case? Justify and explain your answer. P11. Consider the scenario introduced in the previous problem. Now,\nsuppose that the link is shared by Alice with Bob. Alice does not use\nparallel instances of non-persistent HTTP while Bob uses non-\npersistent HTTP with five parallel downloads each. a. Does Alice have any advantage over Bob? Why or why not? b. If Alice opens five parallel instances of non-persistent HTTP,\nthen would her parallel connections be beneficial? Why or why\nnot? P12. Write a simple TCP program for a server that accepts lines of input\nfrom a client and prints the lines onto the server’s standard output. (You can do this by modifying the TCPServer.py program in the text.) Compile and execute your program. On any other machine that\ncontains a Web browser, set the proxy server in the browser to the\nhost that is running your server program; also configure the port\nnumber appropriately. Your browser should now send its GET request\nmessages to your server, and your server should display the messages\non its standard output. Use this platform to determine whether your"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 325,
    "text": "browser generates conditional GET messages for objects that are\nlocally cached. P13. Consider sending over HTTP/2 a Web page that consists of one video\nfile and three images. Suppose that the video clip is transported as\n5000 frames, and each image captures four frames. a. If all the video frames are sent first without interleaving, how\nmany “frame times” are needed until all images are sent? b. If frames are interleaved, how many frame times are needed until\nall three images are sent? P14. Consider the Web page in problem 13. Now HTTP/2 prioritization is\nemployed. Suppose all the images are given priority over the video\nclip, and that the first image is given priority over the second image,\nthe second image over the third image, and so on. How many frame\ntimes will be needed until the second image is sent? P15. What is the difference between MAIL FROM: in SMTP and From: in\nthe mail message itself? P16. How does SMTP mark the end of a message body? How about\nHTTP? Can HTTP use the same method as SMTP to mark the end of\na message body? Explain. P17. Read RFC 5321 for SMTP. What does MTA stand for? Consider the\nfollowing received spam e-mail (modified from a real spam e-mail). Assuming only the originator of this spam e-mail is malicious and all\nother hosts are honest, identify the malacious host that has generated\nthis spam e-mail. From - Fri Nov 07 13:41:30 2008\nReturn-Path: <tennis5@pp33head.com>\nReceived: from barmail.cs.umass.edu\n(barmail.cs.umass.edu"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 128",
    "source": "kurose",
    "page": 326,
    "text": "[128.119.240.3]) by cs.umass.edu\n(8.13.1/8.12.6) for <hg@cs.umass.edu>; Fri, 7\nNov 2008 13:27:10 -0500\nReceived: from asusus-4b96 (localhost\n[127.0.0.1]) by barmail.cs.umass.edu (Spam\nFirewall) for <hg@cs.umass.edu>; Fri, 7\nNov 2008 13:27:07 -0500 (EST)\nReceived: from asusus-4b96 ([58.88.21.177]) by\nbarmail.cs.umass.edu\nfor <hg@cs.umass.edu>; Fri, 07 Nov 2008\n13:27:07 -0500 (EST)\nReceived: from [58.88.21.177] by\ninbnd55.exchangeddd.com; Sat, 8\nNov 2008 01:27:07 +0700\nFrom: ”Jonny” <tennis5@pp33head.com>\nTo: <hg@cs.umass.edu>\nSubject: How to secure your savings\nP18. a. What is a whois database? b. Use various whois databases on the Internet to obtain the names of\ntwo DNS servers. Indicate which whois databases you used. c. Use nslookup on your local host to send DNS queries to three\nDNS servers: your local DNS server and the two DNS servers you\nfound in part (b). Try querying for Type A, NS, and MX reports. Summarize your findings. d. Use nslookup to find a Web server that has multiple IP addresses. Does the Web server of your institution (school or company) have\nmultiple IP addresses?"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 327,
    "text": "e. Use the ARIN whois database to determine the IP address range\nused by your university. f. Describe how an attacker can use whois databases and the\nnslookup tool to perform reconnaissance on an institution before\nlaunching an attack. g. Discuss why whois databases should be publicly available. P19. In this problem, we use the useful dig tool available on Unix and\nLinux hosts to explore the hierarchy of DNS servers. Recall that in\nFigure 2.19, a DNS server in the DNS hierarchy delegates a DNS\nquery to a DNS server lower in the hierarchy, by sending back to the\nDNS client the name of that lower-level DNS server. First read the\nman page for dig, and then answer the following questions. a. Starting with a root DNS server (from one of the root servers [a-\nm].root-servers.net), initiate a sequence of queries for the IP\naddress for your department’s Web server by using dig. Show the\nlist of the names of DNS servers in the delegation chain in\nanswering your query. b. Repeat part (a) for several popular Web sites, such as\ngoogle.com, yahoo.com, or amazon.com. P20. Consider the scenarios illustrated in Figures 2.12 and 2.13. Assume\nthe rate of the institutional network is R  and that of the bottleneck\nlink is R . Suppose there are N clients requesting a file of size L with\nHTTP at the same time. For what values of R  would the file transfer\ntakes less time when a proxy is installed at the institutional network? (Assume the RTT between a client and any other host in the\ninstitutional network is negligible.) P21. Suppose that your department has a local DNS server for all\ncomputers in the department. You are an ordinary user (i.e., not a\nl\nb\nl"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 328,
    "text": "network/system administrator). Can you determine if an external Web\nsite was likely accessed from a computer in your department a couple\nof seconds ago? Explain. P22. Consider distributing a file of F = 10 Gbits to N peers. The server has\nan upload rate of u  = 1 Gbps, and each peer has a download rate of d\n= 200 Mbps and an upload rate of u. For N = 10, 100, and 1,000 and u\n= 2 Mbps, 10 Mbps, and 100 Mbps, prepare a table giving the\nminimum distribution time in seconds for each of the combinations of\nN and u for both client-server distribution and P2P distribution. P23. Consider distributing a file of F bits to N peers using a client-server\narchitecture. Assume a fluid model where the server can\nsimultaneously transmit to multiple peers, transmitting to each peer at\ndifferent rates, as long as the combined rate does not exceed u . a. Suppose that u /N ≤ d\n. Specify a distribution scheme that has a\ndistribution time of NF/u . b. Suppose that u /N ≥ d\n. Specify a distribution scheme that has a\ndistribution time of F/d\n. c. Conclude that the minimum distribution time is in general given\nby max{NF/u , F/d\n}. P24. Consider distributing a file of F bits to N peers using a P2P\narchitecture. Assume a fluid model. For simplicity assume that dmin is\nvery large, so that peer download bandwidth is never a bottleneck. a. Suppose that u  ≤ (u  + u  + . . . + u )/N. Specify a distribution\nscheme that has a distribution time of F/u . b. Suppose that u  ≥ (u  + u  + . . . + u )/N. Specify a distribution\nscheme that has a distribution time of NF/(u  + u  + . . . + u ). c. Conclude that the minimum distribution time is in general given\nby max{F/u , NF/(u  + u  + . . . + u )}. s\ni\ns\ns\nmin\ns\ns\nmin\nmin\ns\nmin\ns\ns\nN\ns\ns\ns\nN\ns\nN\ns\ns\nN"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 329,
    "text": "P25. Consider an overlay network with N active peers, with each pair of\npeers having an active TCP connection. Additionally, suppose that the\nTCP connections pass through a total of M routers. How many nodes\nand edges are there in the corresponding overlay network? P26. Suppose Bob joins a BitTorrent torrent, but he does not want to\nupload any data to any other peers (he wants to be a so-called free-\nrider). a. Alice who has been using BitTorrent tells Bob that he cannot\nreceive a complete copy of the file that is shared by the swarm. Is\nAlice correct or not? Why? b. Charlie claims that Alice is wrong and that he has even been\nusing a collection of multiple computers (with distinct IP\naddresses) in the computer lab in his department to make his\ndownloads faster, using some additional coordination scripting. What could his script have done? P27. Consider a DASH system for which there are N video versions (at N\ndifferent rates and qualities) and N audio versions (at N different rates\nand qualities). Suppose we want to allow the player to choose at any\ntime any of the N video versions and any of the N audio versions. a. If we create files so that the audio is mixed in with the video, so\nserver sends only one media stream at given time, how many\nfiles will the server need to store (each a different URL)? b. If the server instead sends the audio and video streams separately\nand has the client synchronize the streams, how many files will\nthe server need to store? P28. Install the Python programs TCPClient and UDPClient on one host\nand TCPServer and UDPServer on another host."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 330,
    "text": "a. Suppose you run TCPServer and you try to connect using\nUDPClient. What happens? Why? b. Suppose you run UDPClient before you run UDPServer. What\nhappens? Why? c. What happens if you hardwire in the python client and server\nprograms different port numbers for the client and server sides in\neither a TCP or UDP client-server pair? P29. Suppose that in UDPClient.py, after we create the socket, we add the\nline:\nclientSocket.bind((’’, 5432))\nWill it become necessary to change UDPServer.py? What are the port\nnumbers for the sockets in UDPClient and UDPServer? What were\nthey before making this change? P30. Can you configure your browser to open multiple simultaneous\nconnections to a Web site? What are the advantages and\ndisadvantages of having a large number of simultaneous TCP\nconnections? P31. We have seen that Internet TCP sockets treat the data being sent as a\nbyte stream but UDP sockets recognize message boundaries. What are\none advantage and one disadvantage of byte-oriented API versus\nhaving the API explicitly recognize and preserve application-defined\nmessage boundaries? P32. What is the Apache Web server? How much does it cost? What\nfunctionality does it currently have? You may want to look at\nWikipedia to answer this question."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 332,
    "text": "Assignment 2: UDP Pinger\nIn this programming assignment, you will write a client ping program in\nPython. Your client will send a simple ping message to a server, receive a\ncorresponding pong message back from the server, and determine the delay\nbetween when the client sent the ping message and received the pong\nmessage. This delay is called the Round Trip Time (RTT). The functionality\nprovided by the client and server is similar to the functionality provided by\nstandard ping program available in modern operating systems. However,\nstandard ping programs use the Internet Control Message Protocol (ICMP)\n(which we will study in Chapter 5). Here we will create a nonstandard (but\nsimple!) UDP-based ping program. Your ping program is to send 10 ping messages to the target server over\nUDP. For each message, your client is to determine and print the RTT when\nthe corresponding pong message is returned. Because UDP is an unreliable\nprotocol, a packet sent by the client or server may be lost. For this reason,\nthe client cannot wait indefinitely for a reply to a ping message. You should\nhave the client wait up to one second for a reply from the server; if no reply\nis received, the client should assume that the packet was lost and print a\nmessage accordingly. In this assignment, you will be given the complete code for the server\n(available in the Companion Website). Your job is to write the client code,\nwhich will be very similar to the server code. It is recommended that you\nfirst study carefully the server code. You can then write your client code,\nliberally cutting and pasting lines from the server code. Assignment 3: Mail Client\nThe goal of this programming assignment is to create a simple mail client\nthat sends e-mail to any recipient. Your client will need to establish a TCP"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 333,
    "text": "connection with a mail server (e.g., a Google mail server), dialogue with the\nmail server using the SMTP protocol, send an e-mail message to a recipient\n(e.g., your friend) via the mail server, and finally close the TCP connection\nwith the mail server. For this assignment, the Companion Website provides the skeleton code\nfor your client. Your job is to complete the code and test your client by\nsending e-mail to different user accounts. You may also try sending through\ndifferent servers (for example, through a Google mail server and through\nyour university mail server). Assignment 4: Web Proxy\nIn this assignment, you will develop a Web proxy. When your proxy\nreceives an HTTP request for an object from a browser, it generates a new\nHTTP request for the same object and sends it to the origin server. When\nthe proxy receives the corresponding HTTP response with the object from\nthe origin server, it creates a new HTTP response, including the object, and\nsends it to the client. For this assignment, the Companion Website provides the skeleton code\nfor the proxy server. Your job is to complete the code, and then test it by\nhaving different browsers request Web objects via your proxy."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 335,
    "text": "AN INTERVIEW WITH…\nTim Berners-Lee\nSir Tim Berners-Lee is known as the inventor of the World\nWide Web. In 1989, while working as a fellow at CERN, he\nproposed an Internet-based distributed information\nmanagement system including the original version of the\nHTTP protocol. In the same year he successfully\nimplemented his design on a client and server. He received\nthe 2016 Turing award for “inventing the World Wide Web, the\nfirst Web browser, and the fundamental protocols and\nalgorithms allowing the Web to scale.” He is the Co-Founder\nof the World Wide Web Foundation, and currently is a\nProfessorial Fellow of Computer Science at the University of\nOxford and a professor at CSAIL at MIT."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 336,
    "text": "Courtesy of Tim Berners-Lee\nYou originally studied physics. How is\nnetworking similar to physics? When you study physics, you imagine what rules\nof behavior on the very small scale could possibly\ngive rise to the large-scale world as we see it. When you design a global system like the Web,\nyou try to invent rules of behavior of Web pages\nand links and things that could in the large create a\nlarge-scale world as we would like it. One is\nanalysis and the other synthesis, but they are very\nsimilar. What influenced you to specialize in\nnetworking?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 337,
    "text": "After my physics degree, the telecommunications\nresearch companies seemed to be the most\ninteresting places. The microprocessor had just\ncome out, and telecommunications was switching\nvery fast from hardwired logic to microprocessor-\nbased systems. It was very exciting. What is the most challenging part of your\njob? When two groups disagree strongly about\nsomething, but want in the end to achieve a\ncommon goal, finding exactly what they each\nmean and where the misunderstandings are can be\nvery demanding. The chair of any working group\nknows that. However, this is what it takes to make\nprogress toward consensus on a large scale. What people have inspired you\nprofessionally? My parents, who were involved in the early days\nof computing, gave me a fascination with the\nwhole subject. Mike Sendall and Peggie Rimmer,\nfor whom I worked at various times at CERN are\namong the people who taught me and encouraged\nme. I later learned to admire the people, including\nVanevar Bush, Doug Englebart, and Ted Nelson,\nwho had had similar dreams in their time but had"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 338,
    "text": "not had the benefit of the existence for PCs and the\nInternet to be able to realize it."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 339,
    "text": "Transport Layer\nResiding between the application and network\nlayers, the transport layer is a central piece of\nthe layered network architecture. It has the\ncritical role of providing communication\nservices directly to the application processes\nrunning on different hosts. The pedagogic\napproach we take in this chapter is to\nalternate between discussions of transport-\nlayer principles and discussions of how these\nprinciples \nare \nimplemented in \nexisting\nprotocols; as usual, particular emphasis will\nbe given to Internet protocols, in particular\nthe TCP and UDP transport-layer protocols. We’ll begin by discussing the relationship\nbetween the transport and network layers. This sets the stage for examining the first\ncritical function of the transport layer—\nextending the network layer’s delivery service\nbetween two end systems to a delivery service\nbetween two application-layer processes\nrunning on the end systems. We’ll illustrate"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 340,
    "text": "this function in our coverage of the Internet’s\nconnectionless transport protocol, UDP. We’ll then return to principles and\nconfront one of the most fundamental\nproblems in computer networking—how two\nentities can communicate reliably over a\nmedium that may lose and corrupt data. Through a series of increasingly complicated\n(and realistic!) scenarios, we’ll build up an\narray of techniques that transport protocols\nuse to solve this problem. We’ll then show\nhow these principles are embodied in TCP,\nthe Internet’s connection-oriented transport\nprotocol. We’ll next move on to a second\nfundamentally \nimportant \nproblem \nin\nnetworking—controlling the transmission rate\nof transport-layer entities in order to avoid, or\nrecover from, congestion within the network. We’ll consider the causes and consequences\nof congestion, as well as commonly used\ncongestion-control \ntechniques. After\nobtaining a solid understanding of the issues\nbehind congestion control, we’ll study TCP’s\napproach to congestion control."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 341,
    "text": "3.1 Introduction and Transport-Layer Services\nIn the previous two chapters, we touched on the role of the transport layer\nand the services that it provides. Let’s quickly review what we have already\nlearned about the transport layer. A transport-layer protocol provides for logical communication\nbetween application processes running on different hosts. By logical\ncommunication, we mean that from an application’s perspective, it is as if\nthe hosts running the processes were directly connected; in reality, the hosts\nmay be on opposite sides of the planet, connected via numerous routers and\na wide range of link types. Application processes use the logical\ncommunication provided by the transport layer to send messages to each\nother, free from the worry of the details of the physical infrastructure used\nto carry these messages. Figure 3.1 illustrates the notion of logical\ncommunication."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 342,
    "text": "Figure 3.1 ♦The transport layer provides logical rather than\nphysical communication between application\nprocesses\nAs shown in Figure 3.1, transport-layer protocols are implemented in\nthe end systems but not in network routers. On the sending side, the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 343,
    "text": "transport layer converts the application-layer messages it receives from a\nsending application process into transport-layer packets, known as\ntransport-layer segments in Internet terminology. This is done by (possibly)\nbreaking the application messages into smaller chunks and adding a\ntransport-layer header to each chunk to create the transport-layer segment. The transport layer then passes the segment to the network layer at the\nsending end system, where the segment is encapsulated within a network-\nlayer packet (a datagram) and sent to the destination. It’s important to note\nthat network routers act only on the network-layer fields of the datagram;\nthat is, they do not examine the fields of the transport-layer segment\nencapsulated with the datagram. On the receiving side, the network layer\nextracts the transport-layer segment from the datagram and passes the\nsegment up to the transport layer. The transport layer then processes the\nreceived segment, making the data in the segment available to the receiving\napplication. More than one transport-layer protocol may be available to network\napplications. For example, the Internet has two protocols—TCP and UDP. Each of these protocols provides a different set of transport-layer services to\nthe invoking application. 3.1.1 Relationship Between Transport and Network\nLayers\nRecall that the transport layer lies just above the network layer in the\nprotocol stack. Whereas a transport-layer protocol provides logical\ncommunication between processes running on different hosts, a network-\nlayer protocol provides logical-communication between hosts. This"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 344,
    "text": "distinction is subtle but important. Let’s examine this distinction with the\naid of a household analogy. Consider two houses, one on the East Coast and the other on the West\nCoast, with each house being home to a dozen kids. The kids in the East\nCoast household are cousins of the kids in the West Coast household. The\nkids in the two households love to write to each other—each kid writes each\ncousin every week, with each letter delivered by the traditional postal\nservice in a separate envelope. Thus, each household sends 144 letters to the\nother household every week. (These kids would save a lot of money if they\nhad e-mail!) In each of the households, there is one kid—Ann in the West\nCoast house and Bill in the East Coast house—responsible for mail\ncollection and mail distribution. Each week Ann visits all her brothers and\nsisters, collects the mail, and gives the mail to a postal-service mail carrier,\nwho makes daily visits to the house. When letters arrive at the West Coast\nhouse, Ann also has the job of distributing the mail to her brothers and\nsisters. Bill has a similar job on the East Coast. In this example, the postal service provides logical communication\nbetween the two houses—the postal service moves mail from house to\nhouse, not from person to person. On the other hand, Ann and Bill provide\nlogical communication among the cousins—Ann and Bill pick up mail\nfrom, and deliver mail to, their brothers and sisters. Note that from the\ncousins’ perspective, Ann and Bill are the mail service, even though Ann\nand Bill are only a part (the end-system part) of the end-to-end delivery\nprocess. This household example serves as a nice analogy for explaining\nhow the transport layer relates to the network layer:\napplication messages = letters in envelopes\nprocesses = cousins\nhosts (also called end systems) = houses"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 345,
    "text": "transport-layer protocol = Ann and Bill\nnetwork-layer protocol = postal service (including mail carriers)\nContinuing with this analogy, note that Ann and Bill do all their work\nwithin their respective homes; they are not involved, for example, in sorting\nmail in any intermediate mail center or in moving mail from one mail center\nto another. Similarly, transport-layer protocols live in the end systems. Within an end system, a transport protocol moves messages from\napplication processes to the network edge (that is, the network layer) and\nvice versa, but it doesn’t have any say about how the messages are moved\nwithin the network core. In fact, as illustrated in Figure 3.1, intermediate\nrouters neither act on, nor recognize, any information that the transport\nlayer may have added to the application messages. Continuing with our family saga, suppose now that when Ann and Bill\ngo on vacation, another cousin pair—say, Susan and Harvey—substitute for\nthem and provide the household-internal collection and delivery of mail. Unfortunately for the two families, Susan and Harvey do not do the\ncollection and delivery in exactly the same way as Ann and Bill. Being\nyounger kids, Susan and Harvey pick up and drop off the mail less\nfrequently and occasionally lose letters (which are sometimes chewed up by\nthe family dog). Thus, the cousin-pair Susan and Harvey do not provide the\nsame set of services (that is, the same service model) as Ann and Bill. In an\nanalogous manner, a computer network may make available multiple\ntransport protocols, with each protocol offering a different service model to\napplications. The possible services that Ann and Bill can provide are clearly\nconstrained by the possible services that the postal service provides. For\nexample, if the postal service doesn’t provide a maximum bound on how\nlong it can take to deliver mail between the two houses (for example, three"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 346,
    "text": "days), then there is no way that Ann and Bill can guarantee a maximum\ndelay for mail delivery between any of the cousin pairs. In a similar manner,\nthe services that a transport protocol can provide are often constrained by\nthe service model of the underlying network-layer protocol. If the network-\nlayer protocol cannot provide delay or bandwidth guarantees for transport-\nlayer segments sent between hosts, then the transport-layer protocol cannot\nprovide delay or bandwidth guarantees for application messages sent\nbetween processes. Nevertheless, certain services can be offered by a transport protocol\neven when the underlying network protocol doesn’t offer the corresponding\nservice at the network layer. For example, as we’ll see in this chapter, a\ntransport protocol can offer reliable data transfer service to an application\neven when the underlying network protocol is unreliable, that is, even when\nthe network protocol loses, garbles, or duplicates packets. As another\nexample (which we’ll explore in Chapter 8 when we discuss network\nsecurity), a transport protocol can use encryption to guarantee that\napplication messages are not read by intruders, even when the network\nlayer cannot guarantee the confidentiality of transport-layer segments. 3.1.2 Overview of the Transport Layer in the\nInternet\nRecall that the Internet makes two distinct transport-layer protocols\navailable to the application layer. One of these protocols is UDP (User\nDatagram Protocol), which provides an unreliable, connectionless service to\nthe invoking application. The second of these protocols is TCP\n(Transmission Control Protocol), which provides a reliable, connection-\noriented service to the invoking application. When designing a network"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 347,
    "text": "application, the application developer must specify one of these two\ntransport protocols. As we saw in Section 2.7, the application developer\nselects between UDP and TCP when creating sockets. To simplify terminology, we refer to the transport-layer packet as a\nsegment. We mention, however, that the Internet literature (for example, the\nRFCs) also refers to the transport-layer packet for TCP as a segment but\noften refers to the packet for UDP as a datagram. However, this same\nInternet literature also uses the term datagram for the network-layer packet! For an introductory book on computer networking such as this, we believe\nthat it is less confusing to refer to both TCP and UDP packets as segments,\nand reserve the term datagram for the network-layer packet. Before proceeding with our brief introduction of UDP and TCP, it will\nbe useful to say a few words about the Internet’s network layer. (We’ll learn\nabout the network layer in detail in Chapters 4 and 5.) The Internet’s\nnetwork-layer protocol has a name—IP, for Internet Protocol. IP provides\nlogical communication between hosts. The IP service model is a best-effort\ndelivery service. This means that IP makes its “best effort” to deliver\nsegments between communicating hosts, but it makes no guarantees. In\nparticular, it does not guarantee segment delivery, it does not guarantee\norderly delivery of segments, and it does not guarantee the integrity of the\ndata in the segments. For these reasons, IP is said to be an unreliable\nservice. We also mention here that every host has at least one network-layer\naddress, a so-called IP address. We’ll examine IP addressing in detail in\nChapter 4; for this chapter we need only keep in mind that each host has an\nIP address. Having taken a glimpse at the IP service model, let’s now summarize\nthe service models provided by UDP and TCP. The most fundamental\nresponsibility of UDP and TCP is to extend IP’s delivery service between"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 348,
    "text": "two end systems to a delivery service between two processes running on the\nend systems. Extending host-to-host delivery to process-to-process delivery\nis called transport-layer multiplexing and demultiplexing. We’ll discuss\ntransport-layer multiplexing and demultiplexing in the next section. UDP\nand TCP also provide integrity checking by including error-detection fields\nin their segments’ headers. These two minimal transport-layer services—\nprocess-to-process data delivery and error checking—are the only two\nservices that UDP provides! In particular, like IP, UDP is an unreliable\nservice—it does not guarantee that data sent by one process will arrive\nintact (or at all!) to the destination process. UDP is discussed in detail in\nSection 3.3. TCP, on the other hand, offers several additional services to\napplications. First and foremost, it provides reliable data transfer. Using\nflow control, sequence numbers, acknowledgments, and timers (techniques\nwe’ll explore in detail in this chapter), TCP ensures that data is delivered\nfrom sending process to receiving process, correctly and in order. TCP thus\nconverts IP’s unreliable service between end systems into a reliable data\ntransport service between processes. TCP also provides congestion control. Congestion control is not so much a service provided to the invoking\napplication as it is a service for the Internet as a whole, a service for the\ngeneral good. Loosely speaking, TCP congestion control prevents any one\nTCP connection from swamping the links and routers between\ncommunicating hosts with an excessive amount of traffic. TCP strives to\ngive each connection traversing a congested link an equal share of the link\nbandwidth. This is done by regulating the rate at which the sending sides of\nTCP connections can send traffic into the network. UDP traffic, on the other\nhand, is unregulated. An application using UDP transport can send at any\nrate it pleases, for as long as it pleases."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 349,
    "text": "A protocol that provides reliable data transfer and congestion control is\nnecessarily complex. We’ll need several sections to cover the principles of\nreliable data transfer and congestion control, and additional sections to\ncover the TCP protocol itself. These topics are investigated in Sections 3.4\nthrough 3.7. The approach taken in this chapter is to alternate between basic\nprinciples and the TCP protocol. For example, we’ll first discuss reliable\ndata transfer in a general setting and then discuss how TCP specifically\nprovides reliable data transfer. Similarly, we’ll first discuss congestion\ncontrol in a general setting and then discuss how TCP performs congestion\ncontrol. But before getting into all this good stuff, let’s first look at\ntransport-layer multiplexing and demultiplexing."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 350,
    "text": "3.2 Multiplexing and Demultiplexing\nIn this section, we discuss transport-layer multiplexing and demultiplexing,\nthat is, extending the host-to-host delivery service provided by the network\nlayer to a process-to-process delivery service for applications running on\nthe hosts. In order to keep the discussion concrete, we’ll discuss this basic\ntransport-layer service in the context of the Internet. We emphasize,\nhowever, that a multiplexing/demultiplexing service is needed for all\ncomputer networks. At the destination host, the transport layer receives segments from the\nnetwork layer just below. The transport layer has the responsibility of\ndelivering the data in these segments to the appropriate application process\nrunning in the host. Let’s take a look at an example. Suppose you are sitting\nin front of your computer, and you are downloading Web pages while\nrunning one FTP session and two Telnet sessions. You therefore have four\nnetwork application processes running—two Telnet processes, one FTP\nprocess, and one HTTP process. When the transport layer in your computer\nreceives data from the network layer below, it needs to direct the received\ndata to one of these four processes. Let’s now examine how this is done. First recall from Section 2.7 that a process (as part of a network\napplication) can have one or more sockets, doors through which data passes\nfrom the network to the process and through which data passes from the\nprocess to the network. Thus, as shown in Figure 3.2, the transport layer in\nthe receiving host does not actually deliver data directly to arocess, but\ninstead to an intermediary socket. Because at any given time there can be\nmore than one socket in the receiving host, each socket has a unique"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 351,
    "text": "identifier. The format of the identifier depends on whether the socket is a\nUDP or a TCP socket, as we’ll discuss shortly. Figure 3.2 ♦Transport-layer multiplexing and demultiplexing\nNow let’s consider how a receiving host directs an incoming transport-\nlayer segment to the appropriate socket. Each transport-layer segment has a\nset of fields in the segment for this purpose. At the receiving end, the\nransport layer examines these fields to identify the receiving socket and\nthen directs the segment to that socket. This job of delivering the data in a\ntransport-layer segment to the correct socket is called demultiplexing. The\njob of gathering data chunks at the source host from different sockets,\nencapsulating each data chunk with header information (that will later be\nused in demultiplexing) to create segments, and passing the segments to the\nnetwork layer is called multiplexing. Note that the transport layer in the\nmiddle host in Figure 3.2 must demultiplex segments arriving from the\nnetwork layer below to either process P  or P  above; this is done by\ndirecting the arriving segment’s data to the corresponding process’s socket. 2"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 352,
    "text": "The transport layer in the middle host must also gather outgoing data from\nthese sockets, form transport-layer segments, and pass these segments down\nto the network layer. Although we have introduced multiplexing and\ndemultiplexing in the context of the Internet transport protocols, it’s\nimportant to realize that they are concerns whenever a single protocol at\none layer (at the transport layer or elsewhere) is used by multiple protocols\nat the next higher layer. To illustrate the demultiplexing job, recall the household analogy in the\nprevious section. Each of the kids is identified by his or her name. When\nBill receives a batch of mail from the mail carrier, he performs a\ndemultiplexing operation by observing to whom the letters are addressed\nand then hand delivering the mail to his brothers and sisters. Ann performs\na multiplexing operation when she collects letters from her brothers and\nsisters and gives the collected mail to the mail person. Now that we understand the roles of transport-layer multiplexing and\ndemultiplexing, let us examine how it is actually done in a host. From the\ndiscussion above, we know that transport-layer multiplexing requires (1)\nthat sockets have unique identifiers, and (2) that each segment have special\nfields that indicate the socket to which the segment is to be delivered. These\nspecial fields, illustrated in Figure 3.3, are the source port number field\nand the destination port number field. (The UDP and TCP segments have\nother fields as well, as discussed in the subsequent sections of this chapter.) Each port number is a 16-bit number, ranging from 0 to 65535. The port\nnumbers ranging from 0 to 1023 are called well-known port numbers and\nare restricted, which means that they are reserved for use by well-known\napplication protocols such as HTTP (which uses port number 80) and FTP\n(which uses port number 21). The list of well-known port numbers is given\nin RFC 1700 and is updated at http://www.iana.org [RFC 3232]. When we"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 353,
    "text": "develop a new application (such as the simple application developed in\nSection 2.7), we must assign the application a port number. Figure 3.3 ♦Source and destination port-number fields in a\ntransport-layer segment\nIt should now be clear how the transport layer could implement the\ndemultiplexing service: Each socket in the host could be assigned a port\nnumber, and when a segment arrives at the host, the transport layer\nexamines the destination port number in the segment and directs the\nsegment to the corresponding socket. The segment’s data then passes\nthrough the socket into the attached process. As we’ll see, this is basically\nhow UDP does it. However, we’ll also see that multiplexing/demultiplexing\nin TCP is yet more subtle. Connectionless Multiplexing and Demultiplexing\nRecall from Section 2.7.1 that the Python program running in a host can\ncreate a UDP socket with the line\nclientSocket = socket(AF_INET, SOCK_DGRAM)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 354,
    "text": "When a UDP socket is created in this manner, the transport layer\nautomatically assigns a port number to the socket. In particular, the\ntransport layer assigns a port number in the range 1024 to 65535 that is\ncurrently not being used by any other UDP port in the host. Alternatively,\nwe can add a line into our Python program after we create the socket to\nassociate a specific port number (say, 19157) to this UDP socket via the\nsocket bind() method:\nclientSocket.bind((’’, 19157))\nIf the application developer writing the code were implementing the server\nside of a “well-known protocol,” then the developer would have to assign\nthe corresponding well-known port number. Typically, the client side of the\napplication lets the transport layer automatically (and transparently) assign\nthe port number, whereas the server side of the application assigns a\nspecific port number. With port numbers assigned to UDP sockets, we can now precisely\ndescribe UDP multiplexing/demultiplexing. Suppose a process in Host A,\nwith UDP port 19157, wants to send a chunk of application data to a\nprocess with UDP port 46428 in Host B. The transport layer in Host A\ncreates a transport-layer segment that includes the application data, the\nsource port number (19157), the destination port number (46428), and two\nother values (which will be discussed later, but are unimportant for the\ncurrent discussion). The transport layer then passes the resulting segment to\nthe network layer. The network layer encapsulates the segment in an IP\ndatagram and makes a best-effort attempt to deliver the segment to the\nreceiving host. If the segment arrives at the receiving Host B, the transport\nlayer at the receiving host examines the destination port number in the\nsegment (46428) and delivers the segment to its socket identified by port"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 355,
    "text": "46428. Note that Host B could be running multiple processes, each with its\nown UDP socket and associated port number. As UDP segments arrive from\nthe network, Host B directs (demultiplexes) each segment to the appropriate\nsocket by examining the segment’s destination port number. It is important to note that a UDP socket is fully identified by a two-\ntuple consisting of a destination IP address and a destination port number. As a consequence, if two UDP segments have different source IP addresses\nand/or source port numbers, but have the same destination IP address and\ndestination port number, then the two segments will be directed to the same\ndestination process via the same destination socket. You may be wondering now, what is the purpose of the source port\nnumber? As shown in Figure 3.4, in the A-to-B segment the source port\nnumber serves as part of a “return address”—when B wants to send a\nsegment back to A, the destination port in the B-to-A segment will take its\nvalue from the source port value of the A-to-B segment. (The complete\nreturn address is A’s IP address and the source port number.) As an example,\nrecall the UDP server program studied in Section 2.7. In UDPServer.py,\nthe server uses the recvfrom() method to extract the client-side (source)\nport number from the segment it receives from the client; it then sends a\nnew segment to the client, with the extracted source port number serving as\nthe destination port number in this new segment."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 356,
    "text": "Figure 3.4 ♦The inversion of source and destination port numbers\nConnection-Oriented Multiplexing and Demultiplexing\nIn order to understand TCP demultiplexing, we have to take a close look at\nTCP sockets and TCP connection establishment. One subtle difference\nbetween a TCP socket and a UDP socket is that a TCP socket is identified\nby a four-tuple: (source IP address, source port number, destination IP\naddress, destination port number). Thus, when a TCP segment arrives from\nthe network to a host, the host uses all four values to direct (demultiplex)\nthe segment to the appropriate socket. In particular, and in contrast with\nUDP, two arriving TCP segments with different source IP addresses or\nsource port numbers will (with the exception of a TCP segment carrying the\noriginal connection-establishment request) be directed to two different\nsockets. To gain further insight, let’s reconsider the TCP client-server\nprogramming example in Section 2.7.2:"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 357,
    "text": "•\nThe TCP server application has a “welcoming socket,” that waits for\nconnection-establishment requests from TCP clients (see Figure 2.29)\non port number 12000. •\nThe TCP client creates a socket and sends a connection establishment\nrequest segment with the lines:\nclientSocket = socket(AF_INET, SOCK_STREAM)\nclientSocket.connect((serverName,12000))\n•\nA connection-establishment request is nothing more than a TCP\nsegment with destination port number 12000 and a special connection-\nestablishment bit set in the TCP header (discussed in Section 3.5). The\nsegment also includes a source port number that was chosen by the\nclient. •\nWhen the host operating system of the computer running the server\nprocess receives the incoming connection-request segment with\ndestination port 12000, it locates the server process that is waiting to\naccept a connection on port number 12000. The server process then\ncreates a new socket:\nconnectionSocket, addr = serverSocket.accept()\n•\nAlso, the transport layer at the server notes the following four values in\nthe connection-request segment: (1) the source port number in the\nsegment, (2) the IP address of the source host, (3) the destination port\nnumber in the segment, and (4) its own IP address. The newly created\nconnection socket is identified by these four values; all subsequently\narriving segments whose source port, source IP address, destination\nport, and destination IP address match these four values will be"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 358,
    "text": "demultiplexed to this socket. With the TCP connection now in place, the\nclient and server can now send data to each other. The server host may support many simultaneous TCP connection\nsockets, with each socket attached to a process, and with each socket\nidentified by its own four-tuple. When a TCP segment arrives at the host, all\nfour fields (source IP address, source port, destination IP address,\ndestination port) are used to direct (demultiplex) the segment to the\nappropriate socket. FOCUS ON\nSECURITY\nPORT SCANNING\nWe’ve seen that a server process waits patiently on an open port for contact by a\nremote client. Some ports are reserved for well-known applications (e.g., Web, FTP,\nDNS, and SMTP servers); other ports are used by convention by popular applications\n(e.g., the Microsoft Windows SQL server listens for requests on UDP port 1434). Thus,\nif we determine that a port is open on a host, we may be able to map that port to a\nspecific application running on the host. This is very useful for system administrators,\nwho are often interested in knowing which network applications are running on the\nhosts in their networks. But attackers, in order to “case the joint,” also want to know\nwhich ports are open on target hosts. If a host is found to be running an application\nwith a known security flaw (e.g., a SQL server listening on port 1434 was subject to a\nbuffer overflow, allowing a remote user to execute arbitrary code on the vulnerable\nhost, a flaw exploited by the Slammer worm [CERT 2003–04]), then that host is ripe for\nattack."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 359,
    "text": "Determining which applications are listening on which ports is a relatively easy task. Indeed there are a number of public domain programs, called port scanners, that do\njust that. Perhaps the most widely used of these is nmap, freely available at\nhttp://nmap.org and included in most Linux distributions. For TCP, nmap sequentially\nscans ports, looking for ports that are accepting TCP connections. For UDP, nmap\nagain sequentially scans ports, looking for UDP ports that respond to transmitted UDP\nsegments. In both cases, nmap returns a list of open, closed, or unreachable ports. A\nhost running nmap can attempt to scan any target host anywhere in the Internet. We’ll\nrevisit nmap in Section 3.5.6, when we discuss TCP connection management. The situation is illustrated in Figure 3.5, in which Host C initiates two\nHTTP sessions to server B, and Host A initiates one HTTP session to B. Hosts A and C and server B each have their own unique IP address—A, C,\nand B, respectively. Host C assigns two different source port numbers\n(26145 and 7532) to its two HTTP connections. Because Host A is choosing\nsource port numbers independently of C, it might also assign a source port\nof 26145 to its HTTP connection. But this is not a problem—server B will\nstill be able to correctly demultiplex the two connections having the same\nsource port number, since the two connections have different source IP\naddresses."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 360,
    "text": "Figure 3.5 ♦Two clients, using the same destination port number\n(80) to communicate with the same Web server\napplication\nWeb Servers and TCP\nBefore closing this discussion, it’s instructive to say a few additional words\nabout Web servers and how they use port numbers. Consider a host running\na Web server, such as an Apache Web server, on port 80. When clients (for\nexample, browsers) send segments to the server, all segments will have\ndestination port 80. In particular, both the initial connection-establishment\nsegments and the segments carrying HTTP request messages will have\ndestination port 80. As we have just described, the server distinguishes the\nsegments from the different clients using source IP addresses and source\nport numbers."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 361,
    "text": "Figure 3.5 shows a Web server that spawns a new process for each\nconnection. As shown in Figure 3.5, each of these processes has its own\nconnection socket through which HTTP requests arrive and HTTP\nresponses are sent. We mention, however, that there is not always a one-to-\none correspondence between connection sockets and processes. In fact,\ntoday’s high-performing Web servers often use only one process, and create\na new thread with a new connection socket for each new client connection. (A thread can be viewed as a lightweight subprocess.) If you did the first\nprogramming assignment in Chapter 2, you built a Web server that does just\nthis. For such a server, at any given time there may be many connection\nsockets (with different identifiers) attached to the same process. If the client and server are using persistent HTTP, then throughout the\nduration of the persistent connection the client and server exchange HTTP\nmessages via the same server socket. However, if the client and server use\nnon-persistent HTTP, then a new TCP connection is created and closed for\nevery request/response, and hence a new socket is created and later closed\nfor every request/response. This frequent creating and closing of sockets\ncan severely impact the performance of a busy Web server (although a\nnumber of operating system tricks can be used to mitigate the problem). Readers interested in the operating system issues surrounding persistent and\nnon-persistent HTTP are encouraged to see [Nielsen 1997; Nahum 2002]. Now \nthat \nwe’ve \ndiscussed \ntransport-layer \nmultiplexing \nand\ndemultiplexing, let’s move on and discuss one of the Internet’s transport\nprotocols, UDP. In the next section, we’ll see that UDP adds little more to\nthe network-layer protocol than a multiplexing/demultiplexing service."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 362,
    "text": "3.3 Connectionless Transport: UDP\nIn this section, we’ll take a close look at UDP, how it works, and what it\ndoes. We encourage you to refer back to Section 2.1, which includes an\noverview of the UDP service model, and to Section 2.7.1, which discusses\nsocket programming using UDP. To motivate our discussion about UDP, suppose you were interested in\ndesigning a no-frills, bare-bones transport protocol. How might you go\nabout doing this? You might first consider using a vacuous transport\nprotocol. In particular, on the sending side, you might consider taking the\nmessages from the application process and passing them directly to the\nnetwork layer; and on the receiving side, you might consider taking the\nmessages arriving from the network layer and passing them directly to the\napplication process. But as we learned in the previous section, we have to\ndo a little more than nothing! At the very least, the transport layer has to\nprovide a multiplexing/demultiplexing service in order to pass data between\nthe network layer and the correct application-level process. UDP, defined in [RFC 768], does just about as little as a transport\nprotocol can do. Aside from the multiplexing/demultiplexing function and\nsome light error checking, it adds nothing to IP. In fact, if the application\ndeveloper chooses UDP instead of TCP, then the application is almost\ndirectly talking with IP. UDP takes messages from the application process,\nattaches \nsource \nand \ndestination \nport \nnumber \nfields \nfor \nthe\nmultiplexing/demultiplexing service, adds two other small fields, and\npasses the resulting segment to the network layer. The network layer\nencapsulates the transport-layer segment into an IP datagram and then\nmakes a best-effort attempt to deliver the segment to the receiving host. If"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 363,
    "text": "the segment arrives at the receiving host, UDP uses the destination port\nnumber to deliver the segment’s data to the correct application process. Note that with UDP there is no handshaking between sending and receiving\ntransport-layer entities before sending a segment. For this reason, UDP is\nsaid to be connectionless. DNS is an example of an application-layer protocol that typically uses\nUDP. When the DNS application in a host wants to make a query, it\nconstructs a DNS query message and passes the message to UDP. Without\nperforming any handshaking with the UDP entity running on the destination\nend system, the host-side UDP adds header fields to the message and passes\nthe resulting segment to the network layer. The network layer encapsulates\nthe UDP segment into a datagram and sends the datagram to a name server. The DNS application at the querying host then waits for a reply to its query. If it doesn’t receive a reply (possibly because the underlying network lost\nthe query or the reply), it might try resending the query, try sending the\nquery to another name server, or inform the invoking application that it\ncan’t get a reply. Now you might be wondering why an application developer would ever\nchoose to build an application over UDP rather than over TCP. Isn’t TCP\nalways preferable, since TCP provides a reliable data transfer service, while\nUDP does not? The answer is no, as some applications are better suited for\nUDP for the following reasons:\n•\nFiner application-level control over what data is sent, and when. Under\nUDP, as soon as an application process passes data to UDP, UDP will\npackage the data inside a UDP segment and immediately pass the\nsegment to the network layer. TCP, on the other hand, has a congestion-\ncontrol mechanism that throttles the transport-layer TCP sender when\none or more links between the source and destination hosts become"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 364,
    "text": "excessively congested. TCP will also continue to resend a segment until\nthe receipt of the segment has been acknowledged by the destination,\nregardless of how long reliable delivery takes. Since real-time\napplications often require a minimum sending rate, do not want to\noverly delay segment transmission, and can tolerate some data loss,\nTCP’s service model is not particularly well matched to these\napplications’ needs. As discussed below, these applications can use\nUDP and implement, as part of the application, any additional\nfunctionality that is needed beyond UDP’s no-frills segment-delivery\nservice. •\nNo connection establishment. As we’ll discuss later, TCP uses a three-\nway handshake before it starts to transfer data. UDP just blasts away\nwithout any formal preliminaries. Thus UDP does not introduce any\ndelay to establish a connection. This is probably the principal reason\nwhy DNS runs over UDP rather than TCP—DNS would be much\nslower if it ran over TCP. HTTP uses TCP rather than UDP, since\nreliability is critical for Web pages with text. But, as we briefly\ndiscussed in Section 2.2, the TCP connection-establishment delay in\nHTTP is an important contributor to the delays associated with\ndownloading Web documents. Indeed, the QUIC protocol (Quick UDP\nInternet Connection, [IETF QUIC 2020]), used in Google’s Chrome\nbrowser, uses UDP as its underlying transport protocol and implements\nreliability in an application-layer protocol on top of UDP. We’ll take a\ncloser look at QUIC in Section 3.8. •\nNo connection state. TCP maintains connection state in the end systems. This connection state includes receive and send buffers, congestion-\ncontrol parameters, and sequence and acknowledgment number\nparameters. We will see in Section 3.5 that this state information is"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 365,
    "text": "needed to implement TCP’s reliable data transfer service and to provide\ncongestion control. UDP, on the other hand, does not maintain\nconnection state and does not track any of these parameters. For this\nreason, a server devoted to a particular application can typically support\nmany more active clients when the application runs over UDP rather\nthan TCP. •\nSmall packet header overhead. The TCP segment has 20 bytes of header\noverhead in every segment, whereas UDP has only 8 bytes of overhead. Figure 3.6 lists popular Internet applications and the transport protocols\nthat they use. As we expect, e-mail, remote terminal access, and file transfer\nrun over TCP—all these applications need the reliable data transfer service\nof TCP. We learned in Chapter 2 that early versions of HTTP ran over TCP\nbut that more recent versions of HTTP run over UDP, providing their own\nerror control and congestion control (among other services) at the\napplication layer. Nevertheless, many important applications run over UDP\nrather than TCP. For example, UDP is used to carry network management\n(SNMP; see Section 5.7) data. UDP is preferred to TCP in this case, since\nnetwork management applications must often run when the network is in a\nstressed state—precisely when reliable, congestion-controlled data transfer\nis difficult to achieve. Also, as we mentioned earlier, DNS runs over UDP,\nthereby avoiding TCP’s connection-establishment delays."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 366,
    "text": "Figure 3.6 ♦Popular Internet applications and their underlying\ntransport protocols\nAs shown in Figure 3.6, both UDP and TCP are sometimes used today\nwith multimedia applications, such as Internet phone, real-time video\nconferencing, and streaming of stored audio and video. We just mention\nnow that all of these applications can tolerate a small amount of packet loss,\nso that reliable data transfer is not absolutely critical for the application’s\nsuccess. Furthermore, real-time applications, like Internet phone and video\nconferencing, react very poorly to TCP’s congestion control. For these\nreasons, developers of multimedia applications may choose to run their\napplications over UDP instead of TCP. When packet loss rates are low, and\nwith some organizations blocking UDP traffic for security reasons (see\nChapter 8), TCP becomes an increasingly attractive protocol for streaming\nmedia transport."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 367,
    "text": "Although commonly done today, running multimedia applications over\nUDP needs to be done with care. As we mentioned above, UDP has no\ncongestion control. But congestion control is needed to prevent the network\nfrom entering a congested state in which very little useful work is done. If\neveryone were to start streaming high-bit-rate video without using any\ncongestion control, there would be so much packet overflow at routers that\nvery few UDP packets would successfully traverse the source-to-destination\npath. Moreover, the high loss rates induced by the uncontrolled UDP\nsenders would cause the TCP senders (which, as we’ll see, do decrease their\nsending rates in the face of congestion) to dramatically decrease their rates. Thus, the lack of congestion control in UDP can result in high loss rates\nbetween a UDP sender and receiver, and the crowding out of TCP sessions. Many researchers have proposed new mechanisms to force all sources,\nincluding UDP sources, to perform adaptive congestion control [Mahdavi\n1997; Floyd 2000; Kohler 2006: RFC 4340]. Before discussing the UDP segment structure, we mention that it is ­-\npossible for an application to have reliable data transfer when using UDP. This can be done if reliability is built into the application itself (for\nexample, by adding acknowledgment and retransmission mechanisms, such\nas those we’ll study in the next section). We mentioned earlier that the\nQUIC protocol implements reliability in an application-layer protocol on\ntop of UDP. But this is a nontrivial task that would keep an application\ndeveloper busy debugging for a long time. Nevertheless, ­building reliability\ndirectly into the application allows the application to “have its cake and eat\nit too.” That is, application processes can communicate reliably without\nbeing subjected to the transmission-rate constraints imposed by TCP’s\ncongestion-control mechanism."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 368,
    "text": "3.3.1 UDP Segment Structure\nThe UDP segment structure, shown in Figure 3.7, is defined in RFC 768. The application data occupies the data field of the UDP segment. For\nexample, for DNS, the data field contains either a query message or a\nresponse message. For a streaming audio application, audio samples fill the\ndata field. The UDP header has only four fields, each consisting of two\nbytes. As discussed in the previous section, the port numbers allow the\ndestination host to pass the application data to the correct process running\non the destination end system (that is, to perform the demultiplexing\nfunction). The length field specifies the number of bytes in the UDP\nsegment (header plus data). An explicit length value is needed since the size\nof the data field may differ from one UDP segment to the next. The\nchecksum is used by the receiving host to check whether errors have been\nintroduced into the segment. In truth, the checksum is also calculated over a\nfew of the fields in the IP header in addition to the UDP segment. But we\nignore this detail in order to see the forest through the trees. We’ll discuss\nthe checksum calculation below. Basic principles of error detection are\ndescribed in Section 6.2. The length field specifies the length of the UDP\nsegment, including the header, in bytes."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 369,
    "text": "Figure 3.7 ♦UDP segment structure\n3.3.2 UDP Checksum\nThe UDP checksum provides for error detection. That is, the checksum is\nused to determine whether bits within the UDP segment have been altered\n(for example, by noise in the links or while stored in a router) as it moved\nfrom source to destination. UDP at the sender side performs the 1s\ncomplement of the sum of all the 16-bit words in the segment, with any\noverflow encountered during the sum being wrapped around. This result is\nput in the checksum field of the UDP segment. Here we give a simple\nexample of the checksum calculation. You can find details about efficient\nimplementation of the calculation in RFC 1071 and performance over real\ndata in [Stone 1998; Stone 2000]. As an example, suppose that we have the\nfollowing three 16-bit words:\n0101010101010101"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 370,
    "text": "The sum of first two of these 16-bit words is\n0101010101010101\nAdding the third word to the above sum gives\n1000111100001100\nNote that this last addition had overflow, which was wrapped around. The 1s complement is obtained by converting all the 0s to 1s and converting\nall the 1s to 0s. Thus, the 1s complement of the sum 0100101011000010 is\n1011010100111101, which becomes the checksum. At the receiver, all four\n16-bit words are added, including the checksum. If no errors are introduced\ninto the packet, then clearly the sum at the receiver will be\n1111111111111111. If one of the bits is a 0, then we know that errors have\nbeen introduced into the packet. You may wonder why UDP provides a checksum in the first place, as\nmany link-layer protocols (including the popular Ethernet protocol) also\nprovide error checking. The reason is that there is no guarantee that all the\nlinks between source and destination provide error checking; that is, one of\nthe links may use a link-layer protocol that does not provide error checking. Furthermore, even if segments are correctly transferred across a link, it’s\npossible that bit errors could be introduced when a segment is stored in a\nrouter’s memory. Given that neither link-by-link reliability nor in-memory\nerror detection is guaranteed, UDP must provide error detection at the\ntransport layer, on an end-end basis, if the end-end data transfer service is"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 371,
    "text": "to provide error detection. This is an example of the celebrated end-end\nprinciple in system design [Saltzer 1984], which states that since certain\nfunctionality (error detection, in this case) must be implemented on an end-\nend basis: “functions placed at the lower levels may be redundant or of little\nvalue when compared to the cost of providing them at the higher level.”\nBecause IP is supposed to run over just about any layer-2 protocol, it is\nuseful for the transport layer to provide error checking as a safety measure. Although UDP provides error checking, it does not do anything to recover\nfrom an error. Some implementations of UDP simply discard the damaged\nsegment; others pass the damaged segment to the application with a\nwarning. That wraps up our discussion of UDP. We will soon see that TCP offers\nreliable data transfer to its applications as well as other services that UDP\ndoesn’t offer. Naturally, TCP is also more complex than UDP. Before\ndiscussing TCP, however, it will be useful to step back and first discuss the\nunderlying principles of reliable data transfer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 372,
    "text": "3.4 Principles of Reliable Data Transfer\nIn this section, we consider the problem of reliable data transfer in a general\ncontext. This is appropriate since the problem of implementing reliable data\ntransfer occurs not only at the transport layer, but also at the link layer and\nthe application layer as well. The general problem is thus of central\nimportance to networking. Indeed, if one had to identify a “top-ten” list of\nfundamentally important problems in all of networking, this would be a\ncandidate to lead the list. In the next section, we’ll examine TCP and show,\nin particular, that TCP exploits many of the principles that we are about to\ndescribe. Figure 3.8 illustrates the framework for our study of reliable data\ntransfer. The service abstraction provided to the upper-layer entities is that\nof a reliable channel through which data can be transferred. With a reliable\nchannel, no transferred data bits are corrupted (flipped from 0 to 1, or vice\nversa) or lost, and all are delivered in the order in which they were sent. This is precisely the service model offered by TCP to the Internet\napplications that invoke it."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 373,
    "text": "Figure 3.8 ♦Reliable data transfer: Service model and service\nimplementation\nIt is the responsibility of a reliable data transfer protocol to\nimplement this service abstraction. This task is made difficult by the fact\nthat the layer below the reliable data transfer protocol may be unreliable. For example, TCP is a reliable data transfer protocol that is implemented on\ntop of an unreliable (IP) end-to-end network layer. More generally, the layer\nbeneath the two reliably communicating end points might consist of a single\nphysical link (as in the case of a link-level data transfer protocol) or a\nglobal internetwork (as in the case of a transport-level protocol). For our\npurposes, however, we can view this lower layer simply as an unreliable\npoint-to-point channel."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 374,
    "text": "In this section, we will incrementally develop the sender and receiver\nsides of a reliable data transfer protocol, considering increasingly complex\nmodels of the underlying channel. For example, we’ll consider what\nprotocol mechanisms are needed when the underlying channel can corrupt\nbits or lose entire packets. One assumption we’ll adopt throughout our\ndiscussion here is that packets will be delivered in the order in which they\nwere sent, with some packets possibly being lost; that is, the underlying\nchannel will not reorder packets. Figure 3.8(b) illustrates the interfaces for\nour data transfer protocol. The sending side of the data transfer protocol\nwill be invoked from above by a call to rdt_send(). It will pass the data\nto be delivered to the upper layer at the receiving side. (Here rdt stands for\nreliable data transfer protocol and _send indicates that the sending side of\nrdt is being called. The first step in developing any protocol is to choose a\ngood name!) On the receiving side, rdt_rcv() will be called when a\npacket arrives from the receiving side of the channel. When the rdt\nprotocol wants to deliver data to the upper layer, it will do so by calling\ndeliver_data(). In the following, we use the terminology “packet”\nrather than transport-layer “segment.” Because the theory developed in this\nsection applies to computer networks in general and not just to the Internet\ntransport layer, the generic term “packet” is perhaps more appropriate here. In this section, we consider only the case of unidirectional data\ntransfer, that is, data transfer from the sending to the receiving side. The\ncase of reliable bidirectional (that is, full-duplex) data transfer is\nconceptually no more difficult but considerably more tedious to explain. Although we consider only unidirectional data transfer, it is important to\nnote that the sending and receiving sides of our protocol will nonetheless\nneed to transmit packets in both directions, as indicated in Figure 3.8. We\nwill see shortly that, in addition to exchanging packets containing the data"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 375,
    "text": "to be transferred, the sending and receiving sides of rdt will also need to\nexchange control packets back and forth. Both the send and receive sides of\nrdt send packets to the other side by a call to udt_send() (where udt\nstands for unreliable data transfer). 3.4.1 Building a Reliable Data Transfer Protocol\nWe now step through a series of protocols, each one becoming more\ncomplex, arriving at a flawless, reliable data transfer protocol. Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\nWe first consider the simplest case, in which the underlying channel is\ncompletely reliable. The protocol itself, which we’ll call rdt1.0, is trivial. The finite-state machine (FSM) definitions for the rdt1.0 sender and\nreceiver are shown in Figure 3.9. The FSM in Figure 3.9(a) defines the\noperation of the sender, while the FSM in Figure 3.9(b) defines the\noperation of the receiver. It is important to note that there are separate\nFSMs for the sender and for the receiver. The sender and receiver FSMs in\nFigure 3.9 each have just one state. The arrows in the FSM description\nindicate the transition of the protocol from one state to another. (Since each\nFSM in Figure 3.9 has just one state, a transition is necessarily from the one\nstate back to itself; we’ll see more complicated state diagrams shortly.) The\nevent causing the transition is shown above the horizontal line labeling the\ntransition, and the actions taken when the event occurs are shown below the\nhorizontal line. When no action is taken on an event, or no event occurs and\nan action is taken, we’ll use the symbol Λ below or above the horizontal,\nrespectively, to explicitly denote the lack of an action or event. The initial\nstate of the FSM is indicated by the dashed arrow. Although the FSMs in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 376,
    "text": "Figure 3.9 have but one state, the FSMs we will see shortly have multiple\nstates, so it will be important to identify the initial state of each FSM. Figure 3.9 ♦rdt1.0—A protocol for a completely reliable channel\nThe sending side of rdt simply accepts data from the upper layer via\nthe rdt_send(data) event, creates a packet containing the data (via the\naction make_pkt(data)) and sends the packet into the channel. In\npractice, the rdt_send(data) event would result from a procedure call\n(for example, to rdt_send()) by the upper-layer application. On the receiving side, rdt receives a packet from the underlying channel\nvia the rdt_rcv(packet) event, removes the data from the packet (via"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 377,
    "text": "the action extract (packet, data)) and passes the data up to the\nupper layer (via the action deliver_data(data)). In practice, the\nrdt_rcv(packet) event would result from a procedure call (for\nexample, to rdt_rcv()) from the lower-layer protocol. In this simple protocol, there is no difference between a unit of data and\na packet. Also, all packet flow is from the sender to receiver; with a\nperfectly reliable channel there is no need for the receiver side to provide\nany feedback to the sender since nothing can go wrong! Note that we have\nalso assumed that the receiver is able to receive data as fast as the sender\nhappens to send data. Thus, there is no need for the receiver to ask the\nsender to slow down! Reliable Data Transfer over a Channel with Bit Errors: rdt2.0\nA more realistic model of the underlying channel is one in which bits in a\npacket may be corrupted. Such bit errors typically occur in the physical\ncomponents of a network as a packet is transmitted, propagates, or is\nbuffered. We’ll continue to assume for the moment that all transmitted\npackets are received (although their bits may be corrupted) in the order in\nwhich they were sent. Before developing a protocol for reliably communicating over such a\nchannel, first consider how people might deal with such a situation. Consider how you yourself might dictate a long message over the phone. In\na typical scenario, the message taker might say “OK” after each sentence\nhas been heard, understood, and recorded. If the message taker hears a\ngarbled sentence, you’re asked to repeat the garbled sentence. This\nmessage-dictation protocol uses both positive acknowledgments (“OK”)\nand negative acknowledgments (“Please repeat that.”). These control\nmessages allow the receiver to let the sender know what has been received"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 378,
    "text": "correctly, and what has been received in error and thus requires repeating. In a computer network setting, reliable data transfer protocols based on\nsuch retransmission are known as ARQ (Automatic Repeat reQuest)\nprotocols. Fundamentally, three additional protocol capabilities are required in\nARQ protocols to handle the presence of bit errors:\n•\nError detection. First, a mechanism is needed to allow the receiver to\ndetect when bit errors have occurred. Recall from the previous section\nthat UDP uses the Internet checksum field for exactly this purpose. In\nChapter 6, we’ll examine error-detection and -correction techniques in\ngreater detail; these techniques allow the receiver to detect and possibly\ncorrect packet bit errors. For now, we need only know that these\ntechniques require that extra bits (beyond the bits of original data to be\ntransferred) be sent from the sender to the receiver; these bits will be\ngathered into the packet checksum field of the rdt2.0 data packet. •\nReceiver feedback. Since the sender and receiver are typically executing\non different end systems, possibly separated by thousands of miles, the\nonly way for the sender to learn of the receiver’s view of the world (in\nthis case, whether or not a packet was received correctly) is for the\nreceiver to provide explicit feedback to the sender. The positive (ACK)\nand negative (NAK) acknowledgment replies in the message-dictation\nscenario are examples of such feedback. Our rdt2.0 protocol will\nsimilarly send ACK and NAK packets back from the receiver to the\nsender. In principle, these packets need only be one bit long; for\nexample, a 0 value could indicate a NAK and a value of 1 could\nindicate an ACK. •\nRetransmission. A packet that is received in error at the receiver will be\nretransmitted by the sender."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 379,
    "text": "Figure 3.10 shows the FSM representation of rdt2.0, a data transfer\nprotocol employing error detection, positive acknowledgments, and\nnegative acknowledgments. Figure 3.10 ♦rdt2.0—A protocol for a channel with bit errors\nThe send side of rdt2.0 has two states. In the leftmost state, the send-\nside protocol is waiting for data to be passed down from the upper layer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 380,
    "text": "When the rdt_send(data) event occurs, the sender will create a packet\n(sndpkt) containing the data to be sent, along with a packet checksum (for\nexample, as discussed in Section 3.3.2 for the case of a UDP segment), and\nthen send the packet via the udt_send(sndpkt) operation. In the\nrightmost state, the sender protocol is waiting for an ACK or a NAK packet\nfrom the receiver. If an ACK packet is received (the notation\nrdt_rcv(rcvpkt) && isACK(rcvpkt) in Figure 3.10 corresponds\nto this event), the sender knows that the most recently transmitted packet\nhas been received correctly and thus the protocol returns to the state of\nwaiting for data from the upper layer. If a NAK is received, the protocol\nretransmits the last packet and waits for an ACK or NAK to be returned by\nthe receiver in response to the retransmitted data packet. It is important to\nnote that when the sender is in the wait-for-ACK-or-NAK state, it cannot\nget more data from the upper layer; that is, the rdt_send() event can not\noccur; that will happen only after the sender receives an ACK and leaves\nthis state. Thus, the sender will not send a new piece of data until it is sure\nthat the receiver has correctly received the current packet. Because of this\nbehavior, protocols such as rdt2.0 are known as stop-and-wait\nprotocols. The receiver-side FSM for rdt2.0 still has a single state. On packet\narrival, the receiver replies with either an ACK or a NAK, depending on\nwhether or not the received packet is corrupted. In Figure 3.10, the notation\nrdt_rcv(rcvpkt) && corrupt(rcvpkt) corresponds to the event\nin which a packet is received and is found to be in error. Protocol rdt2.0 may look as if it works but, unfortunately, it has a\nfatal flaw. In particular, we haven’t accounted for the possibility that the\nACK or NAK packet could be corrupted! (Before proceeding on, you\nshould think about how this problem may be fixed.) Unfortunately, our"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 381,
    "text": "slight oversight is not as innocuous as it may seem. Minimally, we will need\nto add checksum bits to ACK/NAK packets in order to detect such errors. The more difficult question is how the protocol should recover from errors\nin ACK or NAK packets. The difficulty here is that if an ACK or NAK is\ncorrupted, the sender has no way of knowing whether or not the receiver\nhas correctly received the last piece of transmitted data. Consider three possibilities for handling corrupted ACKs or NAKs:\n•\nFor the first possibility, consider what a human might do in the\nmessage-dictation scenario. If the speaker didn’t understand the “OK”\nor “Please repeat that” reply from the receiver, the speaker would\nprobably ask, “What did you say?” (thus introducing a new type of\nsender-to-receiver packet to our protocol). The receiver would then\nrepeat the reply. But what if the speaker’s “What did you say?” is\ncorrupted? The receiver, having no idea whether the garbled sentence\nwas part of the dictation or a request to repeat the last reply, would\nprobably then respond with “What did you say?” And then, of course,\nthat response might be garbled. Clearly, we’re heading down a difficult\npath. •\nA second alternative is to add enough checksum bits to allow the sender\nnot only to detect, but also to recover from, bit errors. This solves the\nimmediate problem for a channel that can corrupt packets but not lose\nthem. •\nA third approach is for the sender simply to resend the current data\npacket when it receives a garbled ACK or NAK packet. This approach,\nhowever, introduces duplicate packets into the sender-to-receiver\nchannel. The fundamental difficulty with duplicate packets is that the\nreceiver doesn’t know whether the ACK or NAK it last sent was"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 382,
    "text": "received correctly at the sender. Thus, it cannot know a priori whether\nan arriving packet contains new data or is a retransmission! A simple solution to this new problem (and one adopted in almost all\nexisting data transfer protocols, including TCP) is to add a new field to the\ndata packet and have the sender number its data packets by putting a\nsequence number into this field. The receiver then need only check this\nsequence number to determine whether or not the received packet is a\nretransmission. For this simple case of a stop-and-wait protocol, a 1-bit\nsequence number will suffice, since it will allow the receiver to know\nwhether the sender is resending the previously transmitted packet (the\nsequence number of the received packet has the same sequence number as\nthe most recently received packet) or a new packet (the sequence number\nchanges, moving “forward” in modulo-2 arithmetic). Since we are currently\nassuming a channel that does not lose packets, ACK and NAK packets do\nnot themselves need to indicate the sequence number of the packet they are\nacknowledging. The sender knows that a received ACK or NAK packet\n(whether garbled or not) was generated in response to its most recently\ntransmitted data packet. Figures 3.11 and 3.12 show the FSM description for rdt2.1, our\nfixed version of rdt2.0. The rdt2.1 sender and receiver FSMs each\nnow have twice as many states as before. This is because the protocol state\nmust now reflect whether the packet currently being sent (by the sender) or\nexpected (at the receiver) should have a sequence number of 0 or 1. Note\nthat the actions in those states where a 0-numbered packet is being sent or\nexpected are mirror images of those where a 1-numbered packet is being\nsent or expected; the only differences have to do with the handling of the\nsequence number."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 383,
    "text": "Figure 3.11 ♦rdt2.1 sender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 384,
    "text": "Figure 3.12 ♦rdt2.1 receiver\nProtocol rdt2.1 uses both positive and negative acknowledgments\nfrom the receiver to the sender. When an out-of-order packet is received, the\nreceiver sends a positive acknowledgment for the packet it has received. When a corrupted packet is received, the receiver sends a negative\nacknowledgment. We can accomplish the same effect as a NAK if, instead\nof sending a NAK, we send an ACK for the last correctly received packet. A sender that receives two ACKs for the same packet (that is, receives\nduplicate ACKs) knows that the receiver did not correctly receive the\npacket following the packet that is being ACKed twice. Our NAK-free\nreliable data transfer protocol for a channel with bit errors is rdt2.2,\nshown in Figures 3.13 and 3.14. One subtle change between rtdt2.1 and\nrdt2.2 is that the receiver must now include the sequence number of the\npacket being acknowledged by an ACK message (this is done by including\nthe ACK, 0 or ACK, 1 argument in make_pkt() in the receiver FSM), and\nthe sender must now check the sequence number of the packet being"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 385,
    "text": "acknowledged by a received ACK message (this is done by including the 0\nor 1 argument in isACK() in the sender FSM). Figure 3.13 ♦rdt2.2 sender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 386,
    "text": "Figure 3.14 ♦rdt2.2 receiver\nReliable Data Transfer over a Lossy Channel with Bit Errors:\nrdt3.0\nSuppose now that in addition to corrupting bits, the underlying channel can\nlose packets as well, a not-uncommon event in today’s computer networks\n(including the Internet). Two additional concerns must now be addressed by\nthe protocol: how to detect packet loss and what to do when packet loss\noccurs. The use of checksumming, sequence numbers, ACK packets, and\nretransmissions—the techniques already developed in rdt2.2—will allow\nus to answer the latter concern. Handling the first concern will require\nadding a new protocol mechanism. There are many possible approaches toward dealing with packet loss\n(several more of which are explored in the exercises at the end of the\nchapter). Here, we’ll put the burden of detecting and recovering from lost\npackets on the sender. Suppose that the sender transmits a data packet and\neither that packet, or the receiver’s ACK of that packet, gets lost. In either"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 387,
    "text": "case, no reply is forthcoming at the sender from the receiver. If the sender is\nwilling to wait long enough so that it is certain that a packet has been lost, it\ncan simply retransmit the data packet. You should convince yourself that\nthis protocol does indeed work. But how long must the sender wait to be certain that something has\nbeen lost? The sender must clearly wait at least as long as a round-trip delay\nbetween the sender and receiver (which may include buffering at\nintermediate routers) plus whatever amount of time is needed to process a\npacket at the receiver. In many networks, this worst-case maximum delay is\nvery difficult even to estimate, much less know with certainty. Moreover,\nthe protocol should ideally recover from packet loss as soon as possible;\nwaiting for a worst-case delay could mean a long wait until error recovery\nis initiated. The approach thus adopted in practice is for the sender to\njudiciously choose a time value such that packet loss is likely, although not\nguaranteed, to have happened. If an ACK is not received within this time,\nthe packet is retransmitted. Note that if a packet experiences a particularly\nlarge delay, the sender may retransmit the packet even though neither the\ndata packet nor its ACK have been lost. This introduces the possibility of\nduplicate data packets in the sender-to-receiver channel. Happily, protocol\nrdt2.2 already has enough functionality (that is, sequence numbers) to\nhandle the case of duplicate packets. From the sender’s viewpoint, retransmission is a panacea. The sender\ndoes not know whether a data packet was lost, an ACK was lost, or if the\npacket or ACK was simply overly delayed. In all cases, the action is the\nsame: retransmit. Implementing a time-based retransmission mechanism\nrequires a countdown timer that can interrupt the sender after a given\namount of time has expired. The sender will thus need to be able to (1) start\nthe timer each time a packet (either a first-time packet or a retransmission)"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 388,
    "text": "is sent, (2) respond to a timer interrupt (taking appropriate actions), and (3)\nstop the timer. Figure 3.15 shows the sender FSM for rdt3.0, a protocol that reliably\ntransfers data over a channel that can corrupt or lose packets; in the\nhomework problems, you’ll be asked to provide the receiver FSM for\nrdt3.0. Figure 3.16 shows how the protocol operates with no lost or\ndelayed packets and how it handles lost data packets. In Figure 3.16, time\nmoves forward from the top of the diagram toward the bottom of the\ndiagram; note that a receive time for a packet is necessarily later than the\nsend time for a packet as a result of transmission and propagation delays. In\nFigures 3.16(b)–(d), the send-side brackets indicate the times at which a\ntimer is set and later times out. Several of the more subtle aspects of this\nprotocol are explored in the exercises at the end of this chapter. Because\npacket sequence numbers alternate between 0 and 1, protocol rdt3.0 is\nsometimes known as the alternating-bit protocol."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 389,
    "text": "Figure 3.15 ♦rdt3.0 sender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 390,
    "text": "Figure 3.16 ♦Operation of rdt3.0, the alternating-bit protocol\nWe have now assembled the key elements of a data transfer protocol. Checksums, sequence numbers, timers, and positive and negative\nacknowledgment packets each play a crucial and necessary role in the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 391,
    "text": "operation of the protocol. We now have a working reliable data transfer\nprotocol! 3.4.2 Pipelined Reliable Data Transfer Protocols\nProtocol rdt3.0 is a functionally correct protocol, but it is unlikely that\nanyone would be happy with its performance, particularly in today’s high-\nspeed networks. At the heart of rdt3.0’s performance problem is the fact\nthat it is a stop-and-wait protocol. To appreciate the performance impact of this stop-and-wait behavior,\nconsider an idealized case of two hosts, one located on the West Coast of\nthe United States and the other located on the East Coast, as shown in\nFigure 3.17. The speed-of-light round-trip propagation delay between these\ntwo end systems, RTT, is approximately 30 milliseconds. Suppose that they\nare connected by a channel with a transmission rate, R, of 1 Gbps (109 bits\nper second). With a packet size, L, of 1,000 bytes (8,000 bits) per packet,\nincluding both header fields and data, the time needed to actually transmit\nthe packet into the 1 Gbps link is\ndtrans = L\nR =\n8000 bits\n109 bits/sec = 8 microseconds"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 392,
    "text": "Figure 3.17 ♦Stop-and-wait versus pipelined protocol\nFigure 3.18(a) shows that with our stop-and-wait protocol, if the sender\nbegins sending the packet at t = 0, then at t = L/R = 8 microseconds, the last\nbit enters the channel at the sender side. The packet then makes its 15-msec\ncross-country journey, with the last bit of the packet emerging at the\nreceiver at t = RTT/2 + L/R = 15.008 msec. Assuming for simplicity that\nACK packets are extremely small (so that we can ignore their transmission\ntime) and that the receiver can send an ACK as soon as the last bit of a data\npacket is received, the ACK emerges back at the sender at t = RTT + L/R =\n30.008 msec. At this point, the sender can now transmit the next message. Thus, in 30.008 msec, the sender was sending for only 0.008 msec. If we\ndefine the utilization of the sender (or the channel) as the fraction of time\nthe sender is actually busy sending bits into the channel, the analysis in\nFigure 3.18(a) shows that the stop-and-wait protocol has a rather dismal\nsender utilization, U\n, of\nUsender =\nL/R\nRTT+L/R =\n.008\n30.008 = 0.00027\nsender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 393,
    "text": "Figure 3.18 ♦Stop-and-wait and pipelined sending\nThat is, the sender was busy only 2.7 hundredths of one percent of the\ntime! Viewed another way, the sender was able to send only 1,000 bytes in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 30",
    "source": "kurose",
    "page": 394,
    "text": "30.008 milliseconds, an effective throughput of only 267 kbps—even\nthough a 1 Gbps link was available! Imagine the unhappy network manager\nwho just paid a fortune for a gigabit capacity link but manages to get a\nthroughput of only 267 kilobits per second! This is a graphic example of\nhow network protocols can limit the capabilities provided by the underlying\nnetwork hardware. Also, we have neglected lower-layer protocol-processing\ntimes at the sender and receiver, as well as the processing and queuing\ndelays that would occur at any intermediate routers between the sender and\nreceiver. Including these effects would serve only to further increase the\ndelay and further accentuate the poor performance. The solution to this particular performance problem is simple: Rather\nthan operate in a stop-and-wait manner, the sender is allowed to send\nmultiple packets without waiting for acknowledgments, as illustrated in\nFigure 3.17(b). Figure 3.18(b) shows that if the sender is allowed to\ntransmit three packets before having to wait for acknowledgments, the\nutilization of the sender is essentially tripled. Since the many in-transit\nsender-to-receiver packets can be visualized as filling a pipeline, this\ntechnique is known as pipelining. Pipelining has the following\nconsequences for reliable data transfer protocols:\n•\nThe range of sequence numbers must be increased, since each in-transit\npacket (not counting retransmissions) must have a unique sequence\nnumber and there may be multiple, in-transit, unacknowledged packets. •\nThe sender and receiver sides of the protocols may have to buffer more\nthan one packet. Minimally, the sender will have to buffer packets that\nhave been transmitted but not yet acknowledged. Buffering of correctly\nreceived packets may also be needed at the receiver, as discussed below. •\nThe range of sequence numbers needed and the buffering requirements\nwill depend on the manner in which a data transfer protocol responds to"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 395,
    "text": "lost, corrupted, and overly delayed packets. Two basic approaches\ntoward pipelined error recovery can be identified: Go-Back-N and\nselective repeat. 3.4.3 Go-Back-N (GBN)\nIn a Go-Back-N (GBN) protocol, the sender is allowed to transmit multiple\npackets (when available) without waiting for an acknowledgment, but is\nconstrained to have no more than some maximum allowable number, N, of\nunacknowledged packets in the pipeline. We describe the GBN protocol in\nsome detail in this section. But before reading on, you are encouraged to\nplay with the GBN animation (an awesome interactive animation) at the\nCompanion Website. Figure 3.19 shows the sender’s view of the range of sequence numbers\nin a GBN protocol. If we define base to be the sequence number of the\noldest unacknowledged packet and nextseqnum to be the smallest unused\nsequence number (that is, the sequence number of the next packet to be\nsent), then four intervals in the range of sequence numbers can be\nidentified. Sequence numbers in the interval [0,base-1] correspond to\npackets that have already been transmitted and acknowledged. The interval\n[base,nextseqnum-1] corresponds to packets that have been sent but\nnot \nyet \nacknowledged. Sequence \nnumbers \nin \nthe \ninterval\n[nextseqnum,base+N-1] can be used for packets that can be sent\nimmediately, should data arrive from the upper layer. Finally, sequence\nnumbers greater than or equal to base+N cannot be used until an\nunacknowledged packet currently in the pipeline (specifically, the packet\nwith sequence number base) has been acknowledged."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 396,
    "text": "Figure 3.19 ♦Sender’s view of sequence numbers in Go-Back-N\nAs suggested by Figure 3.19, the range of permissible sequence\nnumbers for transmitted but not yet acknowledged packets can be viewed as\na window of size N over the range of sequence numbers. As the protocol\noperates, this window slides forward over the sequence number space. For\nthis reason, N is often referred to as the window size and the GBN protocol\nitself as a sliding-window protocol. You might be wondering why we\nwould even limit the number of outstanding, unacknowledged packets to a\nvalue of N in the first place. Why not allow an unlimited number of such\npackets? We’ll see in Section 3.5 that flow control is one reason to impose a\nlimit on the sender. We’ll examine another reason to do so in Section 3.7,\nwhen we study TCP congestion control. In practice, a packet’s sequence number is carried in a fixed-length field\nin the packet header. If k is the number of bits in the packet sequence\nnumber field, the range of sequence numbers is thus [0,2  − 1]. With a finite\nrange of sequence numbers, all arithmetic involving sequence numbers\nmust then be done using modulo 2  arithmetic. (That is, the sequence\nnumber space can be thought of as a ring of size 2 , where sequence number\n2  − 1 is immediately followed by sequence number 0.) Recall that rdt3.0\nhad a 1-bit sequence number and a range of sequence numbers of [0,1]. Several of the problems at the end of this chapter explore the consequences\nof a finite range of sequence numbers. We will see in Section 3.5 that TCP\nk\nk\nk\nk"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 397,
    "text": "has a 32-bit sequence number field, where TCP sequence numbers count\nbytes in the byte stream rather than packets. Figures 3.20 and 3.21 give an extended FSM description of the sender\nand receiver sides of an ACK-based, NAK-free, GBN protocol. We refer to\nthis FSM description as an extended FSM because we have added variables\n(similar to programming-language variables) for base and nextseqnum,\nand added operations on these variables and conditional actions involving\nthese variables. Note that the extended FSM specification is now beginning\nto look somewhat like a programming-language specification. [Bochman\n1984] provides an excellent survey of additional extensions to FSM\ntechniques as well as other programming-language-based techniques for\nspecifying protocols. Figure 3.20 ♦Extended FSM description of the GBN sender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 398,
    "text": "Figure 3.21 ♦Extended FSM description of the GBN receiver\nThe GBN sender must respond to three types of events:\n•\nInvocation from above. When rdt_send() is called from above, the\nsender first checks to see if the window is full, that is, whether there are\nN outstanding, unacknowledged packets. If the window is not full, a\npacket is created and sent, and variables are appropriately updated. If\nthe window is full, the sender simply returns the data back to the upper\nlayer, an implicit indication that the window is full. The upper layer\nwould presumably then have to try again later. In a real implementation,\nthe sender would more likely have either buffered (but not immediately\nsent) this data, or would have a synchronization mechanism (for\nexample, a semaphore or a flag) that would allow the upper layer to call\nrdt_send() only when the window is not full. •\nReceipt of an ACK. In our GBN protocol, an acknowledgment for a\npacket with sequence number n will be taken to be a cumulative\nacknowledgment, indicating that all packets with a sequence number\nup to and including n have been correctly received at the receiver. We’ll"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 399,
    "text": "come back to this issue shortly when we examine the receiver side of\nGBN. •\nA timeout event. The protocol’s name, “Go-Back-N,” is derived from\nthe sender’s behavior in the presence of lost or overly delayed packets. As in the stop-and-wait protocol, a timer will again be used to recover\nfrom lost data or acknowledgment packets. If a timeout occurs, the\nsender resends all packets that have been previously sent but that have\nnot yet been acknowledged. Our sender in Figure 3.20 uses only a\nsingle timer, which can be thought of as a timer for the oldest\ntransmitted but not yet acknowledged packet. If an ACK is received but\nthere are still additional transmitted but not yet acknowledged packets,\nthe timer is restarted. If there are no outstanding, unacknowledged\npackets, the timer is stopped. The receiver’s actions in GBN are also simple. If a packet with\nsequence number n is received correctly and is in order (that is, the data last\ndelivered to the upper layer came from a packet with sequence number n −\n1), the receiver sends an ACK for packet n and delivers the data portion of\nthe packet to the upper layer. In all other cases, the receiver discards the\npacket and resends an ACK for the most recently received in-order packet. Note that since packets are delivered one at a time to the upper layer, if\npacket k has been received and delivered, then all packets with a sequence\nnumber lower than k have also been delivered. Thus, the use of cumulative\nacknowledgments is a natural choice for GBN. In our GBN protocol, the receiver discards out-of-order packets. Although it may seem silly and wasteful to discard a correctly received (but\nout-of-order) packet, there is some justification for doing so. Recall that the\nreceiver must deliver data in order to the upper layer. Suppose now that\npacket n is expected, but packet n + 1 arrives. Because data must be"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 400,
    "text": "delivered in order, the receiver could buffer (save) packet n + 1 and then\ndeliver this packet to the upper layer after it had later received and delivered\npacket n. However, if packet n is lost, both it and packet n + 1 will\neventually be retransmitted as a result of the GBN retransmission rule at the\nsender. Thus, the receiver can simply discard packet n + 1. The advantage\nof this approach is the simplicity of receiver buffering—the receiver need\nnot buffer any out-of-order packets. Thus, while the sender must maintain\nthe upper and lower bounds of its window and the position of\nnextseqnum within this window, the only piece of information the\nreceiver need maintain is the sequence number of the next in-order packet. This value is held in the variable expectedseqnum, shown in the\nreceiver FSM in Figure 3.21. Of course, the disadvantage of throwing away\na correctly received packet is that the subsequent retransmission of that\npacket might be lost or garbled and thus even more retransmissions would\nbe required. Figure 3.22 shows the operation of the GBN protocol for the case of a\nwindow size of four packets. Because of this window size limitation, the\nsender sends packets 0 through 3 but then must wait for one or more of\nthese packets to be acknowledged before proceeding. As each successive\nACK (for example, ACK0 and ACK1) is received, the window slides\nforward and the sender can transmit one new packet (pkt4 and pkt5,\nrespectively). On the receiver side, packet 2 is lost and thus packets 3, 4,\nand 5 are found to be out of order and are discarded."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 401,
    "text": "Figure 3.22 ♦Go-Back-N in operation"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 402,
    "text": "Before closing our discussion of GBN, it is worth noting that an\nimplementation of this protocol in a protocol stack would likely have a\nstructure similar to that of the extended FSM in Figure 3.20. The\nimplementation would also likely be in the form of various procedures that\nimplement the actions to be taken in response to the various events that can\noccur. In such event-based programming, the various procedures are\ncalled (invoked) either by other procedures in the protocol stack, or as the\nresult of an interrupt. In the sender, these events would be (1) a call from\nthe upper-layer entity to invoke rdt_send(), (2) a timer interrupt, and\n(3) a call from the lower layer to invoke rdt_rcv() when a packet\narrives. The programming exercises at the end of this chapter will give you\na chance to actually implement these routines in a simulated, but realistic,\nnetwork setting. We note here that the GBN protocol incorporates almost all of the\ntechniques that we will encounter when we study the reliable data transfer\ncomponents of TCP in Section 3.5. These techniques include the use of\nsequence numbers, cumulative acknowledgments, checksums, and a\ntimeout/retransmit operation. 3.4.4 Selective Repeat (SR)\nThe GBN protocol allows the sender to potentially “fill the pipeline” in\nFigure 3.17 with packets, thus avoiding the channel utilization problems we\nnoted with stop-and-wait protocols. There are, however, scenarios in which\nGBN itself suffers from performance problems. In particular, when the\nwindow size and bandwidth-delay product are both large, many packets can\nbe in the pipeline. A single packet error can thus cause GBN to retransmit a\nlarge number of packets, many unnecessarily. As the probability of channel"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 403,
    "text": "errors increases, the pipeline can become filled with these unnecessary\nretransmissions. Imagine, in our message-dictation scenario, that if every\ntime a word was garbled, the surrounding 1,000 words (for example, a\nwindow size of 1,000 words) had to be repeated. The dictation would be\nslowed by all of the reiterated words. As the name suggests, selective-repeat protocols avoid unnecessary\nretransmissions by having the sender retransmit only those packets that it\nsuspects were received in error (that is, were lost or corrupted) at the\nreceiver. This individual, as-needed, retransmission will require that the\nreceiver individually acknowledge correctly received packets. A window\nsize of N will again be used to limit the number of outstanding,\nunacknowledged packets in the pipeline. However, unlike GBN, the sender\nwill have already received ACKs for some of the packets in the window. Figure 3.23 shows the SR sender’s view of the sequence number space. Figure 3.24 details the various actions taken by the SR sender."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 404,
    "text": "Figure 3.23 ♦Selective-repeat (SR) sender and receiver views of\nsequence-number space\nFigure 3.24 ♦SR sender events and actions\nThe SR receiver will acknowledge a correctly received packet whether\nor not it is in order. Out-of-order packets are buffered until any missing\npackets (that is, packets with lower sequence numbers) are received, at\nwhich point a batch of packets can be delivered in order to the upper layer. Figure 3.25 itemizes the various actions taken by the SR receiver. Figure\n3.26 shows an example of SR operation in the presence of lost packets. Note that in Figure 3.26, the receiver initially buffers packets 3, 4, and 5,\nand delivers them together with packet 2 to the upper layer when packet 2 is\nfinally received."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 405,
    "text": "Figure 3.25 ♦SR receiver events and actions"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 406,
    "text": "Figure 3.26 ♦SR operation\nIt is important to note that in Step 2 in Figure 3.25, the receiver\nreacknowledges (rather than ignores) already received packets with certain\nsequence numbers below the current window base. You should convince\nyourself that this reacknowledgment is indeed needed. Given the sender and\nreceiver sequence number spaces in Figure 3.23, for example, if there is no\nACK for packet send_base propagating from the receiver to the sender,"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 407,
    "text": "the sender will eventually retransmit packet send_base, even though it is\nclear (to us, not the sender!) that the receiver has already received that\npacket. If the receiver were not to acknowledge this packet, the sender’s\nwindow would never move forward! This example illustrates an important\naspect of SR protocols (and many other protocols as well). The sender and\nreceiver will not always have an identical view of what has been received\ncorrectly and what has not. For SR protocols, this means that the sender and\nreceiver windows will not always coincide. The lack of synchronization between sender and receiver windows has\nimportant consequences when we are faced with the reality of a finite range\nof sequence numbers. Consider what could happen, for example, with a\nfinite range of four packet sequence numbers, 0, 1, 2, 3, and a window size\nof three. Suppose packets 0 through 2 are transmitted and correctly received\nand acknowledged at the receiver. At this point, the receiver’s window is\nover the fourth, fifth, and sixth packets, which have sequence numbers 3, 0,\nand 1, respectively. Now consider two scenarios. In the first scenario,\nshown in Figure 3.27(a), the ACKs for the first three packets are lost and\nthe sender retransmits these packets. The receiver thus next receives a\npacket with sequence number 0—a copy of the first packet sent."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 409,
    "text": "Figure 3.27 ♦SR receiver dilemma with too-large windows: A new\npacket or a retransmission? In the second scenario, shown in Figure 3.27(b), the ACKs for the first\nthree packets are all delivered correctly. The sender thus moves its window\nforward and sends the fourth, fifth, and sixth packets, with sequence\nnumbers 3, 0, and 1, respectively. The packet with sequence number 3 is\nlost, but the packet with sequence number 0 arrives—a packet containing\nnew data. Now consider the receiver’s viewpoint in Figure 3.27, which has a\nfigurative curtain between the sender and the receiver, since the receiver\ncannot “see” the actions taken by the sender. All the receiver observes is the\nsequence of messages it receives from the channel and sends into the\nchannel. As far as it is concerned, the two scenarios in Figure 3.27 are\nidentical. There is no way of distinguishing the retransmission of the first\npacket from an original transmission of the fifth packet. Clearly, a window\nsize that is 1 less than the size of the sequence number space won’t work. But how small must the window size be? A problem at the end of the\nchapter asks you to show that the window size must be less than or equal to\nhalf the size of the sequence number space for SR protocols. At the Companion Website, you will find an animation that illustrates\nthe operation of the SR protocol. Try performing the same experiments that\nyou did with the GBN animation. Do the results agree with what you\nexpect? This completes our discussion of reliable data transfer protocols. We’ve\ncovered a lot of ground and introduced numerous mechanisms that together"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 410,
    "text": "provide for reliable data transfer. Table 3.1 summarizes these mechanisms. Now that we have seen all of these mechanisms in operation and can see the\n“big picture,” we encourage you to review this section again to see how\nthese mechanisms were incrementally added to cover increasingly complex\n(and realistic) models of the channel connecting the sender and receiver, or\nto improve the performance of the protocols. Table 3.1 ♦Summary of reliable data transfer mechanisms and their\nuse\nLet’s conclude our discussion of reliable data transfer protocols by\nconsidering one remaining assumption in our underlying channel model. Recall that we have assumed that packets cannot be reordered within the\nchannel between the sender and receiver. This is generally a reasonable\nassumption when the sender and receiver are connected by a single physical\nwire. However, when the “channel” connecting the two is a network, packet\nreordering can occur. One manifestation of packet reordering is that old\ncopies of a packet with a sequence or acknowledgment number of x can\nappear, even though neither the sender’s nor the receiver’s window contains\nx. With packet reordering, the channel can be thought of as essentially\nbuffering packets and spontaneously emitting these packets at any point in\nthe future. Because sequence numbers may be reused, some care must be\ntaken to guard against such duplicate packets. The approach taken in\npractice is to ensure that a sequence number is not reused until the sender is\n“sure” that any previously sent packets with sequence number x are no\nlonger in the network. This is done by assuming that a packet cannot “live”\nin the network for longer than some fixed maximum amount of time. A\nmaximum packet lifetime of approximately three minutes is assumed in the\nTCP extensions for high-speed networks [RFC 7323]. [Sunshine 1978]"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 411,
    "text": "describes a method for using sequence numbers such that reordering\nproblems can be completely avoided."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 412,
    "text": "3.5 Connection-Oriented Transport: TCP\nNow that we have covered the underlying principles of reliable data\ntransfer, let’s turn to TCP—the Internet’s transport-layer, connection-\noriented, reliable transport protocol. In this section, we’ll see that in order to\nprovide reliable data transfer, TCP relies on many of the underlying\nprinciples discussed in the previous section, including error detection,\nretransmissions, cumulative acknowledgments, timers, and header fields for\nsequence and acknowledgment numbers. TCP is defined in RFC 793, RFC\n1122, RFC 2018, RFC 5681, and RFC 7323. 3.5.1 The TCP Connection\nTCP is said to be connection-oriented because before one application\nprocess can begin to send data to another, the two processes must first\n“handshake” with each other—that is, they must send some preliminary\nsegments to each other to establish the parameters of the ensuing data\ntransfer. As part of TCP connection establishment, both sides of the\nconnection will initialize many TCP state variables (many of which will be\ndiscussed in this section and in Section 3.7) associated with the TCP\nconnection. The TCP “connection” is not an end-to-end TDM or FDM circuit as in\na circuit-switched network. Instead, the “connection” is a logical one, with\ncommon state residing only in the TCPs in the two communicating end\nsystems. Recall that because the TCP protocol runs only in the end systems\nand not in the intermediate network elements (routers and link-layer\nswitches), the intermediate network elements do not maintain TCP"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 413,
    "text": "connection state. In fact, the intermediate routers are completely oblivious\nto TCP connections; they see datagrams, not connections. A TCP connection provides a full-duplex service: If there is a TCP\nconnection between Process A on one host and Process B on another host,\nthen application-layer data can flow from Process A to Process B at the\nsame time as application-layer data flows from Process B to Process A. A\nTCP connection is also always point-to-point, that is, between a single\nsender and a single receiver. So-called “multicasting” (see the online\nsupplementary materials for this text)—the transfer of data from one sender\nto many receivers in a single send operation—is not possible with TCP. With TCP, two hosts are company and three are a crowd! Let’s now take a look at how a TCP connection is established. Suppose\na process running in one host wants to initiate a connection with another\nprocess in another host. Recall that the process that is initiating the\nconnection is called the client process, while the other process is called the\nserver process. The client application process first informs the client\ntransport layer that it wants to establish a connection to a process in the\nserver. Recall from Section 2.7.2, a Python client program does this by\nissuing the command\nclientSocket.connect((serverName,serverPort))\nCASE HISTORY\nVINTON CERF, ROBERT KAHN, AND TCP/IP\nIn the early 1970s, packet-switched networks began to proliferate, with the ARPAnet—\nthe precursor of the Internet—being just one of many networks. Each of these\nnetworks had its own protocol. Two researchers, Vinton Cerf and Robert Kahn,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 414,
    "text": "recognized the importance of interconnecting these networks and invented a cross-\nnetwork protocol called TCP/IP, which stands for Transmission Control\nProtocol/Internet Protocol. Although Cerf and Kahn began by seeing the protocol as a\nsingle entity, it was later split into its two parts, TCP and IP, which operated separately. Cerf and Kahn published a paper on TCP/IP in May 1974 in IEEE Transactions on\nCommunications Technology [Cerf 1974]. The TCP/IP protocol, which is the bread and butter of today’s Internet, was devised\nbefore PCs, workstations, smartphones, and tablets, before the proliferation of\nEthernet, cable, and DSL, WiFi, and other access network technologies, and before the\nWeb, social media, and streaming video. Cerf and Kahn saw the need for a networking\nprotocol that, on the one hand, provides broad support for yet-to-be-defined\napplications and, on the other hand, allows arbitrary hosts and link-layer protocols to\ninteroperate. In 2004, Cerf and Kahn received the ACM’s Turing Award, considered the “Nobel\nPrize of Computing” for “pioneering work on internetworking, including the design and\nimplementation of the Internet’s basic communications protocols, TCP/IP, and for\ninspired leadership in networking.”\nwhere serverName is the name of the server and serverPort\nidentifies the process on the server. TCP in the client then proceeds to\nestablish a TCP connection with TCP in the server. At the end of this section\nwe discuss in some detail the connection-establishment procedure. For now\nit suffices to know that the client first sends a special TCP segment; the\nserver responds with a second special TCP segment; and finally the client\nresponds again with a third special segment. The first two segments carry\nno payload, that is, no application-layer data; the third of these segments\nmay carry a payload. Because three segments are sent between the two"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 415,
    "text": "hosts, this connection-establishment procedure is often referred to as a\nthree-way handshake. Once a TCP connection is established, the two application processes\ncan send data to each other. Let’s consider the sending of data from the\nclient process to the server process. The client process passes a stream of\ndata through the socket (the door of the process), as described in Section\n2.7. Once the data passes through the door, the data is in the hands of TCP\nrunning in the client. As shown in Figure 3.28, TCP directs this data to the\nconnection’s send buffer, which is one of the buffers that is set aside during\nthe initial three-way handshake. From time to time, TCP will grab chunks\nof data from the send buffer and pass the data to the network layer. Interestingly, the TCP specification [RFC 793] is very laid back about\nspecifying when TCP should actually send buffered data, stating that TCP\nshould “send that data in segments at its own convenience.” The maximum\namount of data that can be grabbed and placed in a segment is limited by\nthe maximum segment size (MSS). The MSS is typically set by first\ndetermining the length of the largest link-layer frame that can be sent by the\nlocal sending host (the so-called maximum transmission unit, MTU), and\nthen setting the MSS to ensure that a TCP segment (when encapsulated in\nan IP datagram) plus the TCP/IP header length (typically 40 bytes) will fit\ninto a single link-layer frame. Both Ethernet and PPP link-layer protocols\nhave an MTU of 1,500 bytes. Thus, a typical value of MSS is 1460 bytes. Approaches have also been proposed for discovering the path MTU—the\nlargest link-layer frame that can be sent on all links from source to\ndestination [RFC 1191]—and setting the MSS based on the path MTU\nvalue. Note that the MSS is the maximum amount of application-layer data\nin the segment, not the maximum size of the TCP segment including"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 416,
    "text": "headers. (This terminology is confusing, but we have to live with it, as it is\nwell entrenched.) Figure 3.28 ♦TCP send and receive buffers\nTCP pairs each chunk of client data with a TCP header, thereby forming\nTCP segments. The segments are passed down to the network layer, where\nthey are separately encapsulated within network-layer IP datagrams. The IP\ndatagrams are then sent into the network. When TCP receives a segment at\nthe other end, the segment’s data is placed in the TCP connection’s receive\nbuffer, as shown in Figure 3.28. The application reads the stream of data\nfrom this buffer. Each side of the connection has its own send buffer and its\nown receive buffer. (You can see the online flow-control interactive\nanimation at http://www.awl.com/kurose-ross, which provides an animation\nof the send and receive buffers.) We see from this discussion that a TCP connection consists of buffers,\nvariables, and a socket connection to a process in one host, and another set\nof buffers, variables, and a socket connection to a process in another host. As mentioned earlier, no buffers or variables are allocated to the connection"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 417,
    "text": "in the network elements (routers, switches, and repeaters) between the\nhosts. 3.5.2 TCP Segment Structure\nHaving taken a brief look at the TCP connection, let’s examine the TCP\nsegment structure. The TCP segment consists of header fields and a data\nfield. The data field contains a chunk of application data. As mentioned\nabove, the MSS limits the maximum size of a segment’s data field. When\nTCP sends a large file, such as an image as part of a Web page, it typically\nbreaks the file into chunks of size MSS (except for the last chunk, which\nwill often be less than the MSS). Interactive applications, however, often\ntransmit data chunks that are smaller than the MSS; for example, with\nremote login applications such as Telnet and ssh, the data field in the TCP\nsegment is often only one byte. Because the TCP header is typically 20\nbytes (12 bytes more than the UDP header), segments sent by Telnet and ssh\nmay be only 21 bytes in length. Figure 3.29 shows the structure of the TCP segment. As with UDP, the\nheader includes source and destination port numbers, which are used for\nmultiplexing/demultiplexing data from/to upper-layer applications. Also, as\nwith UDP, the header includes a checksum field. A TCP segment header\nalso contains the following fields:\n•\nThe 32-bit sequence number field and the 32-bit acknowledgment\nnumber field are used by the TCP sender and receiver in implementing\na reliable data transfer service, as discussed below. •\nThe 16-bit receive window field is used for flow control. We will see\nshortly that it is used to indicate the number of bytes that a receiver is\nwilling to accept."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 418,
    "text": "•\nThe 4-bit header length field specifies the length of the TCP header in\n32-bit words. The TCP header can be of variable length due to the TCP\noptions field. (Typically, the options field is empty, so that the length of\nthe typical TCP header is 20 bytes.) •\nThe optional and variable-length options field is used when a sender\nand receiver negotiate the maximum segment size (MSS) or as a\nwindow scaling factor for use in high-speed networks. A time-stamping\noption is also defined. See RFC 854 and RFC 1323 for additional\ndetails. •\nThe flag field contains 6 bits. The ACK bit is used to indicate that the\nvalue carried in the acknowledgment field is valid; that is, the segment\ncontains an acknowledgment for a segment that has been successfully\nreceived. The RST, SYN, and FIN bits are used for connection setup\nand teardown, as we will discuss at the end of this section. The CWR\nand ECE bits are used in explicit congestion notification, as discussed\nin Section 3.7.2. Setting the PSH bit indicates that the receiver should\npass the data to the upper layer immediately. Finally, the URG bit is\nused to indicate that there is data in this segment that the sending-side\nupper-layer entity has marked as “urgent.” The location of the last byte\nof this urgent data is indicated by the 16-bit urgent data pointer field. TCP must inform the receiving-side upper-layer entity when urgent data\nexists and pass it a pointer to the end of the urgent data. (In practice, the\nPSH, URG, and the urgent data pointer are not used. However, we\nmention these fields for completeness.)"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 419,
    "text": "Figure 3.29 ♦TCP segment structure\nOur experience as teachers is that our students sometimes find\ndiscussion of packet formats rather dry and perhaps a bit boring. For a fun\nand fanciful look at TCP header fields, particularly if you love Legos™ as\nwe do, see [Pomeranz 2010]. Sequence Numbers and Acknowledgment Numbers\nTwo of the most important fields in the TCP segment header are the\nsequence number field and the acknowledgment number field. These fields\nare a critical part of TCP’s reliable data transfer service. But before"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 420,
    "text": "discussing how these fields are used to provide reliable data transfer, let us\nfirst explain what exactly TCP puts in these fields. TCP views data as an unstructured, but ordered, stream of bytes. TCP’s\nuse of sequence numbers reflects this view in that sequence numbers are\nover the stream of transmitted bytes and not over the series of transmitted\nsegments. The sequence number for a segment is therefore the byte-\nstream number of the first byte in the segment. Let’s look at an example. Suppose that a process in Host A wants to send a stream of data to a process\nin Host B over a TCP connection. The TCP in Host A will implicitly\nnumber each byte in the data stream. Suppose that the data stream consists\nof a file consisting of 500,000 bytes, that the MSS is 1,000 bytes, and that\nthe first byte of the data stream is numbered 0. As shown in Figure 3.30,\nTCP constructs 500 segments out of the data stream. The first segment gets\nassigned sequence number 0, the second segment gets assigned sequence\nnumber 1,000, the third segment gets assigned sequence number 2,000, and\nso on. Each sequence number is inserted in the sequence number field in the\nheader of the appropriate TCP segment. Figure 3.30 ♦Dividing file data into TCP segments\nNow let’s consider acknowledgment numbers. These are a little trickier\nthan sequence numbers. Recall that TCP is full-duplex, so that Host A may"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 421,
    "text": "be receiving data from Host B while it sends data to Host B (as part of the\nsame TCP connection). Each of the segments that arrive from Host B has a\nsequence number for the data flowing from B to A. The acknowledgment\nnumber that Host A puts in its segment is the sequence number of the next\nbyte Host A is expecting from Host B. It is good to look at a few examples to\nunderstand what is going on here. Suppose that Host A has received all\nbytes numbered 0 through 535 from B and suppose that it is about to send a\nsegment to Host B. Host A is waiting for byte 536 and all the subsequent\nbytes in Host B’s data stream. So Host A puts 536 in the acknowledgment\nnumber field of the segment it sends to B. As another example, suppose that Host A has received one segment\nfrom Host B containing bytes 0 through 535 and another segment\ncontaining bytes 900 through 1,000. For some reason Host A has not yet\nreceived bytes 536 through 899. In this example, Host A is still waiting for\nbyte 536 (and beyond) in order to re-create B’s data stream. Thus, A’s next\nsegment to B will contain 536 in the acknowledgment number field. Because TCP only acknowledges bytes up to the first missing byte in the\nstream, TCP is said to provide cumulative acknowledgments. This last example also brings up an important but subtle issue. Host A\nreceived the third segment (bytes 900 through 1,000) before receiving the\nsecond segment (bytes 536 through 899). Thus, the third segment arrived\nout of order. The subtle issue is: What does a host do when it receives out-\nof-order segments in a TCP connection? Interestingly, the TCP RFCs do not\nimpose any rules here and leave the decision up to the programmers\nimplementing a TCP implementation. There are basically two choices:\neither (1) the receiver immediately discards out-of-order segments (which,\nas we discussed earlier, can simplify receiver design), or (2) the receiver\nkeeps the out-of-order bytes and waits for the missing bytes to fill in the"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 422,
    "text": "gaps. Clearly, the latter choice is more efficient in terms of network\nbandwidth, and is the approach taken in practice. In Figure 3.30, we assumed that the initial sequence number was zero. In truth, both sides of a TCP connection randomly choose an initial\nsequence number. This is done to minimize the possibility that a segment\nthat is still present in the network from an earlier, already-terminated\nconnection between two hosts is mistaken for a valid segment in a later\nconnection between these same two hosts (which also happen to be using\nthe same port numbers as the old connection) [Sunshine 1978]. Telnet: A Case Study for Sequence and Acknowledgment Numbers\nTelnet, defined in RFC 854, is a popular application-layer protocol used for\nremote login. It runs over TCP and is designed to work between any pair of\nhosts. Unlike the bulk data transfer applications discussed in Chapter 2,\nTelnet is an interactive application. We discuss a Telnet example here, as it\nnicely illustrates TCP sequence and acknowledgment numbers. We note that\nmany users now prefer to use the SSH protocol rather than Telnet, since\ndata sent in a Telnet connection (including passwords!) are not encrypted,\nmaking Telnet vulnerable to eavesdropping attacks (as discussed in Section\n8.7). Suppose Host A initiates a Telnet session with Host B. Because Host A\ninitiates the session, it is labeled the client, and Host B is labeled the server. Each character typed by the user (at the client) will be sent to the remote\nhost; the remote host will send back a copy of each character, which will be\ndisplayed on the Telnet user’s screen. This “echo back” is used to ensure\nthat characters seen by the Telnet user have already been received and\nprocessed at the remote site. Each character thus traverses the network"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 423,
    "text": "twice between the time the user hits the key and the time the character is\ndisplayed on the user’s monitor. Now suppose the user types a single letter, ‘C,’ and then grabs a coffee. Let’s examine the TCP segments that are sent between the client and server. As shown in Figure 3.31, we suppose the starting sequence numbers are 42\nand 79 for the client and server, respectively. Recall that the sequence\nnumber of a segment is the sequence number of the first byte in the data\nfield. Thus, the first segment sent from the client will have sequence\nnumber 42; the first segment sent from the server will have sequence\nnumber 79. Recall that the acknowledgment number is the sequence\nnumber of the next byte of data that the host is waiting for. After the TCP\nconnection is established but before any data is sent, the client is waiting for\nbyte 79 and the server is waiting for byte 42."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 424,
    "text": "Figure 3.31 ♦Sequence and acknowledgment numbers for a simple\nTelnet application over TCP\nAs shown in Figure 3.31, three segments are sent. The first segment is\nsent from the client to the server, containing the 1-byte ASCII\nrepresentation of the letter ‘C’ in its data field. This first segment also has\n42 in its sequence number field, as we just described. Also, because the\nclient has not yet received any data from the server, this first segment will\nhave 79 in its acknowledgment number field."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 425,
    "text": "The second segment is sent from the server to the client. It serves a dual\npurpose. First it provides an acknowledgment of the data the server has\nreceived. By putting 43 in the acknowledgment field, the server is telling\nthe client that it has successfully received everything up through byte 42\nand is now waiting for bytes 43 onward. The second purpose of this\nsegment is to echo back the letter ‘C.’ Thus, the second segment has the\nASCII representation of ‘C’ in its data field. This second segment has the\nsequence number 79, the initial sequence number of the server-to-client\ndata flow of this TCP connection, as this is the very first byte of data that\nthe server is sending. Note that the acknowledgment for client-to-server\ndata is carried in a segment carrying server-to-client data; this\nacknowledgment is said to be piggybacked on the server-to-client data\nsegment. The third segment is sent from the client to the server. Its sole purpose\nis to acknowledge the data it has received from the server. (Recall that the\nsecond segment contained data—the letter ‘C’—from the server to the\nclient.) This segment has an empty data field (that is, the acknowledgment\nis not being piggybacked with any client-to-server data). The segment has\n80 in the acknowledgment number field because the client has received the\nstream of bytes up through byte sequence number 79 and it is now waiting\nfor bytes 80 onward. You might think it odd that this segment also has a\nsequence number since the segment contains no data. But because TCP has\na sequence number field, the segment needs to have some sequence number. 3.5.3 Round-Trip Time Estimation and Timeout\nTCP, like our rdt protocol in Section 3.4, uses a timeout/retransmit\nmechanism to recover from lost segments. Although this is conceptually"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 426,
    "text": "simple, many subtle issues arise when we implement a timeout/retransmit\nmechanism in an actual protocol such as TCP. Perhaps the most obvious\nquestion is the length of the timeout intervals. Clearly, the timeout should\nbe larger than the connection’s round-trip time (RTT), that is, the time from\nwhen a segment is sent until it is acknowledged. Otherwise, unnecessary\nretransmissions would be sent. But how much larger? How should the RTT\nbe estimated in the first place? Should a timer be associated with each and\nevery unacknowledged segment? So many questions! Our discussion in this\nsection is based on the TCP work in [Jacobson 1988] and the current IETF\nrecommendations for managing TCP timers [RFC 6298]. Estimating the Round-Trip Time\nLet’s begin our study of TCP timer management by considering how TCP\nestimates the round-trip time between sender and receiver. This is\naccomplished as follows. The sample RTT, denoted SampleRTT, for a\nsegment is the amount of time between when the segment is sent (that is,\npassed to IP) and when an acknowledgment for the segment is received. Instead of measuring a SampleRTT for every transmitted segment, most\nTCP implementations take only one SampleRTT measurement at a time. That is, at any point in time, the SampleRTT is being estimated for only\none of the transmitted but currently unacknowledged segments, leading to a\nnew value of SampleRTT approximately once every RTT. Also, TCP\nnever computes a SampleRTT for a segment that has been retransmitted; it\nonly measures SampleRTT for segments that have been transmitted once\n[Karn 1987]. (A problem at the end of the chapter asks you to consider\nwhy.)"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 427,
    "text": "Obviously, the SampleRTT values will fluctuate from segment to\nsegment due to congestion in the routers and to the varying load on the end\nsystems. Because of this fluctuation, any given SampleRTT value may be\natypical. In order to estimate a typical RTT, it is therefore natural to take\nsome sort of average of the SampleRTT values. TCP maintains an average,\ncalled EstimatedRTT, of the SampleRTT values. Upon obtaining a new\nSampleRTT, TCP updates EstimatedRTT according to the following\nformula:\nEstimatedRTT = (1 – α) · EstimatedRTT + α ·\nSampleRTT\nThe formula above is written in the form of a programming-language\nstatement—the new value of EstimatedRTT is a weighted combination of\nthe previous value of EstimatedRTT and the new value for SampleRTT. The recommended value of α is α = 0.125 (that is, 1/8) [RFC 6298], in\nwhich case the formula above becomes:\nEstimatedRTT = 0.875 · EstimatedRTT + 0.125 ·\nSampleRTT\nNote that EstimatedRTT is a weighted average of the SampleRTT\nvalues. As discussed in a homework problem at the end of this chapter, this\nweighted average puts more weight on recent samples than on old samples. This is natural, as the more recent samples better reflect the current\ncongestion in the network. In statistics, such an average is called an\nexponential weighted moving average (EWMA). The word “exponential”\nappears in EWMA because the weight of a given SampleRTT decays"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 428,
    "text": "exponentially fast as the updates proceed. In the homework problems, you\nwill be asked to derive the exponential term in EstimatedRTT. Figure 3.32 shows the SampleRTT values and EstimatedRTT for a\nvalue of α = 1/8 for a TCP connection between gaia.cs.umass.edu\n(in Amherst, Massachusetts) to fantasia.eurecom.fr (in the south of\nFrance). Clearly, the variations in the SampleRTT are smoothed out in the\ncomputation of the EstimatedRTT. Figure 3.32 ♦RTT samples and RTT estimates\nIn addition to having an estimate of the RTT, it is also valuable to have\na measure of the variability of the RTT. [RFC 6298] defines the RTT\nvariation, DevRTT, as an estimate of how much SampleRTT typically\ndeviates from EstimatedRTT:"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 429,
    "text": "DevRTT = (1 – β) · DevRTT + β · | SampleRTT –\nEstimatedRTT |\nNote that DevRTT is an EWMA of the difference between\nSampleRTT and EstimatedRTT. If the SampleRTT values have little\nfluctuation, then DevRTT will be small; on the other hand, if there is a lot\nof fluctuation, DevRTT will be large. The recommended value of β is 0.25. Setting and Managing the Retransmission Timeout Interval\nGiven values of EstimatedRTT and DevRTT, what value should be used\nfor TCP’s timeout interval? Clearly, the interval should be greater than or\nequal to EstimatedRTT, or unnecessary retransmissions would be sent. But the timeout interval should not be too much larger than\nEstimatedRTT; otherwise, when a segment is lost, TCP would not\nquickly retransmit the segment, leading to large data transfer delays. It is\ntherefore desirable to set the timeout equal to the EstimatedRTT plus\nsome margin. The margin should be large when there is a lot of fluctuation\nin the SampleRTT values; it should be small when there is little\nfluctuation. The value of DevRTT should thus come into play here. All of\nthese considerations are taken into account in TCP’s method for\ndetermining the retransmission timeout interval:\nTimeoutInterval = EstimatedRTT + 4 · DevRTT\nPRINCIPLES IN\nPRACTICE"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 430,
    "text": "TCP provides reliable data transfer by using positive acknowledgments and timers in much\nthe same way that we studied in Section 3.4. TCP acknowledges data that has been\nreceived correctly, and it then retransmits segments when segments or their corresponding\nacknowledgments are thought to be lost or corrupted. Certain versions of TCP also have an\nimplicit NAK mechanism—with TCP’s fast retransmit mechanism, the receipt of three\nduplicate ACKs for a given segment serves as an implicit NAK for the following segment,\ntriggering retransmission of that segment before timeout. TCP uses sequences of numbers\nto allow the receiver to identify lost or duplicate segments. Just as in the case of our reliable\ndata transfer protocol, rdt3.0, TCP cannot itself tell for certain if a segment, or its ACK, is\nlost, corrupted, or overly delayed. At the sender, TCP’s response will be the same:\nretransmit the segment in question. TCP also uses pipelining, allowing the sender to have multiple transmitted but yet-to-be-\nacknowledged segments outstanding at any given time. We saw earlier that pipelining can\ngreatly improve a session’s throughput when the ratio of the segment size to round-trip\ndelay is small. The specific number of outstanding, unacknowledged segments that a\nsender can have is determined by TCP’s flow-control and congestion-control mechanisms. TCP flow control is discussed at the end of this section; TCP congestion control is\ndiscussed in Section 3.7. For the time being, we must simply be aware that the TCP sender\nuses pipelining. An initial TimeoutInterval value of 1 second is recommended\n[RFC \n6298]. Also, \nwhen \na \ntimeout \noccurs, \nthe \nvalue \nof\nTimeoutInterval is doubled to avoid a premature timeout occurring\nfor a subsequent segment that will soon be acknowledged. However, as\nsoon as a segment is received and EstimatedRTT is updated, the\nTimeoutInterval is again computed using the formula above."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 431,
    "text": "3.5.4 Reliable Data Transfer\nRecall that the Internet’s network-layer service (IP service) is unreliable. IP\ndoes not guarantee datagram delivery, does not guarantee in-order delivery\nof datagrams, and does not guarantee the integrity of the data in the\ndatagrams. With IP service, datagrams can overflow router buffers and\nnever reach their destination, datagrams can arrive out of order, and bits in\nthe datagram can get corrupted (flipped from 0 to 1 and vice versa). Because transport-layer segments are carried across the network by IP\ndatagrams, transport-layer segments can suffer from these problems as well. TCP creates a reliable data transfer service on top of IP’s unreliable\nbest-effort service. TCP’s reliable data transfer service ensures that the data\nstream that a process reads out of its TCP receive buffer is uncorrupted,\nwithout gaps, without duplication, and in sequence; that is, the byte stream\nis exactly the same byte stream that was sent by the end system on the other\nside of the connection. How TCP provides a reliable data transfer involves\nmany of the principles that we studied in Section 3.4. In our earlier development of reliable data transfer techniques, it was\nconceptually easiest to assume that an individual timer is associated with\neach transmitted but not yet acknowledged segment. While this is great in\ntheory, timer management can require considerable overhead. Thus, the\nrecommended TCP timer management procedures [RFC 6298] use only a\nsingle retransmission timer, even if there are multiple transmitted but not\nyet acknowledged segments. The TCP protocol described in this section\nfollows this single-timer recommendation. We will discuss how TCP provides reliable data transfer in two\nincremental steps. We first present a highly simplified description of a TCP\nsender that uses only timeouts to recover from lost segments; we then\npresent a more complete description that uses duplicate acknowledgments"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 432,
    "text": "in addition to timeouts. In the ensuing discussion, we suppose that data is\nbeing sent in only one direction, from Host A to Host B, and that Host A is\nsending a large file. Figure 3.33 presents a highly simplified description of a TCP sender. We see that there are three major events related to data transmission and\nretransmission in the TCP sender: data received from application above;\ntimer timeout; and ACK receipt. Upon the occurrence of the first major\nevent, TCP receives data from the application, encapsulates the data in a\nsegment, and passes the segment to IP. Note that each segment includes a\nsequence number that is the byte-stream number of the first data byte in the\nsegment, as described in Section 3.5.2. Also note that if the timer is already\nnot running for some other segment, TCP starts the timer when the segment\nis passed to IP. (It is helpful to think of the timer as being associated with\nthe oldest unacknowledged segment.) The expiration interval for this timer\nis the TimeoutInterval, which is calculated from EstimatedRTT\nand DevRTT, as described in Section 3.5.3."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 433,
    "text": "Figure 3.33 ♦Simplified TCP sender\nThe second major event is the timeout. TCP responds to the timeout\nevent by retransmitting the segment that caused the timeout. TCP then\nrestarts the timer. The third major event that must be handled by the TCP sender is the\narrival of an acknowledgment segment (ACK) from the receiver (more\nspecifically, a segment containing a valid ACK field value). On the\noccurrence of this event, TCP compares the ACK value y with its variable\nSendBase. The TCP state variable SendBase is the sequence number of\nthe oldest unacknowledged byte. (Thus SendBase–1 is the sequence\nnumber of the last byte that is known to have been received correctly and in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 434,
    "text": "order at the receiver.) As indicated earlier, TCP uses cumulative\nacknowledgments, so that y acknowledges the receipt of all bytes before\nbyte number y. If y > SendBase, then the ACK is acknowledging one\nor more previously unacknowledged segments. Thus the sender updates its\nSendBase variable; it also restarts the timer if there currently are any not-\nyet-acknowledged segments. A Few Interesting Scenarios\nWe have just described a highly simplified version of how TCP provides\nreliable data transfer. But even this highly simplified version has many\nsubtleties. To get a good feeling for how this protocol works, let’s now walk\nthrough a few simple scenarios. Figure 3.34 depicts the first scenario, in\nwhich Host A sends one segment to Host B. Suppose that this segment has\nsequence number 92 and contains 8 bytes of data. After sending this\nsegment, Host A waits for a segment from B with acknowledgment number\n100. Although the segment from A is received at B, the acknowledgment\nfrom B to A gets lost. In this case, the timeout event occurs, and Host A\nretransmits the same segment. Of course, when Host B receives the\nretransmission, it observes from the sequence number that the segment\ncontains data that has already been received. Thus, TCP in Host B will\ndiscard the bytes in the retransmitted segment."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 435,
    "text": "Figure 3.34 ♦Retransmission due to a lost acknowledgment\nIn a second scenario, shown in Figure 3.35, Host A sends two segments\nback to back. The first segment has sequence number 92 and 8 bytes of\ndata, and the second segment has sequence number 100 and 20 bytes of\ndata. Suppose that both segments arrive intact at B, and B sends two\nseparate acknowledgments for each of these segments. The first of these\nacknowledgments has acknowledgment number 100; the second has\nacknowledgment number 120. Suppose now that neither of the\nacknowledgments arrives at Host A before the timeout. When the timeout\nevent occurs, Host A resends the first segment with sequence number 92"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 436,
    "text": "and restarts the timer. As long as the ACK for the second segment arrives\nbefore the new timeout, the second segment will not be retransmitted. Figure 3.35 ♦Segment 100 not retransmitted\nIn a third and final scenario, suppose Host A sends the two segments,\nexactly as in the second example. The acknowledgment of the first segment\nis lost in the network, but just before the timeout event, Host A receives an\nacknowledgment with acknowledgment number 120. Host A therefore"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 437,
    "text": "knows that Host B has received everything up through byte 119; so Host A\ndoes not resend either of the two segments. This scenario is illustrated in\nFigure 3.36. Figure 3.36 ♦A cumulative acknowledgment avoids retransmission\nof the first segment\nDoubling the Timeout Interval"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 438,
    "text": "We now discuss a few modifications that most TCP implementations\nemploy. The first concerns the length of the timeout interval after a timer\nexpiration. In this modification, whenever the timeout event occurs, TCP\nretransmits the not-yet-acknowledged segment with the smallest sequence\nnumber, as described above. But each time TCP retransmits, it sets the next\ntimeout interval to twice the previous value, rather than deriving it from the\nlast EstimatedRTT and DevRTT (as described in Section 3.5.3). For\nexample, suppose TimeoutInterval associated with the oldest not yet\nacknowledged segment is .75 sec when the timer first expires. TCP will\nthen retransmit this segment and set the new expiration time to 1.5 sec. If\nthe timer expires again 1.5 sec later, TCP will again retransmit this segment,\nnow setting the expiration time to 3.0 sec. Thus, the intervals grow\nexponentially after each retransmission. However, whenever the timer is\nstarted after either of the two other events (that is, data received from\napplication above, and ACK received), the TimeoutInterval is derived\nfrom the most recent values of EstimatedRTT and DevRTT. This modification provides a limited form of congestion control. (More\ncomprehensive forms of TCP congestion control will be studied in Section\n3.7.) The timer expiration is most likely caused by congestion in the\nnetwork, that is, too many packets arriving at one (or more) router queues in\nthe path between the source and destination, causing packets to be dropped\nand/or long queuing delays. In times of congestion, if the sources continue\nto retransmit packets persistently, the congestion may get worse. Instead,\nTCP acts more politely, with each sender retransmitting after longer and\nlonger intervals. We will see that a similar idea is used by Ethernet when we\nstudy CSMA/CD in Chapter 6. Fast Retransmit"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 439,
    "text": "One of the problems with timeout-triggered retransmissions is that the\ntimeout period can be relatively long. When a segment is lost, this long\ntimeout period forces the sender to delay resending the lost packet, thereby\nincreasing the end-to-end delay. Fortunately, the sender can often detect\npacket loss well before the timeout event occurs by noting so-called\nduplicate ACKs. A duplicate ACK is an ACK that reacknowledges a\nsegment for which the sender has already received an earlier\nacknowledgment. To understand the sender’s response to a duplicate ACK,\nwe must look at why the receiver sends a duplicate ACK in the first place. Table 3.2 summarizes the TCP receiver’s ACK generation policy [RFC\n5681]. When a TCP receiver receives a segment with a sequence number\nthat is larger than the next, expected, in-order sequence number, it detects a\ngap in the data stream—that is, a missing segment. This gap could be the\nresult of lost or reordered segments within the network. Since TCP does not\nuse negative acknowledgments, the receiver cannot send an explicit\nnegative acknowledgment back to the sender. Instead, it simply\nreacknowledges (that is, generates a duplicate ACK for) the last in-order\nbyte of data it has received. (Note that Table 3.2 allows for the case that the\nreceiver does not discard out-of-order segments.) Table 3.2 ♦ TCP ACK Generation Recommendation [RFC 5681]\nBecause a sender often sends a large number of segments back to back,\nif one segment is lost, there will likely be many back-to-back duplicate\nACKs. If the TCP sender receives three duplicate ACKs for the same data,\nit takes this as an indication that the segment following the segment that has\nbeen ACKed three times has been lost. (In the homework problems, we\nconsider the question of why the sender waits for three duplicate ACKs,\nrather than just a single duplicate ACK.) In the case that three duplicate"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 440,
    "text": "ACKs are received, the TCP sender performs a fast retransmit [RFC\n5681], retransmitting the missing segment before that segment’s timer\nexpires. This is shown in Figure 3.37, where the second segment is lost,\nthen retransmitted before its timer expires. For TCP with fast retransmit, the\nfollowing code snippet replaces the ACK received event in Figure 3.33:\nevent: ACK received, with ACK field value of y\n            if (y > SendBase) {\n            SendBase=y\n            if (there are currently any not yet\n                        acknowledged segments)\n               start timer\n               }\n            else {/* a duplicate ACK for already\nACKed\n                   segment */\n               increment number of duplicate ACKs\n                   received for y\n               if (number of duplicate ACKS\nreceived\n                   for y==3)\n                   /* TCP fast retransmit */\n                   resend segment with sequence\nnumber y\n               }\n           break;"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 441,
    "text": "Figure 3.37 ♦Fast retransmit: retransmitting the missing segment\nbefore the segment’s timer expires"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 442,
    "text": "We \nnoted \nearlier \nthat \nmany \nsubtle \nissues \narise \nwhen \na\ntimeout/retransmit mechanism is implemented in an actual protocol such as\nTCP. The procedures above, which have evolved as a result of more than 30\nyears of experience with TCP timers, should convince you that this is\nindeed the case! Go-Back-N or Selective Repeat? Let us close our study of TCP’s error-recovery mechanism by considering\nthe following question: Is TCP a GBN or an SR protocol? Recall that TCP\nacknowledgments are cumulative and correctly received but out-of-order\nsegments are not individually ACKed by the receiver. Consequently, as\nshown in Figure 3.33 (see also Figure 3.19), the TCP sender need only\nmaintain \nthe \nsmallest \nsequence \nnumber \nof \na \ntransmitted \nbut\nunacknowledged byte (SendBase) and the sequence number of the next\nbyte to be sent (NextSeqNum). In this sense, TCP looks a lot like a GBN-\nstyle protocol. But there are some striking differences between TCP and\nGo-Back-N. Many TCP implementations will buffer correctly received but\nout-of-order segments [Stevens 1994]. Consider also what happens when\nthe sender sends a sequence of segments 1, 2, . . . , N, and all of the\nsegments arrive in order without error at the receiver. Further suppose that\nthe acknowledgment for packet n < N gets lost, but the remaining N − 1\nacknowledgments arrive at the sender before their respective timeouts. In\nthis example, GBN would retransmit not only packet n, but also all of the\nsubsequent packets n + 1, n + 2, . . . , N. TCP, on the other hand, would\nretransmit at most one segment, namely, segment n. Moreover, TCP would\nnot even retransmit segment n if the acknowledgment for segment n + 1\narrived before the timeout for segment n."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 443,
    "text": "A \nproposed \nmodification \nto \nTCP, \nthe \nso-called \nselective\nacknowledgment [RFC 2018], allows a TCP receiver to acknowledge out-\nof-order segments selectively rather than just cumulatively acknowledging\nthe last correctly received, in-order segment. When combined with selective\nretransmission—skipping the retransmission of segments that have already\nbeen selectively acknowledged by the receiver—TCP looks a lot like our\ngeneric SR protocol. Thus, TCP’s error-recovery mechanism is probably\nbest categorized as a hybrid of GBN and SR protocols. 3.5.5 Flow Control\nRecall that the hosts on each side of a TCP connection set aside a receive\nbuffer for the connection. When the TCP connection receives bytes that are\ncorrect and in sequence, it places the data in the receive buffer. The\nassociated application process will read data from this buffer, but not\nnecessarily at the instant the data arrives. Indeed, the receiving application\nmay be busy with some other task and may not even attempt to read the\ndata until long after it has arrived. If the application is relatively slow at\nreading the data, the sender can very easily overflow the connection’s\nreceive buffer by sending too much data too quickly. TCP provides a flow-control service to its applications to eliminate the\npossibility of the sender overflowing the receiver’s buffer. Flow control is\nthus a speed-matching service—matching the rate at which the sender is\nsending against the rate at which the receiving application is reading. As\nnoted earlier, a TCP sender can also be throttled due to congestion within\nthe IP network; this form of sender control is referred to as congestion\ncontrol, a topic we will explore in detail in Sections 3.6 and 3.7. Even\nthough the actions taken by flow and congestion control are similar (the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 444,
    "text": "throttling of the sender), they are obviously taken for very different reasons. Unfortunately, many authors use the terms interchangeably, and the savvy\nreader would be wise to distinguish between them. Let’s now discuss how\nTCP provides its flow-control service. In order to see the forest for the\ntrees, we suppose throughout this section that the TCP implementation is\nsuch that the TCP receiver discards out-of-order segments. TCP provides flow control by having the sender maintain a variable\ncalled the receive window. Informally, the receive window is used to give\nthe sender an idea of how much free buffer space is available at the\nreceiver. Because TCP is full-duplex, the sender at each side of the\nconnection maintains a distinct receive window. Let’s investigate the\nreceive window in the context of a file transfer. Suppose that Host A is\nsending a large file to Host B over a TCP connection. Host B allocates a\nreceive buffer to this connection; denote its size by RcvBuffer. From\ntime to time, the application process in Host B reads from the buffer. Define\nthe following variables:\n•\nLastByteRead: the number of the last byte in the data stream read\nfrom the buffer by the application process in B\n•\nLastByteRcvd: the number of the last byte in the data stream that\nhas arrived from the network and has been placed in the receive buffer\nat B\nBecause TCP is not permitted to overflow the allocated buffer, we must\nhave\nLastByteRcvd – LastByteRead ≤ RcvBuffer"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 445,
    "text": "The receive window, denoted rwnd is set to the amount of spare room in\nthe buffer:\nrwnd = RcvBuffer – [LastByteRcvd – LastByteRead]\nBecause the spare room changes with time, rwnd is dynamic. The variable\nrwnd is illustrated in Figure 3.38. Figure 3.38 ♦The receive window (rwnd) and the receive buffer\n(RcvBuffer)\nHow does the connection use the variable rwnd to provide the flow-\ncontrol service? Host B tells Host A how much spare room it has in the\nconnection buffer by placing its current value of rwnd in the receive\nwindow field of every segment it sends to A. Initially, Host B sets rwnd =\nRcvBuffer. Note that to pull this off, Host B must keep track of several\nconnection-specific variables."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 446,
    "text": "Host A in turn keeps track of two variables, LastByteSent and\nLastByteAcked, which have obvious meanings. Note that the difference\nbetween these two variables, LastByteSent – LastByteAcked, is\nthe amount of unacknowledged data that A has sent into the connection. By\nkeeping the amount of unacknowledged data less than the value of rwnd,\nHost A is assured that it is not overflowing the receive buffer at Host B. Thus, Host A makes sure throughout the connection’s life that\nLastByteSent – LastByteAcked ≤ rwnd\nThere is one minor technical problem with this scheme. To see this,\nsuppose Host B’s receive buffer becomes full so that rwnd = 0. After\nadvertising rwnd = 0 to Host A, also suppose that B has nothing to send to\nA. Now consider what happens. As the application process at B empties the\nbuffer, TCP does not send new segments with new rwnd values to Host A;\nindeed, TCP sends a segment to Host A only if it has data to send or if it has\nan acknowledgment to send. Therefore, Host A is never informed that some\nspace has opened up in Host B’s receive buffer—Host A is blocked and can\ntransmit no more data! To solve this problem, the TCP specification\nrequires Host A to continue to send segments with one data byte when B’s\nreceive window is zero. These segments will be acknowledged by the\nreceiver. Eventually the buffer will begin to empty and the\nacknowledgments will contain a nonzero rwnd value. The online site at for this book provides an interactive animation that\nillustrates the operation of the TCP receive window. Having described TCP’s flow-control service, we briefly mention here\nthat UDP does not provide flow control and consequently, segments may be\nlost at the receiver due to buffer overflow. For example, consider sending a"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 447,
    "text": "series of UDP segments from a process on Host A to a process on Host B. For a typical UDP implementation, UDP will append the segments in a\nfinite-sized buffer that “precedes” the corresponding socket (that is, the\ndoor to the process). The process reads one entire segment at a time from\nthe buffer. If the process does not read the segments fast enough from the\nbuffer, the buffer will overflow and segments will get dropped. 3.5.6 TCP Connection Management\nIn this subsection, we take a closer look at how a TCP connection is\nestablished and torn down. Although this topic may not seem particularly\nthrilling, it is important because TCP connection establishment can\nsignificantly add to perceived delays (for example, when surfing the Web). Furthermore, many of the most common network attacks—including the\nincredibly popular SYN flood attack (see sidebar on the SYN flood attack)\n—exploit vulnerabilities in TCP connection management. Let’s first take a\nlook at how a TCP connection is established. Suppose a process running in\none host (client) wants to initiate a connection with another process in\nanother host (server). The client application process first informs the client\nTCP that it wants to establish a connection to a process in the server. The\nTCP in the client then proceeds to establish a TCP connection with the TCP\nin the server in the following manner:\n•\nStep 1. The client-side TCP first sends a special TCP segment to the\nserver-side TCP. This special segment contains no application-layer\ndata. But one of the flag bits in the segment’s header (see Figure 3.29),\nthe SYN bit, is set to 1. For this reason, this special segment is referred\nto as a SYN segment. In addition, the client randomly chooses an initial\nsequence number (client_isn) and puts this number in the sequence"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 448,
    "text": "number field of the initial TCP SYN segment. This segment is\nencapsulated within an IP datagram and sent to the server. There has\nbeen considerable interest in properly randomizing the choice of the\nclient_isn in order to avoid certain security attacks [CERT 2001–\n09; RFC 4987]. •\nStep 2. Once the IP datagram containing the TCP SYN segment arrives\nat the server host (assuming it does arrive! ), the server extracts the TCP\nSYN segment from the datagram, allocates the TCP buffers and\nvariables to the connection, and sends a connection-granted segment to\nthe client TCP. (We’ll see in Chapter 8 that the allocation of these\nbuffers and variables before completing the third step of the three-way\nhandshake makes TCP vulnerable to a denial-of-service attack known as\nSYN flooding.) This connection-granted segment also contains no\napplication-layer data. However, it does contain three important pieces\nof information in the segment header. First, the SYN bit is set to 1. Second, the acknowledgment field of the TCP segment header is set to\nclient_isn+1. Finally, the server chooses its own initial sequence\nnumber (server_isn) and puts this value in the sequence number\nfield of the TCP segment header. This connection-granted segment is\nsaying, in effect, “I received your SYN packet to start a connection with\nyour initial sequence number, client_isn. I agree to establish this\nconnection. My own initial sequence number is server_isn.” The\nconnection-granted segment is referred to as a SYNACK segment. •\nStep 3. Upon receiving the SYNACK segment, the client also allocates\nbuffers and variables to the connection. The client host then sends the\nserver yet another segment; this last segment acknowledges the server’s\nconnection-granted segment (the client does so by putting the value\nserver_isn+1 in the acknowledgment field of the TCP segment"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 449,
    "text": "header). The SYN bit is set to zero, since the connection is established. This third stage of the three-way handshake may carry client-to-server\ndata in the segment payload. Once these three steps have been completed, the client and server hosts\ncan send segments containing data to each other. In each of these future\nsegments, the SYN bit will be set to zero. Note that in order to establish the\nconnection, three packets are sent between the two hosts, as illustrated in\nFigure 3.39. For this reason, this connection-establishment procedure is\noften referred to as a three-way handshake. Several aspects of the TCP\nthree-way handshake are explored in the homework problems (Why are\ninitial sequence numbers needed? Why is a three-way handshake, as\nopposed to a two-way handshake, needed?). It’s interesting to note that a\nrock climber and a belayer (who is stationed below the rock climber and\nwhose job it is to handle the climber’s safety rope) use a three-way-\nhandshake communication protocol that is identical to TCP’s to ensure that\nboth sides are ready before the climber begins ascent."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 450,
    "text": "Figure 3.39 ♦TCP three-way handshake: segment exchange\nAll good things must come to an end, and the same is true with a TCP\nconnection. Either of the two processes participating in a TCP connection\ncan end the connection. When a connection ends, the “resources” (that is,\nthe buffers and variables) in the hosts are deallocated. As an example,\nsuppose the client decides to close the connection, as shown in Figure 3.40. The client application process issues a close command. This causes the\nclient TCP to send a special TCP segment to the server process. This special\nsegment has a flag bit in the segment’s header, the FIN bit (see Figure\n3.29), set to 1. When the server receives this segment, it sends the client an\nacknowledgment segment in return. The server then sends its own"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 451,
    "text": "shutdown segment, which has the FIN bit set to 1. Finally, the client\nacknowledges the server’s shutdown segment. At this point, all the\nresources in the two hosts are now deallocated. Figure 3.40 ♦Closing a TCP connection\nDuring the life of a TCP connection, the TCP protocol running in each\nhost makes transitions through various TCP states. Figure 3.41 illustrates a\ntypical sequence of TCP states that are visited by the client TCP. The client"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 452,
    "text": "TCP begins in the CLOSED state. The application on the client side\ninitiates a new TCP connection (by creating a Socket object in our Python\nexamples from Chapter 2). This causes TCP in the client to send a SYN\nsegment to TCP in the server. After having sent the SYN segment, the client\nTCP enters the SYN_SENT state. While in the SYN_SENT state, the client\nTCP waits for a segment from the server TCP that includes an\nacknowledgment for the client’s previous segment and has the SYN bit set\nto 1. Having received such a segment, the client TCP enters the\nESTABLISHED state. While in the ESTABLISHED state, the TCP client\ncan send and receive TCP segments containing payload (that is, application-\ngenerated) data."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 453,
    "text": "Figure 3.41 ♦A typical sequence of TCP states visited by a client\nTCP\nSuppose that the client application decides it wants to close the\nconnection. (Note that the server could also choose to close the connection.) This causes the client TCP to send a TCP segment with the FIN bit set to 1\nand to enter the FIN_WAIT_1 state. While in the FIN_WAIT_1 state, the\nclient TCP waits for a TCP segment from the server with an\nacknowledgment. When it receives this segment, the client TCP enters the\nFIN_WAIT_2 state. While in the FIN_WAIT_2 state, the client waits for\nanother segment from the server with the FIN bit set to 1; after receiving\nthis segment, the client TCP acknowledges the server’s segment and enters\nthe TIME_WAIT state. The TIME_WAIT state lets the TCP client resend\nthe final acknowledgment in case the ACK is lost. The time spent in the\nTIME_WAIT state is implementation-dependent, but typical values are 30\nseconds, 1 minute, and 2 minutes. After the wait, the connection formally\ncloses and all resources on the client side (including port numbers) are\nreleased. Figure 3.42 illustrates the series of states typically visited by the server-\nside TCP, assuming the client begins connection teardown. The transitions\nare self-explanatory. In these two state-transition diagrams, we have only\nshown how a TCP connection is normally established and shut down. We\nhave not described what happens in certain pathological scenarios, for\nexample, when both sides of a connection want to initiate or shut down at\nthe same time. If you are interested in learning about this and other\nadvanced issues concerning TCP, you are encouraged to see Stevens’\ncomprehensive book [Stevens 1994]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 454,
    "text": "Figure 3.42 ♦A typical sequence of TCP states visited by a server-\nside TCP\nOur discussion above has assumed that both the client and server are\nprepared to communicate, that is, that the server is listening on the port to\nwhich the client sends its SYN segment. Let’s consider what happens when\na host receives a TCP segment whose port numbers or source IP address do\nnot match with any of the ongoing sockets in the host. For example,\nsuppose a host receives a TCP SYN packet with destination port 80, but the\nhost is not accepting connections on port 80 (that is, it is not running a Web\nserver on port 80). Then the host will send a special reset segment to the\nsource. This TCP segment has the RST flag bit (see Section 3.5.2) set to 1. Thus, when a host sends a reset segment, it is telling the source “I don’t\nhave a socket for that segment. Please do not resend the segment.” When a"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 455,
    "text": "host receives a UDP packet whose destination port number doesn’t match\nwith an ongoing UDP socket, the host sends a special ICMP datagram, as\ndiscussed in Chapter 5. Now that we have a good understanding of TCP connection\nmanagement, let’s revisit the nmap port-scanning tool and examine more\nclosely how it works. To explore a specific TCP port, say port 6789, on a\ntarget host, nmap will send a TCP SYN segment with destination port 6789\nto that host. There are three possible outcomes:\n•\nThe source host receives a TCP SYNACK segment from the target host. Since this means that an application is running with TCP port 6789 on\nthe target post, nmap returns “open.”\nFOCUS ON\nSECURITY\nTHE SYN FLOOD ATTACK\nWe’ve seen in our discussion of TCP’s three-way handshake that a server allocates\nand initializes connection variables and buffers in response to a received SYN. The\nserver then sends a SYNACK in response, and awaits an ACK segment from the client. If the client does not send an ACK to complete the third step of this 3-way handshake,\neventually (often after a minute or more) the server will terminate the half-open\nconnection and reclaim the allocated resources. This TCP connection management protocol sets the stage for a classic Denial of\nService (DoS) attack known as the SYN flood attack. In this attack, the attacker(s)\nsend a large number of TCP SYN segments, without completing the third handshake\nstep. With this deluge of SYN segments, the server’s connection resources become\nexhausted as they are allocated (but never used!) for half-open connections; legitimate"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 456,
    "text": "clients are then denied service. Such SYN flooding attacks were among the first\ndocumented DoS attacks [CERT SYN 1996]. Fortunately, an effective defense known\nas SYN cookies [RFC 4987] are now deployed in most major operating systems. SYN\ncookies work as follows:\n•\nWhen the server receives a SYN segment, it does not know if the segment is\ncoming from a legitimate user or is part of a SYN flood attack. So, instead of\ncreating a half-open TCP connection for this SYN, the server creates an initial TCP\nsequence number that is a complicated function (hash function) of source and\ndestination IP addresses and port numbers of the SYN segment, as well as a\nsecret number only known to the server. This carefully crafted initial sequence\nnumber is the so-called “cookie.” The server then sends the client a SYNACK\npacket with this special initial sequence number. Importantly, the server does not\nremember the cookie or any other state information corresponding to the SYN. •\nA legitimate client will return an ACK segment. When the server receives this ACK,\nit must verify that the ACK corresponds to some SYN sent earlier. But how is this\ndone if the server maintains no memory about SYN segments? As you may have\nguessed, it is done with the cookie. Recall that for a legitimate ACK, the value in the\nacknowledgment field is equal to the initial sequence number in the SYNACK (the\ncookie value in this case) plus one (see Figure 3.39). The server can then run the\nsame hash function using the source and destination IP address and port numbers\nin the SYNACK (which are the same as in the original SYN) and the secret number. If the result of the function plus one is the same as the acknowledgment (cookie)\nvalue in the client’s SYNACK, the server concludes that the ACK corresponds to an\nearlier SYN segment and is hence valid. The server then creates a fully open\nconnection along with a socket."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 457,
    "text": "•\nOn the other hand, if the client does not return an ACK segment, then the original\nSYN has done no harm at the server, since the server hasn’t yet allocated any\nresources in response to the original bogus SYN. •\nThe source host receives a TCP RST segment from the target host. This\nmeans that the SYN segment reached the target host, but the target host\nis not running an application with TCP port 6789. But the attacker at\nleast knows that the segments destined to the host at port 6789 are not\nblocked by any firewall on the path between source and target hosts. (Firewalls are discussed in Chapter 8.) •\nThe source receives nothing. This likely means that the SYN segment\nwas blocked by an intervening firewall and never reached the target\nhost. Nmap is a powerful tool that can “case the joint” not only for open TCP\nports, but also for open UDP ports, for firewalls and their configurations,\nand even for the versions of applications and operating systems. Most of\nthis is done by manipulating TCP connection-management segments. You\ncan download nmap from www.nmap.org. This completes our introduction to error control and flow control in\nTCP. In Section 3.7, we’ll return to TCP and look at TCP congestion control\nin some depth. Before doing so, however, we first step back and examine\ncongestion-control issues in a broader context."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 458,
    "text": "3.6 Principles of Congestion Control\nIn the previous sections, we examined both the general principles and\nspecific TCP mechanisms used to provide for a reliable data transfer service\nin the face of packet loss. We mentioned earlier that, in practice, such loss\ntypically results from the overflowing of router buffers as the network\nbecomes congested. Packet retransmission thus treats a symptom of\nnetwork congestion (the loss of a specific transport-layer segment) but does\nnot treat the cause of network congestion—too many sources attempting to\nsend data at too high a rate. To treat the cause of network congestion,\nmechanisms are needed to throttle senders in the face of network\ncongestion. In this section, we consider the problem of congestion control in a\ngeneral context, seeking to understand why congestion is a bad thing, how\nnetwork congestion is manifested in the performance received by upper-\nlayer applications, and various approaches that can be taken to avoid, or\nreact to, network congestion. This more general study of congestion control\nis appropriate since, as with reliable data transfer, it is high on our “top-ten”\nlist of fundamentally important problems in networking. The following\nsection contains a detailed study of TCP’s congestion-control algorithm. 3.6.1 The Causes and the Costs of Congestion\nLet’s begin our general study of congestion control by examining three\nincreasingly complex scenarios in which congestion occurs. In each case,\nwe’ll look at why congestion occurs in the first place and at the cost of\ncongestion (in terms of resources not fully utilized and poor performance"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 459,
    "text": "received by the end systems). We’ll not (yet) focus on how to react to, or\navoid, congestion but rather focus on the simpler issue of understanding\nwhat happens as hosts increase their transmission rate and the network\nbecomes congested. Scenario 1: Two Senders, a Router with Infinite Buffers\nWe begin by considering perhaps the simplest congestion scenario possible:\nTwo hosts (A and B) each have a connection that shares a single hop\nbetween source and destination, as shown in Figure 3.43. Figure 3.43 ♦Congestion scenario 1: Two connections sharing a\nsingle hop with infinite buffers\nLet’s assume that the application in Host A is sending data into the\nconnection (for example, passing data to the transport-level protocol via a\nsocket) at an average rate of λ  bytes/sec. These data are original in the\nsense that each unit of data is sent into the socket only once. The underlying\ntransport-level protocol is a simple one. Data is encapsulated and sent; no\nerror recovery (e.g., retransmission), flow control, or congestion control is\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 460,
    "text": "performed. Ignoring the additional overhead due to adding transport- and\nlower-layer header information, the rate at which Host A offers traffic to the\nrouter in this first scenario is thus λ  bytes/sec. Host B operates in a similar\nmanner, and we assume for simplicity that it too is sending at a rate of λ\nbytes/sec. Packets from Hosts A and B pass through a router and over a\nshared outgoing link of capacity R. The router has buffers that allow it to\nstore incoming packets when the packet-arrival rate exceeds the outgoing\nlink’s capacity. In this first scenario, we assume that the router has an\ninfinite amount of buffer space. Figure 3.44 plots the performance of Host A’s connection under this\nfirst scenario. The left graph plots the per-connection throughput (number\nof bytes per second at the receiver) as a function of the connection-sending\nrate. For a sending rate between 0 and R/2, the throughput at the receiver\nequals the sender’s sending rate—everything sent by the sender is received\nat the receiver with a finite delay. When the sending rate is above R/2,\nhowever, the throughput is only R/2. This upper limit on throughput is a\nconsequence of the sharing of link capacity between two connections. The\nlink simply cannot deliver packets to a receiver at a steady-state rate that\nexceeds R/2. No matter how high Hosts A and B set their sending rates, they\nwill each never see a throughput higher than R/2. in\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 461,
    "text": "Figure 3.44 ♦Congestion scenario 1: Throughput and delay as a\nfunction of host sending rate\nAchieving a per-connection throughput of R/2 might actually appear to\nbe a good thing, because the link is fully utilized in delivering packets to\ntheir destinations. The right-hand graph in Figure 3.44, however, shows the\nconsequence of operating near link capacity. As the sending rate approaches\nR/2 (from the left), the average delay becomes larger and larger. When the\nsending rate exceeds R/2, the average number of queued packets in the\nrouter is unbounded, and the average delay between source and destination\nbecomes infinite (assuming that the connections operate at these sending\nrates for an infinite period of time and there is an infinite amount of\nbuffering available). Thus, while operating at an aggregate throughput of\nnear R may be ideal from a throughput standpoint, it is far from ideal from a\ndelay standpoint. Even in this (extremely) idealized scenario, we’ve already\nfound one cost of a congested network—large queuing delays are\nexperienced as the packet-arrival rate nears the link capacity. Scenario 2: Two Senders and a Router with Finite Buffers"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 462,
    "text": "Let’s now slightly modify scenario 1 in the following two ways (see Figure\n3.45). First, the amount of router buffering is assumed to be finite. A\nconsequence of this real-world assumption is that packets will be dropped\nwhen arriving to an already-full buffer. Second, we assume that each\nconnection is reliable. If a packet containing a transport-level segment is\ndropped at the router, the sender will eventually retransmit it. Because\npackets can be retransmitted, we must now be more careful with our use of\nthe term sending rate. Specifically, let us again denote the rate at which the\napplication sends original data into the socket by λ  bytes/sec. The rate at\nwhich the transport layer sends segments (containing original data and\nretransmitted data) into the network will be denoted λ'  bytes/sec. λ'  is\nsometimes referred to as the offered load to the network. Figure 3.45 ♦Scenario 2: Two hosts (with retransmissions) and a\nrouter with finite buffers\nThe performance realized under scenario 2 will now depend strongly on\nhow retransmission is performed. First, consider the unrealistic case that\nin\nin\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 463,
    "text": "Host A is able to somehow (magically!) determine whether or not a buffer is\nfree in the router and thus sends a packet only when a buffer is free. In this\ncase, no loss would occur, λ  would be equal to λ' , and the throughput of\nthe connection would be equal to λ . This case is shown in Figure 3.46(a). From a throughput standpoint, performance is ideal—everything that is sent\nis received. Note that the average host sending rate cannot exceed R/2 under\nthis scenario, since packet loss is assumed never to occur. Figure 3.46 ♦Scenario 2 performance with finite buffers\nConsider next the slightly more realistic case that the sender retransmits\nonly when a packet is known for certain to be lost. (Again, this assumption\nis a bit of a stretch. However, it is possible that the sending host might set\nits timeout large enough to be virtually assured that a packet that has not\nbeen acknowledged has been lost.) In this case, the performance might look\nsomething like that shown in Figure 3.46(b). To appreciate what is\nhappening here, consider the case that the offered load, λ'  (the rate of\noriginal data transmission plus retransmissions), equals R/2. According to\nFigure 3.46(b), at this value of the offered load, the rate at which data are\ndelivered to the receiver application is R/3. Thus, out of the 0.5R units of\ndata transmitted, 0.333R bytes/sec (on average) are original data and 0.166R\nin\nin\nin\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 464,
    "text": "bytes/sec (on average) are retransmitted data. We see here another cost of a\ncongested network—the sender must perform retransmissions in order to\ncompensate for dropped (lost) packets due to buffer overflow. Finally, let us consider the case that the sender may time out\nprematurely and retransmit a packet that has been delayed in the queue but\nnot yet lost. In this case, both the original data packet and the\nretransmission may reach the receiver. Of course, the receiver needs but one\ncopy of this packet and will discard the retransmission. In this case, the\nwork done by the router in forwarding the retransmitted copy of the original\npacket was wasted, as the receiver will have already received the original\ncopy of this packet. The router would have better used the link transmission\ncapacity to send a different packet instead. Here then is yet another cost of a\ncongested network—unneeded retransmissions by the sender in the face of\nlarge delays may cause a router to use its link bandwidth to forward\nunneeded copies of a packet. Figure 3.46 (c) shows the throughput versus\noffered load when each packet is assumed to be forwarded (on average)\ntwice by the router. Since each packet is forwarded twice, the throughput\nwill have an asymptotic value of R/4 as the offered load approaches R/2. Scenario 3: Four Senders, Routers with Finite Buffers, and\nMultihop Paths\nIn our final congestion scenario, four hosts transmit packets, each over\noverlapping two-hop paths, as shown in Figure 3.47. We again assume that\neach host uses a timeout/retransmission mechanism to implement a reliable\ndata transfer service, that all hosts have the same value of λ , and that all\nrouter links have capacity R bytes/sec. in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 465,
    "text": "Figure 3.47 ♦Four senders, routers with finite buffers, and multihop\npaths\nLet’s consider the connection from Host A to Host C, passing through\nrouters R1 and R2. The A–C connection shares router R1 with the D–B\nconnection and shares router R2 with the B–D connection. For extremely\nsmall values of λ , buffer overflows are rare (as in congestion scenarios 1\nand 2), and the throughput approximately equals the offered load. For\nslightly larger values of λ , the corresponding throughput is also larger,\nsince more original data is being transmitted into the network and delivered\nin\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 466,
    "text": "to the destination, and overflows are still rare. Thus, for small values of λ ,\nan increase in λ  results in an increase in λ . Having considered the case of extremely low traffic, let’s next examine\nthe case that λ  (and hence λ' ) is extremely large. Consider router R2. The\nA–C traffic arriving to router R2 (which arrives at R2 after being forwarded\nfrom R1) can have an arrival rate at R2 that is at most R, the capacity of the\nlink from R1 to R2, regardless of the value of λ . If λ'  is extremely large\nfor all connections (including the B–D connection), then the arrival rate of\nB–D traffic at R2 can be much larger than that of the A–C traffic. Because\nthe A–C and B–D traffic must compete at router R2 for the limited amount\nof buffer space, the amount of A–C traffic that successfully gets through R2\n(that is, is not lost due to buffer overflow) becomes smaller and smaller as\nthe offered load from B–D gets larger and larger. In the limit, as the offered\nload approaches infinity, an empty buffer at R2 is immediately filled by a\nB–D packet, and the throughput of the A–C connection at R2 goes to zero. This, in turn, implies that the A–C end-to-end throughput goes to zero in the\nlimit of heavy traffic. These considerations give rise to the offered load\nversus throughput tradeoff shown in Figure 3.48.\nin\nin\nout\nin\nin\nin\nin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 467,
    "text": "Figure 3.48 ♦Scenario 3 performance with finite buffers and\nmultihop paths\nThe reason for the eventual decrease in throughput with increasing\noffered load is evident when one considers the amount of wasted work done\nby the network. In the high-traffic scenario outlined above, whenever a\npacket is dropped at a second-hop router, the work done by the first-hop\nrouter in forwarding a packet to the second-hop router ends up being\n“wasted.” The network would have been equally well off (more accurately,\nequally bad off) if the first router had simply discarded that packet and\nremained idle. More to the point, the transmission capacity used at the first\nrouter to forward the packet to the second router could have been much\nmore profitably used to transmit a different packet. (For example, when\nselecting a packet for transmission, it might be better for a router to give\npriority to packets that have already traversed some number of upstream\nrouters.) So here we see yet another cost of dropping a packet due to\ncongestion—when a packet is dropped along a path, the transmission"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 468,
    "text": "capacity that was used at each of the upstream links to forward that packet\nto the point at which it is dropped ends up having been wasted. 3.6.2 Approaches to Congestion Control\nIn Section 3.7, we’ll examine TCP’s specific approach to congestion control\nin great detail. Here, we identify the two broad approaches to congestion\ncontrol that are taken in practice and discuss specific network architectures\nand congestion-control protocols embodying these approaches. At the highest level, we can distinguish among congestion-control\napproaches by whether the network layer provides explicit assistance to the\ntransport layer for congestion-control purposes:\n•\nEnd-to-end congestion control. In an end-to-end approach to congestion\ncontrol, the network layer provides no explicit support to the transport\nlayer for congestion-control purposes. Even the presence of network\ncongestion must be inferred by the end systems based only on observed\nnetwork behavior (for example, packet loss and delay). We’ll see\nshortly in Section 3.7.1 that TCP takes this end-to-end approach toward\ncongestion control, since the IP layer is not required to provide\nfeedback to hosts regarding network congestion. TCP segment loss (as\nindicated \nby \na \ntimeout \nor \nthe \nreceipt \nof \nthree \nduplicate\nacknowledgments) is taken as an indication of network congestion, and\nTCP decreases its window size accordingly. We’ll also see a more\nrecent proposal for TCP congestion control that uses increasing round-\ntrip segment delay as an indicator of increased network congestion\n•\nNetwork-assisted congestion control. With network-assisted congestion\ncontrol, routers provide explicit feedback to the sender and/or receiver\nregarding the congestion state of the network. This feedback may be as"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 469,
    "text": "simple as a single bit indicating congestion at a link—an approach taken\nin the early IBM SNA [Schwartz 1982], DEC DECnet [Jain 1989;\nRamakrishnan 1990] architectures, and ATM [Black 1995] network\narchitectures. More sophisticated feedback is also possible. For\nexample, in ATM Available Bite Rate (ABR) congestion control, a\nrouter informs the sender of the maximum host sending rate it (the\nrouter) can support on an outgoing link. As noted above, the Internet-\ndefault versions of IP and TCP adopt an end-to-end approach towards\ncongestion control. We’ll see, however, in Section 3.7.2 that, more\nrecently, IP and TCP may also optionally implement network-assisted\ncongestion control. For network-assisted congestion control, congestion information is\ntypically fed back from the network to the sender in one of two ways, as\nshown in Figure 3.49. Direct feedback may be sent from a network router to\nthe sender. This form of notification typically takes the form of a choke\npacket (essentially saying, “I’m congested!”). The second and more\ncommon form of notification occurs when a router marks/updates a field in\na packet flowing from sender to receiver to indicate congestion. Upon\nreceipt of a marked packet, the receiver then notifies the sender of the\ncongestion indication. This latter form of notification takes a full round-trip\ntime."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 470,
    "text": "Figure 3.49 ♦Two feedback pathways for network-indicated\ncongestion information"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 471,
    "text": "3.7 TCP Congestion Control\nIn this section, we return to our study of TCP. As we learned in Section 3.5,\nTCP provides a reliable transport service between two processes running on\ndifferent hosts. Another key component of TCP is its congestion-control\nmechanism. As indicated in the previous section, what we might refer to as\n“Classic” TCP—the version of TCP standardized in [RFC 2581] and most\nrecently [RFC 5681]—uses end-to-end congestion control rather than\nnetwork-assisted congestion control, since the IP layer provides no explicit\nfeedback to the end systems regarding network congestion. We’ll first cover\nthis “classic” version of TCP in depth in Section 7.3.1. In Section 7.3.2,\nwe’ll then look at newer flavors of TCP that use an explicit congestion\nindication provided by the network layer, or differ a bit from “classic” TCP\nin any of several different ways. We’ll then cover the challenge of providing\nfairness among transport layer flows that must share a congested link. 3.7.1 Classic TCP Congestion Control\nThe approach taken by TCP is to have each sender limit the rate at which it\nsends traffic into its connection as a function of perceived network\ncongestion. If a TCP sender perceives that there is little congestion on the\npath between itself and the destination, then the TCP sender increases its\nsend rate; if the sender perceives that there is congestion along the path,\nthen the sender reduces its send rate. But this approach raises three\nquestions. First, how does a TCP sender limit the rate at which it sends\ntraffic into its connection? Second, how does a TCP sender perceive that\nthere is congestion on the path between itself and the destination? And"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 472,
    "text": "third, what algorithm should the sender use to change its send rate as a\nfunction of perceived end-to-end congestion? Let’s first examine how a TCP sender limits the rate at which it sends\ntraffic into its connection. In Section 3.5, we saw that each side of a TCP\nconnection consists of a receive buffer, a send buffer, and several variables\n(LastByteRead, rwnd, and so on). The TCP congestion-control\nmechanism operating at the sender keeps track of an additional variable, the\ncongestion window. The congestion window, denoted cwnd, imposes a\nconstraint on the rate at which a TCP sender can send traffic into the\nnetwork. Specifically, the amount of unacknowledged data at a sender may\nnot exceed the minimum of cwnd and rwnd, that is:\nLastByteSent – LastByteAcked ≤ min{cwnd, rwnd}\nIn order to focus on congestion control (as opposed to flow control), let us\nhenceforth assume that the TCP receive buffer is so large that the receive-\nwindow constraint can be ignored; thus, the amount of unacknowledged\ndata at the sender is solely limited by cwnd. We will also assume that the\nsender always has data to send, that is, that all segments in the congestion\nwindow are sent. The constraint above limits the amount of unacknowledged data at the\nsender and therefore indirectly limits the sender’s send rate. To see this,\nconsider a connection for which loss and packet transmission delays are\nnegligible. Then, roughly, at the beginning of every RTT, the constraint\npermits the sender to send cwnd bytes of data into the connection; at the\nend of the RTT the sender receives acknowledgments for the data. Thus the\nsender’s send rate is roughly cwnd/RTT bytes/sec. By adjusting the value of\ncwnd, the sender can therefore adjust the rate at which it sends data into its\nconnection."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 473,
    "text": "Let’s next consider how a TCP sender perceives that there is congestion\non the path between itself and the destination. Let us define a “loss event”\nat a TCP sender as the occurrence of either a timeout or the receipt of three\nduplicate ACKs from the receiver. (Recall our discussion in Section 3.5.4 of\nthe timeout event in Figure 3.33 and the subsequent modification to include\nfast retransmit on receipt of three duplicate ACKs.) When there is excessive\ncongestion, then one (or more) router buffers along the path overflows,\ncausing a datagram (containing a TCP segment) to be dropped. The dropped\ndatagram, in turn, results in a loss event at the sender—either a timeout or\nthe receipt of three duplicate ACKs—which is taken by the sender to be an\nindication of congestion on the sender-to-receiver path. Having considered how congestion is detected, let’s next consider the\nmore optimistic case when the network is congestion-free, that is, when a\nloss event doesn’t occur. In this case, acknowledgments for previously\nunacknowledged segments will be received at the TCP sender. As we’ll see,\nTCP will take the arrival of these acknowledgments as an indication that all\nis well—that segments being transmitted into the network are being\nsuccessfully delivered to the destination—and will use acknowledgments to\nincrease its congestion window size (and hence its transmission rate). Note\nthat if acknowledgments arrive at a relatively slow rate (e.g., if the end-end\npath has high delay or contains a low-bandwidth link), then the congestion\nwindow will be increased at a relatively slow rate. On the other hand, if\nacknowledgments arrive at a high rate, then the congestion window will be\nincreased more quickly. Because TCP uses acknowledgments to trigger (or\nclock) its increase in congestion window size, TCP is said to be self-\nclocking. Given the mechanism of adjusting the value of cwnd to control the\nsending rate, the critical question remains: How should a TCP sender"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 474,
    "text": "determine the rate at which it should send? If TCP senders collectively send\ntoo fast, they can congest the network, leading to the type of congestion\ncollapse that we saw in Figure 3.48. Indeed, the version of TCP that we’ll\nstudy shortly was developed in response to observed Internet congestion\ncollapse [Jacobson 1988] under earlier versions of TCP. However, if TCP\nsenders are too cautious and send too slowly, they could under utilize the\nbandwidth in the network; that is, the TCP senders could send at a higher\nrate without congesting the network. How then do the TCP senders\ndetermine their sending rates such that they don’t congest the network but at\nthe same time make use of all the available bandwidth? Are TCP senders\nexplicitly coordinated, or is there a distributed approach in which the TCP\nsenders can set their sending rates based only on local information? TCP\nanswers these questions using the following guiding principles:\n•\nA lost segment implies congestion, and hence, the TCP sender’s rate\nshould be decreased when a segment is lost. Recall from our discussion\nin Section 3.5.4, that a timeout event or the receipt of four\nacknowledgments for a given segment (one original ACK and then\nthree duplicate ACKs) is interpreted as an implicit “loss event”\nindication of the segment following the quadruply ACKed segment,\ntriggering a retransmission of the lost segment. From a congestion-\ncontrol standpoint, the question is how the TCP sender should decrease\nits congestion window size, and hence its sending rate, in response to\nthis inferred loss event. •\nAn acknowledged segment indicates that the network is delivering the\nsender’s segments to the receiver, and hence, the sender’s rate can be\nincreased when an ACK arrives for a previously unacknowledged\nsegment. The arrival of acknowledgments is taken as an implicit\nindication that all is well—segments are being successfully delivered"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 475,
    "text": "from sender to receiver, and the network is thus not congested. The\ncongestion window size can thus be increased. •\nBandwidth probing. Given ACKs indicating a congestion-free source-\nto-destination path and loss events indicating a congested path, TCP’s\nstrategy for adjusting its transmission rate is to increase its rate in\nresponse to arriving ACKs until a loss event occurs, at which point, the\ntransmission rate is decreased. The TCP sender thus increases its\ntransmission rate to probe for the rate that at which congestion onset\nbegins, backs off from that rate, and then to begins probing again to see\nif the congestion onset rate has changed. The TCP sender’s behavior is\nperhaps analogous to the child who requests (and gets) more and more\ngoodies until finally he/she is finally told “No!”, backs off a bit, but\nthen begins making requests again shortly afterward. Note that there is\nno explicit signaling of congestion state by the network—ACKs and\nloss events serve as implicit signals—and that each TCP sender acts on\nlocal information asynchronously from other TCP senders. Given this overview of TCP congestion control, we’re now in a position to\nconsider the details of the celebrated TCP congestion-control algorithm,\nwhich was first described in [Jacobson 1988] and is standardized in [RFC\n5681]. The algorithm has three major components: (1) slow start, (2)\ncongestion avoidance, and (3) fast recovery. Slow start and congestion\navoidance are mandatory components of TCP, differing in how they\nincrease the size of cwnd in response to received ACKs. We’ll see shortly\nthat slow start increases the size of cwnd more rapidly (despite its name!) than congestion avoidance. Fast recovery is recommended, but not required,\nfor TCP senders."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 476,
    "text": "Slow Start\nWhen a TCP connection begins, the value of cwnd is typically initialized to\na small value of 1 MSS [RFC 3390], resulting in an initial sending rate of\nroughly MSS/RTT. For example, if MSS = 500 bytes and RTT = 200 msec,\nthe resulting initial sending rate is only about 20 kbps. Since the available\nbandwidth to the TCP sender may be much larger than MSS/RTT, the TCP\nsender would like to find the amount of available bandwidth quickly. Thus,\nin the slow-start state, the value of cwnd begins at 1 MSS and increases by\n1 MSS every time a transmitted segment is first acknowledged. In the\nexample of Figure 3.50, TCP sends the first segment into the network and\nwaits for an acknowledgment. When this acknowledgment arrives, the TCP\nsender increases the congestion window by one MSS and sends out two\nmaximum-sized segments. These segments are then acknowledged, with the\nsender increasing the congestion window by 1 MSS for each of the\nacknowledged segments, giving a congestion window of 4 MSS, and so on. This process results in a doubling of the sending rate every RTT. Thus, the\nTCP send rate starts slow but grows exponentially during the slow start\nphase."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 477,
    "text": "Figure 3.50 ♦TCP slow start\nBut when should this exponential growth end? Slow start provides\nseveral answers to this question. First, if there is a loss event (i.e.,\ncongestion) indicated by a timeout, the TCP sender sets the value of cwnd\nto 1 and begins the slow start process anew. It also sets the value of a\nsecond state variable, ssthresh (shorthand for “slow start threshold”) to\ncwnd/2—half of the value of the congestion window value when"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 478,
    "text": "congestion was detected. The second way in which slow start may end is\ndirectly tied to the value of ssthresh. Since ssthresh is half the value\nof cwnd when congestion was last detected, it might be a bit reckless to\nkeep doubling cwnd when it reaches or surpasses the value of ssthresh. Thus, when the value of cwnd equals ssthresh, slow start ends and TCP\ntransitions into congestion avoidance mode. As we’ll see, TCP increases\ncwnd more cautiously when in congestion-avoidance mode. The final way\nin which slow start can end is if three duplicate ACKs are detected, in\nwhich case TCP performs a fast retransmit (see Section 3.5.4) and enters the\nfast recovery state, as discussed below. TCP’s behavior in slow start is\nsummarized in the FSM description of TCP congestion control in Figure\n3.51. The slow-start algorithm traces it roots to [Jacobson 1988]; an\napproach similar to slow start was also proposed independently in [Jain\n1986]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 479,
    "text": "Figure 3.51 ♦FSM description of TCP congestion control\nCongestion Avoidance\nOn entry to the congestion-avoidance state, the value of cwnd is\napproximately half its value when congestion was last encountered—\ncongestion could be just around the corner! Thus, rather than doubling the\nvalue of cwnd every RTT, TCP adopts a more conservative approach and\nincreases the value of cwnd by just a single MSS every RTT [RFC 5681]. This can be accomplished in several ways. A common approach is for the\nTCP sender to increase cwnd by MSS bytes (MSS/cwnd) whenever a new\nacknowledgment arrives. For example, if MSS is 1,460 bytes and cwnd is"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 480,
    "text": "14,600 bytes, then 10 segments are being sent within an RTT. Each arriving\nACK (assuming one ACK per segment) increases the congestion window\nsize by 1/10 MSS, and thus, the value of the congestion window will have\nincreased by one MSS after ACKs when all 10 segments have been\nreceived. But when should congestion avoidance’s linear increase (of 1 MSS per\nRTT) end? TCP’s congestion-avoidance algorithm behaves the same when a\ntimeout occurs as in the case of slow start: The value of cwnd is set to 1\nMSS, and the value of ssthresh is updated to half the value of cwnd\nwhen the loss event occurred. Recall, however, that a loss event also can be\ntriggered by a triple duplicate ACK event. In this case, the network is\ncontinuing to deliver some segments from sender to receiver (as indicated\nby the receipt of duplicate ACKs). So TCP’s behavior to this type of loss\nevent should be less drastic than with a timeout-indicated loss: TCP halves\nthe value of cwnd (adding in 3 MSS for good measure to account for the\ntriple duplicate ACKs received) and records the value of ssthresh to be\nhalf the value of cwnd when the triple duplicate ACKs were received. The\nfast-recovery state is then entered. Fast Recovery\nIn fast recovery, the value of cwnd is increased by 1 MSS for every\nduplicate ACK received for the missing segment that caused TCP to enter\nthe fast-recovery state. Eventually, when an ACK arrives for the missing\nsegment, TCP enters the congestion-avoidance state after deflating cwnd. If\na timeout event occurs, fast recovery transitions to the slow-start state after\nperforming the same actions as in slow start and congestion avoidance: The"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 481,
    "text": "value of cwnd is set to 1 MSS, and the value of ssthresh is set to half\nthe value of cwnd when the loss event occurred. VideoNote\nExamining the behavior of TCP\nPRINCIPLES IN\nPRACTICE\nTCP SPLITTING: OPTIMIZING THE PERFORMANCE OF CLOUD SERVICES\nFor cloud services such as search, e-mail, and social networks, it is desirable to provide a\nhigh-level of responsiveness, ideally giving users the illusion that the services are running\nwithin their own end systems (including their smartphones). This can be a major challenge,\nas users are often located far away from the data centers responsible for serving the\ndynamic content associated with the cloud services. Indeed, if the end system is far from a\ndata center, then the RTT will be large, potentially leading to poor response time\nperformance due to TCP slow start. As a case study, consider the delay in receiving a response for a search query. Typically,\nthe server requires three TCP windows during slow start to deliver the response [Pathak\n2010]. Thus the time from when an end system initiates a TCP connection until the time\nwhen it receives the last packet of the response is roughly 4 · RTT (one RTT to set up the\nTCP connection plus three RTTs for the three windows of data) plus the processing time in\nthe data center. These RTT delays can lead to a noticeable delay in returning search results\nfor a significant fraction of queries. Moreover, there can be significant packet loss in access\nnetworks, leading to TCP retransmissions and even larger delays."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 482,
    "text": "One way to mitigate this problem and improve user-perceived performance is to (1)\ndeploy front-end servers closer to the users, and (2) utilize TCP splitting by breaking the\nTCP connection at the front-end server. With TCP splitting, the client establishes a TCP\nconnection to the nearby front-end, and the front-end maintains a persistent TCP\nconnection to the data center with a very large TCP congestion window [Tariq 2008, Pathak\n2010, Chen 2011]. With this approach, the response time roughly becomes 4 · RTT  +\nRTT  + processing time, where RTT  is the round-trip time between client and front-end\nserver, and RTT  is the round-trip time between the front-end server and the data center\n(back-end server). If the front-end server is close to client, then this response time\napproximately becomes RTT plus processing time, since RTT  is negligibly small and\nRTT  is approximately RTT. In summary, TCP splitting can reduce the networking delay\nroughly from 4 · RTT to RTT, significantly improving user-perceived performance,\nparticularly for users who are far from the nearest data center. TCP splitting also helps\nreduce TCP retransmission delays caused by losses in access networks. Google and\nAkamai have made extensive use of their CDN servers in access networks (recall our\ndiscussion in Section 2.6) to perform TCP splitting for the cloud services they support [Chen\n2011]. Fast recovery is a recommended, but not required, component of TCP\n[RFC 5681]. It is interesting that an early version of TCP, known as TCP\nTahoe, unconditionally cut its congestion window to 1 MSS and entered the\nslow-start phase after either a timeout-indicated or triple-duplicate-ACK-\nindicated loss event. The newer version of TCP, TCP Reno, incorporated\nfast recovery. Figure 3.52 illustrates the evolution of TCP’s congestion window for\nboth Reno and Tahoe. In this figure, the threshold is initially equal to 8\nMSS. For the first eight transmission rounds, Tahoe and Reno take identical\nFE\nBE\nFE\nBE\nFE\nBE"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 483,
    "text": "actions. The congestion window climbs exponentially fast during slow start\nand hits the threshold at the fourth round of transmission. The congestion\nwindow then climbs linearly until a triple duplicate- ACK event occurs, just\nafter transmission round 8. Note that the congestion window is 12 · MSS\nwhen this loss event occurs. The value of ssthresh is then set to 0.5 ·\ncwnd = 6 · MSS. Under TCP Reno, the congestion window is set to cwnd\n= 9 · MSS and then grows linearly. Under TCP Tahoe, the congestion\nwindow is set to 1 MSS and grows exponentially until it reaches the value\nof ssthresh, at which point it grows linearly. Figure 3.52 ♦Evolution of TCP’s congestion window (Tahoe and\nReno)\nFigure 3.51 presents the complete FSM description of TCP’s\ncongestion-control algorithms—slow start, congestion avoidance, and fast\nrecovery. The figure also indicates where transmission of new segments or"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 484,
    "text": "retransmitted segments can occur. Although it is important to distinguish\nbetween TCP error control/retransmission and TCP congestion control, it’s\nalso important to appreciate how these two aspects of TCP are inextricably\nlinked. TCP Congestion Control: Retrospective\nHaving delved into the details of slow start, congestion avoidance, and fast\nrecovery, it’s worthwhile to now step back and view the forest from the\ntrees. Ignoring the initial slow-start period when a connection begins and\nassuming that losses are indicated by triple duplicate ACKs rather than\ntimeouts, TCP’s congestion control consists of linear (additive) increase in\ncwnd of 1 MSS per RTT and then a halving (multiplicative decrease) of\ncwnd on a triple duplicate-ACK event. For this reason, TCP congestion\ncontrol is often referred to as an additive-increase, multiplicative-\ndecrease (AIMD) form of congestion control. AIMD congestion control\ngives rise to the “saw tooth” behavior shown in Figure 3.53, which also\nnicely illustrates our earlier intuition of TCP “probing” for bandwidth—\nTCP linearly increases its congestion window size (and hence its\ntransmission rate) until a triple duplicate-ACK event occurs. It then\ndecreases its congestion window size by a factor of two but then again\nbegins increasing it linearly, probing to see if there is additional available\nbandwidth."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 485,
    "text": "Figure 3.53 ♦Additive-increase, multiplicative-decrease congestion\ncontrol\nTCP’s AIMD algorithm was developed based on a tremendous amount\nof engineering insight and experimentation with congestion control in\noperational networks. Ten years after TCP’s development, theoretical\nanalyses showed that TCP’s congestion-control algorithm serves as a\ndistributed asynchronous-optimization algorithm that results in several\nimportant aspects of user and network performance being simultaneously\noptimized [Kelly 1998]. A rich theory of congestion control has since been\ndeveloped [Srikant 2012]. TCP Cubic\nGiven TCP Reno’s additive-increase, multiplicative-decrease approach to\ncongestion control, one might naturally wonder whether this is the best way\nto “probe” for a packet sending rate that is just below the threshold of"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 486,
    "text": "triggering packet loss. Indeed, cutting the sending rate in half (or even\nworse, cutting the sending rate to one packet per RTT as in an earlier\nversion of TCP known as TCP Tahoe) and then increasing rather slowly\nover time may be overly cautious. If the state of the congested link where\npacket loss occurred hasn’t changed much, then perhaps it’s better to more\nquickly ramp up the sending rate to get close to the pre-loss sending rate\nand only then probe cautiously for bandwidth. This insight lies at the heart\nof a flavor of TCP known as TCP CUBIC [Ha 2008, RFC 8312]. TCP CUBIC differs only slightly from TCP Reno. Once again, the\ncongestion window is increased only on ACK receipt, and the slow start and\nfast recovery phases remain the same. CUBIC only changes the congestion\navoidance phase, as follows:\n•\nLet W\n be size of TCP’s congestion control window when loss was\nlast detected, and let K be the future point in time when TCP CUBIC’s\nwindow size will again reach W\n, assuming no losses. Several tunable\nCUBIC parameters determine the value K, that is, how quickly the\nprotocol’s congestion window size would reach W\n. •\nCUBIC increases the congestion window as a function of cube of the\ndistance between the current time, t, and K. Thus, when t is further\naway from K, the congestion window size increases are much larger\nthan when t is close to K. That is, CUBIC quickly ramps up TCP’s\nsending rate to get close to the pre-loss rate, W\n, and only then probes\ncautiously for bandwidth as it approaches W\n. •\nWhen t is greater than K, the cubic rule implies that CUBIC’s\ncongestion window increases are small when t is still close to K (which\nis good if the congestion level of the link causing loss hasn’t changed\nmuch) but then increases rapidly as t exceeds K (which allows CUBIC\nmax\nmax\nmax\nmax\nmax"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 487,
    "text": "to more quickly find a new operating point if the congestion level of the\nlink that caused loss has changed significantly). Under these rules, the idealized performance of TCP Reno and TCP\nCUBIC are compared in Figure 3.54, adapted from [Huston 2017]. We see\nthe slow start phase ending at t . Then, when congestion loss occurs at t , t ,\nand t , CUBIC more quickly ramps up close to Wmax (thereby enjoying\nmore overall throughput than TCP Reno). We can see graphically how TCP\nCUBIC attempts to maintain the flow for as long as possible just below the\n(unknown to the sender) congestion threshold. Note that at t , the\ncongestion level has presumably decreased appreciably, allowing both TCP\nReno and TCP CUBIC to achieve sending rates higher than Wmax. Figure 3.54 ♦TCP congestion avoidance sending rates: TCP Reno\nand TCP CUBIC\n1\n3"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 488,
    "text": "TCP \nCUBIC \nhas \nrecently \ngained \nwide \ndeployment. While\nmeasurements taken around 2000 on popular Web servers showed that\nnearly all were running some ­version of TCP Reno [Padhye 2001], more\nrecent measurements of the 5000 most popular Web servers shows that\nnearly 50% are running a version of TCP CUBIC [Yang 2014], which is\nalso the default version of TCP used in the Linux operating system. Macroscopic Description of TCP Reno Throughput\nGiven the saw-toothed behavior of TCP Reno, it’s natural to consider what\nthe average throughput (that is, the average rate) of a long-lived TCP Reno\nconnection might be. In this analysis, we’ll ignore the slow-start phases that\noccur after timeout events. (These phases are typically very short, since the\nsender grows out of the phase exponentially fast.) During a particular\nround-trip interval, the rate at which TCP sends data is a function of the\ncongestion window and the current RTT. When the window size is w bytes\nand the current round-trip time is RTT seconds, then TCP’s transmission\nrate is roughly w/RTT. TCP then probes for additional bandwidth by\nincreasing w by 1 MSS each RTT until a loss event occurs. Denote by W the\nvalue of w when a loss event occurs. Assuming that RTT and W are\napproximately constant over the duration of the connection, the TCP\ntransmission rate ranges from W/(2 · RTT) to W/RTT. These assumptions lead to a highly simplified macroscopic model for\nthe steady-state behavior of TCP. The network drops a packet from the\nconnection when the rate increases to W/RTT; the rate is then cut in half and\nthen increases by MSS/RTT every RTT until it again reaches W/RTT. This\nprocess repeats itself over and over again. Because TCP’s throughput (that\nis, rate) increases linearly between the two extreme values, we have"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 489,
    "text": "average throughput of a connection = 0.75 ⋅ W\nRTT\nUsing this highly idealized model for the steady-state dynamics of TCP,\nwe can also derive an interesting expression that relates a connection’s loss\nrate to its available bandwidth [Mathis 1997]. This derivation is outlined in\nthe homework problems. A more sophisticated model that has been found\nempirically to agree with measured data is [Padhye 2000]. 3.7.2 Network-Assisted Explicit Congestion\nNotification and Delayed-based Congestion\nControl\nSince the initial standardization of slow start and congestion avoidance in\nthe late 1980’s [RFC 1122], TCP has implemented the form of end-end\ncongestion control that we studied in Section 3.7.1: a TCP sender receives\nno explicit congestion indications from the network layer, and instead infers\ncongestion through observed packet loss. More recently, extensions to both\nIP and TCP [RFC 3168] have been proposed, implemented, and deployed\nthat allow the network to explicitly signal congestion to a TCP sender and\nreceiver. In addition, a number of variations of TCP congestion control\nprotocols have been proposed that infer congestion using measured packet\ndelay. We’ll take a look at both network-assisted and delay-based\ncongestion control in this section. Explicit Congestion Notification\nExplicit Congestion Notification [RFC 3168] is the form of network-\nassisted congestion control performed within the Internet. As shown in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 490,
    "text": "Figure 3.55, both TCP and IP are involved. At the network layer, two bits\n(with four possible values, ­overall) in the Type of Service field of the IP\ndatagram header (which we’ll discuss in Section 4.3) are used for ECN. Figure 3.55 ♦Explicit Congestion Notification: network-assisted\ncongestion control\nOne setting of the ECN bits is used by a router to indicate that it (the\nrouter) is experiencing congestion. This congestion indication is then\ncarried in the marked IP datagram to the destination host, which then\ninforms the sending host, as shown in Figure 3.55. RFC 3168 does not\nprovide a definition of when a router is congested; that decision is a\nconfiguration choice made possible by the router vendor, and decided by\nthe network operator. However, the intuition is that the congestion\nindication bit can be set to signal the onset of congestion to the send before\nloss actually occurs. A second setting of the ECN bits is used by the sending"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 491,
    "text": "host to inform routers that the sender and receiver are ECN-capable, and\nthus capable of taking action in response to ECN-indicated network\ncongestion. As shown in Figure 3.55, when the TCP in the receiving host receives\nan ECN congestion indication via a received datagram, the TCP in the\nreceiving host informs the TCP in the sending host of the congestion\nindication by setting the ECE (Explicit Congestion Notification Echo) bit\n(see Figure 3.29) in a receiver-to-sender TCP ACK segment. The TCP\nsender, in turn, reacts to an ACK with a congestion indication by halving\nthe congestion window, as it would react to a lost segment using fast\nretransmit, and sets the CWR (Congestion Window Reduced) bit in the\nheader of the next transmitted TCP sender-to-receiver segment. Other transport-layer protocols besides TCP may also make use of\nnetwork-layer-signaled ECN. The Datagram Congestion Control Protocol\n(DCCP) [RFC 4340] provides a low-overhead, congestion-controlled UDP-\nlike unreliable service that utilizes ECN. DCTCP (Data Center TCP)\n[Alizadeh 2010, RFC 8257] and DCQCN (Data Center Quantized\nCongestion Notification) [Zhu 2015] designed ­specifically for data center\nnetworks, also makes use of ECN. Recent Internet measurements show\nincreasing deployment of ECN capabilities in popular servers as well as in\nrouters along paths to those servers [Kühlewind 2013]. Delay-based Congestion Control\nRecall from our ECN discussion above that a congested router can set the\ncongestion indication bit to signal congestion onset to senders before full\nbuffers cause ­packets to be dropped at that router. This allows senders to\ndecrease their sending rates ­earlier, hopefully before packet loss, thus\navoiding costly packet loss and retransmission. A second congestion-"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 492,
    "text": "avoidance approach takes a delay-based approach to also proactively detect\ncongestion onset before packet loss occurs. In TCP Vegas [Brakmo 1995], the sender measures the RTT of the\nsource-to-destination path for all acknowledged packets. Let RTT\n be the\nminimum of these measurements at a sender; this occurs when the path is\nuncongested and packets experience minimal queuing delay. If TCP Vegas’\ncongestion window size is cwnd, then the uncongested throughput rate\nwould be cwnd/RTT\n. The intuition behind TCP Vegas is that if the actual\nsender-measured throughput is close to this value, the TCP sending rate can\nbe increased since (by definition and by measurement) the path is not yet\ncongested. However, if the actual sender-measured throughput is\nsignificantly less than the uncongested throughput rate, the path is\ncongested and the Vegas TCP sender will decrease its sending rate. Details\ncan be found in [Brakmo 1995]. TCP Vegas operates under the intuition that TCP senders should “Keep\nthe pipe just full, but no fuller” [Kleinrock 2018]. “Keeping the pipe full”\nmeans that links (in particular the bottleneck link that is limiting a\nconnection’s throughput) are kept busy transmitting, doing useful work;\n“but no fuller” means that there is nothing to gain (except increased delay!) if large queues are allowed to build up while the pipe is kept full. The BBR congestion control protocol [Cardwell 2017] builds on ideas\nin TCP Vegas, and incorporates mechanisms that allows it compete fairly\n(see Section 3.7.3) with TCP non-BBR senders. [Cardwell 2017] reports\nthat in 2016, Google began using BBR for all TCP traffic on its private B4\nnetwork [Jain 2013] that interconnects Google data centers, replacing\nCUBIC. It is also being deployed on Google and YouTube Web servers. Other delay-based TCP congestion control protocols include TIMELY for\nmin\nmin"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 493,
    "text": "data center networks [Mittal 2015], and Compound TCP (CTPC) [Tan\n2006] and FAST [Wei 2006] for high-speed and long distance networks. 3.7.3 Fairness\nConsider K TCP connections, each with a different end-to-end path, but all\npassing through a bottleneck link with transmission rate R bps. (By\nbottleneck link, we mean that for each connection, all the other links along\nthe connection’s path are not congested and have abundant transmission\ncapacity as compared with the transmission capacity of the bottleneck link.) Suppose each connection is transferring a large file and there is no UDP\ntraffic passing through the bottleneck link. A congestion-control mechanism\nis said to be fair if the average transmission rate of each connection is\napproximately R/K; that is, each connection gets an equal share of the link\nbandwidth. Is TCP’s AIMD algorithm fair, particularly given that different TCP\nconnections may start at different times and thus may have different\nwindow sizes at a given point in time? [Chiu 1989] provides an elegant and\nintuitive explanation of why TCP congestion control converges to provide\nan equal share of a bottleneck link’s bandwidth among competing TCP\nconnections. Let’s consider the simple case of two TCP connections sharing a single\nlink with transmission rate R, as shown in Figure 3.55. Assume that the two\nconnections have the same MSS and RTT (so that if they have the same\ncongestion window size, then they have the same throughput), that they\nhave a large amount of data to send, and that no other TCP connections or\nUDP datagrams traverse this shared link. Also, ignore the slow-start phase"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 494,
    "text": "of TCP and assume the TCP connections are operating in CA mode (AIMD)\nat all times. Figure 3.56 plots the throughput realized by the two TCP connections. If TCP is to share the link bandwidth equally between the two connections,\nthen the realized throughput should fall along the 45-degree arrow (equal\nbandwidth share) emanating from the origin. Ideally, the sum of the two\nthroughputs should equal R. (Certainly, each connection receiving an equal,\nbut zero, share of the link capacity is not a desirable situation!) So the goal\nshould be to have the achieved throughputs fall somewhere near the\nintersection of the equal bandwidth share line and the full bandwidth\nutilization line in Figure 3.56. Figure 3.56 ♦Two TCP connections sharing a single bottleneck link\nSuppose that the TCP window sizes are such that at a given point in\ntime, connections 1 and 2 realize throughputs indicated by point A in Figure\n3.56. Because the amount of link bandwidth jointly consumed by the two\nconnections is less than R, no loss will occur, and both connections will\nincrease their window by 1 MSS per RTT as a result of TCP’s congestion-"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 495,
    "text": "avoidance algorithm. Thus, the joint throughput of the two connections\nproceeds along a 45-degree line (equal increase for both connections)\nstarting from point A. Eventually, the link bandwidth jointly consumed by\nthe two connections will be greater than R, and eventually packet loss will\noccur. Suppose that connections 1 and 2 experience packet loss when they\nrealize throughputs indicated by point B. Connections 1 and 2 then decrease\ntheir windows by a factor of two. The resulting throughputs realized are\nthus at point C, halfway along a vector starting at B and ending at the\norigin. Because the joint bandwidth use is less than R at point C, the two\nconnections again increase their throughputs along a 45-degree line starting\nfrom C. Eventually, loss will again occur, for example, at point D, and the\ntwo connections again decrease their window sizes by a factor of two, and\nso on. You should convince yourself that the bandwidth realized by the two\nconnections eventually fluctuates along the equal bandwidth share line. You\nshould also convince yourself that the two connections will converge to this\nbehavior regardless of where they are in the two-dimensional space! Although a number of idealized assumptions lie behind this scenario, it still\nprovides an intuitive feel for why TCP results in an equal sharing of\nbandwidth among connections. In our idealized scenario, we assumed that only TCP connections\ntraverse the bottleneck link, that the connections have the same RTT value,\nand that only a ­single TCP connection is associated with a host-destination\npair. In practice, these ­conditions are typically not met, and client-server\napplications can thus obtain very unequal portions of link bandwidth. In\nparticular, it has been shown that when multiple connections share a\ncommon bottleneck, those sessions with a smaller RTT are able to grab the\navailable bandwidth at that link more quickly as it becomes free (that is,"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 496,
    "text": "open their congestion windows faster) and thus will enjoy higher\nthroughput than those connections with larger RTTs [Lakshman 1997]. Figure 3.57 ♦Throughput realized by TCP connections 1 and 2\nFairness and UDP\nWe have just seen how TCP congestion control regulates an application’s\ntransmission rate via the congestion window mechanism. Many multimedia\napplications, such as Internet phone and video conferencing, often do not\nrun over TCP for this very reason—they do not want their transmission rate"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 497,
    "text": "throttled, even if the network is very congested. Instead, these applications\nprefer to run over UDP, which does not have built-in congestion control. When running over UDP, applications can pump their audio and video into\nthe network at a constant rate and occasionally lose packets, rather than\nreduce their rates to “fair” levels at times of congestion and not lose any\npackets. From the perspective of TCP, the multimedia applications running\nover UDP are not being fair—they do not cooperate with the other\nconnections nor adjust their transmission rates appropriately. Because TCP\ncongestion control will decrease its transmission rate in the face of\nincreasing congestion (loss), while UDP sources need not, it is possible for\nUDP sources to crowd out TCP traffic. A number of congestion-control\nmechanisms have been proposed for the Internet that prevent UDP traffic\nfrom bringing the Internet’s throughput to a grinding halt [Floyd 1999;\nFloyd 2000; Kohler 2006; RFC 4340]. Fairness and Parallel TCP Connections\nBut even if we could force UDP traffic to behave fairly, the fairness\nproblem would still not be completely solved. This is because there is\nnothing to stop a TCP-based application from using multiple parallel\nconnections. For example, Web browsers often use multiple parallel TCP\nconnections to transfer the multiple objects within a Web page. (The exact\nnumber of multiple connections is configurable in most browsers.) When an\napplication uses multiple parallel connections, it gets a larger fraction of the\nbandwidth in a congested link. As an example, consider a link of rate R\nsupporting nine ongoing client-server applications, with each of the\napplications using one TCP connection. If a new application comes along\nand also uses one TCP connection, then each application gets approximately\nthe same transmission rate of R/10. But if this new application instead uses"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 498,
    "text": "11 parallel TCP connections, then the new application gets an unfair\nallocation of more than R/2. Because Web traffic is so pervasive in the\nInternet, multiple parallel connections are not uncommon."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 499,
    "text": "3.8 Evolution of Transport-Layer Functionality\nOur discussion of specific Internet transport protocols in this chapter has\nfocused on UDP and TCP—the two “work horses” of the Internet transport\nlayer. However, as we’ve seen, three decades of experience with these two\nprotocols has identified circumstances in which neither is ideally suited, and\nso the design and implementation of transport layer functionality has\ncontinued to evolve. We’ve seen a rich evolution in the use of TCP over the past decade. In ­-\nSections 3.7.1 and 3.7.2, we learned that in addition to “classic” versions of\nTCP such as TCP Tahoe and Reno, there are now several newer versions of\nTCP that have been developed, implemented, deployed, and are in\nsignificant use today. These include TCP CUBIC, DCTCP, CTCP, BBR,\nand more. Indeed, measurements in [Yang 2014] indicate that CUBIC (and\nits predecessor, BIC [Xu 2004]) and CTCP are more widely deployed on\nWeb servers than classic TCP Reno; we also saw that BBR is being\ndeployed in Google’s internal B4 network, as well as on many of Google’s\npublic-facing servers. And there are many (many!) more versions of TCP! There are versions\nof TCP specifically designed for use over wireless links, over high-\nbandwidth paths with large RTTs, for paths with packet re-ordering, and for\nshort paths strictly within data centers. There are versions of TCP that\nimplement different priorities among TCP connections competing for\nbandwidth at a bottleneck link, and for TCP connections whose segments\nare being sent over different source-destination paths in parallel. There are\nalso variations of TCP that deal with packet acknowledgment and TCP\nsession establishment/closure differently than we studied in Section 3.5.6."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 500,
    "text": "Indeed, it’s probably not even correct anymore to refer to “the” TCP\nprotocol; perhaps the only common features of these protocols is that they\nuse the TCP segment format that we studied in Figure 3.29, and that they\nshould compete “fairly” amongst themselves in the face of network\ncongestion! For a survey of the many flavors of TCP, see ­[Afanasyev 2010]\nand [Narayan 2018]. QUIC: Quick UDP Internet Connections\nIf the transport services needed by an application don’t quite fit either the\nUDP or TCP service models—perhaps an application needs more services\nthan those provided by UDP but does not want all of the particular\nfunctionality that comes with TCP, or may want different services than\nthose provided by TCP—application designers can always “roll their own”\nprotocol at the application layer. This is the approach taken in the QUIC\n(Quick UDP Internet Connections) protocol [Langley 2017, QUIC 2020]. Specifically, QUIC is a new application-layer protocol designed from the\nground up to improve the performance of transport-layer services for secure\nHTTP. QUIC has already been widely deployed, although is still in the\nprocess of being standardized as an Internet RFC [QUIC 2020]. Google has\ndeployed QUIC on many of its public-facing Web servers, in its mobile\nvideo streaming YouTube app, in its Chrome browser, and in Android’s\nGoogle Search app. With more than 7% of Internet traffic today now being\nQUIC [Langley 2017], we’ll want to take a closer look. Our study of QUIC\nwill also serve as a nice culmination of our study of the transport layer, as\nQUIC uses many of the approaches for reliable data transfer, congestion\ncontrol, and connection management that we’ve studied in this chapter. As shown in Figure 3.58, QUIC is an application-layer protocol, using\nUDP as its underlying transport-layer protocol, and is designed to interface"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 501,
    "text": "above specifically to a simplified but evolved version of HTTP/2. In the\nnear future, HTTP/3 will natively incorporate QUIC [HTTP/3 2020]. Some\nof QUIC’s major features include:\n•\nConnection-Oriented and Secure. Like TCP, QUIC is a connection-\noriented protocol between two endpoints. This requires a handshake\nbetween endpoints to set up the QUIC connection state. Two pieces of\nconnection state are the source and destination connection ID. All QUIC\npackets are encrypted, and as suggested in Figure 3.58, QUIC combines\nthe handshakes needed to establish connection state with those needed\nfor authentication and encryption (transport layer security topics that\nwe’ll study in Chapter 8), thus providing faster establishment than the\nprotocol stack in Figure 3.58(a), where multiple RTTs are required to\nfirst establish a TCP connection, and then establish a TLS connection\nover the TCP connection. Figure 3.58 ♦(a) traditional secure HTTP protocol stack, and\nthe (b) secure QUIC-based HTTP/3 protocol stack\n•\nStreams. QUIC allows several different application-level “streams” to\nbe multiplexed through a single QUIC connection, and once a QUIC\nconnection is established, new streams can be quickly added. A stream"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 502,
    "text": "is an abstraction for the reliable, in-order bi-directional delivery of data\nbetween two QUIC endpoints. In the context of HTTP/3, there would be\na different stream for each object in a Web page. Each connection has a\nconnection ID, and each stream within a connection has a stream ID;\nboth of these IDs are contained in a QUIC packet header (along with\nother header information). Data from multiple streams may be\ncontained within a single QUIC segment, which is carried over UDP. The Stream Control Transmission Protocol (SCTP) [RFC 4960, RFC\n3286] is an earlier reliable, message-oriented protocol that pioneered\nthe notion of multiplexing multiple application-level “streams” through\na single SCTP connection. We’ll see in Chapter 7 that SCTP is used in\ncontrol plane protocols in 4G/5G cellular wireless networks. •\nReliable, TCP-friendly congestion-controlled data transfer. As\nillustrated in Figure 3.59(b), QUIC provides reliable data transfer to\neach QUIC stream separately. Figure 3.59(a) shows the case of\nHTTP/1.1 sending multiple HTTP requests, all over a single TCP\nconnection. Since TCP provides reliable, in-order byte delivery, this\nmeans that the multiple HTTP requests must be delivered in-order at the\ndestination HTTP server. Thus, if bytes from one HTTP request are lost,\nthe remaining HTTP requests can not be delivered until those lost bytes\nare retransmitted and correctly received by TCP at the HTTP server—\nthe so-called HOL blocking problem that we encountered earlier in\nSection 2.2.5. Since QUIC provides a reliable in-order delivery on a\nper-stream basis, a lost UDP segment only impacts those streams whose\ndata was carried in that segment; HTTP messages in other streams can\ncontinue to be received and delivered to the application. QUIC provides\nreliable data transfer using acknowledgment mechanisms similar to\nTCP’s, as specified in [RFC 5681]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 503,
    "text": "Figure 3.59 ♦(a) HTTP/1.1: a single-connection client and\nserver using application-level TLS encryption over\nTCP’s reliable data transfer (RDT) and congestion\ncontrol (CC) (b) HTTP/3: a multi-stream client and\nserver using QUIC’s encryption, reliable data\ntransfer and congestion control over UDP’s\nunreliable datagram service\nQUIC’s congestion control is based on TCP NewReno [RFC 6582], a\nslight modification to the TCP Reno protocol that we studied in Section\n3.7.1. QUIC’s Draft specification [QUIC-recovery 2020] notes\n“Readers familiar with TCP’s loss detection and congestion control will\nfind algorithms here that parallel well-known TCP ones.” Since we’ve\ncarefully studied TCP’s congestion control in Section 3.7.1, we’d be\nright at home reading the details of QUIC’s draft specification of its\ncongestion control algorithm! In closing, it’s worth highlighting again that QUIC is an application-\nlayer ­protocol providing reliable, congestion-controlled data transfer\nbetween two ­endpoints. The authors of QUIC [Langley 2017] stress that\nthis means that changes can be made to QUIC at “application-update\ntimescales,” that is, much faster than TCP or UDP update timescales."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 504,
    "text": "3.9 Summary\nWe began this chapter by studying the services that a transport-layer\nprotocol can provide to network applications. At one extreme, the transport-\nlayer protocol can be very simple and offer a no-frills service to\napplications, providing only a multiplexing/demultiplexing function for\ncommunicating processes. The Internet’s UDP ­protocol is an example of\nsuch a no-frills transport-layer protocol. At the other extreme, a ­transport-\nlayer ­protocol can provide a variety of guarantees to applications, such as\nreliable delivery of data, delay guarantees, and bandwidth guarantees. Nevertheless, the services that a transport protocol can provide are often\nconstrained by the service model of the underlying network-layer protocol. If the network-layer protocol cannot provide delay or bandwidth guarantees\nto transport-layer segments, then the transport-layer protocol cannot provide\ndelay or bandwidth guarantees for the messages sent between processes. We learned in Section 3.4 that a transport-layer protocol can provide\nreliable data transfer even if the underlying network layer is unreliable. We\nsaw that providing reliable data transfer has many subtle points, but that the\ntask can be accomplished by carefully combining acknowledgments, timers,\nretransmissions, and sequence numbers. Although we covered reliable data transfer in this chapter, we should\nkeep in mind that reliable data transfer can be provided by link-, network-,\ntransport-, or application-layer protocols. Any of the upper four layers of\nthe \nprotocol \nstack \ncan \nimplement \nacknowledgments, \ntimers,\nretransmissions, and sequence numbers and provide reliable data transfer to\nthe layer above. In fact, over the years, engineers and computer scientists\nhave independently designed and implemented link-, network-, transport-,"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 505,
    "text": "and application-layer protocols that provide reliable data transfer (although\nmany of these protocols have quietly disappeared). In Section 3.5, we took a close look at TCP, the Internet’s connection-\noriented and reliable transport-layer protocol. We learned that TCP is\ncomplex, involving connection management, flow control, and round-trip\ntime estimation, as well as reliable data transfer. In fact, TCP is actually\nmore complex than our description—we intentionally did not discuss a\nvariety of TCP patches, fixes, and improvements that are widely\nimplemented in various versions of TCP. All of this complexity, however, is\nhidden from the network application. If a client on one host wants to send\ndata reliably to a server on another host, it simply opens a TCP socket to the\nserver and pumps data into that socket. The client-server application is\nblissfully unaware of TCP’s complexity. In Section 3.6, we examined congestion control from a broad\nperspective, and in Section 3.7, we showed how TCP implements\ncongestion control. We learned that congestion control is imperative for the\nwell-being of the network. Without congestion control, a network can easily\nbecome gridlocked, with little or no data being transported end-to-end. In\nSection 3.7, we learned that classic TCP implements an end-to-end\ncongestion-control mechanism that additively increases its transmission rate\nwhen the TCP connection’s path is judged to be congestion-free, and\nmultiplicatively decreases its transmission rate when loss occurs. This\nmechanism also strives to give each TCP connection passing through a\ncongested link an equal share of the link bandwidth. We also studied several\nnewer variations of TCP congestion control that try to determine TCP’s\nsending rate rate more quickly than classic TCP, use a delay-based approach\nor explicit congestion notification from the network (rather than a loss-\nbased approach) to determine TCP’s sending rate. We also examined in"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 506,
    "text": "some depth the impact of TCP connection establishment and slow start on\nlatency. We observed that in many important scenarios, connection\nestablishment and slow start significantly contribute to end-to-end delay. We emphasize once more that while TCP congestion control has evolved\nover the years, it remains an area of intensive research and will likely\ncontinue to evolve in the upcoming years. To wrap up this chapter, in\nSection 3.8, we studied recent developments in implementing many of the\ntransport layer’s functions—reliable data transfer, congestion control,\nconnection establishment, and more—in the application layer using the\nQUIC protocol. In Chapter 1, we said that a computer network can be partitioned into\nthe ­“network edge” and the “network core.” The network edge covers\neverything that happens in the end systems. Having now covered the\napplication layer and the t­ransport layer, our discussion of the network edge\nis complete. It is time to explore the network core! This journey begins in\nthe next two chapters, where we’ll study the network layer, and continues\ninto Chapter 6, where we’ll study the link layer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 507,
    "text": "Homework Problems and Questions\nChapter 3 Review Questions\nSECTIONS 3.1–3.3\nR1. Suppose the network layer provides the following service. The\nnetwork layer in the source host accepts a segment of maximum size\n1,200 bytes and a destination host address from the transport layer. The network layer then guarantees to deliver the segment to the\ntransport layer at the destination host. Suppose many network\napplication processes can be running at the destination host. a. Design the simplest possible transport-layer protocol that will\nget application data to the desired process at the destination host. Assume the operating system in the destination host has\nassigned a 4-byte port number to each running application\nprocess. b. Modify this protocol so that it provides a “return address” to the\ndestination process. c. In your protocols, does the transport layer “have to do anything”\nin the core of the computer network? R2. Consider a planet where everyone belongs to a family of six, every\nfamily lives in its own house, each house has a unique address, and\neach person in a given house has a unique name. Suppose this planet\nhas a mail service that delivers letters from source house to\ndestination house. The mail service requires that (1) the letter be in an\nenvelope, and that (2) the address of the destination house (and\nnothing more) be clearly written on the envelope. Suppose each"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 508,
    "text": "family has a delegate family member who collects and distributes\nletters for the other family members. The letters do not necessarily\nprovide any indication of the recipients of the letters. a. Using the solution to Problem R1 above as inspiration, describe\na protocol that the delegates can use to deliver letters from a\nsending family member to a receiving family member. b. In your protocol, does the mail service ever have to open the\nenvelope and examine the letter in order to provide its service? R3. How is a UDP socket fully identified? What about a TCP socket? What is the difference between the full identification of both sockets? R4. Describe why an application developer might choose to run an\napplication over UDP rather than TCP. R5. Why is it that voice and video traffic is often sent over TCP rather\nthan UDP in today’s Internet? (Hint: The answer we are looking for\nhas nothing to do with TCP’s congestion-control mechanism.) R6. Is it possible for an application to enjoy reliable data transfer even\nwhen the application runs over UDP? If so, how? R7. Suppose a process in Host C has a UDP socket with port number\n6789. Suppose both Host A and Host B each send a UDP segment to\nHost C with destination port number 6789. Will both of these\nsegments be directed to the same socket at Host C? If so, how will the\nprocess at Host C know that these two segments originated from two\ndifferent hosts? R8. Suppose that a Web server runs in Host C on port 80. Suppose this\nWeb server uses persistent connections, and is currently receiving\nrequests from two different Hosts, A and B. Are all of the requests\nbeing sent through the same socket at Host C? If they are being"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 509,
    "text": "passed through different sockets, do both of the sockets have port 80? Discuss and explain. SECTION 3.4\nR9. In our rdt protocols, why did we need to introduce sequence\nnumbers? R10. In our rdt protocols, why did we need to introduce timers? R11. Suppose that the roundtrip delay between sender and receiver is\nconstant and known to the sender. Would a timer still be necessary in\nprotocol rdt 3.0, assuming that packets can be lost? Explain. R12. Visit the Go-Back-N interactive animation at the Companion\nWebsite. a. Have the source send five packets, and then pause the animation\nbefore any of the five packets reach the destination. Then kill the\nfirst packet and resume the animation. Describe what happens. b. Repeat the experiment, but now let the first packet reach the\ndestination and kill the first acknowledgment. Describe again\nwhat happens. c. Finally, try sending six packets. What happens? R13. Repeat R12, but now with the Selective Repeat interactive animation. How are Selective Repeat and Go-Back-N different? SECTION 3.5\nR14. True or false? a. Host A is sending Host B a large file over a TCP connection. Assume Host B has no data to send Host A. Host B will not send\nacknowledgments to Host A because Host B cannot piggyback\nthe acknowledgments on data."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 510,
    "text": "b. The size of the TCP rwnd never changes throughout the\nduration of the connection. c. Suppose Host A is sending Host B a large file over a TCP\nconnection. The number of unacknowledged bytes that A sends\ncannot exceed the size of the receive buffer. d. Suppose Host A is sending a large file to Host B over a TCP\nconnection. If the sequence number for a segment of this\nconnection is m, then the sequence number for the subsequent\nsegment will necessarily be m + 1.\ne. The TCP segment has a field in its header for rwnd. f. Suppose that the last SampleRTT in a TCP connection is equal\nto 1 sec. The current value of TimeoutInterval for the\nconnection will necessarily be ≥ 1 sec. g. Suppose Host A sends one segment with sequence number 38\nand 4 bytes of data over a TCP connection to Host B. In this\nsame segment, the acknowledgment number is necessarily 42. R15. Suppose Host A sends two TCP segments back to back to Host B\nover a TCP connection. The first segment has sequence number 90;\nthe second has sequence number 110.\na. How much data is in the first segment? b. Suppose that the first segment is lost but the second segment\narrives at B. In the acknowledgment that Host B sends to Host\nA, what will be the acknowledgment number? R16. Consider the Telnet example discussed in Section 3.5. A few seconds\nafter the user types the letter ‘C,’ the user types the letter ‘R.’ After\ntyping the letter ‘R,’ how many segments are sent, and what is put in\nthe sequence number and acknowledgment fields of the segments?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 511,
    "text": "SECTION 3.7\nR17. Consider two hosts, A and B, transmitting a large file to a server C,\nover a bottleneck link with rate R. To transfer the file, the hosts use\nTCP with the same parameters (including MSS and RTT) and start\ntheir transmissions at the same time. Host A uses a single TCP\nconnection for the entire file, while Host B uses 9 simultaneous TCP\nconnections, each for a portion (i.e., a chunk) of the file. What is the\noverall transmission rate achieved by each host at the beginning of\nthe file transfer? Is this situation fair? R18. True or false? Consider congestion control in TCP. When the timer\nexpires at the sender, the value of ssthresh is set to one half of its\nprevious value. R19. According to the discussion of TCP splitting in the sidebar in Section\n3.7, the response time with TCP splitting is approximately 4 × RTT\n+ RTT  + processing time, as opposed to 4 × RTT + processing time\nwhen a direct connection is used. Assume that RTT BE is 0.5 × RTT. For what values of RTT  does TCP splitting have a shorter delay\nthan a direct connection? Problems\nP1. Suppose Client A requests a web page from Server S through HTTP\nand its socket is associated with port 33000.\na. What are the source and destination ports for the segments sent\nfrom A to S? b. What are the source and destination ports for the segments sent\nfrom S to A? FE\nBE\nFE"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 512,
    "text": "c. Can Client A contact to Server S using UDP as the transport\nprotocol? d. Can Client A request multiple resources in a single TCP\nconnection? P2. Consider Figure 3.5.\na. Let us assume the following change: at B we want to access an\nFTP server from host A. What port number should be used to\nreplace port 80? b. Would there be an error if the right process of C used port\nnumber 8080? c. What are the source and destination network and port values in\nthe ­segments flowing from the server back to the clients’\nprocesses? P3. UDP and TCP use 1s complement for their checksums. Suppose you\nhave the following three 16 bit words: 0101001101100110;\n0111010010110100; 0000110111000001. What is the 1s complement\nof the sum of these words? Show all work. Why is it that UDP offers\na checksum? With the 1’s complement scheme, how does the receiver\ndetect errors? Describe how a single bit flip can be detected. P4. Assume that a host receives a UDP segment with 01011101 11110010\n(we separated the values of each byte with a space for clarity) as the\nchecksum. The host adds the 16-bit words over all necessary fields\nexcluding the checksum and obtains the value 00110010 00001101. Is\nthe segment considered correctly received or not? What does the\nreceiver do? P5. Suppose that the UDP receiver computes the Internet checksum for\nthe received UDP segment and finds that it matches the value carried"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 513,
    "text": "in the checksum field. Can the receiver be absolutely certain that no\nbit errors have occurred? Explain. P6. Consider our motivation for correcting protocol rdt2.1. Show that\nthe receiver, shown in Figure 3.60, when operating with the sender\nshown in Figure 3.11, can lead the sender and receiver to enter into a\ndeadlock state, where each is waiting for an event that will never\noccur. Figure 3.60 ♦An incorrect receiver for protocol rdt 2.1\nP7. In protocol rdt3.0, the ACK packets flowing from the receiver to\nthe sender do not have sequence numbers (although they do have an\nACK field that contains the sequence number of the packet they are\nacknowledging). Why is it that our ACK packets do not require\nsequence numbers? P8. Draw the FSM for the receiver side of protocol rdt3.0."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 514,
    "text": "P9. Give a trace of the operation of protocol rdt3.0 when data packets\nand acknowledgment packets are garbled. Your trace should be\nsimilar to that used in Figure 3.16. P10. Consider a channel that can lose packets but has a maximum delay\nthat is known. Modify protocol rdt2.1 to include sender timeout\nand retransmit. Informally argue why your protocol can communicate\ncorrectly over this channel. P11. Consider the rdt2.2 receiver in Figure 3.14, and the creation of a\nnew packet in the self-transition (i.e., the transition from the state\nback to itself) in the Wait-for-0-from-below and the Wait-for-1-from-\nbelow states: sndpkt=make_pkt(ACK,1,checksum) and\nsndpkt=make_pkt(ACK,0,checksum). Would the protocol\nwork correctly if this action were removed from the self-transition in\nthe Wait-for-1-from-below state? Justify your answer. What if this\nevent were removed from the self-transition in the Wait-for-0-from-\nbelow state? [Hint: In this latter case, consider what would happen if\nthe first sender-to-receiver packet were corrupted.] P12. The sender side of rdt3.0 simply ignores (that is, takes no action\non) all received packets that are either in error or have the wrong\nvalue in the acknum field of an acknowledgment packet. Suppose\nthat in such circumstances, rdt3.0 were simply to retransmit the\ncurrent data packet. Would the protocol still work? (Hint: Consider\nwhat would happen if there were only bit errors; there are no packet\nlosses but premature timeouts can occur. Consider how many times\nthe nth packet is sent, in the limit as n approaches infinity.) P13. Assume Host A is streaming a video from Server B using UDP. Also\nassume that the network suddenly becomes very congested while"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 515,
    "text": "Host A is seeing the video. Is there any way to handle this situation\nwith UDP? What about with TCP? Is there any other option? P14. Consider a stop-and-wait data-transfer protocol that provides error\nchecking and retransmissions but uses only negative\nacknowledgments. Assume that negative acknowledgments are never\ncorrupted. Would such a protocol work over a channel with bit errors? What about over a lossy channel with bit errors? P15. Consider the cross-country example shown in Figure 3.17, with a 10\nGbps link. How big would the window size have to be for the channel\nutilization to be greater than 98 percent? Suppose that the size of a\npacket is 1,500 bytes, including header fields and data. P16. Suppose an application uses rdt 3.0 as its transport layer protocol. As the stop-and-wait protocol has very low channel utilization (shown\nin the cross-country example), the designers of this application let the\nreceiver keep sending back a number (more than two) of alternating\nACK 0 and ACK 1 even if the corresponding data have not arrived at\nthe receiver. Would this application design increase the channel\nutilization? Why? Are there any potential problems with this\napproach? Explain. P17. Consider two network entities, A and B, which are connected by a\nperfect bi-directional channel (i.e., any message sent will be received\ncorrectly; the channel will not corrupt, lose, or re-order packets). A\nand B are to deliver data messages to each other in an alternating\nmanner: First, A must deliver a message to B, then B must deliver a\nmessage to A, then A must deliver a message to B and so on. If an\nentity is in a state where it should not attempt to deliver a message to\nthe other side, and there is an event like rdt_send(data) call\nfrom above that attempts to pass data down for transmission to the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 516,
    "text": "other side, this call from above can simply be ignored with a call to\nrdt_unable_to_send(data), which informs the higher layer\nthat it is currently not able to send data. [Note: This simplifying\nassumption is made so you don’t have to worry about buffering data.] Draw a FSM specification for this protocol (one FSM for A, and one\nFSM for B!). Note that you do not have to worry about a reliability\nmechanism here; the main point of this question is to create a FSM\nspecification that reflects the synchronized behavior of the two\nentities. You should use the following events and actions that have the\nsame meaning as protocol rdt1.0 in Figure 3.9: rdt_send(data),\npacket = make_pkt(data), udt_send(packet),\nrdt_rcv(packet), extract (packet,data),\ndeliver_data(data). Make sure your protocol reflects the strict\nalternation of sending between A and B. Also, make sure to indicate\nthe initial states for A and B in your FSM descriptions. P18. In the generic SR protocol that we studied in Section 3.4.4, the sender\ntransmits a message as soon as it is available (if it is in the window)\nwithout waiting for an acknowledgment. Suppose now that we want\nan SR protocol that sends messages two at a time. That is, the sender\nwill send a pair of messages and will send the next pair of messages\nonly when it knows that both messages in the first pair have been\nreceived correctly. Suppose that the channel may lose messages but will not corrupt or\nreorder messages. Design an error-control protocol for the\nunidirectional reliable transfer of messages. Give an FSM description\nof the sender and receiver. Describe the format of the packets sent\nbetween sender and receiver, and vice versa. If you use any procedure\ncalls other than those in Section 3.4 (for example, udt_send(),"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 517,
    "text": "start_timer(), rdt_rcv(), and so on), clearly state their\nactions. Give an example (a timeline trace of sender and receiver)\nshowing how your protocol recovers from a lost packet. P19. Suppose Host A and Host B use a GBN protocol with window size N\n= 3 and a long-enough range of sequence numbers. Assume Host A\nsends six ­application messages to Host B and that all messages are\ncorrectly received, except for the first acknowledgment and the fifth\ndata segment. Draw a timing diagram (similar to Figure 3.22),\nshowing the data segments and the acknowledgments sent along with\nthe corresponding sequence and ­acknowledge numbers, respectively. P20. Consider a scenario in which Host A and Host B want to send\nmessages to Host C. Hosts A and C are connected by a channel that\ncan lose and corrupt (but not reorder) messages. Hosts B and C are\nconnected by another channel (independent of the channel connecting\nA and C) with the same properties. The transport layer at Host C\nshould alternate in delivering messages from A and B to the layer\nabove (that is, it should first deliver the data from a packet from A,\nthen the data from a packet from B, and so on). Design a stop-and-\nwait-like error-control protocol for reliably transferring packets from\nA and B to C, with alternating delivery at C as described above. Give\nFSM descriptions of A and C. (Hint: The FSM for B should be\nessentially the same as for A.) Also, give a description of the packet\nformat(s) used. P21. Suppose we have two network entities, A and B. B has a supply of\ndata messages that will be sent to A according to the following\nconventions. When A gets a request from the layer above to get the\nnext data (D) message from B, A must send a request (R) message to\nB on the A-to-B channel. Only when B receives an R message can it"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 518,
    "text": "send a data (D) message back to A on the B-to-A channel. A should\ndeliver exactly one copy of each D message to the layer above. R\nmessages can be lost (but not corrupted) in the A-to-B channel; D\nmessages, once sent, are always delivered correctly. The delay along\nboth channels is unknown and variable. Design (give an FSM description of) a protocol that incorporates the\nappropriate mechanisms to compensate for the loss-prone A-to-B\nchannel and implements message passing to the layer above at entity\nA, as discussed above. Use only those mechanisms that are absolutely\nnecessary. P22. Consider the GBN protocol with a sender window size of 4 and a\nsequence number range of 1,024. Suppose that at time t, the next in-\norder packet that the receiver is expecting has a sequence number of\nk. Assume that the medium does not reorder messages. Answer the\nfollowing questions:\na. What are the possible sets of sequence numbers inside the\nsender’s window at time t? Justify your answer. b. What are all possible values of the ACK field in all possible\nmessages currently propagating back to the sender at time t? Justify your answer. P23. Give one example where buffering out-of-order segments would\nsignificantly improve the throughput of a GBN protocol. P24. Consider a scenario where the three hosts A, B, and C are connected\nas a ring: A to B, B to C, and C to A. Assume that A and C run\nprotocol rdt3.0, whereas B simply relays all messages received\nfrom A to C.\na. Does this arrangement enable reliable delivery of messages from\nA to C?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 519,
    "text": "b. Can B tell if a certain message has been correctly received by A? P25. We have said that an application may choose UDP for a transport\nprotocol because UDP offers finer application control (than TCP) of\nwhat data is sent in a segment and when. Why does an application have more control of what data is sent in a\nsegment? Why does an application have more control on when the segment is\nsent? P26. Consider transferring an enormous file of L bytes from Host A to Host\nB. Assume an MSS of 536 bytes. a. What is the maximum value of L such that TCP sequence\nnumbers are not exhausted? Recall that the TCP sequence\nnumber field has 4 bytes. b. For the L you obtain in (a), find how long it takes to transmit the\nfile. Assume that a total of 66 bytes of transport, network, and\ndata-link header are added to each segment before the resulting\npacket is sent out over a 155 Mbps link. Ignore flow control and\ncongestion control so A can pump out the segments back to back\nand continuously. P27. Host A and B are communicating over a TCP connection following\nRFC 5681. Host B has already received from A all bytes up through\nbyte 96. ­Suppose Host A then sends two segments to Host B back-to-\nback. The first and the second segments contain 40 and 80 bytes of\ndata, respectively. In the first segment, the sequence number is 97, the\nsource port number is 302, and the destination port number is 80. Host B sends an acknowledgment whenever it receives a segment\nfrom Host A."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 520,
    "text": "a. In the second segment sent from Host A to B, what are the\nsequence number, source port number, and destination port\nnumber? b. If the first segment arrives before the second segment, in the\nacknowledgment of the first arriving segment, what is the\nacknowledgment number, the source port number, and the\ndestination port number? c. If the second segment arrives before the first segment, in the\nacknowledgment of the first arriving segment, what is the\nacknowledgment number? d. Suppose the two segments sent by A arrive in order at B. The first\nacknow­ledgment arrives after the first timeout interval. What is\nthe sequence number of the next segment that A will transmit? P28. Host A and B are directly connected with a 10 Gbps link. There is one\nTCP connection between the two hosts, and Host A is sending to Host\nB an enormous file over this connection. Host A can send its\napplication data into its TCP socket at a rate as high as 1 Gbps, but\nHost B can read out of its TCP receive buffer at a maximum rate of\n600 Mbps. Describe the effect of TCP flow control. P29. SYN cookies were discussed in Section 3.5.6.\na. Why is it necessary for the server to use a special initial sequence\nnumber in the SYNACK? b. Suppose an attacker knows that a target host uses SYN cookies. Can the attacker create half-open or fully open connections by\nsimply sending an ACK packet to the target? Why or why not? c. Suppose an attacker collects a large amount of initial sequence\nnumbers sent by the server. Can the attacker cause the server to"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 521,
    "text": "create many fully open connections by sending ACKs with those\ninitial sequence numbers? Why? P30. Consider the network shown in Scenario 2 in Section 3.6.1. Suppose\nboth sending hosts A and B have some fixed timeout values. a. Argue that increasing the size of the finite buffer of the router\nmight possibly decrease the throughput (λ ). b. Now suppose both hosts dynamically adjust their timeout values\n(like what TCP does) based on the buffering delay at the router. Would increasing the buffer size help to increase the throughput? Why? P31. Suppose that the five measured SampleRTT values (see Section\n3.5.3) are 112 ms, 140 ms, 110 ms, 90 ms, and 90 ms. Compute the\nEstimatedRTT after each of these SampleRTT values is obtained,\nusing a value of α = 0.125 and assuming that the value of\nEstimatedRTT was 120 ms just before the first of these five\nsamples were obtained. Compute also the DevRTT after each sample is obtained, assuming a\nvalue of β = 0.25 and assuming the value of DevRTT was 6 ms just\nbefore the first of these five samples was obtained. Finally, compute the TCP TimeoutInterval after each of these\nsamples is obtained. P32. Consider the TCP procedure for estimating RTT. Suppose that α = 0.1. Let SampleRTT  be the most recent sample RTT, let SampleRTT\nbe the next most recent sample RTT, and so on. a. For a given TCP connection, suppose four acknowledgments\nhave been returned with corresponding sample RTTs:\nout\n2"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 522,
    "text": "SampleRTT , SampleRTT , SampleRTT , and SampleRTT . Express EstimatedRTT in terms of the four sample RTTs. b. Generalize your formula for n sample RTTs. c. For the formula in part (b) let n approach infinity. Comment on\nwhy this averaging procedure is called an exponential moving\naverage. P33. In Section 3.5.3, we discussed TCP’s estimation of RTT. Why do you\nthink TCP avoids measuring the SampleRTT for retransmitted\nsegments? P34. What is the relationship between the variable SendBase in Section\n3.5.4 and the variable LastByteRcvd in Section 3.5.5? P35. What is the relationship between the variable LastByteRcvd in\nSection 3.5.5 and the variable y in Section 3.5.4? P36. In Section 3.5.4, we saw that TCP waits until it has received three\nduplicate ACKs before performing a fast retransmit. Why do you\nthink the TCP designers chose not to perform a fast retransmit after\nthe first duplicate ACK for a segment is received? P37. Compare GBN, SR, and TCP (no delayed ACK). Assume that the\ntimeout values for all three protocols are sufficiently long such that\nfive consecutive data segments and their corresponding ACKs can be\nreceived (if not lost in the channel) by the receiving host (Host B) and\nthe sending host (Host A) respectively. Suppose Host A sends five\ndata segments to Host B, and the second segment (sent from A) is\nlost. In the end, all five data segments have been correctly received by\nHost B.\na. How many segments has Host A sent in total and how many\nACKs has Host B sent in total? What are their sequence\nnumbers? Answer this question for all three protocols. 3\n1"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 523,
    "text": "b. If the timeout values for all three protocol are much longer than 5\nRTT, then which protocol successfully delivers all five data\nsegments in shortest time interval? P38. In our description of TCP in Figure 3.53, the value of the threshold,\nssthresh, is set as ssthresh=cwnd/2 in several places and\nssthresh value is referred to as being set to half the window size\nwhen a loss event occurred. Must the rate at which the sender is\nsending when the loss event occurred be approximately equal to\ncwnd segments per RTT? Explain your answer. If your answer is no,\ncan you suggest a different manner in which ssthresh should be\nset? P39. Consider Figure 3.46(b). If λ'  increases beyond R/2, can λ  increase\nbeyond R/3? Explain. Now consider Figure 3.46(c). If λ'  increases\nbeyond R/2, can λ  increase beyond R/4 under the assumption that a\npacket will be forwarded twice on average from the router to the\nreceiver? Explain. P40. Consider Figure 3.61. Assuming TCP Reno is the protocol\nexperiencing the behavior shown above, answer the following\nquestions. In all cases, you should provide a short discussion\njustifying your answer. VideoNote\nExamining the behavior of TCP\na. Identify the intervals of time when TCP slow start is operating. b. Identify the intervals of time when TCP congestion avoidance is\noperating. in\nout\nin\nout"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 524,
    "text": "c. After the 16th transmission round, is segment loss detected by a\ntriple duplicate ACK or by a timeout? d. After the 22nd transmission round, is segment loss detected by a\ntriple duplicate ACK or by a timeout? Figure 3.61 ♦TCP window size as a function of time\ne. What is the initial value of ssthresh at the first transmission\nround? f. What is the value of ssthresh at the 22nd transmission round? g. During what transmission round is the 70th segment sent? h. Assuming a packet loss is detected after the 26th round by the\nreceipt of a triple duplicate ACK, what will be the values of the\ncongestion window size and of ssthresh?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 525,
    "text": "i. Suppose TCP Tahoe is used (instead of TCP Reno), and assume\nthat triple duplicate ACKs are received at the 10th round. What\nare the ssthresh and the congestion window size at the 11th\nround? j. Again, suppose TCP Tahoe is used, and there is a timeout event at\nthe 22nd round. How many packets have been sent out from the\n17th round till the 22nd round, inclusive? P41. Refer to Figure 3.55, which illustrates the convergence of TCP’s\nAIMD algorithm. Suppose that instead of a multiplicative decrease,\nTCP decreased the window size by a constant amount. Would the\nresulting AIAD algorithm converge to an equal share algorithm? Justify your answer using a diagram similar to Figure 3.55. P42. In Section 3.5.4, we discussed the doubling of the timeout interval\nafter a timeout event. This mechanism is a form of congestion control. Why does TCP need a window-based congestion-control mechanism\n(as studied in Section 3.7) in addition to this doubling-timeout-\ninterval mechanism? P43. Host A is sending an enormous file to Host B over a TCP connection. Over this connection there is never any packet loss and the timers\nnever expire. Denote the transmission rate of the link connecting Host\nA to the Internet by R bps. Suppose that the process in Host A is\ncapable of sending data into its TCP socket at a rate S bps, where S =\n10 · R. Further suppose that the TCP receive buffer is large enough to\nhold the entire file, and the send buffer can hold only one percent of\nthe file. What would prevent the process in Host A from continuously\npassing data to its TCP socket at rate S bps? TCP flow control? TCP\ncongestion control? Or something else? Elaborate."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 526,
    "text": "P44. Consider sending a large file from a host to another over a TCP\nconnection that has no loss. a. Suppose TCP uses AIMD for its congestion control without slow\nstart. Assuming cwnd increases by 1 MSS every time a batch of\nACKs is received and assuming approximately constant round-\ntrip times, how long does it take for cwnd increase from 6 MSS\nto 12 MSS (assuming no loss events)? b. What is the average throughput (in terms of MSS and RTT) for\nthis connection up through time = 6 RTT? P45. Consider Figure 3.54. Suppose that at t , the sending rate at which\ncongestion loss next occurs drops to 0.75*W\n (unbeknownst to the\nTCP senders, of course). Show the evolution of both TCP Reno and\nTCP CUBIC for two more rounds each (Hint: note that the times at\nwhich TCP Reno and TCP CUBIC react to congestion loss may not\nbe the same anymore). P46. Consider Figure 3.54 again. Suppose that at t , the sending rate at\nwhich congestion loss next occurs increases to 1.5*W\n. Show the\nevolution of both TCP Reno and TCP CUBIC for at two more rounds\neach (Hint: see the hint in P45). P47. Recall the macroscopic description of TCP throughput. In the period\nof time from when the connection’s rate varies from W/(2 ∙ RTT) to\nW/RTT, only one packet is lost (at the very end of the period). a. Show that the loss rate (fraction of packets lost) is equal to\nL = loss rate =\n3\n8 W 2 + 3\n4 W\nb. Use the result above to show that if a connection has loss rate L,\nthen its average rate is approximately given by\nmax\nmax"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 527,
    "text": "≈1.22⋅MSS\nRTT√L\nP48. Consider that only a single TCP (Reno) connection uses one 54 Mbps\nwireless link which does not buffer any data. Suppose that this link is\nthe only congested link between the sending and receiving hosts. Assume that the TCP sender has a huge file to send to the receiver\nand the receiver’s receive buffer is much larger than the congestion\nwindow. We also make the following assumptions: each TCP segment size is\n536 bytes; the two-way propagation delay of this connection is 6\nmsec; and this TCP ­connection is always in congestion avoidance\nphase, that is, ignore slow start. a. What is the maximum window size (in segments) that this TCP\nconnection can achieve? b. What is the average window size (in segments) and average\nthroughput (in bps) of this TCP connection? c. How long would it take for this TCP connection to reach its\nmaximum window again after recovering from a packet loss? P49. Consider the scenario described in the previous problem. Suppose that\nthe 10 Mbps link can buffer a finite number of segments. Argue that\nin order for the link to always be busy sending data, we would like to\nchoose a buffer size that is at least the product of the link speed C and\nthe two-way propagation delay between the sender and the receiver. P50. Repeat Problem 48, but replacing the 54 Mbps link with a 100 Gbps\nlink and an RTT of 60 ms. Note that in your answer to part c, you will\nrealize that it takes a very long time for the congestion window size to\nreach its maximum window size after recovering from a packet loss. Can you consider solutions for this?"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 528,
    "text": "P51. Let T (measured by RTT) denote the time interval that a TCP\nconnection takes to increase its congestion window size from W/2 to\nW, where W is the maximum congestion window size. Argue that T is\na function of TCP’s average throughput. P52. Consider a simplified TCP’s AIMD algorithm where the congestion\nwindow size is measured in number of segments, not in bytes. In\nadditive increase, the congestion window size increases by one\nsegment in each RTT. In multiplicative decrease, the congestion\nwindow size decreases by half (if the result is not an integer, round\ndown to the nearest integer). Suppose that two TCP connections, C\nand C , share a single congested link of speed 30 segments per\nsecond. Assume that both C  and C  are in the congestion avoidance\nphase. Connection C ’s RTT is 50 msec and connection C ’s RTT is\n100 msec. Assume that when the data rate in the link exceeds the\nlink’s speed, all TCP connections experience data segment loss. a. If both C  and C  at time t  have a congestion window of 10\nsegments, what are their congestion window sizes after 1000\nmsec? b. In the long run, will these two connections get the same share of\nthe bandwidth of the congested link? Explain. P53. Consider the network described in the previous problem. Now\nsuppose that the two TCP connections, C1 and C2, have the same\nRTT of 100 msec. Suppose that at time t , C1’s congestion window\nsize is 15 segments but C2’s congestion window size is 10 segments. a. What are their congestion window sizes after 2200 msec? b. In the long run, will these two connections get about the same\nshare of the bandwidth of the congested link? 2\n2\n2\n2\n0"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 529,
    "text": "c. We say that two connections are synchronized, if both\nconnections reach their maximum window sizes at the same time\nand reach their minimum window sizes at the same time. In the\nlong run, will these two connections get synchronized\neventually? If so, what are their maximum window sizes? d. Will this synchronization help to improve the utilization of the\nshared link? Why? Sketch some idea to break this\nsynchronization. P54. Consider a modification to TCP’s congestion control algorithm. Instead of additive increase, we can use multiplicative increase. A\nTCP sender increases its window size by a small positive constant a\n(0 < a < 1) whenever it receives a valid ACK. Find the functional\nrelationship between loss rate L and maximum congestion window W.\nArgue that for this modified TCP, regardless of TCP’s average\nthroughput, a TCP connection always spends the same amount of time\nto increase its congestion window size from W/2 to W.\nP55. In our discussion of TCP futures in Section 3.7, we noted that to\nachieve a throughput of 10 Gbps, TCP could only tolerate a segment\nloss probability of 2 · 10\n (or equivalently, one loss event for every\n5,000,000,000 segments). Show the derivation for the values of 2 ·\n (1 out of 5,000,000) for the RTT and MSS values given in\nSection 3.7. If TCP needed to support a 100 Gbps connection, what\nwould the tolerable loss be? P56. In our discussion of TCP congestion control in Section 3.7, we\nimplicitly assumed that the TCP sender always had data to send. Consider now the case that the TCP sender sends a large amount of\ndata and then goes idle (since it has no more data to send) at t . TCP\nremains idle for a relatively long period of time and then wants to\n−10\n−10"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 530,
    "text": "send more data at t . What are the advantages and disadvantages of\nhaving TCP use the cwnd and ssthresh values from t  when\nstarting to send data at t ? What alternative would you recommend? Why? P57. In this problem, we investigate whether either UDP or TCP provides a\ndegree of end-point authentication. a. Consider a server that receives a request within a UDP packet\nand responds to that request within a UDP packet (for example,\nas done by a DNS server). If a client with IP address X spoofs its\naddress with address Y, where will the server send its response? b. Suppose a server receives a SYN with IP source address Y, and\nafter responding with a SYNACK, receives an ACK with IP\nsource address Y with the correct acknowledgment number. Assuming the server chooses a random initial sequence number\nand there is no “man-in-the-middle,” can the server be certain\nthat the client is indeed at Y (and not at some other address X that\nis spoofing Y)? P58. In this problem, we consider the delay introduced by the TCP slow-\nstart phase. Consider a client and a Web server directly connected by\none link of rate R. Suppose the client wants to retrieve an object\nwhose size is exactly equal to 15 S, where S is the maximum segment\nsize (MSS). Denote the round-trip time between client and server as\nRTT (assumed to be constant). Ignoring protocol headers, determine\nthe time to retrieve the object (including TCP connection\nestablishment) when\na. 4 S/R > S/R + RTT > 2S/R\nb. S/R + RTT > 4 S/R\nc. S/R > RTT. 1"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 533,
    "text": "AN INTERVIEW WITH...\nVan Jacobson\nVan Jacobson works at Google and was previously a\nResearch Fellow at PARC. Prior to that, he was co-founder\nand Chief Scientist of Packet Design. Before that, he was\nChief Scientist at Cisco. Before joining Cisco, he was head of\nthe Network Research Group at Lawrence Berkeley National\nLaboratory and taught at UC Berkeley and Stanford. Van\nreceived the ACM SIGCOMM Award in 2001 for outstanding\nlifetime contribution to the field of communication networks\nand the IEEE Kobayashi Award in 2002 for “contributing to\nthe understanding of network congestion and developing\ncongestion control mechanisms that enabled the successful\nscaling of the Internet”. He was elected to the U.S. National\nAcademy of Engineering in 2004."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 534,
    "text": "Courtesy of Van Jacobson\nPlease describe one or two of the most\nexciting projects you have worked on\nduring your career. What were the biggest\nchallenges? School teaches us lots of ways to find answers. In\nevery interesting problem I’ve worked on, the\nchallenge has been finding the right question. When Mike Karels and I started looking at TCP\ncongestion, we spent months staring at protocol\nand packet traces asking “Why is it failing?”. One\nday in Mike’s office, one of us said “The reason I\ncan’t figure out why it fails is because I don’t\nunderstand how it ever worked to begin with.”\nThat turned out to be the right question and it"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 535,
    "text": "forced us to figure out the “ack clocking” that\nmakes TCP work. After that, the rest was easy. More generally, where do you see the\nfuture of networking and the Internet? For most people, the Web is the Internet. Networking geeks smile politely since we know\nthe Web is an application running over the Internet\nbut what if they’re right? The Internet is about\nenabling conversations between pairs of hosts. The\nWeb is about distributed information production\nand consumption. “Information propagation” is a\nvery general view of communication of which\n“pairwise conversation” is a tiny subset. We need\nto move into the larger tent. Networking today\ndeals with broadcast media (radios, PONs, etc.) by\npretending it’s a point-to-point wire. That’s\nmassively inefficient. Terabits-per-second of data\nare being exchanged all over the World via thumb\ndrives or smart phones but we don’t know how to\ntreat that as “networking”. ISPs are busily setting\nup caches and CDNs to scalably distribute video\nand audio. Caching is a necessary part of the\nsolution but there’s no part of today’s networking\n—from Information, Queuing or Traffic Theory\ndown to the Internet protocol specs—that tells us\nhow to engineer and deploy it. I think and hope\nthat over the next few years, networking will"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 536,
    "text": "evolve to embrace the much larger vision of\ncommunication that underlies the Web. What people inspired you professionally? When I was in grad school, Richard Feynman\nvisited and gave a colloquium. He talked about a\npiece of Quantum theory that I’d been struggling\nwith all semester and his explanation was so\nsimple and lucid that what had been\nincomprehensible gibberish to me became obvious\nand inevitable. That ability to see and convey the\nsimplicity that underlies our complex world seems\nto me a rare and wonderful gift. What are your recommendations for\nstudents who want careers in computer\nscience and networking? It’s a wonderful field—computers and networking\nhave probably had more impact on society than\nany invention since the book. Networking is\nfundamentally about connecting stuff, and\nstudying it helps you make intellectual\nconnections: Ant foraging & Bee dances\ndemonstrate protocol design better than RFCs,\ntraffic jams or people leaving a packed stadium are\nthe essence of congestion, and students finding\nflights back to school in a post-Thanksgiving\nblizzard are the core of dynamic routing. If you’re"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 537,
    "text": "interested in lots of stuff and want to have an\nimpact, it’s hard to imagine a better field."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 538,
    "text": "The Network Layer:\nData Plane\nWe learned in the previous chapter that the transport layer provides\nvarious forms of process-to-process communication by relying on the\nnetwork layer’s host-to-host communication service. We also learned\nthat the transport layer does so without any knowledge about how the\nnetwork layer actually implements this service. So perhaps you’re now\nwondering, what’s under the hood of the host-to-host communication\nservice, what makes it tick? In this chapter and the next, we’ll learn exactly how the network\nlayer can provide its host-to-host communication service. We’ll see\nthat unlike the transport and application layers, there is a piece of the\nnetwork layer in each and every host and router in the network. Because of this, network-layer protocols are among the most\nchallenging (and therefore among the most interesting!) in the protocol\nstack. Since the network layer is arguably the most complex layer in the\nprotocol stack, we’ll have a lot of ground to cover here. Indeed, there\nis so much to cover that we cover the network layer in two chapters. We’ll see that the network layer can be decomposed into two\ninteracting parts, the data plane and the control plane. In Chapter 4,\nwe’ll first cover the data plane functions of the network layer—the"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 539,
    "text": "per-router functions in the network layer that determine how a\ndatagram (that is, a network-layer packet) arriving on one of a router’s\ninput links is forwarded to one of that router’s output links. We’ll\ncover both traditional IP forwarding (where forwarding is based on a\ndatagram’s destination address) and generalized forwarding (where\nforwarding and other functions may be performed using values in\nseveral different fields in the datagram’s header). We’ll study the IPv4\nand IPv6 protocols and addressing in detail. In Chapter 5, we’ll cover\nthe control plane functions of the network layer—the network-wide\nlogic that controls how a datagram is routed among routers along an\nend-to-end path from the source host to the destination host. We’ll\ncover routing algorithms, as well as routing protocols, such as OSPF\nand BGP, that are in widespread use in today’s Internet. Traditionally,\nthese control-plane routing protocols and data-plane forwarding\nfunctions have been implemented together, monolithically, within a\nrouter. Software-defined networking (SDN) explicitly separates the\ndata plane and control plane by implementing these control plane\nfunctions as a separate service, typically in a remote “controller.” We’ll\nalso cover SDN controllers in Chapter 5. This distinction between data-plane and control-plane functions in the\nnetwork layer is an important concept to keep in mind as you learn about\nthe network layer —it will help structure your thinking about the network\nlayer and reflects a modern view of the network layer’s role in computer\nnetworking."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 540,
    "text": "4.1 Overview of Network Layer\nFigure 4.1 shows a simple network with two hosts, H1 and H2, and several\nrouters on the path between H1 and H2. Let’s suppose that H1 is sending\ninformation to H2, and consider the role of the network layer in these hosts\nand in the intervening routers. The network layer in H1 takes segments\nfrom the transport layer in H1, encapsulates each segment into a datagram,\nand then sends the datagrams to its nearby router, R1. At the receiving host,\nH2, the network layer receives the datagrams from its nearby router R2,\nextracts the transport-layer segments, and delivers the segments up to the\ntransport layer at H2. The primary data-plane role of each router is to\nforward datagrams from its input links to its output links; the primary role\nof the network control plane is to coordinate these local, per-router\nforwarding actions so that datagrams are ultimately transferred end-to-end,\nalong paths of routers between source and destination hosts. Note that the\nrouters in Figure 4.1 are shown with a truncated protocol stack, that is, with\nno upper layers above the network layer, because routers do not run\napplication- and transport-layer protocols such as those we examined in\nChapters 2 and 3. 4.1.1 Forwarding and Routing: The Data and\nControl Planes\nThe primary role of the network layer is deceptively simple—to move\npackets from a sending host to a receiving host. To do so, two important\nnetwork-layer functions can be identified:"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 541,
    "text": "•\nForwarding. When a packet arrives at a router’s input link, the router\nmust move the packet to the appropriate output link. For example, a\npacket arriving from Host H1 to Router R1 in Figure 4.1 must be\nforwarded to the next router on a path to H2. As we will see, forwarding\nis but one function (albeit the most common and important one!) implemented in the data plane. In the more general case, which we’ll\ncover in Section 4.4, a packet might also be blocked from exiting a\nrouter (for example, if the packet originated at a known malicious\nsending host, or if the packet were destined to a forbidden destination\nhost), or might be duplicated and sent over multiple outgoing links. •\nRouting. The network layer must determine the route or path taken by\npackets as they flow from a sender to a receiver. The algorithms that\ncalculate these paths are referred to as routing algorithms. A routing\nalgorithm would determine, for example, the path along which packets\nflow from H1 to H2 in Figure 4.1. Routing is implemented in the\ncontrol plane of the network layer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 542,
    "text": "Figure 4.1 ♦The network layer\nThe terms forwarding and routing are often used interchangeably by\nauthors discussing the network layer. We’ll use these terms much more\nprecisely in this book. Forwarding refers to the router-local action of"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 543,
    "text": "transferring a packet from an input link interface to the appropriate output\nlink interface. Forwarding takes place at very short timescales (typically a\nfew nanoseconds), and thus is typically implemented in hardware. Routing\nrefers to the network-wide process that determines the end-to-end paths that\npackets take from source to destination. Routing takes place on much\nlonger timescales (typically seconds), and as we will see is often\nimplemented in software. Using our driving analogy, consider the trip from\nPennsylvania to Florida undertaken by our traveler back in Section 1.3.1. During this trip, our driver passes through many interchanges en route to\nFlorida. We can think of forwarding as the process of getting through a\nsingle interchange: A car enters the interchange from one road and\ndetermines which road it should take to leave the interchange. We can think\nof routing as the process of planning the trip from Pennsylvania to Florida:\nBefore embarking on the trip, the driver has consulted a map and chosen\none of many paths possible, with each path consisting of a series of road\nsegments connected at interchanges. A key element in every network router is its forwarding table. A router\nforwards a packet by examining the value of one or more fields in the\narriving packet’s header, and then using these header values to index into its\nforwarding table. The value stored in the forwarding table entry for those\nvalues indicates the outgoing link interface at that router to which that\npacket is to be forwarded. For example, in Figure 4.2, a packet with header\nfield value of 0110 arrives to a router. The router indexes into its forwarding\ntable and determines that the output link interface for this packet is interface\n2. The router then internally forwards the packet to interface 2. In Section\n4.2, we’ll look inside a router and examine the forwarding function in much\ngreater detail. Forwarding is the key function performed by the data-plane\nfunctionality of the network layer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 544,
    "text": "Control Plane: The Traditional Approach\nBut now you are undoubtedly wondering how a router’s forwarding tables\nare configured in the first place. This is a crucial issue, one that exposes the\nimportant interplay between forwarding (in data plane) and routing (in\ncontrol plane). As shown in Figure 4.2, the routing algorithm determines the\ncontents of the routers’ forwarding tables. In this example, a routing\nalgorithm runs in each and every router and both forwarding and routing\nfunctions are contained within a router. As we’ll see in Sections 5.3 and 5.4,\nthe routing algorithm function in one router communicates with the routing\nalgorithm function in other routers to compute the values for its forwarding\ntable. How is this communication performed? By exchanging routing\nmessages containing routing information according to a routing protocol! We’ll cover routing algorithms and protocols in Sections 5.2 through 5.4."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 545,
    "text": "Figure 4.2 ♦Routing algorithms determine values in forward tables\nThe distinct and different purposes of the forwarding and routing\nfunctions can be further illustrated by considering the hypothetical (and\nunrealistic, but technically feasible) case of a network in which all\nforwarding tables are configured directly by human network operators\nphysically present at the routers. In this case, no routing protocols would be\nrequired! Of course, the human operators would need to interact with each\nother to ensure that the forwarding tables were configured in such a way\nthat packets reached their intended destinations. It’s also likely that human\nconfiguration would be more error-prone and much slower to respond to\nchanges in the network topology than a routing protocol. We’re thus\nfortunate that all networks have both a forwarding and a routing function! Control Plane: The SDN Approach\nThe approach to implementing routing functionality shown in Figure 4.2—\nwith each router having a routing component that communicates with the\nrouting component of other routers—has been the traditional approach\nadopted by routing vendors in their products, at least until recently. Our\nobservation that humans could manually configure forwarding tables does\nsuggest, however, that there may be other ways for control-plane\nfunctionality to determine the contents of the data-plane forwarding tables. Figure 4.3 shows an alternative approach in which a physically\nseparate, remote controller computes and distributes the forwarding tables\nto be used by each and every router. Note that the data plane components of\nFigures 4.2 and 4.3 are identical. In Figure 4.3; however, control-plane\nrouting functionality is separated from the physical router—the routing\ndevice performs forwarding only, while the remote controller computes and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 546,
    "text": "distributes forwarding tables. The remote controller might be implemented\nin a remote data center with high reliability and redundancy, and might be\nmanaged by the ISP or some third party. How might the routers and the\nremote controller communicate? By exchanging messages containing\nforwarding tables and other pieces of routing information. The control-\nplane approach shown in Figure 4.3 is at the heart of software-defined\nnetworking (SDN), where the network is “software-defined” because the\ncontroller that computes forwarding tables and interacts with routers is\nimplemented in software. Increasingly, these software implementations are\nalso open, that is, similar to Linux OS code, the code is publically available,\nallowing ISPs (and networking researchers and students!) to innovate and\npropose changes to the software that controls network-layer functionality. We will cover the SDN control plane in Section 5.5."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 547,
    "text": "Figure 4.3 ♦A remote controller determines and distributes values\nin forwarding tables\n4.1.2 Network Service Model\nBefore delving into the network layer’s data plane, let’s wrap up our\nintroduction by taking the broader view and consider the different types of\nservice that might be offered by the network layer. When the transport layer\nat a sending host transmits a packet into the network (that is, passes it down\nto the network layer at the sending host), can the transport layer rely on the\nnetwork layer to deliver the packet to the destination? When multiple\npackets are sent, will they be delivered to the transport layer in the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 548,
    "text": "receiving host in the order in which they were sent? Will the amount of time\nbetween the sending of two sequential packet transmissions be the same as\nthe amount of time between their reception? Will the network provide any\nfeedback about congestion in the network? The answers to these questions\nand others are determined by the service model provided by the network\nlayer. The network service model defines the characteristics of end-to-end\ndelivery of packets between sending and receiving hosts. Let’s now consider some possible services that the network layer could\nprovide. These services could include:\n•\nGuaranteed delivery. This service guarantees that a packet sent by a\nsource host will eventually arrive at the destination host. •\nGuaranteed delivery with bounded delay. This service not only\nguarantees delivery of the packet, but delivery within a specified host-\nto-host delay bound (for example, within 100 msec). •\nIn-order packet delivery. This service guarantees that packets arrive at\nthe destination in the order that they were sent. •\nGuaranteed minimal bandwidth. This network-layer service emulates\nthe behavior of a transmission link of a specified bit rate (for example, 1\nMbps) between sending and receiving hosts. As long as the sending host\ntransmits bits (as part of packets) at a rate below the specified bit rate,\nthen all packets are eventually delivered to the destination host. •\nSecurity. The network layer could encrypt all datagrams at the source\nand decrypt them at the destination, thereby providing confidentiality to\nall transport-layer segments. This is only a partial list of services that a network layer could provide—\nthere are countless variations possible."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 549,
    "text": "The Internet’s network layer provides a single service, known as best-\neffort service. With best-effort service, packets are neither guaranteed to be\nreceived in the order in which they were sent, nor is their eventual delivery\neven guaranteed. There is no guarantee on the end-to-end delay nor is there\na minimal bandwidth guarantee. It might appear that best-effort service is a\neuphemism for no service at all—a network that delivered no packets to the\ndestination would satisfy the definition of best-effort delivery service! Other network architectures have defined and implemented service models\nthat go beyond the Internet’s best-effort service. For example, the ATM\nnetwork architecture [Black 1995] provides for guaranteed in-order delay,\nbounded delay, and guaranteed minimal bandwidth. There have also been\nproposed service model extensions to the Internet architecture; for example,\nthe Intserv architecture [RFC 1633] aims to provide end-end delay\nguarantees and congestion-free communication. Interestingly, in spite of\nthese well-developed alternatives, the Internet’s basic best-effort service\nmodel combined with adequate bandwidth provisioning and bandwidth-\nadaptive application-level protocols such as the DASH protocol we\nencountered in Section 2.6.2 have arguably proven to be more than “good\nenough” to enable an amazing range of applications, including streaming\nvideo services such as Netflix and video-over-IP, real-time conferencing\napplications such as Skype and Facetime. An Overview of Chapter 4\nHaving now provided an overview of the network layer, we’ll cover the\ndata-plane component of the network layer in the following sections in this\nchapter. In Section 4.2, we’ll dive down into the internal hardware\noperations of a router, including input and output packet processing, the\nrouter’s internal switching mechanism, and packet queuing and scheduling."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 550,
    "text": "In Section 4.3, we’ll take a look at traditional IP forwarding, in which\npackets are forwarded to output ports based on their destination IP\naddresses. We’ll encounter IP addressing, the celebrated IPv4 and IPv6\nprotocols and more. In Section 4.4, we’ll cover more generalized\nforwarding, where packets may be forwarded to output ports based on a\nlarge number of header values (i.e., not only based on destination IP\naddress). Packets may be blocked or duplicated at the router, or may have\ncertain header field values rewritten—all under software control. This more\ngeneralized form of packet forwarding is a key component of a modern\nnetwork data plane, including the data plane in software-defined networks\n(SDN). In Section 4.5, we’ll learn about “middleboxes” that can perform\nfunctions in addition to forwarding. We mention here in passing that the terms forwarding and switching are\noften used interchangeably by computer-networking researchers and\npractitioners; we’ll use both terms interchangeably in this textbook as well. While we’re on the topic of terminology, it’s also worth mentioning two\nother terms that are often used interchangeably, but that we will use more\ncarefully. We’ll reserve the term packet switch to mean a general packet-\nswitching device that transfers a packet from input link interface to output\nlink interface, according to values in a packet’s header fields. Some packet\nswitches, called link-layer switches (examined in Chapter 6), base their\nforwarding decision on values in the fields of the link-layer frame; switches\nare thus referred to as link-layer (layer 2) devices. Other packet switches,\ncalled routers, base their forwarding decision on header field values in the\nnetwork-layer datagram. Routers are thus network-layer (layer 3) devices. (To fully appreciate this important distinction, you might want to review\nSection 1.5.2, where we discuss network-layer datagrams and link-layer"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 551,
    "text": "frames and their relationship.) Since our focus in this chapter is on the\nnetwork layer, we’ll mostly use the term router in place of packet switch."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 552,
    "text": "4.2 What’s Inside a Router? Now that we’ve overviewed the data and control planes within the network\nlayer, the important distinction between forwarding and routing, and the\nservices and functions of the network layer, let’s turn our attention to its\nforwarding function—the actual transfer of packets from a router’s\nincoming links to the appropriate outgoing links at that router. A high-level view of a generic router architecture is shown in Figure\n4.4. Four router components can be identified:\nFigure 4.4 ♦Router architecture\n•\nInput ports. An input port performs several key functions. It performs\nthe physical layer function of terminating an incoming physical link at a\nrouter; this is shown in the leftmost box of an input port and the\nrightmost box of an output port in Figure 4.4. An input port also"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 553,
    "text": "performs link-layer functions needed to interoperate with the link layer\nat the other side of the incoming link; this is represented by the middle\nboxes in the input and output ports. Perhaps most crucially, a lookup\nfunction is also performed at the input port; this will occur in the\nrightmost box of the input port. It is here that the forwarding table is\nconsulted to determine the router output port to which an arriving\npacket will be forwarded via the switching fabric. Control packets (for\nexample, packets carrying routing protocol information) are forwarded\nfrom an input port to the routing processor. Note that the term “port”\nhere—referring to the physical input and output router interfaces—is\ndistinctly different from the software ports associated with network\napplications and sockets discussed in Chapters 2 and 3. In practice, the\nnumber of ports supported by a router can range from a relatively small\nnumber in enterprise routers, to hundreds of 10 Gbps ports in a router at\nan ISP’s edge, where the number of incoming lines tends to be the\ngreatest. The Juniper MX2020, edge router, for example, supports up to\n800 100 Gbps Ethernet ports, with an overall router system capacity of\n800 Tbps [Juniper MX 2020 2020]. •\nSwitching fabric. The switching fabric connects the router’s input ports\nto its output ports. This switching fabric is completely contained within\nthe router—a network inside of a network router! •\nOutput ports. An output port stores packets received from the\nswitching fabric and transmits these packets on the outgoing link by\nperforming the necessary link-layer and physical-layer functions. When\na link is bidirectional (that is, carries traffic in both directions), an\noutput port will typically be paired with the input port for that link on\nthe same line card."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 554,
    "text": "•\nRouting processor. The routing processor performs control-plane\nfunctions. In traditional routers, it executes the routing protocols (which\nwe’ll study in Sections 5.3 and 5.4), maintains routing tables and\nattached link state information, and computes the forwarding table for\nthe router. In SDN routers, the routing processor is responsible for\ncommunicating with the remote controller in order to (among other\nactivities) receive forwarding table entries computed by the remote\ncontroller, and install these entries in the router’s input ports. The\nrouting processor also performs the network management functions that\nwe’ll study in Section 5.7. A router’s input ports, output ports, and switching fabric are almost\nalways implemented in hardware, as shown in Figure 4.4. To appreciate\nwhy a hardware implementation is needed, consider that with a 100 Gbps\ninput link and a 64-byte IP datagram, the input port has only 5.12 ns to\nprocess the datagram before another datagram may arrive. If N ports are\ncombined on a line card (as is often done in practice), the datagram-\nprocessing pipeline must operate N times faster—far too fast for software\nimplementation. Forwarding hardware can be implemented either using a\nrouter vendor’s own hardware designs, or constructed using purchased\nmerchant-silicon chips (for example, as sold by companies such as Intel and\nBroadcom). While the data plane operates at the nanosecond time scale, a router’s\ncontrol functions—executing the routing protocols, responding to attached\nlinks that go up or down, communicating with the remote controller (in the\nSDN case) and performing management functions—operate at the\nmillisecond or second timescale. These control plane functions are thus\nusually implemented in software and execute on the routing processor\n(typically a traditional CPU)."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 555,
    "text": "Before delving into the details of router internals, let’s return to our\nanalogy from the beginning of this chapter, where packet forwarding was\ncompared to cars entering and leaving an interchange. Let’s suppose that\nthe interchange is a roundabout, and that as a car enters the roundabout, a\nbit of processing is required. Let’s consider what information is required for\nthis processing:\n•\nDestination-based forwarding. Suppose the car stops at an entry station\nand indicates its final destination (not at the local roundabout, but the\nultimate destination of its journey). An attendant at the entry station\nlooks up the final destination, determines the roundabout exit that leads\nto that final destination, and tells the driver which roundabout exit to\ntake. •\nGeneralized forwarding. The attendant could also determine the car’s\nexit ramp on the basis of many other factors besides the destination. For\nexample, the selected exit ramp might depend on the car’s origin, for\nexample the state that issued the car’s license plate. Cars from a certain\nset of states might be directed to use one exit ramp (that leads to the\ndestination via a slow road), while cars from other states might be\ndirected to use a different exit ramp (that leads to the destination via\nsuperhighway). The same decision might be made based on the model,\nmake and year of the car. Or a car not deemed roadworthy might be\nblocked and not be allowed to pass through the roundabout. In the case\nof generalized forwarding, any number of factors may contribute to the\nattendant’s choice of the exit ramp for a given car. Once the car enters the roundabout (which may be filled with other cars\nentering from other input roads and heading to other roundabout exits), it"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 556,
    "text": "eventually leaves at the prescribed roundabout exit ramp, where it may\nencounter other cars leaving the roundabout at that exit. We can easily recognize the principal router components in Figure 4.4\nin this analogy—the entry road and entry station correspond to the input\nport (with a lookup function to determine to local outgoing port); the\nroundabout corresponds to the switch fabric; and the roundabout exit road\ncorresponds to the output port. With this analogy, it’s instructive to consider\nwhere bottlenecks might occur. What happens if cars arrive blazingly fast\n(for example, the roundabout is in Germany or Italy!) but the station\nattendant is slow? How fast must the attendant work to ensure there’s no\nbackup on an entry road? Even with a blazingly fast attendant, what\nhappens if cars traverse the roundabout slowly—can backups still occur? And what happens if most of the cars entering at all of the roundabout’s\nentrance ramps all want to leave the roundabout at the same exit ramp—can\nbackups occur at the exit ramp or elsewhere? How should the roundabout\noperate if we want to assign priorities to different cars, or block certain cars\nfrom entering the roundabout in the first place? These are all analogous to\ncritical questions faced by router and switch designers. In the following subsections, we’ll look at router functions in more\ndetail. [Turner 1988; McKeown 1997a; Partridge 1998; Iyer 2008; Serpanos\n2011; Zilberman 2019] provide a discussion of specific router architectures. For concreteness and simplicity, we’ll initially assume in this section that\nforwarding decisions are based only on the packet’s destination address,\nrather than on a generalized set of packet header fields. We will cover the\ncase of more generalized packet forwarding in Section 4.4."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 557,
    "text": "4.2.1 Input Port Processing and Destination-Based\nForwarding\nA more detailed view of input processing is shown in Figure 4.5. As just\ndiscussed, the input port’s line-termination function and link-layer\nprocessing implement the physical and link layers for that individual input\nlink. The lookup performed in the input port is central to the router’s\noperation—it is here that the router uses the forwarding table to look up the\noutput port to which an arriving packet will be forwarded via the switching\nfabric. The forwarding table is either computed and updated by the routing\nprocessor (using a routing protocol to interact with the routing processors in\nother network routers) or is received from a remote SDN controller. The\nforwarding table is copied from the routing processor to the line cards over\na separate bus (e.g., a PCI bus) indicated by the dashed line from the\nrouting processor to the input line cards in Figure 4.4. With such a shadow\ncopy at each line card, forwarding decisions can be made locally, at each\ninput port, without invoking the centralized routing processor on a per-\npacket basis and thus avoiding a centralized processing bottleneck. Figure 4.5 ♦Input port processing\nLet’s now consider the “simplest” case that the output port to which an\nincoming packet is to be switched is based on the packet’s destination"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 558,
    "text": "address. In the case of 32-bit IP addresses, a brute-force implementation of\nthe forwarding table would have one entry for every possible destination\naddress. Since there are more than 4 billion possible addresses, this option\nis totally out of the question. As an example of how this issue of scale can be handled, let’s suppose\nthat our router has four links, numbered 0 through 3, and that packets are to\nbe forwarded to the link interfaces as follows:\nClearly, for this example, it is not necessary to have 4 billion entries in the\nrouter’s forwarding table. We could, for example, have the following\nforwarding table with just four entries:\nWith this style of forwarding table, the router matches a prefix of the\npacket’s destination address with the entries in the table; if there’s a match,\nthe router forwards the packet to a link associated with the match. For\nexample, suppose the packet’s destination address is 11001000\n00010111 00010110 10100001; because the 21-bit prefix of this\naddress matches the first entry in the table, the router forwards the packet to\nlink interface 0. If a prefix doesn’t match any of the first three entries, then\nthe router forwards the packet to the default interface 3. Although this\nsounds simple enough, there’s a very important subtlety here. You may have\nnoticed that it is possible for a destination address to match more than one\nentry. For example, the first 24 bits of the address 11001000 00010111\n00011000 10101010 match the second entry in the table, and the first\n21 bits of the address match the third entry in the table. When there are\nmultiple matches, the router uses the longest prefix matching rule; that is,\nit finds the longest matching entry in the table and forwards the packet to\nthe link interface associated with the longest prefix match. We’ll see exactly\nwhy this longest prefix-matching rule is used when we study Internet\naddressing in more detail in Section 4.3."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 559,
    "text": "Given the existence of a forwarding table, lookup is conceptually\nsimple—­hardware logic just searches through the forwarding table looking\nfor the longest prefix match. But at Gigabit transmission rates, this lookup\nmust be performed in nanoseconds (recall our earlier example of a 10 Gbps\nlink and a 64-byte IP datagram). Thus, not only must lookup be performed\nin hardware, but techniques beyond a simple linear search through a large\ntable are needed; surveys of fast lookup algorithms can be found in [Gupta\n2001, Ruiz-Sanchez 2001]. Special attention must also be paid to memory\naccess times, resulting in designs with embedded on-chip DRAM and faster\nSRAM (used as a DRAM cache) memories. In practice, Ternary Content\nAddressable Memories (TCAMs) are also often used for lookup [Yu 2004]. With a TCAM, a 32-bit IP address is presented to the memory, which\nreturns the content of the forwarding table entry for that address in\nessentially constant time. The Cisco Catalyst 6500 and 7600 Series routers\nand switches can hold upwards of a million TCAM forwarding table entries\n[Cisco TCAM 2014]. Once a packet’s output port has been determined via the lookup, the\npacket can be sent into the switching fabric. In some designs, a packet may\nbe temporarily blocked from entering the switching fabric if packets from\nother input ports are currently using the fabric. A blocked packet will be\nqueued at the input port and then scheduled to cross the fabric at a later\npoint in time. We’ll take a closer look at the blocking, queuing, and\nscheduling of packets (at both input ports and output ports) shortly. Although “lookup” is arguably the most important action in input port\nprocessing, many other actions must be taken: (1) physical- and link-layer\nprocessing must occur, as discussed previously; (2) the packet’s version\nnumber, checksum and time-to-live field—all of which we’ll study in\nSection 4.3—must be checked and the latter two fields rewritten; and (3)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 560,
    "text": "counters used for network management (such as the number of IP\ndatagrams received) must be updated. Let’s close our discussion of input port processing by noting that the\ninput port steps of looking up a destination IP address (“match”) and then\nsending the packet into the switching fabric to the specified output port\n(“action”) is a specific case of a more general “match plus action”\nabstraction that is performed in many networked devices, not just routers. In\nlink-layer switches (covered in Chapter 6), link-layer destination addresses\nare looked up and several actions may be taken in addition to sending the\nframe into the switching fabric towards the output port. In firewalls\n(covered in Chapter 8)—devices that filter out selected incoming packets—\nan incoming packet whose header matches a given criteria (e.g., a\ncombination of source/destination IP addresses and transport-layer port\nnumbers) may be dropped (action). In a network address translator (NAT,\ncovered in Section 4.3), an incoming packet whose transport-layer port\nnumber matches a given value will have its port number rewritten before\nforwarding (action). Indeed, the “match plus action” abstraction [Bosshart\n2013] is both powerful and prevalent in network devices today, and is\ncentral to the notion of generalized forwarding that we’ll study in Section\n4.4. 4.2.2 Switching\nThe switching fabric is at the very heart of a router, as it is through this\nfabric that the packets are actually switched (that is, forwarded) from an\ninput port to an output port. Switching can be accomplished in a number of\nways, as shown in Figure 4.6:"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 561,
    "text": "•\nSwitching via memory. The simplest, earliest routers were traditional\ncomputers, with switching between input and output ports being done\nunder direct control of the CPU (routing processor). Input and output\nports functioned as traditional I/O devices in a traditional operating\nsystem. An input port with an arriving packet first signaled the routing\nprocessor via an interrupt. The packet was then copied from the input\nport into processor memory. The routing processor then extracted the\ndestination address from the header, looked up the appropriate output\nport in the forwarding table, and copied the packet to the output port’s\nbuffers. In this scenario, if the memory bandwidth is such that a\nmaximum of B packets per second can be written into, or read from,\nmemory, then the overall forwarding throughput (the total rate at which\npackets are transferred from input ports to output ports) must be less\nthan B/2. Note also that two packets cannot be forwarded at the same\ntime, even if they have different destination ports, since only one\nmemory read/write can be done at a time over the shared system bus. Some modern routers switch via memory. A major difference from early\nrouters, however, is that the lookup of the destination address and the\nstoring of the packet into the appropriate memory location are\nperformed by processing on the input line cards. In some ways, routers\nthat switch via memory look very much like shared-memory\nmultiprocessors, with the processing on a line card switching (writing)\npackets into the memory of the appropriate output port. Cisco’s Catalyst\n8500 series switches [Cisco 8500 2020] internally switches packets via\na shared memory. •\nSwitching via a bus. In this approach, an input port transfers a packet\ndirectly to the output port over a shared bus, without intervention by the\nrouting processor. This is typically done by having the input port pre-"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 562,
    "text": "pend a switch-internal label (header) to the packet indicating the local\noutput port to which this packet is being transferred and transmitting the\npacket onto the bus. All output ports receive the packet, but only the\nport that matches the label will keep the packet. The label is then\nremoved at the output port, as this label is only used within the switch\nto cross the bus. If multiple packets arrive to the router at the same time,\neach at a different input port, all but one must wait since only one\npacket can cross the bus at a time. Because every packet must cross the\nsingle bus, the switching speed of the router is limited to the bus speed;\nin our roundabout analogy, this is as if the roundabout could only\ncontain one car at a time. Nonetheless, switching via a bus is often\nsufficient for routers that operate in small local area and enterprise\nnetworks. The Cisco 6500 router [Cisco 6500 2020] internally switches\npackets over a 32-Gbps-backplane bus. •\nSwitching via an interconnection network. One way to overcome the\nbandwidth limitation of a single, shared bus is to use a more\nsophisticated interconnection network, such as those that have been\nused in the past to interconnect processors in a multiprocessor computer\narchitecture. A crossbar switch is an interconnection network consisting\nof 2N buses that connect N input ports to N output ports, as shown in\nFigure 4.6. Each vertical bus intersects each horizontal bus at a\ncrosspoint, which can be opened or closed at any time by the switch\nfabric controller (whose logic is part of the switching fabric itself). When a packet arrives from port A and needs to be forwarded to port Y,\nthe switch controller closes the crosspoint at the intersection of busses A\nand Y, and port A then sends the packet onto its bus, which is picked up\n(only) by bus Y. Note that a packet from port B can be forwarded to port\nX at the same time, since the A-to-Y and B-to-X packets use different"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 563,
    "text": "input and output busses. Thus, unlike the previous two switching\napproaches, crossbar switches are capable of forwarding multiple\npackets in parallel. A crossbar switch is non-blocking—a packet being\nforwarded to an output port will not be blocked from reaching that\noutput port as long as no other packet is currently being forwarded to\nthat output port. However, if two packets from two different input ports\nare destined to that same output port, then one will have to wait at the\ninput, since only one packet can be sent over any given bus at a time. Cisco 12000 series switches [Cisco 12000 2020] use a crossbar\nswitching network; the Cisco 7600 series can be configured to use\neither a bus or crossbar switch [Cisco 7600 2020]. •\nMore sophisticated interconnection networks use multiple stages of\nswitching elements to allow packets from different input ports to\nproceed towards the same output port at the same time through the\nmulti-stage switching fabric. See [Tobagi 1990] for a survey of switch\narchitectures. The Cisco CRS employs a three-stage non-blocking\nswitching strategy. A router’s switching capacity can also be scaled by\nrunning multiple switching fabrics in parallel. In this approach, input\nports and output ports are connected to N switching fabrics that operate\nin parallel. An input port breaks a packet into K smaller chunks, and\nsends (“sprays”) the chunks through K of these N switching fabrics to\nthe selected output port, which reassembles the K chunks back into the\noriginal packet."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 564,
    "text": "Figure 4.6 ♦Three switching techniques\n4.2.3 Output Port Processing\nOutput port processing, shown in Figure 4.7, takes packets that have been\nstored in the output port’s memory and transmits them over the output link. This includes selecting (i.e., scheduling) and de-queuing packets for\ntransmission, and performing the needed link-layer and physical-layer\ntransmission functions."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 565,
    "text": "Figure 4.7 ♦Output port processing\n4.2.4 Where Does Queuing Occur? If we consider input and output port functionality and the configurations\nshown in Figure 4.6, it’s clear that packet queues may form at both the input\nports and the output ports, just as we identified cases where cars may wait\nat the inputs and outputs of the traffic intersection in our roundabout\nanalogy. The location and extent of ­queuing (either at the input port queues\nor the output port queues) will depend on the traffic load, the relative speed\nof the switching fabric, and the line speed. Let’s now consider these queues\nin a bit more detail, since as these queues grow large, the router’s memory\ncan eventually be exhausted and packet loss will occur when no memory is\navailable to store arriving packets. Recall that in our earlier ­discussions, we\nsaid that packets were “lost within the network” or “dropped at a router.” It\nis here, at these queues within a router, where such packets are actually\ndropped and lost. Suppose that the input and output line speeds (transmission rates) all\nhave an identical transmission rate of R\n packets per second, and that there\nare N input ports and N output ports. To further simplify the discussion, let’s\nassume that all packets have the same fixed length, and that packets arrive\nto input ports in a synchronous manner. That is, the time to send a packet on\nany link is equal to the time to receive a packet on any link, and during such\nline"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 566,
    "text": "an interval of time, either zero or one packets can arrive on an input link. Define the switching fabric transfer rate R\n as the rate at which packets\ncan be moved from input port to output port. If R\n is N times faster than\nR\n, then only negligible queuing will occur at the input ports. This is\nbecause even in the worst case, where all N input lines are receiving\npackets, and all packets are to be forwarded to the same output port, each\nbatch of N packets (one packet per input port) can be cleared through the\nswitch fabric before the next batch arrives. Input Queuing\nBut what happens if the switch fabric is not fast enough (relative to the\ninput line speeds) to transfer all arriving packets through the fabric without\ndelay? In this case, packet queuing can also occur at the input ports, as\npackets must join input port queues to wait their turn to be transferred\nthrough the switching fabric to the output port. To illustrate an important\nconsequence of this queuing, consider a crossbar switching fabric and\nsuppose that (1) all link speeds are identical, (2) that one packet can be\ntransferred from any one input port to a given output port in the same\namount of time it takes for a packet to be received on an input link, and (3)\npackets are moved from a given input queue to their desired output queue in\nan FCFS manner. Multiple packets can be transferred in parallel, as long as\ntheir output ports are different. However, if two packets at the front of two\ninput queues are destined for the same output queue, then one of the packets\nwill be blocked and must wait at the input queue—the switching fabric can\ntransfer only one packet to a given output port at a time. Figure 4.8 shows an example in which two packets (darkly shaded) at\nthe front of their input queues are destined for the same upper-right output\nport. Suppose that the switch fabric chooses to transfer the packet from the\nswitch\nswitch\nline"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 567,
    "text": "front of the upper-left queue. In this case, the darkly shaded packet in the\nlower-left queue must wait. But not only must this darkly shaded packet\nwait, so too must the lightly shaded packet that is queued behind that packet\nin the lower-left queue, even though there is no contention for the middle-\nright output port (the destination for the lightly shaded packet). This\nphenomenon is known as head-of-the-line (HOL) blocking in an input-\nqueued switch—a queued packet in an input queue must wait for transfer\nthrough the fabric (even though its output port is free) because it is blocked\nby another packet at the head of the line. [Karol 1987] shows that due to\nHOL blocking, the input queue will grow to unbounded length (informally,\nthis is equivalent to saying that significant packet loss will occur) under\ncertain assumptions as soon as the packet arrival rate on the input links\nreaches only 58 percent of their capacity. A number of solutions to HOL\nblocking are discussed in [McKeown 1997]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 568,
    "text": "Figure 4.8 ♦HOL blocking at and input-queued switch\nOutput Queuing\nLet’s next consider whether queuing can occur at a switch’s output ports. Suppose that R\n is again N times faster than R\n and that packets arriving\nat each of the N input ports are destined to the same output port. In this\nswitch\nline"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 569,
    "text": "case, in the time it takes to send a single packet onto the outgoing link, N\nnew packets will arrive at this output port (one from each of the N input\nports). Since the output port can transmit only a single packet in a unit of\ntime (the packet transmission time), the N arriving packets will have to\nqueue (wait) for transmission over the outgoing link. Then N more packets\ncan possibly arrive in the time it takes to transmit just one of the N packets\nthat had just previously been queued. And so on. Thus, packet queues can\nform at the output ports even when the switching fabric is N times faster\nthan the port line speeds. Eventually, the number of queued packets can\ngrow large enough to exhaust available memory at the output port. When there is not enough memory to buffer an incoming packet, a\ndecision must be made to either drop the arriving packet (a policy known as\ndrop-tail) or remove one or more already-queued packets to make room for\nthe newly arrived packet. In some cases, it may be advantageous to drop (or\nmark the header of) a packet before the buffer is full in order to provide a\ncongestion signal to the sender. This marking could be done using the\nExplicit Congestion Notification bits that we studied in Section 3.7.2. A\nnumber of proactive packet-dropping and -marking policies (which\ncollectively have become known as active queue management (AQM)\nalgorithms) have been proposed and analyzed [Labrador 1999, Hollot\n2002]. One of the most widely studied and implemented AQM algorithms is\nthe Random Early Detection (RED) algorithm [Christiansen 2001]. More\nrecent AQM policies include PIE (the Proportional Integral controller\nEnhanced [RFC 8033]), and CoDel [Nichols 2012]. Output port queuing is illustrated in Figure 4.9. At time t, a packet has\narrived at each of the incoming input ports, each destined for the uppermost\noutgoing port. Assuming identical line speeds and a switch operating at\nthree times the line speed, one time unit later (that is, in the time needed to"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 570,
    "text": "receive or send a packet), all three original packets have been transferred to\nthe outgoing port and are queued awaiting transmission. In the next time\nunit, one of these three packets will have been transmitted over the outgoing\nlink. In our example, two new packets have arrived at the incoming side of\nthe switch; one of these packets is destined for this uppermost output port. A consequence of such queuing is that a packet scheduler at the output\nport must choose one packet, among those queued, for transmission—a\ntopic we’ll cover in the following section. Figure 4.9 ♦Output port queuing"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 571,
    "text": "How Much Buffering Is “Enough?”\nOur study above has shown how a packet queue forms when bursts of\npackets arrive at a router’s input or (more likely) output port, and the packet\narrival rate temporarily exceeds the rate at which packets can be forwarded. The longer the amount of time that this mismatch persists, the longer the\nqueue will grow, until eventually a port’s buffers become full and packets\nare dropped. One natural question is how much buffering should be\nprovisioned at a port. It turns out the answer to this question is much more\ncomplicated than one might imagine and can teach us quite a bit about the\nsubtle interaction among congestion-aware senders at the network’s edge\nand the network core! For many years, the rule of thumb [RFC 3439] for buffer sizing was\nthat the amount of buffering (B) should be equal to an average round-trip\ntime (RTT, say 250 msec) times the link capacity (C). Thus, a 10-Gbps link\nwith an RTT of 250 msec would need an amount of buffering equal to B =\nRTT · C = 2.5 Gbits of buffers. This result was based on an analysis of the\nqueuing dynamics of a relatively small number of TCP flows [Villamizar\n1994]. More recent theoretical and experimental efforts [Appenzeller 2004],\nhowever, suggest that when a large number of independent TCP flows (N)\npass through a link, the amount of buffering needed is B = RTT · C/√N. In\ncore networks, where a large number of TCP flows typically pass through\nlarge backbone router links, the value of N can be large, with the decrease\nin needed buffer size becoming quite significant. [Appenzeller 2004;\nWischik 2005; Beheshti 2008] provide very readable discussions of the\nbuffer-sizing problem from a theoretical, implementation, and operational\nstandpoint. It’s temping to think that more buffering must be better—larger buffers\nwould allow a router to absorb larger fluctuations in the packet arrival rate,"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 572,
    "text": "thereby decreasing the router’s packet loss rate. But larger buffers also\nmean potentially longer queuing delays. For gamers and for interactive\nteleconferencing users, tens of milliseconds count. Increasing the amount of\nper-hop buffer by a factor of 10 to decrease packet loss could increase the\nend-end delay by a factor of 10! Increased RTTs also make TCP senders\nless responsive and slower to respond to incipient congestion and/or packet\nloss. These delay-based considerations show that buffering is a double-\nedged sword—buffering can be used to absorb short-term statistical\nfluctuations in traffic but can also lead to increased delay and the attendant\nconcerns. Buffering is a bit like salt—just the right amount of salt makes\nfood better, but too much makes it inedible! In the discussion above, we’ve implicitly assumed that many\nindependent senders are competing for bandwidth and buffers at a\ncongested link. While this is probably an excellent assumption for routers\nwithin the network core, at the network edge this may not hold. Figure\n4.10(a) shows a home router sending TCP segments to a remote game\nserver. Following [Nichols 2012], suppose that it takes 20 ms to transmit a\npacket (containing a gamer’s TCP segment), that there are negligible\nqueuing delays elsewhere on the path to the game server, and that the RTT\nis 200 ms. As shown in Figure 4.10(b), suppose that at time t = 0, a burst of\n25 packets arrives to the queue. One of these queued packets is then\ntransmitted once every 20 ms, so that at t = 200 msec, the first ACK arrives,\njust as the 21st packet is being transmitted. This ACK arrival causes the\nTCP sender to send another packet, which is queued at the outgoing link of\nthe home router. At t = 220, the next ACK arrives, and another TCP\nsegment is released by the gamer and is queued, as the 22nd packet is being\ntransmitted, and so on. You should convince yourself that in this scenario,\nACK clocking results in a new packet arriving at the queue every time a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 573,
    "text": "queued packet is sent, resulting in queue size at the home router’s outgoing\nlink that is always five packets! That is, the end-end-pipe is full (delivering\npackets to the destination at the path bottleneck rate of one packet every 20\nms), but the amount of queuing delay is constant and persistent. As a result,\nthe gamer is unhappy with the delay, and the parent (who even knows\nwireshark!) is confused because he or she doesn’t understand why delays\nare persistent and excessively long, even when there is no other traffic on\nthe home network. Figure 4.10 ♦Bufferbloat: persistent queues\nThis scenario above of long delay due to persistent buffering is known\nas bufferbloat and illustrates that not only is throughput important, but also\nminimal delay is important as well [Kleinrock 2018], and that the\ninteraction among senders at the network edge and queues within the\nnetwork can indeed be complex and subtle. The DOCSIS 3.1 standard for\ncable networks that we will study in Chapter 6, recently added a specific\nAQM mechanism [RFC 8033, RFC 8034] to combat bufferbloat, while\npreserving bulk throughput performance."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 574,
    "text": "4.2.5 Packet Scheduling\nLet’s now return to the question of determining the order in which queued\npackets are transmitted over an outgoing link. Since you yourself have\nundoubtedly had to wait in long lines on many occasions and observed how\nwaiting customers are served, you’re no doubt familiar with many of the\nqueuing disciplines commonly used in routers. There is first-come-first-\nserved (FCFS, also known as first-in-first-out, FIFO). The British are\nfamous for patient and orderly FCFS queuing at bus stops and in the\nmarketplace (“Oh, are you queuing?”). Other countries operate on a priority\nbasis, with one class of waiting customers given priority service over other\nwaiting customers. There is also round-robin queuing, where customers are\nagain divided into classes (as in priority queuing) but each class of\ncustomer is given service in turn. First-in-First-Out (FIFO)\nFigure 4.11 shows the queuing model abstraction for the FIFO link-\nscheduling discipline. Packets arriving at the link output queue wait for\ntransmission if the link is currently busy transmitting another packet. If\nthere is not sufficient buffering space to hold the arriving packet, the\nqueue’s packet-discarding policy then determines whether the packet will\nbe dropped (lost) or whether other packets will be removed from the queue\nto make space for the arriving packet, as discussed above. In our discussion\nbelow, we’ll ignore packet discard. When a packet is completely transmitted\nover the outgoing link (that is, receives service) it is removed from the\nqueue."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 575,
    "text": "Figure 4.11 ♦FIFO queuing abstraction\nThe FIFO (also known as first-come-first-served, or FCFS) scheduling\ndiscipline selects packets for link transmission in the same order in which\nthey arrived at the output link queue. We’re all familiar with FIFO queuing\nfrom service centers, where arriving customers join the back of the single\nwaiting line, remain in order, and are then served when they reach the front\nof the line. Figure 4.12 shows the FIFO queue in operation. Packet arrivals\nare indicated by numbered arrows above the upper timeline, with the\nnumber indicating the order in which the packet arrived. Individual packet\ndepartures are shown below the lower timeline. The time that a packet\nspends in service (being transmitted) is indicated by the shaded rectangle\nbetween the two timelines. In our examples here, let’s assume that each\npacket takes three units of time to be transmitted. Under the FIFO\ndiscipline, packets leave in the same order in which they arrived. Note that\nafter the departure of packet 4, the link remains idle (since packets 1\nthrough 4 have been transmitted and removed from the queue) until the\narrival of packet 5."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 576,
    "text": "Figure 4.12 ♦The FIFO queue in operation\nPriority Queuing\nUnder priority queuing, packets arriving at the output link are classified into\npriority classes upon arrival at the queue, as shown in Figure 4.13. In\npractice, a network operator may configure a queue so that packets carrying\nnetwork management information (for example, as indicated by the source\nor destination TCP/UDP port number) receive priority over user traffic;\nadditionally, real-time voice-over-IP packets might receive priority over\nnon-real-time traffic such e-mail packets. Each priority class typically has\nits own queue. When choosing a packet to transmit, the priority queuing\ndiscipline will transmit a packet from the highest priority class that has a\nnonempty queue (that is, has packets waiting for transmission). The choice\namong packets in the same priority class is typically done in a FIFO\nmanner."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 577,
    "text": "Figure 4.13 ♦The priority queuing model\nFigure 4.14 illustrates the operation of a priority queue with two\npriority classes. Packets 1, 3, and 4 belong to the high-priority class, and\npackets 2 and 5 belong to the low-priority class. Packet 1 arrives and,\nfinding the link idle, begins transmission. During the transmission of packet\n1, packets 2 and 3 arrive and are queued in the low- and high-priority\nqueues, respectively. After the transmission of packet 1, packet 3 (a high-\npriority packet) is selected for transmission over packet 2 (which, even\nthough it arrived earlier, is a low-priority packet). At the end of the\ntransmission of packet 3, packet 2 then begins transmission. Packet 4 (a\nhigh-priority packet) arrives during the transmission of packet 2 (a low-\npriority packet). Under a non-preemptive priority queuing discipline, the\ntransmission of a packet is not interrupted once it has begun. In this case,\npacket 4 queues for transmission and begins being transmitted after the\ntransmission of packet 2 is completed."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 578,
    "text": "Figure 4.14 ♦The priority queue in operation\nPRINCIPLES IN\nPRACTICE\nNET NEUTRALITY\nWe’ve seen that packet scheduling mechanisms (e.g., priority traffic scheduling disciplines\nsuch a strict priority, and WFQ) can be used to provide different levels of service to different\n“classes” of traffic. The definition of what precisely constitutes a “class” of traffic is up to an\nISP to decide, but could be potentially based on any set of fields in the IP datagram header. For example, the port field in the IP datagram header could be used to classify datagrams\naccording to the “well-know service” associated with that port: SNMP network management\ndatagram (port 161) might be assigned to a higher priority class than an IMAP e-mail\nprotocol (ports 143, or 993) datagram and therefore receive better service. An ISP could\nalso potentially use a datagram’s source IP address to provide priority to datagrams being\nsent by certain companies (who have presumably paid the ISP for this privilege) over\ndatagrams being sent from other companies (who have not paid); an ISP could even block\ntraffic with a source IP address in a given company, or country. There are many\nmechanisms that would allow an ISP to provide different levels of service to different\nclasses of traffic. The real question is what policies and laws determine what an ISP can"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 579,
    "text": "actually do. Of course, these laws will vary by country; see [Smithsonian 2017] for a brief\nsurvey. Here, we’ll briefly consider US policy on what has come to be known as “net\nneutrality.”\nThe term “net neutrality” doesn’t have a precise decision, but the March 2015 Order on\nProtecting and Promoting an Open Internet [FCC 2015] by the US Federal Communications\nCommission provides three “clear, bright line” rules that are now often associated with net\nneutrality:\n•\n“No Blocking. . . . A person engaged in the provision of broadband Internet access\nservice, . . . shall not block lawful content, applications, services, or non-harmful\ndevices, subject to reasonable network management.”\n•\n“No Throttling. . . . A person engaged in the provision of broadband Internet access\nservice, . . . shall not impair or degrade lawful Internet traffic on the basis of Internet\ncontent, application, or service, or use of a non-harmful device, subject to reasonable\nnetwork management.”\n•\n“No Paid Prioritization. . . . A person engaged in the provision of broadband Internet\naccess service, . . . shall not engage in paid prioritization. “Paid prioritization” refers to\nthe management of a broadband provider’s network to directly or indirectly favor some\ntraffic over other traffic, including through use of techniques such as traffic shaping,\nprioritization, resource reservation, or other forms of preferential traffic\nmanagement, . . .”\nQuite interestingly, before the Order, ISP behaviors violating the first two of these rules had\nbeen observed [Faulhaber 2012]. In 2005, an ISP in North Carolina agreed to stop its\npractice of blocking its customers from using Vonage, a voice-over-IP service that competed\nwith its own telephone service. In 2007, Comcast was judged to be interfering with\nBitTorrent P2P traffic by internally creating and sending TCP RST packets to BitTorrent\nsenders and receivers, which caused them to close their BitTorrent connection [FCC 2008]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 580,
    "text": "Both sides of the net neutrality debate have been argued strenuously, mostly focused on\nthe extent to which net neutrality provides benefits to customers, while at the same time\npromoting innovation. See [Peha 2006, Faulhaber 2012, Economides 2017, Madhyastha\n2017]. The 2015 FCC Order on Protecting and Promoting an Open Internet, which banned ISPs\nfrom blocking, throttling, or providing paid prioritizing, was superseded by the 2017 FCC\nRestoring Internet Freedom Order, [FCC 2017] which rolled back these prohibitions and\nfocused instead on ISP transparency. With so much interest and so many changes, it’s\nprobably safe to say we aren’t close to having seen the final chapter written on net neutrality\nin the United States, or elsewhere. Round Robin and Weighted Fair Queuing (WFQ)\nUnder the round robin queuing discipline, packets are sorted into classes as\nwith priority queuing. However, rather than there being a strict service\npriority among classes, a round robin scheduler alternates service among\nthe classes. In the simplest form of round robin scheduling, a class 1 packet\nis transmitted, followed by a class 2 packet, followed by a class 1 packet,\nfollowed by a class 2 packet, and so on. A so-called work-conserving\nqueuing discipline will never allow the link to remain idle whenever there\nare packets (of any class) queued for transmission. A work-conserving\nround robin discipline that looks for a packet of a given class but finds none\nwill immediately check the next class in the round robin sequence. Figure 4.15 illustrates the operation of a two-class round robin queue. In this example, packets 1, 2, and 4 belong to class 1, and packets 3 and 5\nbelong to the second class. Packet 1 begins transmission immediately upon\narrival at the output queue. Packets 2 and 3 arrive during the transmission\nof packet 1 and thus queue for transmission. After the transmission of"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 581,
    "text": "packet 1, the link scheduler looks for a class 2 packet and thus transmits\npacket 3. After the transmission of packet 3, the scheduler looks for a class\n1 packet and thus transmits packet 2. After the transmission of packet 2,\npacket 4 is the only queued packet; it is thus transmitted immediately after\npacket 2. Figure 4.15 ♦The two-class robin queue in operation\nA generalized form of round robin queuing that has been widely\nimplemented in routers is the so-called weighted fair queuing (WFQ)\ndiscipline [Demers 1990; Parekh 1993. WFQ is illustrated in Figure 4.16. Here, arriving packets are classified and queued in the appropriate per-class\nwaiting area. As in round robin scheduling, a WFQ scheduler will serve\nclasses in a circular manner—first serving class 1, then serving class 2, then\nserving class 3, and then (assuming there are three classes) repeating the\nservice pattern. WFQ is also a work-conserving queuing discipline and thus\nwill immediately move on to the next class in the service sequence when it\nfinds an empty class queue."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 582,
    "text": "Figure 4.16 ♦Weighted fair queuing\nWFQ differs from round robin in that each class may receive a\ndifferential amount of service in any interval of time. Specifically, each\nclass, i, is assigned a weight, w . Under WFQ, during any interval of time\nduring which there are class i packets to send, class i will then be\nguaranteed to receive a fraction of service equal to w /(Σw ), where the sum\nin the denominator is taken over all classes that also have packets queued\nfor transmission. In the worst case, even if all classes have queued packets,\nclass i will still be guaranteed to receive a fraction w /(Σw ) of the\nbandwidth, where in this worst case the sum in the denominator is over all\nclasses. Thus, for a link with transmission rate R, class i will always achieve\na throughput of at least R · w  / (Σw ) Our description of WFQ has been\nidealized, as we have not considered the fact that packets are discrete and a\npacket’s transmission will not be interrupted to begin transmission of\nanother packet; [Demers 1990; Parekh 1993] discuss this packetization\nissue. i\ni\nj\ni\nj\ni\nj"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 583,
    "text": "4.3 The Internet Protocol (IP): IPv4, Addressing,\nIPv6, and More\nOur study of the network layer thus far in Chapter 4—the notion of the data\nand control plane component of the network layer, our distinction between\nforwarding and routing, the identification of various network service\nmodels, and our look inside a router—have often been without reference to\nany specific computer network architecture or protocol. In this section,\nwe’ll focus on key aspects of the network layer on today’s Internet and the\ncelebrated Internet Protocol (IP). There are two versions of IP in use today. We’ll first examine the\nwidely deployed IP protocol version 4, which is usually referred to simply\nas IPv4 [RFC 791] in Section 4.3.1. We’ll examine IP version 6 [RFC 2460;\nRFC 4291], which has been proposed to replace IPv4, in Section 4.3.4. In\nbetween, we’ll primarily cover Internet addressing—a topic that might\nseem rather dry and detail-oriented but we’ll see is crucial to understanding\nhow the Internet’s network layer works. To master IP addressing is to\nmaster the Internet’s network layer itself! 4.3.1 IPv4 Datagram Format\nRecall that the Internet’s network-layer packet is referred to as a datagram. We begin our study of IP with an overview of the syntax and semantics of\nthe IPv4 datagram. You might be thinking that nothing could be drier than\nthe syntax and semantics of a packet’s bits. Nevertheless, the datagram\nplays a central role in the Internet—every networking student and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 584,
    "text": "professional needs to see it, absorb it, and master it. (And just to see that\nprotocol headers can indeed be fun to study, check out [Pomeranz 2010]). The IPv4 datagram format is shown in Figure 4.17. The key fields in the\nIPv4 datagram are the following:\nFigure 4.17 ♦IPv4 datagram format\n•\nVersion number. These 4 bits specify the IP protocol version of the\ndatagram. By looking at the version number, the router can determine\nhow to interpret the remainder of the IP datagram. Different versions of\nIP use different datagram formats. The datagram format for IPv4 is\nshown in Figure 4.17. The datagram format for the new version of IP\n(IPv6) is discussed in Section 4.3.4."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 585,
    "text": "•\nHeader length. Because an IPv4 datagram can contain a variable\nnumber of options (which are included in the IPv4 datagram header),\nthese 4 bits are needed to determine where in the IP datagram the\npayload (for example, the transport-layer segment being encapsulated in\nthis datagram) actually begins. Most IP datagrams do not contain\noptions, so the typical IP datagram has a 20-byte header. •\nType of service. The type of service (TOS) bits were included in the\nIPv4 header to allow different types of IP datagrams to be distinguished\nfrom each other. For example, it might be useful to distinguish real-time\ndatagrams (such as those used by an IP telephony application) from\nnon-real-time traffic (e.g., FTP). The ­specific level of service to be\nprovided is a policy issue determined and configured by the network\nadministrator for that router. We also learned in Section 3.7.2 that two\nof the TOS bits are used for Explicit Congestion ­Notification. •\nDatagram length. This is the total length of the IP datagram (header\nplus data), measured in bytes. Since this field is 16 bits long, the\ntheoretical maximum size of the IP datagram is 65,535 bytes. However,\ndatagrams are rarely larger than 1,500 bytes, which allows an IP\ndatagram to fit in the payload field of a maximally sized Ethernet frame. •\nIdentifier, flags, fragmentation offset. These three fields have to do with\nso-called IP fragmentation, when a large IP datagram is broken into\nseveral smaller IP datagrams which are then forwarded independently to\nthe destination, where they are reassembled before their payload data\n(see below) is passed up to the transport layer at the destination host. Interestingly, the new version of IP, IPv6, does not allow for\nfragmentation. We’ll not cover fragmentation here; but readers can find\na detailed discussion online, among the “retired” material from earlier\nversions of this book."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 586,
    "text": "•\nTime-to-live. The time-to-live (TTL) field is included to ensure that\ndatagrams do not circulate forever (due to, for example, a long-lived\nrouting loop) in the network. This field is decremented by one each time\nthe datagram is processed by a router. If the TTL field reaches 0, a\nrouter must drop that datagram. •\nProtocol. This field is typically used only when an IP datagram reaches\nits final destination. The value of this field indicates the specific\ntransport-layer protocol to which the data portion of this IP datagram\nshould be passed. For example, a value of 6 indicates that the data\nportion is passed to TCP, while a value of 17 indicates that the data is\npassed to UDP. For a list of all possible values, see [IANA Protocol\nNumbers 2016]. Note that the protocol number in the IP datagram has a\nrole that is analogous to the role of the port number field in the\ntransport-layer segment. The protocol number is the glue that binds the\nnetwork and transport layers together, whereas the port number is the\nglue that binds the transport and application layers together. We’ll see in\nChapter 6 that the link-layer frame also has a special field that binds the\nlink layer to the network layer. •\nHeader checksum. The header checksum aids a router in detecting bit\nerrors in a received IP datagram. The header checksum is computed by\ntreating each 2  bytes in the header as a number and summing these\nnumbers using 1s complement arithmetic. As discussed in Section 3.3,\nthe 1s complement of this sum, known as the Internet checksum, is\nstored in the checksum field. A router computes the header checksum\nfor each received IP datagram and detects an error condition if the\nchecksum carried in the datagram header does not equal the computed\nchecksum. Routers typically discard datagrams for which an error has\nbeen detected. Note that the checksum must be recomputed and stored"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 587,
    "text": "again at each router, since the TTL field, and possibly the options field\nas well, will change. An interesting discussion of fast algorithms for\ncomputing the Internet checksum is [RFC 1071]. A question often asked\nat this point is, why does TCP/IP perform error checking at both the\ntransport and network layers? There are several reasons for this\nrepetition. First, note that only the IP header is checksummed at the IP\nlayer, while the TCP/UDP checksum is computed over the entire\nTCP/UDP segment. Second, TCP/UDP and IP do not necessarily both\nhave to belong to the same protocol stack. TCP can, in principle, run\nover a different network-layer protocol (for example, ATM) [Black\n1995]) and IP can carry data that will not be passed to TCP/UDP. •\nSource and destination IP addresses. When a source creates a datagram,\nit inserts its IP address into the source IP address field and inserts the\naddress of the ultimate destination into the destination IP address field. Often the source host determines the destination address via a DNS\nlookup, as discussed in Chapter 2. We’ll discuss IP addressing in detail\nin Section 4.3.2. •\nOptions. The options fields allow an IP header to be extended. Header\noptions were meant to be used rarely—hence the decision to save\noverhead by not including the information in options fields in every\ndatagram header. However, the mere existence of options does\ncomplicate matters—since datagram headers can be of variable length,\none cannot determine a priori where the data field will start. Also, since\nsome datagrams may require options processing and others may not, the\namount of time needed to process an IP datagram at a router can vary\ngreatly. These considerations become particularly important for IP\nprocessing in high-performance routers and hosts. For these reasons and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 588,
    "text": "others, IP options were not included in the IPv6 header, as discussed in\nSection 4.3.4. •\nData (payload). Finally, we come to the last and most important field—\nthe raison d’etre for the datagram in the first place! In most\ncircumstances, the data field of the IP datagram contains the transport-\nlayer segment (TCP or UDP) to be delivered to the destination. However, the data field can carry other types of data, such as ICMP\nmessages (discussed in Section 5.6). Note that an IP datagram has a total of 20 bytes of header (assuming no\noptions). If the datagram carries a TCP segment, then each datagram carries\na total of 40 bytes of header (20 bytes of IP header plus 20 bytes of TCP\nheader) along with the application-layer message. 4.3.2 IPv4 Addressing\nWe now turn our attention to IPv4 addressing. Although you may be\nthinking that addressing must be a straightforward topic, hopefully by the\nend of this section you’ll be convinced that Internet addressing is not only a\njuicy, subtle, and interesting topic but also one that is of central importance\nto the Internet. An excellent treatment of IPv4 addressing can be found in\nthe first chapter in [Stewart 1999]. Before discussing IP addressing, however, we’ll need to say a few\nwords about how hosts and routers are connected into the Internet. A host\ntypically has only a single link into the network; when IP in the host wants\nto send a datagram, it does so over this link. The boundary between the host\nand the physical link is called an interface. Now consider a router and its\ninterfaces. Because a router’s job is to receive a datagram on one link and\nforward the datagram on some other link, a router necessarily has two or"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 589,
    "text": "more links to which it is connected. The boundary between the router and\nany one of its links is also called an interface. A router thus has multiple\ninterfaces, one for each of its links. Because every host and router is\ncapable of sending and receiving IP datagrams, IP requires each host and\nrouter interface to have its own IP address. Thus, an IP address is\ntechnically associated with an interface, rather than with the host or router\ncontaining that interface. Each IP address is 32 bits long (equivalently, 4 bytes), and there are\nthus a total of 232 (or approximately 4 billion) possible IP addresses. These\naddresses are typically written in so-called dotted-decimal notation, in\nwhich each byte of the address is written in its decimal form and is\nseparated by a period (dot) from other bytes in the address. For example,\nconsider the IP address 193.32.216.9. The 193 is the decimal equivalent of\nthe first 8 bits of the address; the 32 is the decimal equivalent of the second\n8 bits of the address, and so on. Thus, the address 193.32.216.9 in binary\nnotation is\n11000001 00100000 11011000 00001001\nEach interface on every host and router in the global Internet must have an\nIP address that is globally unique (except for interfaces behind NATs, as\ndiscussed in Section 4.3.3). These addresses cannot be chosen in a willy-\nnilly manner, however. A portion of an interface’s IP address will be\ndetermined by the subnet to which it is connected. Figure 4.18 provides an example of IP addressing and interfaces. In this\nfigure, one router (with three interfaces) is used to interconnect seven hosts. Take a close look at the IP addresses assigned to the host and router\ninterfaces, as there are several things to notice. The three hosts in the upper-\nleft portion of Figure 4.18, and the router interface to which they are"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 590,
    "text": "connected, all have an IP address of the form 223.1.1.xxx. That is, they all\nhave the same leftmost 24 bits in their IP address. These four interfaces are\nalso interconnected to each other by a network that contains no routers. This network could be interconnected by an Ethernet LAN, in which case\nthe interfaces would be interconnected by an Ethernet switch (as we’ll\ndiscuss in Chapter 6), or by a wireless access point (as we’ll discuss in\nChapter 7). We’ll represent this routerless network connecting these hosts as\na cloud for now, and dive into the internals of such networks in Chapters 6\nand 7. Figure 4.18 ♦Interface addresses and subnets"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 223",
    "source": "kurose",
    "page": 591,
    "text": "In IP terms, this network interconnecting three host interfaces and one\nrouter interface forms a subnet [RFC 950]. (A subnet is also called an IP\nnetwork or simply a network in the Internet literature.) IP addressing assigns\nan address to this subnet: 223.1.1.0/24, where the /24 (“slash-24”) notation,\nsometimes known as a subnet mask, indicates that the leftmost 24 bits of\nthe 32-bit quantity define the subnet address. The 223.1.1.0/24 subnet thus\nconsists of the three host interfaces (223.1.1.1, 223.1.1.2, and 223.1.1.3)\nand one router interface (223.1.1.4). Any additional hosts attached to the\n223.1.1.0/24 subnet would be required to have an address of the form\n223.1.1.xxx. There are two additional subnets shown in Figure 4.18: the\n223.1.2.0/24 network and the 223.1.3.0/24 subnet. Figure 4.19 illustrates\nthe three IP subnets present in Figure 4.18."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 592,
    "text": "Figure 4.19 ♦Subnet addresses\nThe IP definition of a subnet is not restricted to Ethernet segments that\nconnect multiple hosts to a router interface. To get some insight here,\nconsider Figure 4.20, which shows three routers that are interconnected\nwith each other by point-to-point links. Each router has three interfaces, one\nfor each point-to-point link and one for the broadcast link that directly\nconnects the router to a pair of hosts. What subnets are present here? Three\nsubnets, 223.1.1.0/24, 223.1.2.0/24, and 223.1.3.0/24, are similar to the\nsubnets we encountered in Figure 4.18. But note that there are three\nadditional subnets in this example as well: one subnet, 223.1.9.0/24, for the\ninterfaces that connect routers R1 and R2; another subnet, 223.1.8.0/24, for\nthe interfaces that connect routers R2 and R3; and a third subnet,\n223.1.7.0/24, for the interfaces that connect routers R3 and R1. For a\ngeneral interconnected system of routers and hosts, we can use the\nfollowing recipe to define the subnets in the system:\nTo determine the subnets, detach each interface from its host or router,\ncreating islands of isolated networks, with interfaces terminating the\nend points of the isolated networks. Each of these isolated networks is\ncalled a subnet. If we apply this procedure to the interconnected system in Figure 4.20, we\nget six islands or subnets."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 593,
    "text": "Figure 4.20 ♦Three routers interconnecting six subnets\nFrom the discussion above, it’s clear that an organization (such as a\ncompany or academic institution) with multiple Ethernet segments and\npoint-to-point links will have multiple subnets, with all of the devices on a\ngiven subnet having the same subnet address. In principle, the different\nsubnets could have quite different subnet addresses. In practice, however,\ntheir subnet addresses often have much in common. To understand why,\nlet’s next turn our attention to how addressing is handled in the global\nInternet."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 594,
    "text": "The Internet’s address assignment strategy is known as Classless\nInterdomain Routing (CIDR—pronounced cider) [RFC 4632]. CIDR\ngeneralizes the notion of subnet addressing. As with subnet addressing, the\n32-bit IP address is divided into two parts and again has the dotted-decimal\nform a.b.c.d/x, where x indicates the number of bits in the first part of the\naddress. The x most significant bits of an address of the form a.b.c.d/x constitute\nthe network portion of the IP address, and are often referred to as the prefix\n(or network prefix) of the address. An organization is typically assigned a\nblock of contiguous addresses, that is, a range of addresses with a common\nprefix (see the Principles in Practice feature). In this case, the IP addresses\nof devices within the organization will share the common prefix. When we\ncover the Internet’s BGP routing protocol in Section 5.4, we’ll see that only\nthese x leading prefix bits are considered by routers outside the\norganization’s network. That is, when a router outside the organization\nforwards a datagram whose destination address is inside the organization,\nonly the leading x bits of the address need be considered. This considerably\nreduces the size of the forwarding table in these routers, since a single entry\nof the form a.b.c.d/x will be sufficient to forward packets to any destination\nwithin the organization. The remaining 32-x bits of an address can be thought of as\ndistinguishing among the devices within the organization, all of which have\nthe same network prefix. These are the bits that will be considered when\nforwarding packets at routers within the organization. These lower-order\nbits may (or may not) have an additional subnetting structure, such as that\ndiscussed above. For example, suppose the first 21 bits of the CIDRized\naddress a.b.c.d/21 specify the organization’s network prefix and are\ncommon to the IP addresses of all devices in that organization. The"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 595,
    "text": "remaining 11 bits then identify the specific hosts in the organization. The\norganization’s internal structure might be such that these 11 rightmost bits\nare used for subnetting within the organization, as discussed above. For\nexample, a.b.c.d/24 might refer to a specific subnet within the organization. PRINCIPLES IN\nPRACTICE\nThis example of an ISP that connects eight organizations to the Internet nicely illustrates\nhow carefully allocated CIDRized addresses facilitate routing. Suppose, as shown in Figure\n4.21, that the ISP (which we’ll call Fly-By-Night-ISP) advertises to the outside world that it\nshould be sent any datagrams whose first 20 address bits match 200.23.16.0/20. The rest\nof the world need not know that within the address block 200.23.16.0/20 there are in fact\neight other organizations, each with its own subnets. This ability to use a single prefix to\nadvertise multiple networks is often referred to as address aggregation (also route\naggregation or route summarization). Address aggregation works extremely well when addresses are allocated in blocks to\nISPs and then from ISPs to client organizations. But what happens when addresses are not\nallocated in such a hierarchical manner? What would happen, for example, if Fly-By-Night-\nISP acquires ISPs-R-Us and then has Organization 1 connect to the Internet through its\nsubsidiary ISPs-R-Us? As shown in Figure 4.21, the subsidiary ISPs-R-Us owns the\naddress block 199.31.0.0/16, but Organization 1’s IP addresses are unfortunately outside of\nthis address block. What should be done here? Certainly, Organization 1 could renumber all\nof its routers and hosts to have addresses within the ISPs-R-Us address block. But this is a\ncostly solution, and Organization 1 might well be reassigned to another subsidiary in the\nfuture. The solution typically adopted is for Organization 1 to keep its IP addresses in\n200.23.18.0/23. In this case, as shown in Figure 4.22, Fly-By-Night-ISP continues to\nadvertise the address block 200.23.16.0/20 and ISPs-R-Us continues to advertise"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 199",
    "source": "kurose",
    "page": 596,
    "text": "199.31.0.0/16. However, ISPs-R-Us now also advertises the block of addresses for\nOrganization 1, 200.23.18.0/23. When other routers in the larger Internet see the address\nblocks 200.23.16.0/20 (from Fly-By-Night-ISP) and 200.23.18.0/23 (from ISPs-R-Us) and\nwant to route to an address in the block 200.23.18.0/23, they will use longest prefix\nmatching (see Section 4.2.1), and route toward ISPs-R-Us, as it advertises the longest (i.e.,\nmost-specific) address prefix that matches the destination address. Figure 4.21 ♦Hierarchical addressing and route aggregation"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 597,
    "text": "Figure 4.22 ♦ISPs-R-Us has a more specific route to Organization\nBefore CIDR was adopted, the network portions of an IP address were\nconstrained to be 8, 16, or 24 bits in length, an addressing scheme known as\nclassful addressing, since subnets with 8-, 16-, and 24-bit subnet addresses\nwere known as class A, B, and C networks, respectively. The requirement\nthat the subnet portion of an IP address be exactly 1, 2, or 3 bytes long\nturned out to be problematic for supporting the rapidly growing number of\norganizations with small and medium-sized subnets. A class C (/24) subnet\ncould accommodate only up to 2  − 2 = 254 hosts (two of the 2  = 256\naddresses are reserved for special use)—too small for many organizations. 8"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 255",
    "source": "kurose",
    "page": 598,
    "text": "However, a class B (/16) subnet, which supports up to 65,634 hosts, was too\nlarge. Under classful addressing, an organization with, say, 2,000 hosts was\ntypically allocated a class B (/16) subnet address. This led to a rapid\ndepletion of the class B address space and poor utilization of the assigned\naddress space. For example, the organization that used a class B address for\nits 2,000 hosts was allocated enough of the address space for up to 65,534\ninterfaces—leaving more than 63,000 addresses that could not be used by\nother organizations. We would be remiss if we did not mention yet another type of IP\naddress, the IP broadcast address 255.255.255.255. When a host sends a\ndatagram with destination address 255.255.255.255, the message is\ndelivered to all hosts on the same subnet. Routers optionally forward the\nmessage into neighboring subnets as well (although they usually don’t). Having now studied IP addressing in detail, we need to know how hosts\nand subnets get their addresses in the first place. Let’s begin by looking at\nhow an organization gets a block of addresses for its devices, and then look\nat how a device (such as a host) is assigned an address from within the\norganization’s block of addresses. Obtaining a Block of Addresses\nIn order to obtain a block of IP addresses for use within an organization’s\nsubnet, a network administrator might first contact its ISP, which would\nprovide addresses from a larger block of addresses that had already been\nallocated to the ISP. For example, the ISP may itself have been allocated the\naddress block 200.23.16.0/20. The ISP, in turn, could divide its address\nblock into eight equal-sized contiguous address blocks and give one of\nthese address blocks out to each of up to eight organizations that are"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 255",
    "source": "kurose",
    "page": 599,
    "text": "supported by this ISP, as shown below. (We have underlined the subnet part\nof these addresses for your convenience.) While obtaining a set of addresses from an ISP is one way to get a\nblock of addresses, it is not the only way. Clearly, there must also be a way\nfor the ISP itself to get a block of addresses. Is there a global authority that\nhas ultimate responsibility for managing the IP address space and allocating\naddress blocks to ISPs and other organizations? Indeed there is! IP\naddresses are managed under the authority of the Internet Corporation for\nAssigned Names and Numbers (ICANN) [ICANN 2020], based on\nguidelines set forth in [RFC 7020]. The role of the nonprofit ICANN\norganization is not only to allocate IP addresses, but also to manage the\nDNS root servers. It also has the very contentious job of assigning domain\nnames and resolving domain name disputes. The ICANN allocates\naddresses to regional Internet registries (for example, ARIN, RIPE, APNIC,\nand LACNIC, which together form the Address Supporting Organization of\nICANN [ASO-ICANN 2020]), and handle the allocation/management of\naddresses within their regions. Obtaining a Host Address: The Dynamic Host Configuration\nProtocol\nOnce an organization has obtained a block of addresses, it can assign\nindividual IP addresses to the host and router interfaces in its organization. A system administrator will typically manually configure the IP addresses\ninto the router (often remotely, with a network management tool). Host\naddresses can also be configured manually, but typically this is done using\nthe Dynamic Host Configuration Protocol (DHCP) [RFC 2131]. DHCP\nallows a host to obtain (be allocated) an IP address automatically. A network"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 600,
    "text": "administrator can configure DHCP so that a given host receives the same IP\naddress each time it connects to the network, or a host may be assigned a\ntemporary IP address that will be different each time the host connects to\nthe network. In addition to host IP address assignment, DHCP also allows a\nhost to learn additional information, such as its subnet mask, the address of\nits first-hop router (often called the default gateway), and the address of its\nlocal DNS server. Because of DHCP’s ability to automate the network-related aspects of\nconnecting a host into a network, it is often referred to as a plug-and-play\nor zeroconf (zero-configuration) protocol. This capability makes it very\nattractive to the network administrator who would otherwise have to\nperform these tasks manually! DHCP is also enjoying widespread use in\nresidential Internet access networks, enterprise networks, and in wireless\nLANs, where hosts join and leave the network frequently. Consider, for\nexample, the student who carries a laptop from a dormitory room to a\nlibrary to a classroom. It is likely that in each location, the student will be\nconnecting into a new subnet and hence will need a new IP address at each\nlocation. DHCP is ideally suited to this situation, as there are many users\ncoming and going, and addresses are needed for only a limited amount of\ntime. The value of DHCP’s plug-and-play capability is clear, since it’s\nunimaginable that a system administrator would be able to reconfigure\nlaptops at each location, and few students (except those taking a computer\nnetworking class!) would have the expertise to configure their laptops\nmanually. DHCP is a client-server protocol. A client is typically a newly arriving\nhost wanting to obtain network configuration information, including an IP\naddress for itself. In the simplest case, each subnet (in the addressing sense\nof Figure 4.20) will have a DHCP server. If no server is present on the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 601,
    "text": "subnet, a DHCP relay agent (typically a router) that knows the address of a\nDHCP server for that network is needed. Figure 4.23 shows a DHCP server\nattached to subnet 223.1.2/24, with the router serving as the relay agent for\narriving clients attached to subnets 223.1.1/24 and 223.1.3/24. In our\ndiscussion below, we’ll assume that a DHCP server is available on the\nsubnet. For a newly arriving host, the DHCP protocol is a four-step process, as\nshown in Figure 4.24 for the network setting shown in Figure 4.23. In this\nfigure, yiaddr (as in “your Internet address”) indicates the address being\nallocated to the newly arriving client. The four steps are:\nFigure 4.23 ♦DHCP client and server"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 255",
    "source": "kurose",
    "page": 602,
    "text": "•\nDHCP server discovery. The first task of a newly arriving host is to find\na DHCP server with which to interact. This is done using a DHCP\ndiscover message, which a client sends within a UDP packet to port 67. The UDP packet is encapsulated in an IP datagram. But to whom should\nthis datagram be sent? The host doesn’t even know the IP address of the\nnetwork to which it is attaching, much less the address of a DHCP\nserver for this network. Given this, the DHCP client creates an IP\ndatagram containing its DHCP discover message along with the\nbroadcast destination IP address of 255.255.255.255 and a “this host”\nsource IP address of 0.0.0.0. The DHCP client passes the IP datagram to\nthe link layer, which then broadcasts this frame to all nodes attached to\nthe subnet (we will cover the details of link-layer broadcasting in\nSection 6.4). •\nDHCP server offer(s). A DHCP server receiving a DHCP discover\nmessage responds to the client with a DHCP offer message that is\nbroadcast to all nodes on the subnet, again using the IP broadcast\naddress of 255.255.255.255. (You might want to think about why this\nserver reply must also be broadcast). Since several DHCP servers can\nbe present on the subnet, the client may find itself in the enviable\nposition of being able to choose from among several offers. Each server\noffer message contains the transaction ID of the received discover\nmessage, the proposed IP address for the client, the network mask, and\nan IP address lease time—the amount of time for which the IP address\nwill be valid. It is common for the server to set the lease time to several\nhours or days [Droms 2002]. •\nDHCP request. The newly arriving client will choose from among one\nor more server offers and respond to its selected offer with a DHCP\nrequest message, echoing back the configuration parameters."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 255",
    "source": "kurose",
    "page": 603,
    "text": "•\nDHCP ACK. The server responds to the DHCP request message with a\nDHCP ACK message, confirming the requested parameters."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 604,
    "text": "Figure 4.24 ♦DHCP client-server interaction"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 605,
    "text": "Once the client receives the DHCP ACK, the interaction is complete\nand the client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease’s expiration,\nDHCP also provides a mechanism that allows a client to renew its lease on\nan IP address. From a mobility aspect, DHCP does have one very significant\nshortcoming. Since a new IP address is obtained from DHCP each time a\nnode connects to a new subnet, a TCP connection to a remote application\ncannot be maintained as a mobile node moves between subnets. In Chapter\n7, we will learn how mobile cellular networks allow a host to retain its IP\naddress and ongoing TCP connections as it moves between base stations in\na provider’s cellular network. Additional details about DHCP can be found\nin [Droms 2002] and [dhc 2020]. An open source reference implementation\nof DHCP is available from the Internet Systems Consortium [ISC 2020]. 4.3.3 Network Address Translation (NAT)\nGiven our discussion about Internet addresses and the IPv4 datagram\nformat, we’re now well aware that every IP-capable device needs an IP\naddress. With the ­proliferation of small office, home office (SOHO)\nsubnets, this would seem to imply that whenever a SOHO wants to install a\nLAN to connect multiple machines, a range of addresses would need to be\nallocated by the ISP to cover all of the SOHO’s IP devices (including\nphones, tablets, gaming devices, IP TVs, printers and more). If the subnet\ngrew bigger, a larger block of addresses would have to be allocated. But\nwhat if the ISP had already allocated the contiguous portions of the SOHO ­-\nnetwork’s current address range? And what typical homeowner wants (or\nshould need) to know how to manage IP addresses in the first place?"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 606,
    "text": "Fortunately, there is a simpler approach to address allocation that has found\nincreasingly widespread use in such scenarios: network address\ntranslation (NAT) [RFC 2663; RFC 3022; Huston 2004, Zhang 2007;\nHuston 2017]. Figure 4.25 shows the operation of a NAT-enabled router. The NAT-\nenabled router, residing in the home, has an interface that is part of the\nhome network on the right of Figure 4.25. Addressing within the home\nnetwork is exactly as we have seen above—all four interfaces in the home\nnetwork have the same subnet address of 10.0.0.0/24. The address space\n10.0.0.0/8 is one of three portions of the IP address space that is reserved in\n[RFC 1918] for a private network or a realm with private addresses,\nsuch as the home network in Figure 4.25. A realm with private addresses\nrefers to a network whose addresses only have meaning to devices within\nthat network. To see why this is important, consider the fact that there are\nhundreds of thousands of home networks, many using the same address\nspace, 10.0.0.0/24. Devices within a given home network can send packets\nto each other using 10.0.0.0/24 addressing. However, packets forwarded\nbeyond the home network into the larger global Internet clearly cannot use\nthese addresses (as either a source or a destination address) because there\nare hundreds of thousands of networks using this block of addresses. That\nis, the 10.0.0.0/24 addresses can only have meaning within the given home\nnetwork. But if private addresses only have meaning within a given\nnetwork, how is addressing handled when packets are sent to or received\nfrom the global Internet, where addresses are necessarily unique? The\nanswer lies in understanding NAT."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 607,
    "text": "Figure 4.25 ♦Network address translation\nThe NAT-enabled router does not look like a router to the outside\nworld. Instead the NAT router behaves to the outside world as a single\ndevice with a single IP address. In Figure 4.25, all traffic leaving the home\nrouter for the larger Internet has a source IP address of 138.76.29.7, and all\ntraffic entering the home router must have a destination address of\n138.76.29.7. In essence, the NAT-enabled router is hiding the details of the\nhome network from the outside world. (As an aside, you might wonder\nwhere the home network computers get their addresses and where the router\ngets its single IP address. Often, the answer is the same—DHCP! The router\ngets its address from the ISP’s DHCP server, and the router runs a DHCP\nserver to provide addresses to computers within the NAT-DHCP-router-\ncontrolled home network’s address space.) If all datagrams arriving at the NAT router from the WAN have the\nsame destination IP address (specifically, that of the WAN-side interface of\nthe NAT router), then how does the router know the internal host to which it\nshould forward a given datagram? The trick is to use a NAT translation"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 608,
    "text": "table at the NAT router, and to include port numbers as well as IP addresses\nin the table entries. Consider the example in Figure 4.25. Suppose a user sitting in a home\nnetwork behind host 10.0.0.1 requests a Web page on some Web server\n(port 80) with IP address 128.119.40.186. The host 10.0.0.1 assigns the\n(arbitrary) source port number 3345 and sends the datagram into the LAN. The NAT router receives the datagram, generates a new source port number\n5001 for the datagram, replaces the source IP address with its WAN-side IP\naddress 138.76.29.7, and replaces the original source port number 3345\nwith the new source port number 5001. When generating a new source port\nnumber, the NAT router can select any source port number that is not\ncurrently in the NAT translation table. (Note that because a port number\nfield is 16 bits long, the NAT protocol can support over 60,000\nsimultaneous connections with a single WAN-side IP address for the\nrouter!) NAT in the router also adds an entry to its NAT translation table. The Web server, blissfully unaware that the arriving datagram containing\nthe HTTP request has been manipulated by the NAT router, responds with a\ndatagram whose destination address is the IP address of the NAT router, and\nwhose destination port number is 5001. When this datagram arrives at the\nNAT router, the router indexes the NAT translation table using the\ndestination IP address and destination port number to obtain the appropriate\nIP address (10.0.0.1) and destination port number (3345) for the browser in\nthe home network. The router then rewrites the datagram’s destination\naddress and destination port number, and forwards the datagram into the\nhome network. NAT has enjoyed widespread deployment in recent years. But NAT is\nnot without detractors. First, one might argue that, port numbers are meant\nto be used for addressing processes, not for addressing hosts. This violation"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 609,
    "text": "can indeed cause problems for servers running on the home network, since,\nas we have seen in Chapter 2, server processes wait for incoming requests\nat well-known port numbers and peers in a P2P protocol need to accept\nincoming connections when acting as servers. How can one peer connect to\nanother peer that is behind a NAT server, and has a DHCP-provided NAT\naddress? Technical solutions to these problems include NAT traversal tools\n[RFC 5389] [RFC 5389, RFC 5128, Ford 2005]. More “philosophical” arguments have also been raised against NAT by\narchitectural purists. Here, the concern is that routers are meant to be layer\n3 (i.e., network-layer) devices, and should process packets only up to the\nnetwork layer. NAT violates this principle that hosts should be talking\ndirectly with each other, without interfering nodes modifying IP addresses,\nmuch less port numbers. We’ll return to this debate later in Section 4.5,\nwhen we cover middleboxes. FOCUS ON\nSECURITY\nINSPECTING DATAGRAMS: FIREWALLS AND INTRUSION DETECTION SYSTEMS\nSuppose you are assigned the task of administering a home, departmental, university,\nor corporate network. Attackers, knowing the IP address range of your network, can\neasily send IP datagrams to addresses in your range. These datagrams can do all\nkinds of devious things, including mapping your network with ping sweeps and port\nscans, crashing vulnerable hosts with malformed packets, scanning for open TCP/UDP\nports on servers in your network, and infecting hosts by including malware in the\npackets. As the network administrator, what are you going to do about all those bad\nguys out there, each capable of sending malicious packets into your network? Two"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 610,
    "text": "popular defense mechanisms to malicious packet attacks are firewalls and intrusion\ndetection systems (IDSs). As a network administrator, you may first try installing a firewall between your\nnetwork and the Internet. (Most access routers today have firewall capability.) Firewalls\ninspect the datagram and segment header fields, denying suspicious datagrams entry\ninto the internal network. For example, a firewall may be configured to block all ICMP\necho request packets (see Section 5.6), thereby preventing an attacker from doing a\ntraditional port scan across your IP address range. Firewalls can also block packets\nbased on source and destination IP addresses and port numbers. Additionally, firewalls\ncan be configured to track TCP connections, granting entry only to datagrams that\nbelong to approved connections. Additional protection can be provided with an IDS. An IDS, typically situated at the\nnetwork boundary, performs “deep packet inspection,” examining not only header fields\nbut also the payloads in the datagram (including application-layer data). An IDS has a\ndatabase of packet signatures that are known to be part of attacks. This database is\nautomatically updated as new attacks are discovered. As packets pass through the\nIDS, the IDS attempts to match header fields and payloads to the signatures in its\nsignature database. If such a match is found, an alert is created. An intrusion\nprevention system (IPS) is similar to an IDS, except that it actually blocks packets in\naddition to creating alerts. We’ll explore firewalls and IDSs in more detail in Section 4.5\nand in again Chapter 8. Can firewalls and IDSs fully shield your network from all attacks? The answer is\nclearly no, as attackers continually find new attacks for which signatures are not yet\navailable. But firewalls and traditional signature-based IDSs are useful in protecting\nyour network from known attacks. 4.3.4 IPv6"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 611,
    "text": "In the early 1990s, the Internet Engineering Task Force began an effort to\ndevelop a successor to the IPv4 protocol. A prime motivation for this effort\nwas the realization that the 32-bit IPv4 address space was beginning to be\nused up, with new subnets and IP nodes being attached to the Internet (and\nbeing allocated unique IP addresses) at a breathtaking rate. To respond to\nthis need for a large IP address space, a new IP protocol, IPv6, was\ndeveloped. The designers of IPv6 also took this opportunity to tweak and\naugment other aspects of IPv4, based on the accumulated operational\nexperience with IPv4. The point in time when IPv4 addresses would be completely allocated\n(and hence no new networks could attach to the Internet) was the subject of\nconsiderable debate. The estimates of the two leaders of the IETF’s Address\nLifetime Expectations working group were that addresses would become\nexhausted in 2008 and 2018, respectively [Solensky 1996]. In February\n2011, IANA allocated out the last remaining pool of unassigned IPv4\naddresses to a regional registry. While these registries still have available\nIPv4 addresses within their pool, once these addresses are exhausted, there\nare no more available address blocks that can be allocated from a central\npool [Huston 2011a]. A recent survey of IPv4 address-space exhaustion, and\nthe steps taken to prolong the life of the address space is [Richter 2015]; a\nrecent analysis of IPv4 address use is [Huston 2019]. Although the mid-1990s estimates of IPv4 address depletion suggested\nthat a considerable amount of time might be left until the IPv4 address\nspace was exhausted, it was realized that considerable time would be\nneeded to deploy a new technology on such an extensive scale, and so the\nprocess to develop IP version 6 (IPv6) [RFC 2460] was begun [RFC 1752]. (An often-asked question is what happened to IPv5? It was initially"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 612,
    "text": "envisioned that the ST-2 protocol would become IPv5, but ST-2 was later\ndropped.) An excellent source of information about IPv6 is [Huitema 1998]. IPv6 Datagram Format\nThe format of the IPv6 datagram is shown in Figure 4.26. The most\nimportant changes introduced in IPv6 are evident in the datagram format:\n•\nExpanded addressing capabilities. IPv6 increases the size of the IP\naddress from 32 to 128 bits. This ensures that the world won’t run out\nof IP addresses. Now, every grain of sand on the planet can be IP-\naddressable. In addition to unicast and multicast addresses, IPv6 has\nintroduced a new type of address, called an anycast address, that\nallows a datagram to be delivered to any one of a group of hosts. (This\nfeature could be used, for example, to send an HTTP GET to the nearest\nof a number of mirror sites that contain a given document.) •\nA streamlined 40-byte header. As discussed below, a number of IPv4\nfields have been dropped or made optional. The resulting 40-byte fixed-\nlength header allows for faster processing of the IP datagram by a\nrouter. A new encoding of options allows for more flexible options\nprocessing. •\nFlow labeling. IPv6 has an elusive definition of a flow. RFC 2460 states\nthat this allows “labeling of packets belonging to particular flows for\nwhich the sender requests special handling, such as a non-default\nquality of service or real-time service.” For example, audio and video\ntransmission might likely be treated as a flow. On the other hand, the\nmore traditional applications, such as file transfer and e-mail, might not\nbe treated as flows. It is possible that the traffic carried by a high-\npriority user (for example, someone paying for better service for their"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 613,
    "text": "traffic) might also be treated as a flow. What is clear, however, is that\nthe designers of IPv6 foresaw the eventual need to be able to\ndifferentiate among the flows, even if the exact meaning of a flow had\nyet to be determined. As noted above, a comparison of Figure 4.26 with Figure 4.17 reveals\nthe simpler, more streamlined structure of the IPv6 datagram. The following\nfields are defined in IPv6:\nFigure 4.26 ♦IPv6 datagram format\n•\nVersion. This 4-bit field identifies the IP version number. Not\nsurprisingly, IPv6 carries a value of 6 in this field. Note that putting a 4\nin this field does not create a valid IPv4 datagram. (If it did, life would\nbe a lot simpler—see the discussion below regarding the transition from\nIPv4 to IPv6.) •\nTraffic class. The 8-bit traffic class field, like the TOS field in IPv4, can\nbe used to give priority to certain datagrams within a flow, or it can be"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 614,
    "text": "used to give priority to datagrams from certain applications (for\nexample, voice-over-IP) over datagrams from other applications (for\nexample, SMTP e-mail). •\nFlow label. As discussed above, this 20-bit field is used to identify a\nflow of datagrams. •\nPayload length. This 16-bit value is treated as an unsigned integer\ngiving the number of bytes in the IPv6 datagram following the fixed-\nlength, 40-byte datagram header. •\nNext header. This field identifies the protocol to which the contents\n(data field) of this datagram will be delivered (for example, to TCP or\nUDP). The field uses the same values as the protocol field in the IPv4\nheader. •\nHop limit. The contents of this field are decremented by one by each\nrouter that forwards the datagram. If the hop limit count reaches zero, a\nrouter must discard that datagram. •\nSource and destination addresses. The various formats of the IPv6 128-\nbit address are described in RFC 4291. •\nData. This is the payload portion of the IPv6 datagram. When the\ndatagram reaches its destination, the payload will be removed from the\nIP datagram and passed on to the protocol specified in the next header\nfield. The discussion above identified the purpose of the fields that are\nincluded in the IPv6 datagram. Comparing the IPv6 datagram format in\nFigure 4.26 with the IPv4 datagram format that we saw in Figure 4.17, we\nnotice that several fields appearing in the IPv4 datagram are no longer\npresent in the IPv6 datagram:"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 615,
    "text": "•\nFragmentation/reassembly. IPv6 does not allow for fragmentation and\nreassembly at intermediate routers; these operations can be performed\nonly by the source and destination. If an IPv6 datagram received by a\nrouter is too large to be forwarded over the outgoing link, the router\nsimply drops the datagram and sends a “Packet Too Big” ICMP error\nmessage (see Section 5.6) back to the sender. The sender can then\nresend the data, using a smaller IP datagram size. Fragmentation and\nreassembly is a time-consuming operation; removing this functionality\nfrom the routers and placing it squarely in the end systems considerably\nspeeds up IP forwarding within the network. •\nHeader checksum. Because the transport-layer (for example, TCP and\nUDP) and link-layer (for example, Ethernet) protocols in the Internet\nlayers perform checksumming, the designers of IP probably felt that this\nfunctionality was sufficiently redundant in the network layer that it\ncould be removed. Once again, fast processing of IP packets was a\ncentral concern. Recall from our discussion of IPv4 in Section 4.3.1 that\nsince the IPv4 header contains a TTL field (similar to the hop limit field\nin IPv6), the IPv4 header checksum needed to be recomputed at every\nrouter. As with fragmentation and reassembly, this too was a costly\noperation in IPv4. •\nOptions. An options field is no longer a part of the standard IP header. However, it has not gone away. Instead, the options field is one of the\npossible next headers pointed to from within the IPv6 header. That is,\njust as TCP or UDP protocol headers can be the next header within an\nIP packet, so too can an options field. The removal of the options field\nresults in a fixed-length, 40-byte IP header. Transitioning from IPv4 to IPv6"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 616,
    "text": "Now that we have seen the technical details of IPv6, let us consider a very\npractical matter: How will the public Internet, which is based on IPv4, be\ntransitioned to IPv6? The problem is that while new IPv6-capable systems\ncan be made backward-compatible, that is, can send, route, and receive\nIPv4 datagrams, already deployed IPv4-capable systems are not capable of\nhandling IPv6 datagrams. Several options are possible [Huston 2011b, RFC\n4213]. One option would be to declare a flag day—a given time and date when\nall Internet machines would be turned off and upgraded from IPv4 to IPv6. The last major technology transition (from using NCP to using TCP for\nreliable transport service) occurred almost 40 years ago. Even back then\n[RFC 801], when the Internet was tiny and still being administered by a\nsmall number of “wizards,” it was realized that such a flag day was not\npossible. A flag day involving billions of devices is even more unthinkable\ntoday. The approach to IPv4-to-IPv6 transition that has been most widely\nadopted in practice involves tunneling [RFC 4213]. The basic idea behind\ntunneling—a key concept with applications in many other scenarios beyond\nIPv4-to-IPv6 transition, including wide use in the all-IP cellular networks\nthat we’ll cover in Chapter 7—is the following. Suppose two IPv6 nodes (in\nthis example, B and E in Figure 4.27) want to interoperate using IPv6\ndatagrams but are connected to each other by intervening IPv4 routers. We\nrefer to the intervening set of IPv4 routers between two IPv6 routers as a\ntunnel, as illustrated in Figure 4.27. With tunneling, the IPv6 node on the\nsending side of the tunnel (in this example, B) takes the entire IPv6\ndatagram and puts it in the data (payload) field of an IPv4 datagram. This\nIPv4 datagram is then addressed to the IPv6 node on the receiving side of\nthe tunnel (in this example, E) and sent to the first node in the tunnel (in this"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 617,
    "text": "example, C). The intervening IPv4 routers in the tunnel route this IPv4\ndatagram among themselves, just as they would any other datagram,\nblissfully unaware that the IPv4 datagram itself contains a complete IPv6\ndatagram. The IPv6 node on the receiving side of the tunnel eventually\nreceives the IPv4 datagram (it is the destination of the IPv4 datagram! ),\ndetermines that the IPv4 datagram contains an IPv6 datagram (by observing\nthat the protocol number field in the IPv4 datagram is 41 [RFC 4213],\nindicating that the IPv4 payload is a IPv6 datagram), extracts the IPv6\ndatagram, and then routes the IPv6 datagram exactly as it would if it had\nreceived the IPv6 datagram from a directly connected IPv6 neighbor."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 618,
    "text": "Figure 4.27 ♦Tunneling\nWe end this section by noting that while the adoption of IPv6 was\ninitially slow to take off [Lawton 2001; Huston 2008b], momentum has\nbeen building. NIST [NIST IPv6 2020] reports that more than a third of US\ngovernment second-level domains are IPv6-enabled. On the client side,\nGoogle reports that about 25 percent of the clients accessing Google\nservices do so via IPv6 [Google IPv6 2020]. Other recent measurements\n[Czyz 2014] indicate that IPv6 adoption has been accelerating. The\nproliferation of devices such as IP-enabled phones and other portable\ndevices provides an additional push for more widespread deployment of\nIPv6. Europe’s Third Generation Partnership Program [3GPP 2020] has\nspecified IPv6 as the standard addressing scheme for mobile multimedia. One important lesson that we can learn from the IPv6 experience is that\nit is enormously difficult to change network-layer protocols. Since the early\n1990s, numerous new network-layer protocols have been trumpeted as the\nnext major revolution for the Internet, but most of these protocols have had\nlimited penetration to date. These protocols include IPv6, multicast\nprotocols, and resource reservation protocols; a discussion of these latter\ntwo classes of protocols can be found in the online supplement to this text. Indeed, introducing new protocols into the network layer is like replacing\nthe foundation of a house—it is difficult to do without tearing the whole\nhouse down or at least temporarily relocating the house’s residents. On the\nother hand, the Internet has witnessed rapid deployment of new protocols at\nthe application layer. The classic examples, of course, are the Web, instant\nmessaging, streaming media, distributed games, and various forms of social\nmedia. Introducing new application-layer protocols is like adding a new\nlayer of paint to a house—it is relatively easy to do, and if you choose an\nattractive color, others in the neighborhood will copy you. In summary, in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 619,
    "text": "the future, we can certainly expect to see changes in the Internet’s network\nlayer, but these changes will likely occur on a time scale that is much\nslower than the changes that will occur at the application layer."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 620,
    "text": "4.4 Generalized Forwarding and SDN\nRecall that Section 4.2.1 characterized destination-based forwarding as the\ntwo steps of looking up a destination IP address (“match”), then sending the\npacket into the switching fabric to the specified output port (“action”). Let’s\nnow consider a significantly more general “match-plus-action” paradigm,\nwhere the “match” can be made over multiple header fields associated with\ndifferent protocols at different layers in the protocol stack. The “action” can\ninclude forwarding the packet to one or more output ports (as in\ndestination-based forwarding), load balancing packets across multiple\noutgoing interfaces that lead to a service (as in load balancing), rewriting\nheader values (as in NAT), purposefully blocking/dropping a packet (as in a\nfirewall), sending a packet to a special server for further processing and\naction (as in DPI), and more. In generalized forwarding, a match-plus-action table generalizes the\nnotion of the destination-based forwarding table that we encountered in\nSection 4.2.1. Because forwarding decisions may be made using network-\nlayer and/or link-layer source and destination addresses, the forwarding\ndevices shown in Figure 4.28 are more accurately described as “packet\nswitches” rather than layer 3 “routers” or layer 2 “switches.” Thus, in the\nremainder of this section, and in Section 5.5, we’ll refer to these devices as\npacket switches, adopting the terminology that is gaining widespread\nadoption in SDN literature. Figure 4.28 shows a match-plus-action table in each packet switch, with\nthe table being computed, installed, and updated by a remote controller. We\nnote that while it is possible for the control components at the individual\npacket switches to interact with each other (e.g., in a manner similar to that"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 621,
    "text": "in Figure 4.2), in practice, generalized match-plus-action capabilities are\nimplemented via a remote controller that computes, installs, and updates\nthese tables. You might take a minute to compare Figures 4.2, 4.3, and 4.28\n—what similarities and differences do you notice between destination-based\nforwarding shown in Figures 4.2 and 4.3, and generalized forwarding\nshown in Figure 4.28? Figure 4.28 ♦Generalized forwarding: Each packet switch contains\na match-plus-action table that is computed and\ndistributed by a remote controller"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 622,
    "text": "Our following discussion of generalized forwarding will be based on\nOpenFlow [McKeown 2008, ONF 2020, Casado 2014, Tourrilhes 2014]—a\nhighly visible standard that has pioneered the notion of the match-plus-\naction forwarding abstraction and controllers, as well as the SDN revolution\nmore generally [Feamster 2013]. We’ll primarily consider OpenFlow 1.0,\nwhich introduced key SDN abstractions and functionality in a particularly\nclear and concise manner. Later versions of ­OpenFlow introduced\nadditional capabilities as a result of experience gained through\nimplementation and use; current and earlier versions of the OpenFlow\nstandard can be found at [ONF 2020]. Each entry in the match-plus-action forwarding table, known as a flow\ntable in OpenFlow, includes:\n•\nA set of header field values to which an incoming packet will be\nmatched. As in the case of destination-based forwarding, hardware-\nbased matching is most rapidly performed in TCAM memory, with\nmore than a million destination address entries being possible [Bosshart\n2013]. A packet that matches no flow table entry can be dropped or sent\nto the remote controller for more processing. In practice, a flow table\nmay be implemented by multiple flow tables for performance or cost\nreasons [Bosshart 2013], but we’ll focus here on the abstraction of a\nsingle flow table. •\nA set of counters that are updated as packets are matched to flow table\nentries. These counters might include the number of packets that have\nbeen matched by that table entry, and the time since the table entry was\nlast updated. •\nA set of actions to be taken when a packet matches a flow table entry. These actions might be to forward the packet to a given output port, to"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 623,
    "text": "drop the packet, makes copies of the packet and sent them to multiple\noutput ports, and/or to rewrite selected header fields. We’ll explore matching and actions in more detail in Sections 4.4.1 and\n4.4.2, respectively. We’ll then study how the network-wide collection of\nper-packet switch matching rules can be used to implement a wide range of\nfunctions including routing, layer-2 switching, firewalling, load-balancing,\nvirtual networks, and more in Section 4.4.3. In closing, we note that the\nflow table is essentially an API, the abstraction through which an individual\npacket switch’s behavior can be programmed; we’ll see in Section 4.4.3 that\nnetwork-wide behaviors can similarly be programmed by appropriately\nprogramming/configuring these tables in a collection of network packet\nswitches [Casado 2014]. 4.4.1 Match\nFigure 4.29 shows the 11 packet-header fields and the incoming port ID that\ncan be matched in an OpenFlow 1.0 match-plus-action rule. Recall from\nSection 1.5.2 that a link-layer (layer 2) frame arriving to a packet switch\nwill contain a network-layer (layer 3) datagram as its payload, which in turn\nwill typically contain a transport-layer (layer 4) segment. The first\nobservation we make is that OpenFlow’s match abstraction allows for a\nmatch to be made on selected fields from three layers of protocol headers\n(thus rather brazenly defying the layering principle we studied in Section\n1.5). Since we’ve not yet covered the link layer, suffice it to say that the\nsource and destination MAC addresses shown in Figure 4.29 are the link-\nlayer addresses associated with the frame’s sending and receiving\ninterfaces; by forwarding on the basis of Ethernet addresses rather than IP\naddresses, we can see that an OpenFlow-enabled device can equally"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 624,
    "text": "perform as a router (layer-3 device) forwarding datagrams as well as a\nswitch (layer-2 device) forwarding frames. The Ethernet type field\ncorresponds to the upper layer protocol (e.g., IP) to which the frame’s\npayload will be de-multiplexed, and the VLAN fields are concerned with\nso-called virtual local area networks that we’ll study in Chapter 6. The set\nof 12 values that can be matched in the OpenFlow 1.0 specification has\ngrown to 41 values in more recent OpenFlow specifications [Bosshart\n2014]. Figure 4.29 ♦Packet matching fields, OpenFlow 1.0 flow table\nThe ingress port refers to the input port at the packet switch on which a\npacket is received. The packet’s IP source address, IP destination address,\nIP protocol field, and IP type of service fields were discussed earlier in\nSection 4.3.1. The transport-layer source and destination port number fields\ncan also be matched. Flow table entries may also have wildcards. For example, an IP address\nof 128.119.*. * in a flow table will match the corresponding address field of\nany datagram that has 128.119 as the first 16 bits of its address. Each flow\ntable entry also has an associated priority. If a packet matches multiple flow\ntable entries, the selected match and corresponding action will be that of the\nhighest priority entry with which the packet matches. Lastly, we observe that not all fields in an IP header can be matched. For example OpenFlow does not allow matching on the basis of TTL field"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 625,
    "text": "or datagram length field. Why are some fields allowed for matching, while\nothers are not? Undoubtedly, the answer has to do with the tradeoff between\nfunctionality and complexity. The “art” in choosing an abstraction is to\nprovide for enough functionality to accomplish a task (in this case to\nimplement, configure, and manage a wide range of network-layer functions\nthat had previously been implemented through an assortment of ­network-\nlayer devices), without over-burdening the abstraction with so much detail\nand generality that it becomes bloated and unusable. Butler Lampson has\nfamously noted [Lampson 1983]:\nDo one thing at a time, and do it well. An interface should capture the\nminimum essentials of an abstraction. Don’t generalize; generalizations\nare generally wrong. Given OpenFlow’s success, one can surmise that its designers indeed chose\ntheir abstraction well. Additional details of OpenFlow matching can be\nfound in [ONF 2020]. 4.4.2 Action\nAs shown in Figure 4.28, each flow table entry has a list of zero or more\nactions that determine the processing that is to be applied to a packet that\nmatches a flow table entry. If there are multiple actions, they are performed\nin the order specified in the list. Among the most important possible actions are:\n•\nForwarding. An incoming packet may be forwarded to a particular\nphysical output port, broadcast over all ports (except the port on which\nit arrived) or multicast over a selected set of ports. The packet may be"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 626,
    "text": "encapsulated and sent to the remote controller for this device. That\ncontroller then may (or may not) take some action on that packet,\nincluding installing new flow table entries, and may return the packet to\nthe device for forwarding under the updated set of flow table rules. •\nDropping. A flow table entry with no action indicates that a matched\npacket should be dropped. •\nModify-field. The values in 10 packet-header fields (all layer 2, 3, and 4\nfields shown in Figure 4.29 except the IP Protocol field) may be re-\nwritten before the packet is forwarded to the chosen output port. 4.4.3 OpenFlow Examples of Match-plus-action in\nAction\nHaving now considered both the match and action components of\ngeneralized forwarding, let’s put these ideas together in the context of the\nsample network shown in Figure 4.30. The network has 6 hosts (h1, h2, h3,\nh4, h5 and h6) and three packet switches (s1, s2 and s3), each with four\nlocal interfaces (numbered 1 through 4). We’ll consider a number of\nnetwork-wide behaviors that we’d like to implement, and the flow table\nentries in s1, s2 and s3 needed to implement this behavior."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 627,
    "text": "Figure 4.30 ♦OpenFlow match-plus-action network with three\npacket switches, 6 hosts, and an OpenFlow controller\nA First Example: Simple Forwarding\nAs a very simple example, suppose that the desired forwarding behavior is\nthat packets from h5 or h6 destined to h3 or h4 are to be forwarded from s3\nto s1, and then from s1 to s2 (thus completely avoiding the use of the link\nbetween s3 and s2). The flow table entry in s1 would be:\nOf course, we’ll also need a flow table entry in s3 so that datagrams\nsent from h5 or h6 are forwarded to s1 over outgoing interface 3:\nLastly, we’ll also need a flow table entry in s2 to complete this first\nexample, so that datagrams arriving from s1 are forwarded to their\ndestination, either host h3 or h4:\nA Second Example: Load Balancing"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 628,
    "text": "As a second example, let’s consider a load-balancing scenario, where\ndatagrams from h3 destined to 10.1.*. * are to be forwarded over the direct\nlink between s2 and s1, while datagrams from h4 destined to 10.1.*. * are to\nbe forwarded over the link between s2 and s3 (and then from s3 to s1). Note\nthat this behavior couldn’t be achieved with IP’s destination-based\nforwarding. In this case, the flow table in s2 would be:\nFlow table entries are also needed at s1 to forward the datagrams\nreceived from s2 to either h1 or h2; and flow table entries are needed at s3\nto forward datagrams received on interface 4 from s2 over interface 3\ntoward s1. See if you can figure out these flow table entries at s1 and s3. A Third Example: Firewalling\nAs a third example, let’s consider a firewall scenario in which s2 wants only\nto receive (on any of its interfaces) traffic sent from hosts attached to s3. If there were no other entries in s2’s flow table, then only traffic from\n10.3.*. * would be forwarded to the hosts attached to s2. Although we’ve only considered a few basic scenarios here, the\nversatility and advantages of generalized forwarding are hopefully apparent. In homework problems, we’ll explore how flow tables can be used to create\nmany different logical behaviors, including virtual networks—two or more\nlogically separate networks (each with their own independent and distinct\nforwarding behavior)—that use the same physical set of packet switches\nand links. In Section 5.5, we’ll return to flow tables when we study the\nSDN controllers that compute and distribute the flow tables, and the\nprotocol used for communicating between a packet switch and its controller. The match-plus-action flow tables that we’ve seen in this section are\nactually a limited form of programmability, specifying how a router should\nforward and manipulate (e.g., change a header field) a datagram, based on"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 629,
    "text": "the match between the datagram’s header values and the matching\nconditions. One could imagine an even richer form of programmability—a\nprogramming language with higher-level constructs such as variables,\ngeneral purpose arithmetic and Boolean operations, variables, functions,\nand conditional statements, as well as constructs specifically designed for\ndatagram processing at line rate. P4 (Programming Protocol-independent\nPacket Processors) [P4 2020] is such a language, and has gained\nconsiderable interest and traction since its introduction five years ago\n[Bosshart 2014]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 630,
    "text": "4.5 Middleboxes\nRouters are the workhorses of the network layer, and in this chapter, we’ve\nlearned how they accomplish their “bread and butter” job of forwarding IP\ndatagrams toward their destination. But in this chapter, and in earlier\nchapters, we’ve also encountered other network equipment (“boxes”) within\nthe network that sit on the data path and perform functions other than\nforwarding. We encountered Web caches in Section 2.2.5; TCP connection\nsplitters in section 3.7; and network address translation (NAT), firewalls,\nand intrusion detection systems in Section 4.3.4. We learned in Section 4.4\nthat generalized forwarding allows a modern router to easily and naturally\nperform firewalling and load balancing with generalized “match plus\naction” operations. In the past 20 years, we’ve seen tremendous growth in such\nmiddleboxes, which RFC 3234 defines as:\n“any intermediary box performing functions apart from normal,\nstandard functions of an IP router on the data path between a source\nhost and destination host”\nWe can broadly identify three types of services performed by middleboxes:\n•\nNAT Translation. As we saw in Section 4.3.4, NAT boxes implement\nprivate network addressing, rewriting datagram header IP addresses and\nport numbers. •\nSecurity Services. Firewalls block traffic based on header-field values or\nredirect packets for additional processing, such as deep packet\ninspection (DPI). Intrusion Detection Systems (IDS) are able to detect"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 631,
    "text": "predetermined patterns and filter packets accordingly. Application-level\ne-mail filters block e-mails considered to be junk, phishing or otherwise\nposing a security threat. •\nPerformance Enhancement. These middleboxes perform services such\nas compression, content caching, and load balancing of service requests\n(e.g., an HTTP request, or a search engine query) to one of a set of\nservers that can provide the desired service. Many other middleboxes [RFC 3234] provide capabilities belonging to\nthese three types of services, in both wired and wireless cellular [Wang\n2011] networks. With the proliferation of middleboxes comes the attendant need to\noperate, manage, and upgrade this equipment. Separate specialized\nhardware \nboxes, \nseparate \nsoftware \nstacks, \nand \nseparate\nmanagement/operation skills translate to significant operational and capital\ncosts. It is perhaps not surprising then that researchers are exploring the use\nof commodity hardware (networking, computing, and storage) with\nspecialized software built on top of a common software stack—exactly the\napproach taken in SDN a decade earlier—to implement these services. This\napproach has become known as network function virtualization (NFV)\n[Mijumbi 2016]. An alternate approach that has also been explored is to\noutsource middlebox functionality to the cloud [Sherry 2012]. For many years, the Internet architecture had a clear separation between\nthe network layer and the transport/application layers. In these “good old\ndays,” the network layer consisted of routers, operating within the network\ncore, to forward datagrams toward their destinations using fields only in the\nIP datagram header. The transport and application layers were implemented\nin hosts operating at the network edge. Hosts exchanged packets among\nthemselves in transport-layer segments and application-layer messages."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 632,
    "text": "Today’s middleboxes clearly violate this separation: a NAT box, sitting\nbetween a router and host, rewrites network-layer IP addresses and\ntransport-layer port numbers; an in-network firewall blocks suspect\ndatagrams using application-layer (e.g., HTTP), transport-layer, and\nnetwork-layer header fields; e-mail security gateways are injected between\nthe e-mail sender (whether malicious or not) and the intended e-mail\nreceiver, \nfiltering \napplication-layer \ne-mail \nmessages \nbased \non\nwhitelisted/blacklisted IP addresses as well as e-mail message content. While there are those who have considered such middleboxes as a bit of an\narchitectural abomination [Garfinkel 2003], others have adopted the\nphilosophy that such middleboxes “exist for important and permanent\nreasons”—that they fill an important need—and that we’ll have more, not\nfewer, middleboxes in the future [Walfish 2004]. See the section in attached\nsidebar on “The end-to-end argument” for a slightly different lens on the\nquestion of where to place service functionality in a network. PRINCIPLES IN\nPRACTICE\nARCHITECTURAL PRINCIPLES OF THE INTERNET\nGiven the phenomenal success of the Internet, one might naturally wonder about the\narchitectural principles that have guided the development of what is arguably the largest\nand most complex engineered system ever built by humankind. RFC 1958, entitled\n“Architectural Principles of the Internet,” suggests that these principles, if indeed they exist,\nare truly minimal:\n“Many members of the Internet community would argue that there is no architecture,\nbut only a tradition, which was not written down for the first 25 years (or at least not by"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 633,
    "text": "the IAB). However, in very general terms, the community believes that the goal is\nconnectivity, the tool is the Internet Protocol, and the intelligence is end to end rather\nthan hidden in the network.” [RFC 1958]\nSo there we have it! The goal was to provide connectivity, there would be just one network-\nlayer protocol (the celebrated IP protocol we have studied in this chapter), and “intelligence”\n(one might say the “complexity”) would be placed at the network edge, rather than in the\nnetwork core. Let’s look these last two considerations in a bit more detail. THE IP HOURGLASS\nBy now, we’re well acquainted with the five-layer Internet protocol stack that we first\nencountered in Figure 1.23. Another visualization of this stack, shown in Figure 4.31 and\nsometimes known as the “IP hourglass,” illustrates the “narrow waist” of the layered\nInternet architecture. While the Internet has many protocols in the physical, link, transport,\nand application layers, there is only one network layer protocol—the IP protocol. This is the\none protocol that must be implemented by each and every of the billions of Internet-\nconnected devices. This narrow waist has played a critical role in the phenomenal growth of\nthe Internet. The relative simplicity of the IP protocol, and the fact that it is the only universal\nrequirement for Internet connectivity has allowed a rich variety of networks—with very\ndifferent underlying link-layer technologies, from Ethernet to WiFi to cellular to optical\nnetworks to become part of the Internet. [Clark 1997] notes that role of the narrow waist,\nwhich he refers to as a “spanning layer,” is to “… hide the detailed differences among these\nvarious [underlying] technologies and present a uniform service interface to the applications\nabove.” For the IP layer in particular: “How does the IP spanning layer achieve its purpose? It defines a basic set of services, which were carefully designed so that they could be\nconstructed from a wide range of underlying network technologies. Software, as a part of\nthe Internet [i.e., network] layer, translates what each of these lower-layer technologies\noffers into the common service of the Internet layer.”"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 634,
    "text": "For a discussion the narrow waist, including examples beyond the Internet, see [Beck\n2019; Akhshabi 2011]. We note here that as the Internet architecture enters mid-life\n(certainly, the Internet’s age of 40 to 50 years qualifies it for middle age! ), one might observe\nthat its “narrow waist” may indeed be widening a bit (as often happens in middle age!) via\nthe rise of middleboxes. Figure 4.31 ♦The narrow-waisted Internet hourglass\nTHE END-TO-END ARGUMENT\nThe third principle in RFC 1958—that “intelligence is end to end rather than hidden in the\nnetwork”—speaks to the placement of functionality within the network. Here, we’ve seen\nthat until the recent rise of middleboxes, most Internet functionality was indeed placed at the\nnetwork’s edge. It’s worth noting that, in direct contrast with the 20th century telephone\nnetwork—which had “dumb” (non-programmable) endpoints and smart switches—the\nInternet has always had smart endpoints (programmable computers), enabling complex\nfunctionality to be placed at those endpoints. But a more principled argument for actually\nplacing functionality at the endpoints was made in an extremely influential paper [Saltzer\n1984] that articulated the “end-to-end argument.” It stated:"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 635,
    "text": "“ . . . there is a list of functions each of which might be implemented in any of several\nways: by the communication subsystem, by its client, as a joint venture, or perhaps\nredundantly, each doing its own version. In reasoning about this choice, the\nrequirements of the application provide the basis for a class of arguments, which go as\nfollows:\nThe function in question can completely and correctly be implemented only with\nthe knowledge and help of the application standing at the end points of the\ncommunication system. Therefore, providing that questioned function as a feature\nof the communication system itself is not possible. (Sometimes an incomplete\nversion of the function provided by the communication system may be useful as a\nperformance enhancement.) We call this line of reasoning against low-level function implementation the “end-to-end\nargument.”\nAn example illustrating the end-to-end argument is that of reliable data transfer. Since\npackets can be lost within the network (e.g., even without buffer overflows, a router holding\na queued packet could crash, or a portion of the network in which a packet is queued\nbecomes detached due to link failures), the endpoints (in this case via the TCP protocol)\nmust perform error control. As we will see in Chapter 6, some link-layer protocols do indeed\nperform local error control, but this local error control alone is “incomplete” and not sufficient\nto provide end-to-end reliable data transfer. And so reliable data transfer must be\nimplemented end to end. RFC 1958 deliberately includes only two references, both of which are “fundamental\npapers on the Internet architecture.” One of these is the end-to-end paper itself [Saltzer\n1984]; the second paper [Clark 1988] discusses the design philosophy of the DARPA\nInternet Protocols. Both are interesting “must reads” for anyone interested in Internet\narchitecture. Follow-ons to [Clark 1988] are [Blumenthal 2001; Clark 2005] which reconsider"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 636,
    "text": "Internet architecture in light of the much more complex environment in which today’s\nInternet must now operate."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 637,
    "text": "4.6 Summary\nIn this chapter, we’ve covered the data plane functions of the network layer\n—the per-router functions that determine how packets arriving on one of a\nrouter’s input links are forwarded to one of that router’s output links. We\nbegan by taking a detailed look at the internal operations of a router,\nstudying input and output port functionality and destination-based\nforwarding, a router’s internal switching mechanism, packet queue\nmanagement and more. We covered both traditional IP forwarding (where\nforwarding is based on a datagram’s destination address) and generalized\nforwarding (where forwarding and other functions may be performed using\nvalues in several different fields in the datagram’s header) and seen the\nversatility of the latter approach. We also studied the IPv4 and IPv6\nprotocols in detail, and Internet addressing, which we found to be much\ndeeper, subtler, and more interesting than we might have expected. We\ncompleted our study of the network-layer data plane with a study of\nmiddleboxes, and a broad discussion of Internet architecture. With our newfound understanding of the network-layer’s data plane,\nwe’re now ready to dive into the network layer’s control plane in Chapter 5!"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 638,
    "text": "Homework Problems and Questions\nChapter 4 Review Questions\nSECTION 4.1\nR1. Let’s review some of the terminology used in this textbook. Recall\nthat the name of a transport-layer packet is segment and that the name\nof a link-layer packet is frame. What is the name of a network-layer\npacket? Recall that both routers and link-layer switches are called\npacket switches. What is the fundamental difference between a router\nand link-layer switch? R2. We noted that network layer functionality can be broadly divided into\ndata plane functionality and control plane functionality. What are the\nmain functions of the data plane? Of the control plane? R3. We made a distinction between the forwarding function and the\nrouting function performed in the network layer. What are the key\ndifferences between routing and forwarding? R4. What is the role of the forwarding table within a router? R5. We said that a network layer’s service model “defines the\ncharacteristics of end-to-end transport of packets between sending\nand receiving hosts.” What is the service model of the Internet’s\nnetwork layer? What guarantees are made by the Internet’s service\nmodel regarding the host-to-host delivery of datagrams? SECTION 4.2\nR6. In Section 4.2, we saw that a router typically consists of input ports,\noutput ports, a switching fabric and a routing processor. Which of"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 639,
    "text": "these are implemented in hardware and which are implemented in\nsoftware? Why? Returning to the notion of the network layer’s data\nplane and control plane, which are implemented in hardware and\nwhich are implemented in software? Why? R7. How can the input ports of a high-speed router facilitate fast\nforwarding ­decisions? R8. What is meant by destination-based forwarding? How does this differ\nfrom generalized forwarding (assuming you’ve read Section 4.4,\nwhich of the two approaches are adopted by Software-Defined\nNetworking)? R9. Suppose that an arriving packet matches two or more entries in a\nrouter’s forwarding table. With traditional destination-based\nforwarding, what rule does a router apply to determine which of these\nrules should be applied to determine the output port to which the\narriving packet should be switched? R10. Switching in a router forwards data from an input port to an output\nport. What is the advantage of switching via an interconnection\nnetwork over switching via memory and switching via bus? R11. What is the role of a packet scheduler at the output port of a router? R12. a. What is a drop-tail policy? b. What are AQM algorithms? c. Name one of the most widely studied and implemented AQM\nalgorithms and explain how it works. R13. What is HOL blocking? Does it occur in input ports or output ports? R14. In Section 4.2, we studied FIFO, Priority, Round Robin (RR), and\nWeighted Fair Queuing (WFQ) packet scheduling disciplines? Which"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 640,
    "text": "of these queuing disciplines ensure that all packets depart in the order\nin which they arrived? R15. Give an example showing why a network operator might want one\nclass of packets to be given priority over another class of packets. R16. What is an essential different between RR and WFQ packet\nscheduling? Is there a case (Hint: Consider the WFQ weights) where\nRR and WFQ will behave exactly the same? SECTION 4.3\nR17. Suppose Host A sends Host B a TCP segment encapsulated in an IP\ndatagram. When Host B receives the datagram, how does the network\nlayer in Host B know it should pass the segment (that is, the payload\nof the datagram) to TCP rather than to UDP or to some other upper-\nlayer protocol? R18. What field in the IP header can be used to ensure that a packet is\nforwarded through no more than N routers? R19. Recall that we saw the Internet checksum being used in both\ntransport-layer segment (in UDP and TCP headers, Figures 3.7 and\n3.29 respectively) and in network-layer datagrams (IP header, Figure\n4.17). Now consider a transport layer segment encapsulated in an IP\ndatagram. Are the checksums in the segment header and datagram\nheader computed over any common bytes in the IP datagram? Explain your answer. R20. When a large datagram is fragmented into multiple smaller\ndatagrams, where are these smaller datagrams reassembled into a\nsingle larger datagram? R21. How many IP addresses does a router have? R22. What is the 32-bit binary equivalent of the IP address 202.3.14.25?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 641,
    "text": "R23. Visit a host that uses DHCP to obtain its IP address, network mask,\ndefault router, and IP address of its local DNS server. List these\nvalues. R24. Suppose there are four routers between a source host and a\ndestination host. Ignoring fragmentation, an IP datagram sent from\nthe source host to the ­destination host will travel over how many\ninterfaces? How many forwarding tables will be indexed to move the\ndatagram from the source to the destination? R25. Suppose an application generates chunks of 40 bytes of data every 20\nmsec, and each chunk gets encapsulated in a TCP segment and then\nan IP datagram. What percentage of each datagram will be overhead,\nand what percentage will be application data? R26. Suppose you purchase a wireless router and connect it to your cable\nmodem. Also suppose that your ISP dynamically assigns your\nconnected device (that is, your wireless router) one IP address. Also\nsuppose that you have five PCs at home that use 802.11 to wirelessly\nconnect to your wireless router. How are IP addresses assigned to the\nfive PCs? Does the wireless router use NAT? Why or why not? R27. What is meant by the term “route aggregation”? Why is it useful for a\nrouter to perform route aggregation? R28. What is meant by a “plug-and-play” or “zeroconf” protocol? R29. What is a private network address? Should a datagram with a private\nnetwork address ever be present in the larger public Internet? Explain. R30. Compare and contrast the IPv4 and the IPv6 header fields. Do they\nhave any fields in common? R31. It has been said that when IPv6 tunnels through IPv4 routers, IPv6\ntreats the IPv4 tunnels as link-layer protocols. Do you agree with this"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 642,
    "text": "statement? Why or why not? SECTION 4.4\nR32. How does generalized forwarding differ from destination-based ­-\nforwarding? R33. What is the difference between a forwarding table that we\nencountered in destination-based forwarding in Section 4.1 and\nOpenFlow’s flow table that we encountered in Section 4.4? R34. What is meant by the “match plus action” operation of a router or\nswitch? In the case of destination-based forwarding packet switch,\nwhat is matched and what is the action taken? In the case of an SDN,\nname three fields that can be matched, and three actions that can be\ntaken. R35. Name three header fields in an IP datagram that can be “matched” in\nOpenFlow 1.0 generalized forwarding. What are three IP datagram\nheader fields that cannot be “matched” in OpenFlow? Problems\nP1. Consider the network below. a. Show the forwarding table in router A, such that all traffic\ndestined to host H3 is forwarded through interface 3.\nb. Can you write down a forwarding table in router A, such that all\ntraffic from H1 destined to host H3 is forwarded through\ninterface 3, while all traffic from H2 destined to host H3 is\nforwarded through interface 4? (Hint: This is a trick question.)"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 643,
    "text": "P2. Suppose two packets arrive to two different input ports of a router at\nexactly the same time. Also suppose there are no other packets\nanywhere in the router. a. Suppose the two packets are to be forwarded to two different\noutput ports. Is it possible to forward the two packets through the\nswitch fabric at the same time when the fabric uses a shared bus? b. Suppose the two packets are to be forwarded to two different\noutput ports. Is it possible to forward the two packets through the\nswitch fabric at the same time when the fabric uses switching via\nmemory? c. Suppose the two packets are to be forwarded to the same output\nport. Is it possible to forward the two packets through the switch\nfabric at the same time when the fabric uses a crossbar? P3. In Section 4.2.4, it was said that if R_switch is N times faster than\nR_line, then only negligible queuing will occur at the input ports,\neven if all the packets are to be forwarded to the same output port. Now suppose that R_switch = R_line, but all packets are to be\nforwarded to different output ports. Let D be the time to transmit a\npacket. As a function of D, what is the maximum input queuing delay\nfor a packet for the (a) memory, (b) bus, and (c) crossbar switching\nfabrics?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 644,
    "text": "P4. Consider the switch shown below. Suppose that all datagrams have\nthe same fixed length, that the switch operates in a slotted,\nsynchronous manner, and that in one time slot a datagram can be\ntransferred from an input port to an output port. The switch fabric is a\ncrossbar so that at most one datagram can be transferred to a given\noutput port in a time slot, but different output ports can receive\ndatagrams from different input ports in a single time slot. What is the\nminimal number of time slots needed to transfer the packets shown\nfrom input ports to their output ports, assuming any input queue\nscheduling order you want (i.e., it need not have HOL blocking)? What is the largest number of slots needed, assuming the worst-case\nscheduling order you can devise, assuming that a non-empty input\nqueue is never idle? P5. Suppose that the WEQ scheduling policy is applied to a buffer that\nsupports three classes, and suppose the weights are 0.5, 0.25, and 0.25\nfor the three classes. a. Suppose that each class has a large number of packets in the\nbuffer. In what sequence might the three classes be served in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 645,
    "text": "order to achieve the WFQ weights? (For round robin scheduling,\na natural sequence is 123123123 . . .). b. Suppose that classes 1 and 2 have a large number of packets in\nthe buffer, and there are no class 3 packets in the buffer. In what\nsequence might the three classes be served in to achieve the WFQ\nweights? P6. Consider the figure below. Answer the following questions:\na. Assuming FIFO service, indicate the time at which packets 2\nthrough 12 each leave the queue. For each packet, what is the\ndelay between its arrival and the beginning of the slot in which it\nis transmitted? What is the average of this delay over all 12\npackets? b. Now assume a priority service, and assume that odd-numbered\npackets are high priority, and even-numbered packets are low\npriority. Indicate the time at which packets 2 through 12 each\nleave the queue. For each packet, what is the delay between its\narrival and the beginning of the slot in which it is transmitted? What is the average of this delay over all 12 packets?"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 646,
    "text": "c. Now assume round robin service. Assume that packets 1, 2, 3, 6,\n11, and 12 are from class 1, and packets 4, 5, 7, 8, 9, and 10 are\nfrom class 2. Indicate the time at which packets 2 through 12\neach leave the queue. For each packet, what is the delay between\nits arrival and its departure? What is the average delay over all 12\npackets? d. Now assume weighted fair queuing (WFQ) service. Assume that\nodd-numbered packets are from class 1, and even-numbered\npackets are from class 2. Class 1 has a WFQ weight of 2, while\nclass 2 has a WFQ weight of 1. Note that it may not be possible\nto achieve an idealized WFQ schedule as described in the text, so\nindicate why you have chosen the particular packet to go into\nservice at each time slot. For each packet what is the delay\nbetween its arrival and its departure? What is the average delay\nover all 12 packets? e. What do you notice about the average delay in all four cases\n(FIFO, RR, priority, and WFQ)? P7. Consider again the figure for P6. a. Assume a priority service, with packets 1, 4, 5, 6, and 11 being\nhigh-priority packets. The remaining packets are low priority. Indicate the slots in which packets 2 through 12 each leave the\nqueue. b. Now suppose that round robin service is used, with packets 1, 4,\n5, 6, and 11 belonging to one class of traffic, and the remaining\npackets belonging to the second class of traffic. Indicate the slots\nin which packets 2 through 12 each leave the queue. c. Now suppose that WFQ service is used, with packets 1, 4, 5, 6,\nand 11 belonging to one class of traffic, and the remaining"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 647,
    "text": "packets belonging to the second class of traffic. Class 1 has a\nWFQ weight of 1, while class 2 has a WFQ weight of 2 (note that\nthese weights are different than in the previous question). Indicate the slots in which packets 2 through 12 each leave the\nqueue. See also the caveat in the question above regarding WFQ\nservice. P8. Consider a datagram network using 32-bit host addresses. Suppose a\nrouter has four links, numbered 0 through 3, and packets are to be\nforwarded to the link interfaces as follows:\na. Provide a forwarding table that has five entries, uses longest\nprefix matching, and forwards packets to the correct link\ninterfaces. b. Describe how your forwarding table determines the appropriate\nlink interface for datagrams with destination addresses:\n11001000 10010001 01010001 01010101\n11100001 01000000 11000011 00111100\n11100001 10000000 00010001 01110111\nP9. Consider a datagram network using 8-bit host addresses. Suppose a\nrouter uses longest prefix matching and has the following forwarding\ntable:\nFor each of the four interfaces, give the associated range of\ndestination host addresses and the number of addresses in the range. P10. Consider a datagram network using 8-bit host addresses. Suppose a\nrouter uses longest prefix matching and has the following forwarding\ntable:\nFor each of the four interfaces, give the associated range of\ndestination host addresses and the number of addresses in the range."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 223",
    "source": "kurose",
    "page": 648,
    "text": "P11. Consider a router that interconnects three subnets: Subnet 1, Subnet 2,\nand Subnet 3. Suppose all of the interfaces in each of these three\nsubnets are required to have the prefix 223.1.17/24. Also suppose that\nSubnet 1 is required to support at least 60 interfaces, Subnet 2 is to\nsupport at least 90 interfaces, and Subnet 3 is to support at least 12\ninterfaces. Provide three network addresses (of the form a.b.c.d/x)\nthat satisfy these constraints. P12. In Section 4.2.2, an example forwarding table (using longest prefix\nmatching) is given. Rewrite this forwarding table using the a.b.c.d/x\nnotation instead of the binary string notation. P13. In Problem P8, you are asked to provide a forwarding table (using\nlongest prefix matching). Rewrite this forwarding table using the\na.b.c.d/x notation instead of the binary string notation. P14. Consider a subnet with prefix 128.119.40.128/26. Give an example of\none IP address (of form xxx.xxx.xxx.xxx) that can be assigned to this\nnetwork. Suppose an ISP owns the block of addresses of the form\n128.119.40.64/26. Suppose it wants to create four subnets from this\nblock, with each block having the same number of IP addresses. What\nare the prefixes (of form a.b.c.d/x) for the four subnets? P15. Consider the topology shown in Figure 4.20. Denote the three subnets\nwith hosts (starting clockwise at 12:00) as Networks A, B, and C.\nDenote the subnets without hosts as Networks D, E, and F.\na. Assign network addresses to each of these six subnets, with the\nfollowing constraints: All addresses must be allocated from\n214.97.254/23; Subnet A should have enough addresses to\nsupport 250 interfaces; Subnet B should have enough addresses\nto support 120 interfaces; and Subnet C should have enough\naddresses to support 120 interfaces. Of course, subnets D, E and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 649,
    "text": "F should each be able to support two interfaces. For each subnet,\nthe assignment should take the form a.b.c.d/x or a.b.c.d/x –\ne.f.g.h/y. b. Using your answer to part (a), provide the forwarding tables\n(using longest prefix matching) for each of the three routers. P16. Use the whois service at the American Registry for Internet Numbers\n(http://www.arin.net/whois) to determine the IP address blocks for\nthree universities. Can the whois services be used to determine with\ncertainty the geographical location of a specific IP address? Use\nwww.maxmind.com to determine the locations of the Web servers at\neach of these universities. P17. Suppose datagrams are limited to 1,500 bytes (including header)\nbetween source Host A and destination Host B. Assuming a 20-byte\nIP header, how many datagrams would be required to send an MP3\nconsisting of 5 million bytes? Explain how you computed your\nanswer. P18. Consider the network setup in Figure 4.25. Suppose that the ISP\ninstead assigns the router the address 24.34.101.225 and that the\nnetwork address of the home network is 192.168.0/24. a. Assign addresses to all interfaces in the home network. b. Suppose each host has two ongoing TCP connections, all to port\n80 at host 128.119.40.86. Provide the six corresponding entries in\nthe NAT translation table. P19. Suppose you are interested in detecting the number of hosts behind a\nNAT. You observe that the IP layer stamps an identification number\nsequentially on each IP packet. The identification number of the first\nIP packet generated by a host is a random number, and the\nidentification numbers of the subsequent IP packets are sequentially"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 650,
    "text": "assigned. Assume all IP packets generated by hosts behind the NAT\nare sent to the outside world. a. Based on this observation, and assuming you can sniff all packets\nsent by the NAT to the outside, can you outline a simple\ntechnique that detects the number of unique hosts behind a NAT? Justify your answer. b. If the identification numbers are not sequentially assigned but\nrandomly assigned, would your technique work? Justify your\nanswer. P20. In this problem, we’ll explore the impact of NATs on P2P\napplications. Suppose a peer with username Arnold discovers through\nquerying that a peer with username Bernard has a file it wants to\ndownload. Also suppose that Bernard and Arnold are both behind a\nNAT. Try to devise a technique that will allow Arnold to establish a\nTCP connection with Bernard without application-specific NAT\nconfiguration. If you have difficulty devising such a technique,\ndiscuss why. P21. Consider the SDN OpenFlow network shown in Figure 4.30. Suppose\nthat the desired forwarding behavior for datagrams arriving at s2 is as\nfollows:\n•\nany datagrams arriving on input port 1 from hosts h5 or h6 that\nare destined to hosts h1 or h2 should be forwarded over output\nport 2;\n•\nany datagrams arriving on input port 2 from hosts h1 or h2 that\nare destined to hosts h5 or h6 should be forwarded over output\nport 1;\n•\nany arriving datagrams on input ports 1 or 2 and destined to hosts\nh3 or h4 should be delivered to the host specified;"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 651,
    "text": "•\nhosts h3 and h4 should be able to send datagrams to each other. Specify the flow table entries in s2 that implement this forwarding\nbehavior. P22. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose that the desired forwarding behavior for datagrams arriving\nfrom hosts h3 or h4 at s2 is as follows:\n•\nany datagrams arriving from host h3 and destined for h1, h2, h5\nor h6 should be forwarded in a clockwise direction in the\nnetwork;\n•\nany datagrams arriving from host h4 and destined for h1, h2, h5\nor h6 should be forwarded in a counter-clockwise direction in the\nnetwork. Specify the flow table entries in s2 that implement this forwarding\nbehavior. P23. Consider again the scenario from P21 above. Give the flow tables\nentries at packet switches s1 and s3, such that any arriving datagrams\nwith a source address of h3 or h4 are routed to the destination hosts\nspecified in the destination address field in the IP datagram. (Hint:\nYour forwarding table rules should include the cases that an arriving\ndatagram is destined for a directly attached host or should be\nforwarded to a neighboring router for eventual host delivery there.) P24. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose we want switch s2 to function as a firewall. Specify the flow\ntable in s2 that implements the following firewall behaviors (specify a\ndifferent flow table for each of the four firewalling behaviors below)\nfor delivery of datagrams destined to h3 and h4. You do not need to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 652,
    "text": "specify the forwarding behavior in s2 that forwards traffic to other\nrouters. •\nOnly traffic arriving from hosts h1 and h6 should be delivered to\nhosts h3 or h4 (i.e., that arriving traffic from hosts h2 and h5 is\nblocked). •\nOnly TCP traffic is allowed to be delivered to hosts h3 or h4 (i.e.,\nthat UDP traffic is blocked). •\nOnly traffic destined to h3 is to be delivered (i.e., all traffic to h4\nis blocked). •\nOnly UDP traffic from h1 and destined to h3 is to be delivered. All other traffic is blocked. P25. Consider the Internet protocol stack in Figures 1.23 and 4.31. Would\nyou consider the ICMP protocol to be a network-layer protocol or a\ntransport-layer protocol? Justify your answer."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 654,
    "text": "AN INTERVIEW WITH…\nVinton G. Cerf\nVinton G. Cerf has served as Vice President and Chief\nInternet Evangelist for Google since 2005. He served for over\n15 years at MCI in various positions, ending up his tenure\nthere as Senior Vice President for Technology Strategy. He is\nwidely known as the co-designer of the TCP/IP protocols and\nthe architecture of the Internet. During his time from 1976 to\n1982 at the US Department of Defense Advanced Research\nProjects Agency (DARPA), he played a key role leading the\ndevelopment of Internet and Internet-related packet\ncommunication and security techniques. He received the US\nPresidential Medal of Freedom in 2005 and the US National\nMedal of Technology in 1997. He holds a BS in Mathematics\nfrom Stanford University and an MS and PhD in computer\nscience from UCLA."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 655,
    "text": "Courtesy of Vinton G. Cerf\nWhat brought you to specialize in\nnetworking? I was working as a programmer at UCLA in the\nlate 1960s. My job was supported by the US\nDefense Advanced Research Projects Agency\n(called ARPA then and DARPA now). I was\nworking in the laboratory of Professor Leonard\nKleinrock in the Network Measurement Center of\nthe newly created ARPANet. The first node of the\nARPANet was installed at UCLA on September 1,\n1969. I was responsible for programming a\ncomputer that was used to capture performance\ninformation about the ARPANet and to report this\ninformation back for comparison with\nmathematical models and predictions of the\nperformance of the network. Several of the other graduate students and I\nwere made responsible for working on the so-\ncalled host-level protocols of the ARPAnet—the\nprocedures and formats that would allow many\ndifferent kinds of computers on the network to\ninteract with each other. It was a fascinating\nexploration into a new world (for me) of\ndistributed computing and communication."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 656,
    "text": "Did you imagine that IP would become as\npervasive as it is today when you first\ndesigned the protocol? When Bob Kahn and I first worked on this in 1973,\nI think we were mostly very focused on the central\nquestion: How can we make heterogeneous packet\nnetworks interoperate with one another, assuming\nwe cannot actually change the networks\nthemselves? We hoped that we could find a way to\npermit an arbitrary collection of packet-switched\nnetworks to be interconnected in a transparent\nfashion, so that host computers could communicate\nend-to-end without having to do any translations in\nbetween. I think we knew that we were dealing\nwith powerful and expandable technology, but I\ndoubt we had a clear image of what the world\nwould be like with billions of computers all\ninterlinked on the Internet. What do you now envision for the future of\nnetworking and the Internet? What major\nchallenges/obstacles do you think lie\nahead in their development? I believe the Internet itself and networks in general\nwill continue to proliferate. There are already\nbillions of Internet-enabled devices on the Internet,\nincluding appliances like cell phones, refrigerators,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 657,
    "text": "personal digital assistants, home servers,\ntelevisions, as well as the usual array of laptops,\nservers, and so on. Big challenges include support\nfor mobility, battery life, capacity of the access\nlinks to the network, and ability to scale the optical\ncore of the network in an unlimited fashion. The\ninterplanetary extension of the Internet is a project\nthat is well underway at NASA and other space\nagencies. We still need to add IPv6 [128-bit]\naddressing to the original IPv4 [32-bit addresses]\npacket format. The list is long! Who has inspired you professionally? My colleague Bob Kahn; my thesis advisor, Gerald\nEstrin; my best friend, Steve Crocker (we met in\nhigh school and he introduced me to computers in\n1960! ); and the thousands of engineers who\ncontinue to evolve the Internet today. Do you have any advice for students\nentering the networking/Internet field? Think outside the limitations of existing systems—\nimagine what might be possible; but then do the\nhard work of figuring out how to get there from the\ncurrent state of affairs. Dare to dream. The\n“Internet of Things” is the next big phase of\nInternet expansion. Safety, security, privacy,\nreliability, and autonomy all need attention. The"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 658,
    "text": "interplanetary extension of the terrestrial Internet\nstarted as a speculative design but is becoming a\nreality. It may take decades to implement this,\nmission by mission, but to paraphrase: “A man’s\nreach should exceed his grasp, or what are the\nheavens for?”"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 659,
    "text": "The Network Layer:\nControl Plane\nIn this chapter, we’ll complete our journey through the network layer\nby covering the control-plane component of the network layer—the\nnetwork-wide logic that controls not only how a datagram is routed\nalong an end-to-end path from the source host to the destination host,\nbut also how network-layer components and services are configured\nand managed. In Section 5.2, we’ll cover traditional routing algorithms\nfor computing least cost paths in a graph; these algorithms are the\nbasis for two widely deployed Internet routing protocols: OSPF and\nBGP, that we’ll cover in Sections 5.3 and 5.4, respectively. As we’ll\nsee, OSPF is a routing protocol that operates within a single ISP’s\nnetwork. BGP is a routing protocol that serves to interconnect all of\nthe networks in the Internet; BGP is thus often referred to as the “glue”\nthat holds the Internet together. Traditionally, control-plane routing\nprotocols have been implemented together with data-plane forwarding\nfunctions, monolithically, within a router. As we learned in the\nintroduction to Chapter 4, software-defined networking (SDN) makes\na clear separation between the data and control planes, implementing\ncontrol-plane functions in a separate “controller” service that is\ndistinct, and remote, from the forwarding components of the routers it\ncontrols. We’ll cover SDN controllers in Section 5.5."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 660,
    "text": "In Sections 5.6 and 5.7, we’ll cover some of the nuts and bolts of\nmanaging an IP network: ICMP (the Internet Control Message\nProtocol) and SNMP (the Simple Network Management Protocol)."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 661,
    "text": "5.1 Introduction\nLet’s quickly set the context for our study of the network control plane by\nrecalling Figures 4.2 and 4.3. There, we saw that the forwarding table (in\nthe case of ­destination-based forwarding) and the flow table (in the case of\ngeneralized forwarding) were the principal elements that linked the network\nlayer’s data and control planes. We learned that these tables specify the\nlocal data-plane forwarding behavior of a router. We saw that in the case of\ngeneralized forwarding, the actions taken could include not only forwarding\na packet to a router’s output port, but also dropping a packet, replicating a\npacket, and/or rewriting layer 2, 3 or 4 packet-header fields. In this chapter, we’ll study how those forwarding and flow tables are\ncomputed, maintained and installed. In our introduction to the network\nlayer in Section 4.1, we learned that there are two possible approaches for\ndoing so."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 662,
    "text": "Figure 5.1 ♦Per-router control: Individual routing algorithm\ncomponents interact in the control plane\n•\nPer-router control. Figure 5.1 illustrates the case where a routing\nalgorithm runs in each and every router; both a forwarding and a\nrouting function are contained within each router. Each router has a\nrouting component that communicates with the routing components in\nother routers to compute the values for its forwarding table. This per-\nrouter control approach has been used in the Internet for decades. The\nOSPF and BGP protocols that we’ll study in Sections 5.3 and 5.4 are\nbased on this per-router approach to control. •\nLogically centralized control. Figure 5.2 illustrates the case in which a\nlogically centralized controller computes and distributes the forwarding\ntables to be used by each and every router. As we saw in Sections 4.4"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 663,
    "text": "and 4.5, the generalized match-plus-action abstraction allows the router\nto perform traditional IP forwarding as well as a rich set of other\nfunctions (load sharing, firewalling, and NAT) that had been previously\nimplemented in separate middleboxes. Figure 5.2 ♦Logically centralized control: A distinct, typically\nremote, controller interacts with local control agents\n(CAs)\nThe controller interacts with a control agent (CA) in each of the routers\nvia a well-defined protocol to configure and manage that router’s flow"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 664,
    "text": "table. Typically, the CA has minimum functionality; its job is to\ncommunicate with the controller, and to do as the controller commands. Unlike the routing algorithms in Figure 5.1, the CAs do not directly interact\nwith each other nor do they actively take part in computing the forwarding\ntable. This is a key distinction between per-router control and logically\ncentralized control. By “logically centralized” control [Levin 2012] we mean that the\nrouting control service is accessed as if it were a single central service\npoint, even though the service is likely to be implemented via multiple\nservers for fault-tolerance, and performance scalability reasons. As we will\nsee in Section 5.5, SDN adopts this notion of a logically centralized\ncontroller—an approach that is finding increased use in production\ndeployments. Google uses SDN to control the routers in its internal B4\nglobal wide-area network that interconnects its data centers [Jain 2013]. SWAN [Hong 2013], from Microsoft Research, uses a logically ­centralized\ncontroller to manage routing and forwarding between a wide area network\nand a data center network. Major ISP deployments, including COMCAST’s\nActiveCore and Deutsche Telecom’s Access 4.0 are actively integrating\nSDN into their networks. And as we’ll see in Chapter 8, SDN control is\ncentral to 4G/5G cellular networking as well. [AT&T 2019] notes, “ …\nSDN, isn’t a vision, a goal, or a promise. It’s a reality. By the end of next\nyear, 75% of our network functions will be fully virtualized and software-\ncontrolled.” China Telecom and China Unicom are using SDN both within\ndata centers and between data centers [Li 2015]."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 665,
    "text": "5.2 Routing Algorithms\nIn this section, we’ll study routing algorithms, whose goal is to determine good paths\n(equivalently, routes), from senders to receivers, through the network of routers. Typically, a “good” path is one that has the least cost. We’ll see that in practice,\nhowever, real-world concerns such as policy issues (for example, a rule such as “router\nx, belonging to organization Y, should not forward any packets originating from the\nnetwork owned by organization Z ”) also come into play. We note that whether the\nnetwork control plane adopts a per-router control approach or a logically centralized\napproach, there must always be a well-defined sequence of routers that a packet will\ncross in traveling from sending to receiving host. Thus, the routing algorithms that\ncompute these paths are of fundamental importance, and another candidate for our top-\n10 list of fundamentally important networking concepts. A graph is used to formulate routing problems. Recall that a graph G = (N, E) is a\nset N of nodes and a collection E of edges, where each edge is a pair of nodes from N.\nIn the context of network-layer routing, the nodes in the graph represent routers—the\npoints at which packet-forwarding decisions are made—and the edges connecting\nthese nodes represent the physical links between these routers. Such a graph\nabstraction of a computer network is shown in Figure 5.3. When we study the BGP\ninter-domain routing protocol, we’ll see that nodes represent networks, and the edge\nconnecting two such nodes represents direction connectivity (know as peering)\nbetween the two networks. To view some graphs representing real network maps, see\n[CAIDA 2020]; for a discussion of how well different graph-based models model the\nInternet, see [Zegura 1997, Faloutsos 1999, Li 2004]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 666,
    "text": "Figure 5.3 ♦Abstract graph model of a computer network\nAs shown in Figure 5.3, an edge also has a value representing its cost. Typically,\nan edge’s cost may reflect the physical length of the corresponding link (for example,\na transoceanic link might have a higher cost than a short-haul terrestrial link), the link\nspeed, or the monetary cost associated with a link. For our purposes, we’ll simply take\nthe edge costs as a given and won’t worry about how they are determined. For any\nedge (x, y) in E, in E, we denote c(x, y) as the cost of the edge between nodes x and y. If the pair (x, y) does not belong to E, we set c(x, y) = ∞. Also, we’ll only consider\nundirected graphs (i.e., graphs whose edges do not have a direction) in our discussion\nhere, so that edge (x, y) is the same as edge (y, x) and that c(x, y) = c(y, x); however, the\nalgorithms we’ll study can be easily extended to the case of directed links with a\ndifferent cost in each direction. Also, a node y is said to be a neighbor of node x if (x,\ny) belongs to E.\nGiven that costs are assigned to the various edges in the graph abstraction, a\nnatural goal of a routing algorithm is to identify the least costly paths between sources\nand destinations. To make this problem more precise, recall that a path in a graph G =\n(N, E) is a sequence of nodes (x , x , ..., x ) such that each of the pairs (x , x ), (x , x ),\n..., (x\n, x ) are edges in E. The cost of a path (x , x , ..., x ) is simply the sum of all the\nedge costs along the path, that is, c(x , x ) + c(x , x ) + ...+ c(x\n, x ). Given any two\nnodes x and y, there are typically many paths between the two nodes, with each path\nhaving a cost. One or more of these paths is a least-cost path. The least-cost problem\n2\np\n2\n3\np−1\np\n2\np\n2\n3\np−1\np"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 667,
    "text": "is therefore clear: Find a path between the source and destination that has least cost. In\nFigure 5.3, for example, the least-cost path between source node u and destination\nnode w is (u, x, y, w) with a path cost of 3. Note that if all edges in the graph have the\nsame cost, the least-cost path is also the shortest path (that is, the path with the\nsmallest number of links between the source and the destination). As a simple exercise, try finding the least-cost path from node u to z in Figure 5.3\nand reflect for a moment on how you calculated that path. If you are like most people,\nyou found the path from u to z by examining Figure 5.3, tracing a few routes from u to\nz, and somehow convincing yourself that the path you had chosen had the least cost\namong all possible paths. (Did you check all of the 17 possible paths between u and z? Probably not!) Such a calculation is an example of a centralized routing algorithm—\nthe routing algorithm was run in one location, your brain, with complete information\nabout the network. Broadly, one way in which we can classify routing algorithms is\naccording to whether they are centralized or decentralized. •\nA centralized routing algorithm computes the least-cost path between a source\nand destination using complete, global knowledge about the network. That is, the\nalgorithm takes the connectivity between all nodes and all link costs as inputs. This then requires that the algorithm somehow obtain this information before\nactually performing the calculation. The calculation itself can be run at one site\n(e.g., a logically centralized controller as in Figure 5.2) or could be replicated in\nthe routing component of each and every router (e.g., as in Figure 5.1). The key\ndistinguishing feature here, however, is that the algorithm has complete\ninformation about connectivity and link costs. Algorithms with global state\ninformation are often referred to as link-state (LS) algorithms, since the\nalgorithm must be aware of the cost of each link in the network. We’ll study LS\nalgorithms in Section 5.2.1. •\nIn a decentralized routing algorithm, the calculation of the least-cost path is\ncarried out in an iterative, distributed manner by the routers. No node has complete\ninformation about the costs of all network links. Instead, each node begins with\nonly the knowledge of the costs of its own directly attached links. Then, through\nan iterative process of calculation and exchange of information with its\nneighboring nodes, a node gradually calculates the least-cost path to a destination"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 668,
    "text": "or set of destinations. The decentralized routing algorithm we’ll study below in\nSection 5.2.2 is called a distance-vector (DV) algorithm, because each node\nmaintains a vector of estimates of the costs (distances) to all other nodes in the\nnetwork. Such decentralized algorithms, with interactive message exchange\nbetween neighboring routers is perhaps more naturally suited to control planes\nwhere the routers interact directly with each other, as in Figure 5.1. A second broad way to classify routing algorithms is according to whether they\nare static or dynamic. In static routing algorithms, routes change very slowly over\ntime, often as a result of human intervention (for example, a human manually editing a\nlink costs). Dynamic routing algorithms change the routing paths as the network\ntraffic loads or topology change. A dynamic algorithm can be run either periodically or\nin direct response to topology or link cost changes. While dynamic algorithms are\nmore responsive to network changes, they are also more susceptible to problems such\nas routing loops and route oscillation. A third way to classify routing algorithms is according to whether they are load-\nsensitive or load-insensitive. In a load-sensitive algorithm, link costs vary\ndynamically to reflect the current level of congestion in the underlying link. If a high\ncost is associated with a link that is currently congested, a routing algorithm will tend\nto choose routes around such a congested link. While early ARPAnet routing\nalgorithms were load-sensitive [McQuillan 1980], a number of difficulties were\nencountered [Huitema 1998]. Today’s Internet routing algorithms (such as RIP, OSPF,\nand BGP) are load-insensitive, as a link’s cost does not explicitly reflect its current (or\nrecent past) level of congestion. 5.2.1 The Link-State (LS) Routing Algorithm\nRecall that in a link-state algorithm, the network topology and all link costs are\nknown, that is, available as input to the LS algorithm. In practice, this is accomplished\nby having each node broadcast link-state packets to all other nodes in the network,\nwith each link-state packet containing the identities and costs of its attached links. In\npractice (for example, with the Internet’s OSPF routing protocol, discussed in Section\n5.3), this is often accomplished by a link-state broadcast algorithm ­[Perlman 1999]."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 669,
    "text": "The result of the nodes’ broadcast is that all nodes have an identical and complete view\nof the network. Each node can then run the LS algorithm and compute the same set of\nleast-cost paths as every other node. The link-state routing algorithm we present below is known as Dijkstra’s\nalgorithm, named after its inventor. A closely related algorithm is Prim’s algorithm;\nsee [Cormen 2001] for a general discussion of graph algorithms. Dijkstra’s algorithm\ncomputes the least-cost path from one node (the source, which we will refer to as u) to\nall other nodes in the network. Dijkstra’s algorithm is iterative and has the property\nthat after the kth iteration of the algorithm, the least-cost paths are known to k\ndestination nodes, and among the least-cost paths to all destination nodes, these k\npaths will have the k smallest costs. Let us define the following notation:\n•\nD(v): cost of the least-cost path from the source node to destination v as of this\niteration of the algorithm. •\np(v): previous node (neighbor of v) along the current least-cost path from the\nsource to v.\n•\nN': subset of nodes; v is in N' if the least-cost path from the source to v is\ndefinitively known. The centralized routing algorithm consists of an initialization step followed by a\nloop. The number of times the loop is executed is equal to the number of nodes in the\nnetwork. Upon termination, the algorithm will have calculated the shortest paths from\nthe source node u to every other node in the network. Link-State (LS) Algorithm for Source Node u\nInitialization:\nN’ = {u}\nfor all nodes v\nif v is a neighbor of u\nthen D(v) = c(u,v)\nelse D(v) = ∞"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 670,
    "text": "8\nLoop\nfind w not in N’ such that D(w) is a minimum\n10 add w to N’\n11 update D(v) for each neighbor v of w and not in N’:\n12  D(v) = min(D(v), D(w)+ c(w,v) )\n13  /* new cost to v is either old cost to v or known\n14  least path cost to w plus cost from w to v */\n15 until N’= N\nAs an example, let’s consider the network in Figure 5.3 and compute the least-cost\npaths from u to all possible destinations. A tabular summary of the algorithm’s\ncomputation is shown in Table 5.1, where each line in the table gives the values of the\nalgorithm’s variables at the end of the iteration. Let’s consider the few first steps in\ndetail. •\nIn the initialization step, the currently known least-cost paths from u to its directly\nattached neighbors, v, x, and w, are initialized to 2, 1, and 5, respectively. Note in\nparticular that the cost to w is set to 5 (even though we will soon see that a lesser-\ncost path does indeed exist) since this is the cost of the direct (one hop) link from u\nto w. The costs to y and z are set to infinity because they are not directly connected\nto u. •\nIn the first iteration, we look among those nodes not yet added to the set N' and\nfind that node with the least cost as of the end of the previous iteration. That node\nis x, with a cost of 1, and thus x is added to the set N'. Line 12 of the LS algorithm\nis then performed to update D(v) for all nodes v, yielding the results shown in the\nsecond line (Step 1) in Table 5.1. The cost of the path to v is unchanged. The cost\nof the path to w (which was 5 at the end of the initialization) through node x is\nfound to have a cost of 4. Hence this lower-cost path is selected and w’s\npredecessor along the shortest path from u is set to x. Similarly, the cost to y\n(through x) is computed to be 2, and the table is updated accordingly. •\nIn the second iteration, nodes v and y are found to have the least-cost paths (2), and\nwe break the tie arbitrarily and add y to the set N' so that N' now contains u, x, and"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 671,
    "text": "y. The cost to the remaining nodes not yet in N', that is, nodes v, w, and z, are\nupdated via line 12 of the LS algorithm, yielding the results shown in the third row\nin Table 5.1. •\nAnd so on . . . Table 5.1 ♦Running the link-state algorithm on the network in Figure 5.3\nWhen the LS algorithm terminates, we have, for each node, its predecessor along\nthe least-cost path from the source node. For each predecessor, we also have its\npredecessor, and so in this manner we can construct the entire path from the source to\nall destinations. The forwarding table in a node, say node u, can then be constructed\nfrom this information by storing, for each destination, the next-hop node on the least-\ncost path from u to the destination. Figure 5.4 shows the resulting least-cost paths and\nforwarding table in u for the network in Figure 5.3. Figure 5.4 ♦Least cost path and forwarding table for node u\nWhat is the computational complexity of this algorithm? That is, given n nodes\n(not counting the source), how much computation must be done in the worst case to\nfind the least-cost paths from the source to all destinations? In the first iteration, we\nneed to search through all n nodes to determine the node, w, not in N' that has the\nminimum cost. In the second iteration, we need to check n − 1 nodes to determine the\nminimum cost; in the third iteration n − 2 nodes, and so on. Overall, the total number\nof nodes we need to search through over all the iterations is n(n + 1)/2, and thus we"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 672,
    "text": "say that the preceding implementation of the LS algorithm has worst-case complexity\nof order n squared: O(n ). (A more sophisticated implementation of this algorithm,\nusing a data structure known as a heap, can find the minimum in line 9 in logarithmic\nrather than linear time, thus reducing the complexity.) Before completing our discussion of the LS algorithm, let us consider a pathology\nthat can arise. Figure 5.5 shows a simple network topology where link costs are equal\nto the load carried on the link, for example, reflecting the delay that would be\nexperienced. In this example, link costs are not symmetric; that is, c(u,v) equals c(v,u)\nonly if the load carried on both directions on the link (u,v) is the same. In this example,\nnode z originates a unit of traffic destined for w, node x also originates a unit of traffic\ndestined for w, and node y injects an amount of traffic equal to e, also destined for w.\nThe initial routing is shown in Figure 5.5(a) with the link costs corresponding to the\namount of traffic carried. When the LS algorithm is next run, node y determines (based on the link costs\nshown in Figure 5.5(a)) that the clockwise path to w has a cost of 1, while the\ncounterclockwise path to w (which it had been using) has a cost of 1 + e. Hence y’s\nleast-cost path to w is now clockwise. Similarly, x determines that its new least-cost\npath to w is also clockwise, resulting in costs shown in Figure 5.5(b). When the LS\nalgorithm is run next, nodes x, y, and z all detect a zero-cost path to w in the\ncounterclockwise direction, and all route their traffic to the counterclockwise routes. The next time the LS algorithm is run, x, y, and z all then route their traffic to the\nclockwise routes."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 673,
    "text": "Figure 5.5 ♦Oscillations with congestion-sensitive routing\nWhat can be done to prevent such oscillations (which can occur in any algorithm,\nnot just an LS algorithm, that uses a congestion or delay-based link metric)? One\nsolution would be to mandate that link costs not depend on the amount of traffic\ncarried—an unacceptable solution since one goal of routing is to avoid highly\ncongested (for example, high-delay) links. Another solution is to ensure that not all\nrouters run the LS algorithm at the same time. This seems a more reasonable solution,"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 674,
    "text": "since we would hope that even if routers ran the LS algorithm with the same\nperiodicity, the execution instance of the algorithm would not be the same at each\nnode. Interestingly, researchers have found that routers in the Internet can self-\nsynchronize among themselves [Floyd Synchronization 1994]. That is, even though\nthey initially execute the algorithm with the same period but at different instants of\ntime, the algorithm execution instance can eventually become, and remain,\nsynchronized at the routers. One way to avoid such self-synchronization is for each\nrouter to randomize the time it sends out a link advertisement. Having studied the LS algorithm, let’s consider the other major routing algorithm\nthat is used in practice today—the distance-vector routing algorithm. 5.2.2 The Distance-Vector (DV) Routing Algorithm\nWhereas the LS algorithm is an algorithm using global information, the distance-\nvector (DV) algorithm is iterative, asynchronous, and distributed. It is distributed in\nthat each node receives some information from one or more of its directly attached\nneighbors, performs a calculation, and then distributes the results of its calculation\nback to its neighbors. It is iterative in that this process continues on until no more\ninformation is exchanged between neighbors. (Interestingly, the algorithm is also self-\nterminating—there is no signal that the computation should stop; it just stops.) The\nalgorithm is asynchronous in that it does not require all of the nodes to operate in\nlockstep with each other. We’ll see that an asynchronous, iterative, self-terminating,\ndistributed algorithm is much more interesting and fun than a centralized algorithm! Before we present the DV algorithm, it will prove beneficial to discuss an\nimportant relationship that exists among the costs of the least-cost paths. Let d (y) be\nthe cost of the least-cost path from node x to node y. Then the least costs are related by\nthe celebrated Bellman-Ford equation, namely,\nwhere the min  in the equation is taken over all of x’s neighbors. The Bellman-Ford\nequation is rather intuitive. Indeed, after traveling from x to v, if we then take the least-\ncost path from v to y, the path cost will be c(x, v) + d (y). Since we must begin by\nx\ndx(y) = minv{c(x,  v) + dv( y)},\n(5.1)\nv\nv"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 675,
    "text": "traveling to some neighbor v, the least cost from x to y is the minimum of c(x, v) +\nd (y) taken over all neighbors v.\nBut for those who might be skeptical about the validity of the equation, let’s check\nit for source node u and destination node z in Figure 5.3. The source node u has three\nneighbors: nodes v, x, and w. By walking along various paths in the graph, it is easy to\nsee that d (z) = 5, d (z) = 3, and d (z) = 3. Plugging these values into Equation 5.1,\nalong with the costs c(u, v) = 2, c(u, x) = 1, and c(u, w) = 5, gives d (z) = min{2 + 5, 5\n+ 3, 1 + 3} = 4, which is obviously true and which is exactly what the Dijskstra\nalgorithm gave us for the same network. This quick verification should help relieve\nany skepticism you may have. The Bellman-Ford equation is not just an intellectual curiosity. It actually has\nsignificant practical importance: the solution to the Bellman-Ford equation provides\nthe entries in node x’s forwarding table. To see this, let v* be any neighboring node\nthat achieves the minimum in Equation 5.1. Then, if node x wants to send a packet to\nnode y along a least-cost path, it should first forward the packet to node v*. Thus, node\nx’s forwarding table would specify node v* as the next-hop router for the ultimate\ndestination y. Another important practical contribution of the Bellman-Ford equation is\nthat it suggests the form of the neighbor-to-neighbor communication that will take\nplace in the DV algorithm. The basic idea is as follows. Each node x begins with D (y), an estimate of the cost\nof the least-cost path from itself to node y, for all nodes, y, in N. Let D  = [D (y): y in\nN] be node x’s distance vector, which is the vector of cost estimates from x to all other\nnodes, y, in N. With the DV algorithm, each node x maintains the following routing\ninformation:\n•\nFor each neighbor v, the cost c(x,v) from x to directly attached neighbor, v\n•\nNode x’s distance vector, that is, D  = [D (y): y in N], containing x’s estimate of its\ncost to all destinations, y, in N\n•\nThe distance vectors of each of its neighbors, that is, D  = [D (y): y in N] for each\nneighbor v of x\nIn the distributed, asynchronous algorithm, from time to time, each node sends a copy\nof its distance vector to each of its neighbors. When a node x receives a new distance\nv\nv\nx\nw\nu\nx\nx\nx\nx\nx\nv\nv"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 675,
    "text": "traveling to some neighbor v, the least cost from x to y is the minimum of c(x, v) +\nd (y) taken over all neighbors v.\nBut for those who might be skeptical about the validity of the equation, let’s check\nit for source node u and destination node z in Figure 5.3. The source node u has three\nneighbors: nodes v, x, and w. By walking along various paths in the graph, it is easy to\nsee that d (z) = 5, d (z) = 3, and d (z) = 3. Plugging these values into Equation 5.1,\nalong with the costs c(u, v) = 2, c(u, x) = 1, and c(u, w) = 5, gives d (z) = min{2 + 5, 5\n+ 3, 1 + 3} = 4, which is obviously true and which is exactly what the Dijskstra\nalgorithm gave us for the same network. This quick verification should help relieve\nany skepticism you may have. The Bellman-Ford equation is not just an intellectual curiosity. It actually has\nsignificant practical importance: the solution to the Bellman-Ford equation provides\nthe entries in node x’s forwarding table. To see this, let v* be any neighboring node\nthat achieves the minimum in Equation 5.1. Then, if node x wants to send a packet to\nnode y along a least-cost path, it should first forward the packet to node v*. Thus, node\nx’s forwarding table would specify node v* as the next-hop router for the ultimate\ndestination y. Another important practical contribution of the Bellman-Ford equation is\nthat it suggests the form of the neighbor-to-neighbor communication that will take\nplace in the DV algorithm. The basic idea is as follows. Each node x begins with D (y), an estimate of the cost\nof the least-cost path from itself to node y, for all nodes, y, in N. Let D  = [D (y): y in\nN] be node x’s distance vector, which is the vector of cost estimates from x to all other\nnodes, y, in N. With the DV algorithm, each node x maintains the following routing\ninformation:\n•\nFor each neighbor v, the cost c(x,v) from x to directly attached neighbor, v\n•\nNode x’s distance vector, that is, D  = [D (y): y in N], containing x’s estimate of its\ncost to all destinations, y, in N\n•\nThe distance vectors of each of its neighbors, that is, D  = [D (y): y in N] for each\nneighbor v of x\nIn the distributed, asynchronous algorithm, from time to time, each node sends a copy\nof its distance vector to each of its neighbors. When a node x receives a new distance\nv\nv\nx\nw\nu\nx\nx\nx\nx\nx\nv\nv"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 676,
    "text": "vector from any of its neighbors w, it saves w’s distance vector, and then uses the\nBellman-Ford equation to update its own distance vector as follows:\nIf node x’s distance vector has changed as a result of this update step, node x will then\nsend its updated distance vector to each of its neighbors, which can in turn update their\nown distance vectors. Miraculously enough, as long as all the nodes continue to\nexchange their distance vectors in an asynchronous fashion, each cost estimate D (y)\nconverges to d (y), the actual cost of the least-cost path from node x to node y\n[Bertsekas 1991]! Distance-Vector (DV) Algorithm\nAt each node, x:\nInitialization:\n for all destinations y in N:\n Dx(y)= c(x,y)/* if y is not a neighbor then c(x,y)= ∞\n*/\n for each neighbor w\n D w(y) = ? for all destinations y in N\n for each neighbor w\n send distance vector Dx = [Dx(y): y in N] to w\n9\nloop\n10 wait (until I see a link cost change to some neighbor w\nor\n11  until I receive a distance vector from some neighbor\nw)\n13  for each y in N:\n14  D x(y) = minv{c(x,v) + Dv(y)}\nDx(y) = minv{c(x,  v) + Dv(y)}\nfor each node y in N\nx\nx"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 677,
    "text": "15\n16 if Dx(y) changed for any destination y\n17  send distance vector Dx = [Dx(y): y in N] to all\nneighbors\n19 forever\nIn the DV algorithm, a node x updates its distance-vector estimate when it either\nsees a cost change in one of its directly attached links or receives a distance-vector\nupdate from some neighbor. But to update its own forwarding table for a given\ndestination y, what node x really needs to know is not the shortest-path distance to y\nbut instead the neighboring node v*(y) that is the next-hop router along the shortest\npath to y. As you might expect, the next-hop router v*(y) is the neighbor v that\nachieves the minimum in Line 14 of the DV algorithm. (If there are multiple neighbors\nv that achieve the minimum, then v*(y) can be any of the minimizing neighbors.) Thus, in Lines 13–14, for each destination y, node x also determines v*(y) and updates\nits forwarding table for destination y. Recall that the LS algorithm is a centralized algorithm in the sense that it requires\neach node to first obtain a complete map of the network before running the Dijkstra\nalgorithm. The DV algorithm is decentralized and does not use such global\ninformation. Indeed, the only information a node will have is the costs of the links to\nits directly attached neighbors and information it receives from these neighbors. Each\nnode waits for an update from any neighbor (Lines 10–11), calculates its new distance\nvector when receiving an update (Line 14), and distributes its new distance vector to\nits neighbors (Lines 16–17). DV-like algorithms are used in many routing protocols in\npractice, including the Internet’s RIP and BGP, ISO IDRP, Novell IPX, and the\noriginal ARPAnet. Figure 5.6 illustrates the operation of the DV algorithm for the simple three-node\nnetwork shown at the top of the figure. The operation of the algorithm is illustrated in\na synchronous manner, where all nodes simultaneously receive distance vectors from\ntheir neighbors, compute their new distance vectors, and inform their neighbors if their\ndistance vectors have changed. After studying this example, you should convince"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 678,
    "text": "yourself that the algorithm operates correctly in an asynchronous manner as well, with\nnode computations and update generation/reception occurring at any time. Figure 5.6 ♦Distance-vector (DV) algorithm in operation"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 679,
    "text": "The leftmost column of the figure displays three initial routing tables for each of\nthe three nodes. For example, the table in the upper-left corner is node x’s initial\nrouting table. Within a specific routing table, each row is a distance vector—\nspecifically, each node’s routing table includes its own distance vector and that of each\nof its neighbors. Thus, the first row in node x’s initial routing table is D  = [D (x),\nD (y), D (z)] = [0, 2, 7]. The second and third rows in this table are the most recently\nreceived distance vectors from nodes y and z, respectively. Because at initialization\nnode x has not received anything from node y or z, the entries in the second and third\nrows are initialized to infinity. After initialization, each node sends its distance vector to each of its two\nneighbors. This is illustrated in Figure 5.6 by the arrows from the first column of\ntables to the second column of tables. For example, node x sends its distance vector D\n= [0, 2, 7] to both nodes y and z. After receiving the updates, each node recomputes its\nown distance vector. For example, node x computes\nD (x) = 0\nD (y) = min{c(x,y) + D (y), c(x,z) + D (y)} = min{2 + 0, 7 + 1} = 2\nD (z) = min{c(x,y) + D (z), c(x,z) + D (z)} = min{2 + 1, 7 + 0} = 3\nThe second column therefore displays, for each node, the node’s new distance vector\nalong with distance vectors just received from its neighbors. Note, for example, that\nnode x’s estimate for the least cost to node z, D (z), has changed from 7 to 3. Also note\nthat for node x, neighboring node y achieves the minimum in line 14 of the DV\nalgorithm; thus, at this stage of the algorithm, we have at node x that v (y) = y and v (z)\n= y. After the nodes recompute their distance vectors, they again send their updated\ndistance vectors to their neighbors (if there has been a change). This is illustrated in\nFigure 5.6 by the arrows from the second column of tables to the third column of\ntables. Note that only nodes x and z send updates: node y’s distance vector didn’t\nchange so node y doesn’t send an update. After receiving the updates, the nodes then\nrecompute their distance vectors and update their routing tables, which are shown in\nthe third column. The process of receiving updated distance vectors from neighbors, recomputing\nrouting table entries, and informing neighbors of changed costs of the least-cost path\nx\nx\nx\nx\nx\nx\nx\ny\nz\nx\ny\nz\nx\n*\n*"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 679,
    "text": "The leftmost column of the figure displays three initial routing tables for each of\nthe three nodes. For example, the table in the upper-left corner is node x’s initial\nrouting table. Within a specific routing table, each row is a distance vector—\nspecifically, each node’s routing table includes its own distance vector and that of each\nof its neighbors. Thus, the first row in node x’s initial routing table is D  = [D (x),\nD (y), D (z)] = [0, 2, 7]. The second and third rows in this table are the most recently\nreceived distance vectors from nodes y and z, respectively. Because at initialization\nnode x has not received anything from node y or z, the entries in the second and third\nrows are initialized to infinity. After initialization, each node sends its distance vector to each of its two\nneighbors. This is illustrated in Figure 5.6 by the arrows from the first column of\ntables to the second column of tables. For example, node x sends its distance vector D\n= [0, 2, 7] to both nodes y and z. After receiving the updates, each node recomputes its\nown distance vector. For example, node x computes\nD (x) = 0\nD (y) = min{c(x,y) + D (y), c(x,z) + D (y)} = min{2 + 0, 7 + 1} = 2\nD (z) = min{c(x,y) + D (z), c(x,z) + D (z)} = min{2 + 1, 7 + 0} = 3\nThe second column therefore displays, for each node, the node’s new distance vector\nalong with distance vectors just received from its neighbors. Note, for example, that\nnode x’s estimate for the least cost to node z, D (z), has changed from 7 to 3. Also note\nthat for node x, neighboring node y achieves the minimum in line 14 of the DV\nalgorithm; thus, at this stage of the algorithm, we have at node x that v (y) = y and v (z)\n= y. After the nodes recompute their distance vectors, they again send their updated\ndistance vectors to their neighbors (if there has been a change). This is illustrated in\nFigure 5.6 by the arrows from the second column of tables to the third column of\ntables. Note that only nodes x and z send updates: node y’s distance vector didn’t\nchange so node y doesn’t send an update. After receiving the updates, the nodes then\nrecompute their distance vectors and update their routing tables, which are shown in\nthe third column. The process of receiving updated distance vectors from neighbors, recomputing\nrouting table entries, and informing neighbors of changed costs of the least-cost path\nx\nx\nx\nx\nx\nx\nx\ny\nz\nx\ny\nz\nx\n*\n*"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 680,
    "text": "to a destination continues until no update messages are sent. At this point, since no\nupdate messages are sent, no further routing table calculations will occur and the\nalgorithm will enter a quiescent state; that is, all nodes will be performing the wait in\nLines 10–11 of the DV algorithm. The algorithm remains in the quiescent state until a\nlink cost changes, as discussed next. Distance-Vector Algorithm: Link-Cost Changes and Link Failure\nWhen a node running the DV algorithm detects a change in the link cost from itself to\na neighbor (Lines 10–11), it updates its distance vector (Lines 13–14) and, if there’s a\nchange in the cost of the least-cost path, informs its neighbors (Lines 16–17) of its new\ndistance vector. Figure 5.7(a) illustrates a scenario where the link cost from y to x\nchanges from 4 to 1. We focus here only on y’ and z’s distance table entries to\ndestination x. The DV algorithm causes the following sequence of events to occur:\n•\nAt time t , y detects the link-cost change (the cost has changed from 4 to 1),\nupdates its distance vector, and informs its neighbors of this change since its\ndistance vector has changed. •\nAt time t , z receives the update from y and updates its table. It computes a new\nleast cost to x (it has decreased from a cost of 5 to a cost of 2) and sends its new\ndistance vector to its neighbors. •\nAt time t , y receives z’s update and updates its distance table. y’s least costs do not\nchange and hence y does not send any message to z. The algorithm comes to a\nquiescent state. Thus, only two iterations are required for the DV algorithm to reach a quiescent state. The good news about the decreased cost between x and y has propagated quickly\nthrough the network. Let’s now consider what can happen when a link cost increases. Suppose that the\nlink cost between x and y increases from 4 to 60, as shown in Figure 5.7(b). 1"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 681,
    "text": "Figure 5.7 ♦Changes in link cost\n1. Before the link cost changes, D (x) = 4, D (z) = 1, D (y) = 1, and D (x) = 5. At time\nt , y detects the link-cost change (the cost has changed from 4 to 60). y computes\nits new minimum-cost path to x to have a cost of\nDy(x) = min{c(y, x) + Dx(x), c(y, z) + Dz(x)} = min{60 + 0, 1 + 5} = 6\nOf course, with our global view of the network, we can see that this new cost via z\nis wrong. But the only information node y has is that its direct cost to x is 60 and\nthat z has last told y that z could get to x with a cost of 5. So in order to get to x, y\nwould now route through z, fully expecting that z will be able to get to x with a cost\nof 5. As of t  we have a routing loop—in order to get to x, y routes through z, and z\nroutes through y. A routing loop is like a black hole—a packet destined for x\narriving at y or z as of t  will bounce back and forth between these two nodes\nforever (or until the forwarding tables are changed). 2. Since node y has computed a new minimum cost to x, it informs z of its new\ndistance vector at time t . 3. Sometime after t , z receives y’s new distance vector, which indicates that y’s\nminimum cost to x is 6. z knows it can get to y with a cost of 1 and hence computes\na new least cost to x of D (x) = min {50 + 0,1 + 6} = 7. Since z’s least cost to x has\nincreased, it then informs y of its new distance vector at t . 4. In a similar manner, after receiving z’s new distance vector, y determines D (x) = 8\nand sends z its distance vector. z then determines D (x) = 9 and sends y its distance\nvector, and so on. y\ny\nz\nz\n1\n1\nz\ny\nz"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 682,
    "text": "How long will the process continue? You should convince yourself that the loop will\npersist for 44 iterations (message exchanges between y and z)—until z eventually\ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) determine that its least-cost path to x is via its direct connection to x. y will then route\nto x via z. The result of the bad news about the increase in link cost has indeed traveled\nslowly! What would have happened if the link cost c(y, x) had changed from 4 to\n10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the problem we\nhave seen is sometimes referred to as the count-to-infinity ­problem. Distance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known\nas poisoned reverse. The idea is simple—if z routes through y to get to destination x,\nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y\nthat D (x) = ∞ (even though z knows D (x) = 5 in truth). z will continue telling this\nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path to\nx, y will never attempt to route to x via z, as long as z continues to route to x via y (and\nlies about doing so). Let’s now see how poisoned reverse solves the particular looping problem we\nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y’s distance\ntable indicates D (x) = ∞. When the cost of the (x, y) link changes from 4 to 60 at time\nt , y updates its table and continues to route directly to x, albeit at a higher cost of 60,\nand informs z of its new cost to x, that is, D (x) = 60. After receiving the update at t , z\nimmediately shifts its route to x to be via the direct (z, x) link at a cost of 50. Since this\nis a new least-cost path to x, and since the path no longer passes through y, z now\ninforms y that D (x) = 50 at t . After receiving the update from z, y updates its distance\ntable with D (x) = 51. Also, since z is now on y’s least-cost path to x, y poisons the\nreverse path from z to x by informing z at time t  that D (x) = ∞ (even though y knows\nthat D (x) = 51 in truth). Does poisoned reverse solve the general count-to-infinity problem?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 682,
    "text": "How long will the process continue? You should convince yourself that the loop will\npersist for 44 iterations (message exchanges between y and z)—until z eventually\ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) determine that its least-cost path to x is via its direct connection to x. y will then route\nto x via z. The result of the bad news about the increase in link cost has indeed traveled\nslowly! What would have happened if the link cost c(y, x) had changed from 4 to\n10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the problem we\nhave seen is sometimes referred to as the count-to-infinity ­problem. Distance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known\nas poisoned reverse. The idea is simple—if z routes through y to get to destination x,\nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y\nthat D (x) = ∞ (even though z knows D (x) = 5 in truth). z will continue telling this\nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path to\nx, y will never attempt to route to x via z, as long as z continues to route to x via y (and\nlies about doing so). Let’s now see how poisoned reverse solves the particular looping problem we\nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y’s distance\ntable indicates D (x) = ∞. When the cost of the (x, y) link changes from 4 to 60 at time\nt , y updates its table and continues to route directly to x, albeit at a higher cost of 60,\nand informs z of its new cost to x, that is, D (x) = 60. After receiving the update at t , z\nimmediately shifts its route to x to be via the direct (z, x) link at a cost of 50. Since this\nis a new least-cost path to x, and since the path no longer passes through y, z now\ninforms y that D (x) = 50 at t . After receiving the update from z, y updates its distance\ntable with D (x) = 51. Also, since z is now on y’s least-cost path to x, y poisons the\nreverse path from z to x by informing z at time t  that D (x) = ∞ (even though y knows\nthat D (x) = 51 in truth). Does poisoned reverse solve the general count-to-infinity problem? It does not."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 682,
    "text": "How long will the process continue? You should convince yourself that the loop will\npersist for 44 iterations (message exchanges between y and z)—until z eventually\ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) determine that its least-cost path to x is via its direct connection to x. y will then route\nto x via z. The result of the bad news about the increase in link cost has indeed traveled\nslowly! What would have happened if the link cost c(y, x) had changed from 4 to\n10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the problem we\nhave seen is sometimes referred to as the count-to-infinity ­problem. Distance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known\nas poisoned reverse. The idea is simple—if z routes through y to get to destination x,\nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y\nthat D (x) = ∞ (even though z knows D (x) = 5 in truth). z will continue telling this\nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path to\nx, y will never attempt to route to x via z, as long as z continues to route to x via y (and\nlies about doing so). Let’s now see how poisoned reverse solves the particular looping problem we\nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y’s distance\ntable indicates D (x) = ∞. When the cost of the (x, y) link changes from 4 to 60 at time\nt , y updates its table and continues to route directly to x, albeit at a higher cost of 60,\nand informs z of its new cost to x, that is, D (x) = 60. After receiving the update at t , z\nimmediately shifts its route to x to be via the direct (z, x) link at a cost of 50. Since this\nis a new least-cost path to x, and since the path no longer passes through y, z now\ninforms y that D (x) = 50 at t . After receiving the update from z, y updates its distance\ntable with D (x) = 51. Also, since z is now on y’s least-cost path to x, y poisons the\nreverse path from z to x by informing z at time t  that D (x) = ∞ (even though y knows\nthat D (x) = 51 in truth). Does poisoned reverse solve the general count-to-infinity problem? It does not. You should convince yourself that loops involving three or more nodes (rather than\nsimply two immediately neighboring nodes) will not be detected by the poisoned\nreverse technique."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 682,
    "text": "How long will the process continue? You should convince yourself that the loop will\npersist for 44 iterations (message exchanges between y and z)—until z eventually\ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) determine that its least-cost path to x is via its direct connection to x. y will then route\nto x via z. The result of the bad news about the increase in link cost has indeed traveled\nslowly! What would have happened if the link cost c(y, x) had changed from 4 to\n10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the problem we\nhave seen is sometimes referred to as the count-to-infinity ­problem. Distance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known\nas poisoned reverse. The idea is simple—if z routes through y to get to destination x,\nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y\nthat D (x) = ∞ (even though z knows D (x) = 5 in truth). z will continue telling this\nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path to\nx, y will never attempt to route to x via z, as long as z continues to route to x via y (and\nlies about doing so). Let’s now see how poisoned reverse solves the particular looping problem we\nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y’s distance\ntable indicates D (x) = ∞. When the cost of the (x, y) link changes from 4 to 60 at time\nt , y updates its table and continues to route directly to x, albeit at a higher cost of 60,\nand informs z of its new cost to x, that is, D (x) = 60. After receiving the update at t , z\nimmediately shifts its route to x to be via the direct (z, x) link at a cost of 50. Since this\nis a new least-cost path to x, and since the path no longer passes through y, z now\ninforms y that D (x) = 50 at t . After receiving the update from z, y updates its distance\ntable with D (x) = 51. Also, since z is now on y’s least-cost path to x, y poisons the\nreverse path from z to x by informing z at time t  that D (x) = ∞ (even though y knows\nthat D (x) = 51 in truth). Does poisoned reverse solve the general count-to-infinity problem? It does not. You should convince yourself that loops involving three or more nodes (rather than\nsimply two immediately neighboring nodes) will not be detected by the poisoned\nreverse technique. z\nz\nz\ny\nz\ny\ny\ny"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 682,
    "text": "How long will the process continue? You should convince yourself that the loop will\npersist for 44 iterations (message exchanges between y and z)—until z eventually\ncomputes the cost of its path via y to be greater than 50. At this point, z will (finally!) determine that its least-cost path to x is via its direct connection to x. y will then route\nto x via z. The result of the bad news about the increase in link cost has indeed traveled\nslowly! What would have happened if the link cost c(y, x) had changed from 4 to\n10,000 and the cost c(z, x) had been 9,999? Because of such scenarios, the problem we\nhave seen is sometimes referred to as the count-to-infinity ­problem. Distance-Vector Algorithm: Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known\nas poisoned reverse. The idea is simple—if z routes through y to get to destination x,\nthen z will advertise to y that its distance to x is infinity, that is, z will advertise to y\nthat D (x) = ∞ (even though z knows D (x) = 5 in truth). z will continue telling this\nlittle white lie to y as long as it routes to x via y. Since y believes that z has no path to\nx, y will never attempt to route to x via z, as long as z continues to route to x via y (and\nlies about doing so). Let’s now see how poisoned reverse solves the particular looping problem we\nencountered before in Figure 5.5(b). As a result of the poisoned reverse, y’s distance\ntable indicates D (x) = ∞. When the cost of the (x, y) link changes from 4 to 60 at time\nt , y updates its table and continues to route directly to x, albeit at a higher cost of 60,\nand informs z of its new cost to x, that is, D (x) = 60. After receiving the update at t , z\nimmediately shifts its route to x to be via the direct (z, x) link at a cost of 50. Since this\nis a new least-cost path to x, and since the path no longer passes through y, z now\ninforms y that D (x) = 50 at t . After receiving the update from z, y updates its distance\ntable with D (x) = 51. Also, since z is now on y’s least-cost path to x, y poisons the\nreverse path from z to x by informing z at time t  that D (x) = ∞ (even though y knows\nthat D (x) = 51 in truth). Does poisoned reverse solve the general count-to-infinity problem? It does not. You should convince yourself that loops involving three or more nodes (rather than\nsimply two immediately neighboring nodes) will not be detected by the poisoned\nreverse technique. z\nz\nz\ny\nz\ny\ny\ny"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 683,
    "text": "A Comparison of LS and DV Routing Algorithms\nThe DV and LS algorithms take complementary approaches toward computing\nrouting. In the DV algorithm, each node talks to only its directly connected neighbors,\nbut it provides its neighbors with least-cost estimates from itself to all the nodes (that\nit knows about) in the network. The LS algorithm requires global information. Consequently, when implemented in each and every router, for example, as in Figures\n4.2 and 5.1, each node would need to communicate with all other nodes (via\nbroadcast), but it tells them only the costs of its directly connected links. Let’s\nconclude our study of LS and DV algorithms with a quick comparison of some of their\nattributes. Recall that N is the set of nodes (routers) and E is the set of edges (links). •\nMessage complexity. We have seen that LS requires each node to know the cost of\neach link in the network. This requires O(|N| |E|) messages to be sent. Also,\nwhenever a link cost changes, the new link cost must be sent to all nodes. The DV\nalgorithm requires message exchanges between directly connected neighbors at\neach iteration. We have seen that the time needed for the algorithm to converge\ncan depend on many factors. When link costs change, the DV algorithm will\npropagate the results of the changed link cost only if the new link cost results in a\nchanged least-cost path for one of the nodes attached to that link. •\nSpeed of convergence. We have seen that our implementation of LS is an O(|N|2)\nalgorithm requiring O(|N| |E|)) messages. The DV algorithm can converge slowly\nand can have routing loops while the algorithm is converging. DV also suffers\nfrom the count-to-infinity problem. •\nRobustness. What can happen if a router fails, misbehaves, or is sabotaged? Under\nLS, a router could broadcast an incorrect cost for one of its attached links (but no\nothers). A node could also corrupt or drop any packets it received as part of an LS\nbroadcast. But an LS node is computing only its own forwarding tables; other\nnodes are performing similar calculations for themselves. This means route\ncalculations are somewhat separated under LS, providing a degree of robustness. Under DV, a node can advertise incorrect least-cost paths to any or all destinations. (Indeed, in 1997, a malfunctioning router in a small ISP provided national\nbackbone routers with erroneous routing information. This caused other routers to"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 684,
    "text": "flood the malfunctioning router with traffic and caused large portions of the\nInternet to become disconnected for up to several hours [Neumann 1997].) More\ngenerally, we note that, at each iteration, a node’s calculation in DV is passed on to\nits neighbor and then indirectly to its neighbor’s neighbor on the next iteration. In\nthis sense, an incorrect node calculation can be diffused through the entire network\nunder DV. In the end, neither algorithm is an obvious winner over the other; indeed, both\nalgorithms are used in the Internet."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 685,
    "text": "5.3 Intra-AS Routing in the Internet: OSPF\nIn our study of routing algorithms so far, we’ve viewed the network simply\nas a collection of interconnected routers. One router was indistinguishable\nfrom another in the sense that all routers executed the same routing\nalgorithm to compute routing paths through the entire network. In practice,\nthis model and its view of a homogenous set of routers all executing the\nsame routing algorithm is simplistic for two important reasons:\n•\nScale. As the number of routers becomes large, the overhead involved\nin communicating, computing, and storing routing information becomes\nprohibitive. Today’s Internet consists of hundreds of millions of routers. Storing routing information for possible destinations at each of these\nrouters would clearly require enormous amounts of memory. The\noverhead required to broadcast connectivity and link cost updates\namong all of the routers would be huge! A distance-vector algorithm\nthat iterated among such a large number of routers would surely never\nconverge. Clearly, something must be done to reduce the complexity of\nroute computation in a network as large as the Internet. •\nAdministrative autonomy. As described in Section 1.3, the Internet is a\nnetwork of ISPs, with each ISP consisting of its own network of routers. An ISP generally desires to operate its network as it pleases (for\nexample, to run whatever routing algorithm it chooses within its\nnetwork) or to hide aspects of its network’s internal organization from\nthe outside. Ideally, an organization should be able to operate and\nadminister its network as it wishes, while still being able to connect its\nnetwork to other outside networks."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 686,
    "text": "Both of these problems can be solved by organizing routers into\nautonomous ­systems (ASs), with each AS consisting of a group of routers\nthat are under the same administrative control. Often the routers in an ISP,\nand the links that interconnect them, constitute a single AS. Some ISPs,\nhowever, partition their network into multiple ASs. In particular, some tier-1\nISPs use one gigantic AS for their entire network, whereas others break up\ntheir ISP into tens of interconnected ASs. An autonomous system is\nidentified by its globally unique autonomous system number (ASN) [RFC\n1930]. AS numbers, like IP addresses, are assigned by ICANN regional\nregistries [ICANN 2020]. Routers within the same AS all run the same routing algorithm and\nhave information about each other. The routing algorithm ­running within an\nautonomous system is called an intra-autonomous system routing ­-\nprotocol. Open Shortest Path First (OSPF)\nOSPF routing and its closely related cousin, IS-IS, are widely used for\nintra-AS routing in the Internet. The Open in OSPF indicates that the\nrouting protocol specification is publicly available (for example, as opposed\nto Cisco’s EIGRP protocol, which was only recently became open [Savage\n2015], after roughly 20 years as a Cisco-proprietary protocol). The most\nrecent version of OSPF, version 2, is defined in [RFC 2328], a public\ndocument. OSPF is a link-state protocol that uses flooding of link-state\ninformation and a Dijkstra’s least-cost path algorithm. With OSPF, each\nrouter constructs a complete topological map (that is, a graph) of the entire\nautonomous system. Each router then locally runs Dijkstra’s shortest-path\nalgorithm to determine a shortest-path tree to all subnets, with itself as the"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 687,
    "text": "root node. Individual link costs are configured by the network administrator\n(see sidebar, Principles and Practice: Setting OSPF Weights). The\nadministrator might choose to set all link costs to 1, thus achieving\nminimum-hop routing, or might choose to set the link weights to be\ninversely proportional to link capacity in order to discourage traffic from\nusing low-bandwidth links. OSPF does not mandate a policy for how link\nweights are set (that is the job of the ­network administrator), but instead\nprovides the mechanisms (protocol) for determining least-cost path routing\nfor the given set of link weights. PRINCIPLES IN\nPRACTICE\nSETTING OSPF LINK WEIGHTS\nOur discussion of link-state routing has implicitly assumed that link weights are set, a\nrouting algorithm such as OSPF is run, and traffic flows according to the routing tables\ncomputed by the LS algorithm. In terms of cause and effect, the link weights are given (i.e.,\nthey come first) and result (via Dijkstra’s algorithm) in routing paths that minimize overall\ncost. In this viewpoint, link weights reflect the cost of using a link (for example, if link\nweights are inversely proportional to capacity, then the use of high-capacity links would\nhave smaller weight and thus be more attractive from a routing standpoint) and Dijsktra’s\nalgorithm serves to minimize overall cost. In practice, the cause and effect relationship between link weights and routing paths may\nbe reversed, with network operators configuring link weights in order to obtain routing paths\nthat achieve certain traffic engineering goals [Fortz 2000, Fortz 2002]. For example,\nsuppose a network operator has an estimate of traffic flow entering the network at each\ningress point and destined for each egress point. The operator may then want to put in\nplace a specific routing of ingress-to-egress flows that minimizes the maximum utilization"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 688,
    "text": "over all of the network’s links. But with a routing algorithm such as OSPF, the operator’s\nmain “knobs” for tuning the routing of flows through the network are the link weights. Thus,\nin order to achieve the goal of minimizing the maximum link utilization, the operator must\nfind the set of link weights that achieves this goal. This is a reversal of the cause and effect\nrelationship—the desired routing of flows is known, and the OSPF link weights must be\nfound such that the OSPF routing algorithm results in this desired routing of flows. With OSPF, a router broadcasts routing information to all other routers\nin the autonomous system, not just to its neighboring routers. A router\nbroadcasts link-state information whenever there is a change in a link’s state\n(for example, a change in cost or a change in up/down status). It also\nbroadcasts a link’s state periodically (at least once every 30 minutes), even\nif the link’s state has not changed. RFC 2328 notes that “this periodic\nupdating of link state advertisements adds robustness to the link state\nalgorithm.” OSPF advertisements are contained in OSPF messages that are\ncarried directly by IP, with an upper-layer protocol of 89 for OSPF. Thus,\nthe OSPF protocol must itself implement functionality such as reliable\nmessage transfer and link-state broadcast. The OSPF protocol also checks\nthat links are operational (via a HELLO message that is sent to an attached\nneighbor) and allows an OSPF router to obtain a neighboring router’s\ndatabase of network-wide link state. Some of the advances embodied in OSPF include the following:\n•\nSecurity. Exchanges between OSPF routers (for example, link-state\nupdates) can be authenticated. With authentication, only trusted routers\ncan participate in the OSPF protocol within an AS, thus preventing\nmalicious intruders (or networking students taking their newfound"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 689,
    "text": "knowledge out for a joyride) from injecting incorrect information into\nrouter tables. By default, OSPF packets between routers are  not\nauthenticated and could be forged. Two types of authentication can be\nconfigured—simple and MD5 (see Chapter 8 for a discussion on MD5\nand authentication in general). With simple authentication, the same\npassword is configured on each router. When a router sends an OSPF\npacket, it includes the password in plaintext. Clearly, simple\nauthentication is not very secure. MD5 authentication is based on\nshared secret keys that are configured in all the routers. For each OSPF\npacket that it sends, the router computes the MD5 hash of the content of\nthe OSPF packet appended with the secret key. (See the discussion of\nmessage authentication codes in Chapter 8.) Then the router includes\nthe resulting hash value in the OSPF packet. The receiving router, using\nthe preconfigured secret key, will compute an MD5 hash of the packet\nand compare it with the hash value that the packet carries, thus\nverifying the packet’s authenticity. Sequence numbers are also used\nwith MD5 authentication to protect against replay attacks. •\nMultiple same-cost paths. When multiple paths to a destination have the\nsame cost, OSPF allows multiple paths to be used (that is, a single path\nneed not be chosen for carrying all traffic when multiple equal-cost\npaths exist). •\nIntegrated support for unicast and multicast routing. Multicast OSPF\n(MOSPF) [RFC 1584] provides simple extensions to OSPF to provide\nfor multicast routing. MOSPF uses the existing OSPF link database and\nadds a new type of link-state advertisement to the existing OSPF link-\nstate broadcast mechanism. •\nSupport for hierarchy within a single AS. An OSPF autonomous system\ncan be configured hierarchically into areas. Each area runs its own"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 690,
    "text": "OSPF link-state routing algorithm, with each router in an area\nbroadcasting its link state to all other routers in that area. Within each\narea, one or more area border routers are responsible for routing packets\noutside the area. Lastly, exactly one OSPF area in the AS is configured\nto be the backbone area. The primary role of the backbone area is to\nroute traffic between the other areas in the AS. The backbone always\ncontains all area border routers in the AS and may contain non-border\nrouters as well. Inter-area routing within the AS requires that the packet\nbe first routed to an area border router (intra-area routing), then routed\nthrough the backbone to the area border router that is in the destination\narea, and then routed to the final destination. OSPF is a relatively complex protocol, and our coverage here has been\nnecessarily brief; [Huitema 1998; Moy 1998; RFC 2328] provide additional\ndetails."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 691,
    "text": "5.4 Routing Among the ISPs: BGP\nWe just learned that OSPF is an example of an intra-AS routing protocol. When routing a packet between a source and destination within the same\nAS, the route the packet follows is entirely determined by the intra-AS\nrouting protocol. However, to route a packet across multiple ASs, say from\na smartphone in Timbuktu to a server in a datacenter in Silicon Valley, we\nneed an inter-autonomous ­system routing protocol. Since an inter-AS\nrouting \nprotocol \ninvolves \ncoordination \namong \nmultiple \nASs,\ncommunicating ASs must run the same inter-AS routing protocol. In fact, in\nthe Internet, all ASs run the same inter-AS routing protocol, called the\nBorder Gateway Protocol, more commonly known as BGP [RFC 4271;\nStewart 1999]. VideoNote\nGluing the Internet Together: BGP\nBGP is arguably the most important of all the Internet protocols (the\nonly other contender would be the IP protocol that we studied in Section\n4.3), as it is the protocol that glues the thousands of ISPs in the Internet\ntogether. As we will soon see, BGP is a decentralized and asynchronous\nprotocol in the vein of distance-vector routing described in Section 5.2.2. Although BGP is a complex and challenging protocol, to understand the\nInternet on a deep level, we need to become familiar with its underpinnings\nand operation. The time we devote to learning BGP will be well worth the\neffort."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 692,
    "text": "5.4.1 The Role of BGP\nTo understand the responsibilities of BGP, consider an AS and an arbitrary\nrouter in that AS. Recall that every router has a forwarding table, which\nplays the central role in the process of forwarding arriving packets to\noutbound router links. As we have learned, for destinations that are within\nthe same AS, the entries in the router’s forwarding table are determined by\nthe AS’s intra-AS routing protocol. But what about destinations that are\noutside of the AS? This is precisely where BGP comes to the rescue. In BGP, packets are not routed to a specific destination address, but\ninstead to CIDRized prefixes, with each prefix representing a subnet or a\ncollection of subnets. In the world of BGP, a destination may take the form\n138.16.68/22, which for this example includes 1,024 IP addresses. Thus, a\nrouter’s forwarding table will have entries of the form (x, I), where x is a\nprefix (such as 138.16.68/22) and I is an interface number for one of the\nrouter’s interfaces. As an inter-AS routing protocol, BGP provides each router a means to:\n1. Obtain prefix reachability information from neighboring ASs. In\nparticular, BGP allows each subnet to advertise its existence to the rest\nof the Internet. A subnet screams, “I exist and I am here,” and BGP\nmakes sure that all the routers in the Internet know about this subnet. If\nit weren’t for BGP, each subnet would be an isolated island—alone,\nunknown and unreachable by the rest of the Internet. 2. Determine the “best” routes to the prefixes. A router may learn about\ntwo or more different routes to a specific prefix. To determine the best\nroute, the router will locally run a BGP route-selection procedure (using\nthe prefix reachability information it obtained via neighboring routers)."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 693,
    "text": "The best route will be determined based on policy as well as the\nreachability information. Let us now delve into how BGP carries out these two tasks. 5.4.2 Advertising BGP Route Information\nConsider the network shown in Figure 5.8. As we can see, this simple\nnetwork has three autonomous systems: AS1, AS2, and AS3. As shown,\nAS3 includes a subnet with prefix x. For each AS, each router is either a\ngateway router or an internal router. A gateway router is a router on the\nedge of an AS that directly connects to one or more routers in other ASs. An\ninternal router connects only to hosts and routers within its own AS. In\nAS1, for example, router 1c is a gateway router; routers 1a, 1b, and 1d are\ninternal routers. Figure 5.8 ♦Network with three autonomous systems. AS3 includes\na subnet with prefix x"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 694,
    "text": "Let’s consider the task of advertising reachability information for prefix\nx to all of the routers shown in Figure 5.8. At a high level, this is\nstraightforward. First, AS3 sends a BGP message to AS2, saying that x\nexists and is in AS3; let’s denote this message as “AS3 x”. Then AS2 sends\na BGP message to AS1, saying that x exists and that you can get to x by\nfirst passing through AS2 and then going to AS3; let’s denote that message\nas “AS2 AS3 x”. In this manner, each of the autonomous systems will not\nonly learn about the existence of x, but also learn about a path of\nautonomous systems that leads to x. Although the discussion in the above paragraph about advertising BGP\nreachability information should get the general idea across, it is not precise\nin the sense that autonomous systems do not actually send messages to each\nother, but instead routers do. To understand this, let’s now re-examine the\nexample in Figure 5.8. In BGP, pairs of routers exchange routing\ninformation over semi-permanent TCP connections using port 179. Each\nsuch TCP connection, along with all the BGP messages sent over the\nconnection, is called a BGP connection. Furthermore, a BGP connection\nthat spans two ASs is called an external BGP (eBGP) connection, and a\nBGP session between routers in the same AS is called an internal BGP\n(iBGP) connection. Examples of BGP connections for the network in\nFigure 5.8 are shown in Figure 5.9. There is typically one eBGP connection\nfor each link that directly connects gateway routers in different ASs; thus, in\nFigure 5.9, there is an eBGP connection between gateway routers 1c and 2a\nand an eBGP connection between gateway routers 2c and 3a."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 695,
    "text": "Figure 5.9 ♦eBGP and iBGP connections\nThere are also iBGP connections between routers within each of the\nASs. In particular, Figure 5.9 displays a common configuration of one BGP\nconnection for each pair of routers internal to an AS, creating a mesh of\nTCP connections within each AS. In Figure 5.9, the eBGP connections are\nshown with the long dashes; the iBGP connections are shown with the short\ndashes. Note that iBGP connections do not always correspond to physical\nlinks. In order to propagate the reachability information, both iBGP and\neBGP sessions are used. Consider again advertising the reachability\ninformation for prefix x to all routers in AS1 and AS2. In this process,\ngateway router 3a first sends an eBGP message “AS3 x” to gateway router\n2c. Gateway router 2c then sends the iBGP message “AS3 x” to all of the\nother routers in AS2, including to gateway router 2a. Gateway router 2a\nthen sends the eBGP message “AS2 AS3 x” to gateway router 1c. Finally,\ngateway router 1c uses iBGP to send the message “AS2 AS3 x” to all the\nrouters in AS1. After this process is complete, each router in AS1 and AS2"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 696,
    "text": "is aware of the existence of x and is also aware of an AS path that leads to\nx. Of course, in a real network, from a given router there may be many\ndifferent paths to a given destination, each through a different sequence of\nASs. For example, consider the network in Figure 5.10, which is the\noriginal network in Figure 5.8, with an additional physical link from router\n1d to router 3d. In this case, there are two paths from AS1 to x: the path\n“AS2 AS3 x” via router 1c; and the new path “AS3 x” via the router 1d. 5.4.3 Determining the Best Routes\nAs we have just learned, there may be many paths from a given router to a\ndestination subnet. In fact, in the Internet, routers often receive reachability\ninformation about dozens of different possible paths. How does a router\nchoose among these paths (and then configure its forwarding table\naccordingly)? Before addressing this critical question, we need to introduce a little\nmore BGP terminology. When a router advertises a prefix across a BGP\nconnection, it includes with the prefix several BGP attributes. In BGP\njargon, a prefix along with its attributes is called a route. Two of the more\nimportant attributes are AS-PATH and NEXT-HOP. The AS-PATH attribute\ncontains the list of ASs through which the advertisement has passed, as\nwe’ve seen in our examples above. To generate the AS-PATH value, when a\nprefix is passed to an AS, the AS adds its ASN to the existing list in the AS-\nPATH. For example, in Figure 5.10, there are two routes from AS1 to\nsubnet x: one which uses the AS-PATH “AS2 AS3”; and another that uses\nthe AS-PATH “A3”. BGP routers also use the AS-PATH attribute to detect"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 697,
    "text": "and prevent looping advertisements; specifically, if a router sees that its\nown AS is contained in the path list, it will reject the advertisement. Figure 5.10 ♦Network augmented with peering link between AS1\nand AS3\nProviding the critical link between the inter-AS and intra-AS routing\nprotocols, the NEXT-HOP attribute has a subtle but important use. The\nNEXT-HOP is the IP address of the router interface that begins the AS-\nPATH. To gain insight into this attribute, let’s again refer to Figure 5.10. As\nindicated in Figure 5.10, the NEXT-HOP attribute for the route “AS2 AS3\nx” from AS1 to x that passes through AS2 is the IP address of the left\ninterface on router 2a. The NEXT-HOP attribute for the route “AS3 x” from\nAS1 to x that bypasses AS2 is the IP address of the leftmost interface of\nrouter 3d. In summary, in this toy example, each router in AS1 becomes\naware of two BGP routes to prefix x:\nIP address of leftmost interface for router 2a; AS2 AS3; x\nIP address of leftmost interface of router 3d; AS3; x"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 698,
    "text": "Here, each BGP route is written as a list with three components: NEXT-\nHOP; AS-PATH; destination prefix. In practice, a BGP route includes\nadditional attributes, which we will ignore for the time being. Note that the\nNEXT-HOP attribute is an IP address of a router that does not belong to\nAS1; however, the subnet that contains this IP address directly attaches to\nAS1. Hot Potato Routing\nWe are now finally in position to talk about BGP routing algorithms in a\nprecise manner. We will begin with one of the simplest routing algorithms,\nnamely, hot potato routing. Consider router 1b in the network in Figure 5.10. As just described, this\nrouter will learn about two possible BGP routes to prefix x. In hot potato\nrouting, the route chosen (from among all possible routes) is that route with\nthe least cost to the NEXT-HOP router beginning that route. In this\nexample, router 1b will consult its intra-AS routing information to find the\nleast-cost intra-AS path to NEXT-HOP router 2a and the least-cost intra-AS\npath to NEXT-HOP router 3d, and then select the route with the smallest of\nthese least-cost paths. For example, suppose that cost is defined as the\nnumber of links traversed. Then the least cost from router 1b to router 2a is\n2, the least cost from router 1b to router 2d is 3, and router 2a would\ntherefore be selected. Router 1b would then consult its forwarding table\n(configured by its intra-AS algorithm) and find the interface I that is on the\nleast-cost path to router 2a. It then adds (x, I) to its forwarding table. The steps for adding an outside-AS prefix in a router’s forwarding table\nfor hot potato routing are summarized in Figure 5.11. It is important to note\nthat when adding an outside-AS prefix into a forwarding table, both the"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 699,
    "text": "inter-AS routing protocol (BGP) and the intra-AS routing protocol (e.g.,\nOSPF) are used. Figure 5.11 ♦Steps in adding outside-AS destination in a router’s\nforwarding table\nThe idea behind hot-potato routing is for router 1b to get packets out of\nits AS as quickly as possible (more specifically, with the least cost possible)\nwithout worrying about the cost of the remaining portions of the path\noutside of its AS to the destination. In the name “hot potato routing,” a\npacket is analogous to a hot potato that is burning in your hands. Because it\nis burning hot, you want to pass it off to another person (another AS) as\nquickly as possible. Hot potato routing is thus a selfish ­algorithm—it tries\nto reduce the cost in its own AS while ignoring the other components of the\nend-to-end costs outside its AS. Note that with hot potato routing, two\nrouters in the same AS may choose two different AS paths to the same\nprefix. For example, we just saw that router 1b would send packets through\nAS2 to reach x. However, router 1d would bypass AS2 and send packets\ndirectly to AS3 to reach x.\nRoute-Selection Algorithm\nIn practice, BGP uses an algorithm that is more complicated than hot potato\nrouting, but nevertheless incorporates hot potato routing. For any given\ndestination prefix, the input into BGP’s route-selection algorithm is the set"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 700,
    "text": "of all routes to that prefix that have been learned and accepted by the router. If there is only one such route, then BGP obviously selects that route. If\nthere are two or more routes to the same prefix, then BGP sequentially\ninvokes the following elimination rules until one route remains:\n1. A route is assigned a local preference value as one of its attributes (in\naddition to the AS-PATH and NEXT-HOP attributes). The local\npreference of a route could have been set by the router or could have\nbeen learned from another router in the same AS. The value of the local\npreference attribute is a policy decision that is left entirely up to the\nAS’s network administrator. (We will shortly discuss BGP policy issues\nin some detail.) The routes with the highest local preference values are\nselected. 2. From the remaining routes (all with the same highest local preference\nvalue), the route with the shortest AS-PATH is selected. If this rule were\nthe only rule for route selection, then BGP would be using a DV\nalgorithm for path determination, where the distance metric uses the\nnumber of AS hops rather than the number of router hops. 3. From the remaining routes (all with the same highest local preference\nvalue and the same AS-PATH length), hot potato routing is used, that is,\nthe route with the closest NEXT-HOP router is selected. 4. If more than one route still remains, the router uses BGP identifiers to\nselect the route; see [Stewart 1999]. As an example, let’s again consider router 1b in Figure 5.10. Recall that\nthere are exactly two BGP routes to prefix x, one that passes through AS2\nand one that bypasses AS2. Also recall that if hot potato routing on its own\nwere used, then BGP would route packets through AS2 to prefix x. But in\nthe above route-selection algorithm, rule 2 is applied before rule 3, causing"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 701,
    "text": "BGP to select the route that bypasses AS2, since that route has a shorter AS\nPATH. So we see that with the above route-selection algorithm, BGP is no\nlonger a selfish algorithm—it first looks for routes with short AS paths\n(thereby likely reducing end-to-end delay). As noted above, BGP is the de facto standard for inter-AS routing for\nthe Internet. To see the contents of various BGP routing tables (large!) extracted from routers in tier-1 ISPs, see http://www.routeviews.org. BGP\nrouting tables often contain over half a million routes (that is, prefixes and\ncorresponding attributes). Statistics about the size and characteristics of\nBGP routing tables are presented in [Huston 2019b]. 5.4.4 IP-Anycast\nIn addition to being the Internet’s inter-AS routing protocol, BGP is often\nused to implement the IP-anycast service [RFC 1546, RFC 7094], which is\ncommonly used in DNS. To motivate IP-anycast, consider that in many\napplications, we are interested in (1) replicating the same content on\ndifferent servers in many different dispersed geographical locations, and (2)\nhaving each user access the content from the server that is closest. For\nexample, a CDN may replicate videos and other objects on servers in\ndifferent countries. Similarly, the DNS system can replicate DNS records on\nDNS servers throughout the world. When a user wants to access this\nreplicated content, it is desirable to point the user to the “nearest” server\nwith the replicated content. BGP’s route-selection algorithm provides an\neasy and natural mechanism for doing so. To make our discussion concrete, let’s describe how a CDN might use\nIP-­anycast. As shown in Figure 5.12, during the IP-anycast configuration\nstage, the CDN company assigns the same IP address to each of its servers,"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 702,
    "text": "and uses standard BGP to advertise this IP address from each of the servers. When a BGP router receives multiple route advertisements for this IP\naddress, it treats these advertisements as providing different paths to the\nsame physical location (when, in fact, the advertisements are for different\npaths to different physical locations). When configuring its routing table,\neach router will locally use the BGP route-selection algorithm to pick the\n“best” (for example, closest, as determined by AS-hop counts) route to that\nIP address. For example, if one BGP route (corresponding to one location)\nis only one AS hop away from the router, and all other BGP routes\n(corresponding to other locations) are two or more AS hops away, then the\nBGP router would choose to route packets to the location that is one hop\naway. After this initial BGP address-advertisement phase, the CDN can do\nits main job of distributing content. When a client requests the video, the\nCDN returns to the client the common IP address used by the\ngeographically dispersed servers, no matter where the client is located. When the client sends a request to that IP address, Internet routers then\nforward the request packet to the “closest” server, as defined by the BGP\nroute-selection algorithm."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 703,
    "text": "Figure 5.12 ♦Using IP-anycast to bring users to the closest CDN\nserver\nAlthough the above CDN example nicely illustrates how IP-anycast can\nbe used, in practice, CDNs generally choose not to use IP-anycast because\nBGP routing changes can result in different packets of the same TCP\nconnection arriving at different instances of the Web server. But IP-anycast\nis extensively used by the DNS system to direct DNS queries to the closest\nroot DNS server. Recall from Section 2.4, there are currently 13 IP\naddresses for root DNS servers. But corresponding to each of these\naddresses, there are multiple DNS root servers, with some of these\naddresses having over 100 DNS root servers scattered over all corners of\nthe world. When a DNS query is sent to one of these 13 IP addresses, IP\nanycast is used to route the query to the nearest of the DNS root servers that"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 704,
    "text": "is responsible for that address. [Li 2018] presents recent measurements\nillustrating Internet anycast, use, performance, and challenges. 5.4.5 Routing Policy\nWhen a router selects a route to a destination, the AS routing policy can\ntrump all other considerations, such as shortest AS path or hot potato\nrouting. Indeed, in the route-selection algorithm, routes are first selected\naccording to the local-preference attribute, whose value is fixed by the\npolicy of the local AS. Let’s illustrate some of the basic concepts of BGP routing policy with a\nsimple example. Figure 5.13 shows six interconnected autonomous\nsystems: A, B, C, W, X, and Y. It is important to note that A, B, C, W, X,\nand Y are ASs, not routers. Let’s assume that autonomous systems W, X,\nand Y are access ISPs and that A, B, and C are backbone provider networks. We’ll also assume that A, B, and C, directly send traffic to each other, and\nprovide full BGP information to their customer networks. All traffic\nentering an ISP access network must be destined for that network, and all\ntraffic leaving an ISP access network must have originated in that network. W and Y are clearly access ISPs. X is a multi-homed access ISP, since it is\nconnected to the rest of the network via two different providers (a scenario\nthat is becoming increasingly common in practice). However, like W and Y,\nX itself must be the source/destination of all traffic leaving/entering X. But\nhow will this stub network behavior be implemented and enforced? How\nwill X be prevented from forwarding traffic between B and C? This can\neasily be accomplished by controlling the manner in which BGP routes are\nadvertised. In particular, X will function as an access ISP network if it\nadvertises (to its neighbors B and C) that it has no paths to any other"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 705,
    "text": "destinations except itself. That is, even though X may know of a path, say\nXCY, that reaches network Y, it will not advertise this path to B. Since B is\nunaware that X has a path to Y, B would never forward traffic destined to Y\n(or C) via X. This simple example illustrates how a selective route\nadvertisement policy can be used to implement customer/provider routing\nrelationships. Figure 5.13 ♦A simple BGP policy scenario\nLet’s next focus on a provider network, say AS B. Suppose that B has\nlearned (from A) that A has a path AW to W. B can thus install the route AW\ninto its routing information base. Clearly, B also wants to advertise the path\nBAW to its customer, X, so that X knows that it can route to W via B. But\nshould B advertise the path BAW to C? If it does so, then C could route\ntraffic to W via BAW. If A, B, and C are all backbone providers, than B\nmight rightly feel that it should not have to shoulder the burden (and cost!) of carrying transit traffic between A and C. B might rightly feel that it is A’s\nand C’s job (and cost!) to make sure that C can route to/from A’s customers\nvia a direct connection between A and C. There are currently no official\nstandards that govern how backbone ISPs route among themselves. However, a rule of thumb followed by commercial ISPs is that any traffic\nflowing across an ISP’s backbone network must have either a source or a"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 706,
    "text": "destination (or both) in a network that is a customer of that ISP; otherwise\nthe traffic would be getting a free ride on the ISP’s network. Individual\npeering agreements (that would govern questions such as those raised\nabove) are typically negotiated between pairs of ISPs and are often\nconfidential; [Huston 1999a; Huston 2012] provide an interesting\ndiscussion of peering agreements. For a detailed description of how routing\npolicy reflects commercial relationships among ISPs, see [Gao 2001;\nDmitiropoulos 2007]. For a discussion of BGP routing polices from an ISP\nstandpoint, see [Caesar 2005b]. PRINCIPLES IN\nPRACTICE\nWHY ARE THERE DIFFERENT INTER-AS AND INTRA-AS ROUTING PROTOCOLS? Having now studied the details of specific inter-AS and intra-AS routing protocols deployed\nin today’s Internet, let’s conclude by considering perhaps the most fundamental question we\ncould ask about these protocols in the first place (hopefully, you have been wondering this\nall along, and have not lost the forest for the trees! ): Why are different inter-AS and intra-AS\nrouting protocols used? The answer to this question gets at the heart of the differences between the goals of\nrouting within an AS and among ASs:\n•\nPolicy. Among ASs, policy issues dominate. It may well be important that traffic\noriginating in a given AS not be able to pass through another specific AS. Similarly, a\ngiven AS may well want to control what transit traffic it carries between other ASs. We\nhave seen that BGP carries path attributes and provides for controlled distribution of\nrouting information so that such policy-based routing decisions can be made. Within an"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 707,
    "text": "AS, everything is nominally under the same administrative control, and thus policy\nissues play a much less important role in choosing routes within the AS. •\nScale. The ability of a routing algorithm and its data structures to scale to handle routing\nto/among large numbers of networks is a critical issue in inter-AS routing. Within an AS,\nscalability is less of a concern. For one thing, if a single ISP becomes too large, it is\nalways possible to divide it into two ASs and perform inter-AS routing between the two\nnew ASs. (Recall that OSPF allows such a hierarchy to be built by splitting an AS into\nareas.) •\nPerformance. Because inter-AS routing is so policy oriented, the quality (for example,\nperformance) of the routes used is often of secondary concern (that is, a longer or more\ncostly route that satisfies certain policy criteria may well be taken over a route that is\nshorter but does not meet that criteria). Indeed, we saw that among ASs, there is not\neven the notion of cost (other than AS hop count) associated with routes. Within a single\nAS, however, such policy concerns are of less importance, allowing routing to focus\nmore on the level of performance realized on a route. This completes our brief introduction to BGP. Understanding BGP is\nimportant because it plays a central role in the Internet. We encourage you\nto see the references [Stewart 1999; Huston 2019a; Labovitz 1997; Halabi\n2000; Huitema 1998; Gao 2001; Feamster 2004; Caesar 2005b; Li 2007] to\nlearn more about BGP. 5.4.6 Putting the Pieces Together: Obtaining Internet\nPresence"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 708,
    "text": "Although this subsection is not about BGP per se, it brings together many\nof the protocols and concepts we’ve seen thus far, including IP addressing,\nDNS, and BGP. Suppose you have just created a small company that has a number of\nservers, including a public Web server that describes your company’s\nproducts and services, a mail server from which your employees obtain\ntheir e-mail messages, and a DNS server. Naturally, you would like the\nentire world to be able to visit your Web site in order to learn about your\nexciting products and services. Moreover, you would like your employees\nto be able to send and receive e-mail to potential customers throughout the\nworld. To meet these goals, you first need to obtain Internet connectivity,\nwhich is done by contracting with, and connecting to, a local ISP. Your\ncompany will have a gateway router, which will be connected to a router in\nyour local ISP. This connection might be a DSL connection through the\nexisting telephone infrastructure, a leased line to the ISP’s router, or one of\nthe many other access solutions described in Chapter 1. Your local ISP will\nalso provide you with an IP address range, for example, a /24 address range\nconsisting of 256 addresses. Once you have your physical connectivity and\nyour IP address range, you will assign one of the IP addresses (in your\naddress range) to your Web server, one to your mail server, one to your\nDNS server, one to your gateway router, and other IP addresses to other\nservers and ­networking devices in your company’s network. In addition to contracting with an ISP, you will also need to contract\nwith an Internet registrar to obtain a domain name for your company, as\ndescribed in Chapter 2. For example, if your company’s name is, say,\nXanadu Inc., you will naturally try to obtain the domain name xanadu.com. Your company must also obtain presence in the DNS system. Specifically,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 709,
    "text": "because outsiders will want to contact your DNS server to obtain the IP\naddresses of your servers, you will also need to provide your registrar with\nthe IP address of your DNS server. Your registrar will then put an entry for\nyour DNS server (domain name and corresponding IP address) in the .com\ntop-level-domain servers, as described in Chapter 2. After this step is\ncompleted, any user who knows your domain name (e.g., xanadu.com) will\nbe able to obtain the IP address of your DNS server via the DNS system. So that people can discover the IP addresses of your Web server, in\nyour DNS server you will need to include entries that map the host name of\nyour Web server (e.g., www.xanadu.com) to its IP address. You will want to\nhave similar entries for other publicly available servers in your company,\nincluding your mail server. In this manner, if Alice wants to browse your\nWeb server, the DNS system will contact your DNS server, find the IP\naddress of your Web server, and give it to Alice. Alice can then establish a\nTCP connection directly with your Web server. However, there still remains one other necessary and crucial step to\nallow outsiders from around the world to access your Web server. Consider\nwhat happens when Alice, who knows the IP address of your Web server,\nsends an IP datagram (e.g., a TCP SYN segment) to that IP address. This\ndatagram will be routed through the Internet, visiting a series of routers in\nmany different ASs, and eventually reach your Web server. When any one\nof the routers receives the datagram, it is going to look for an entry in its\nforwarding table to determine on which outgoing port it should forward the\ndatagram. Therefore, each of the routers needs to know about the existence\nof your company’s /24 prefix (or some aggregate entry). How does a router\nbecome aware of your company’s prefix? As we have just seen, it becomes\naware of it from BGP! Specifically, when your company contracts with a\nlocal ISP and gets assigned a prefix (i.e., an address range), your local ISP"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 710,
    "text": "will use BGP to advertise your prefix to the ISPs to which it connects. Those ISPs will then, in turn, use BGP to propagate the advertisement. Eventually, all Internet routers will know about your prefix (or about some\naggregate that includes your prefix) and thus be able to appropriately\nforward datagrams destined to your Web and mail servers."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 711,
    "text": "5.5 The SDN Control Plane\nIn this section, we’ll dive into the SDN control plane—the network-wide\nlogic that controls packet forwarding among a network’s SDN-enabled\ndevices, as well as the configuration and management of these devices and\ntheir services. Our study here builds on our earlier discussion of generalized\nSDN forwarding in Section 4.4, so you might want to first review that\nsection, as well as Section 5.1 of this chapter, before continuing on. As in\nSection 4.4, we’ll again adopt the terminology used in the SDN literature\nand refer to the network’s forwarding devices as “packet switches” (or just\nswitches, with “packet” being understood), since forwarding decisions can\nbe made on the basis of network-layer source/destination addresses, link-\nlayer source/destination addresses, as well as many other values in\ntransport-, network-, and link-layer packet-header fields. Four key characteristics of an SDN architecture can be identified\n[Kreutz 2015]:\n•\nFlow-based forwarding. Packet forwarding by SDN-controlled switches\ncan be based on any number of header field values in the transport-\nlayer, network-layer, or link-layer header. We saw in Section 4.4 that the\nOpenFlow1.0 abstraction allows forwarding based on eleven different\nheader field values. This contrasts sharply with the traditional approach\nto router-based forwarding that we studied in Sections 5.2–5.4, where\nforwarding of IP datagrams was based solely on a datagram’s\ndestination IP address. Recall from Figure 5.2 that packet forwarding\nrules are specified in a switch’s flow table; it is the job of the SDN"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 712,
    "text": "control plane to compute, manage and install flow table entries in all of\nthe network’s switches. •\nSeparation of data plane and control plane. This separation is shown\nclearly in Figures 5.2 and 5.14. The data plane consists of the network’s\nswitches—relatively simple (but fast) devices that execute the “match\nplus action” rules in their flow tables. The control plane consists of\nservers and software that determine and manage the switches’ flow\ntables. •\nNetwork control functions: external to data-plane switches. Given that\nthe “S” in SDN is for “software,” it’s perhaps not surprising that the\nSDN control plane is implemented in software. Unlike traditional\nrouters, however, this software executes on servers that are both distinct\nand remote from the network’s switches. As shown in Figure 5.14, the\ncontrol plane itself consists of two components—an SDN controller (or\nnetwork operating system [Gude 2008]) and a set of network-control\napplications. The controller maintains accurate network state\ninformation (e.g., the state of remote links, switches, and hosts);\nprovides this information to the network-control applications running in\nthe control plane; and provides the means through which these\napplications can monitor, program, and control the underlying network\ndevices. Although the controller in Figure 5.14 is shown as a single\ncentral server, in practice the controller is only logically centralized; it\nis typically implemented on several servers that provide coordinated,\nscalable performance and high availability. •\nA programmable network. The network is programmable through the\nnetwork-control applications running in the control plane. These\napplications represent the “brains” of the SDN control plane, using the\nAPIs provided by the SDN controller to specify and control the data"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 713,
    "text": "plane in the network devices. For example, a routing network-control\napplication might determine the end-end paths between sources and\ndestinations (for example, by executing Dijkstra’s algorithm using the\nnode-state and link-state information maintained by the SDN\ncontroller). Another network application might perform access control,\nthat is, determine which packets are to be blocked at a switch, as in our\nthird example in Section 4.4.3. Yet another application might have\nswitches forward packets in a manner that performs server load\nbalancing (the second example we considered in Section 4.4.3). From this discussion, we can see that SDN represents a significant\n“unbundling” of network functionality—data plane switches, SDN\ncontrollers, and network-control applications are separate entities that may\neach be provided by different vendors and organizations. This contrasts\nwith the pre-SDN model in which a switch/router (together with its\nembedded control plane software and protocol implementations) was\nmonolithic, vertically integrated, and sold by a single vendor. This\nunbundling of network functionality in SDN has been likened to the earlier\nevolution from mainframe computers (where hardware, system software,\nand applications were provided by a single vendor) to personal computers\n(with their separate hardware, operating systems, and applications). The\nunbundling of computing hardware, system software, and applications has\nled to a rich, open ecosystem driven by innovation in all three of these\nareas; one hope for SDN is that it will continue to drive and enable such\nrich innovation. Given our understanding of the SDN architecture of Figure 5.14, many\nquestions naturally arise. How and where are the flow tables actually\ncomputed? How are these tables updated in response to events at SDN-\ncontrolled devices (e.g., an attached link going up/down)? And how are the"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 714,
    "text": "flow table entries at multiple switches coordinated in such a way as to result\nin orchestrated and consistent network-wide functionality (e.g., end-to-end\npaths for forwarding packets from sources to destinations, or coordinated\ndistributed firewalls)? It is the role of the SDN control plane to provide\nthese, and many other, capabilities. Figure 5.14 ♦Components of the SDN architecture: SDN-controlled\nswitches, the SDN controller, network-control\napplications"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 715,
    "text": "5.5.1 The SDN Control Plane: SDN Controller and\nSDN Network-control Applications\nLet’s begin our discussion of the SDN control plane in the abstract, by\nconsidering the generic capabilities that the control plane must provide. As\nwe’ll see, this abstract, “first principles” approach will lead us to an overall\narchitecture that reflects how SDN control planes have been implemented\nin practice. As noted above, the SDN control plane divides broadly into two\ncomponents—the \nSDN \ncontroller \nand \nthe \nSDN \nnetwork-control\napplications. Let’s explore the controller first. Many SDN controllers have\nbeen developed since the earliest SDN controller [Gude 2008]; see [Kreutz\n2015] for an extremely thorough survey. Figure 5.15 provides a more\ndetailed view of a generic SDN controller. A controller’s functionality can\nbe broadly organized into three layers. Let’s consider these layers in an\nuncharacteristically bottom-up fashion:"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 716,
    "text": "Figure 5.15 ♦Components of an SDN controller\n•\nA communication layer: communicating between the SDN controller\nand controlled network devices. Clearly, if an SDN controller is going\nto control the operation of a remote SDN-enabled switch, host, or other"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 717,
    "text": "device, a protocol is needed to transfer information between the\ncontroller and that device. In addition, a device must be able to\ncommunicate locally-observed events to the controller (for example, a\nmessage indicating that an attached link has gone up or down, that a\ndevice has just joined the network, or a heartbeat indicating that a\ndevice is up and operational). These events provide the SDN controller\nwith an up-to-date view of the network’s state. This protocol constitutes\nthe lowest layer of the controller architecture, as shown in Figure 5.15. The communication between the controller and the controlled devices\ncross what has come to be known as the controller’s “southbound”\ninterface. In Section 5.5.2, we’ll study OpenFlow—a specific protocol\nthat provides this communication functionality. OpenFlow is\nimplemented in most, if not all, SDN controllers. •\nA network-wide state-management layer. The ultimate control decisions\nmade by the SDN control plane—for example, configuring flow tables\nin all switches to achieve the desired end-end forwarding, to implement\nload balancing, or to implement a particular firewalling capability—will\nrequire that the controller have up-to-date information about state of the\nnetworks’ hosts, links, switches, and other SDN-controlled devices. A\nswitch’s flow table contains counters whose values might also be\nprofitably used by network-control applications; these values should\nthus be available to the applications. Since the ultimate aim of the\ncontrol plane is to determine flow tables for the various controlled\ndevices, a controller might also maintain a copy of these tables. These\npieces of information all constitute examples of the network-wide\n“state” maintained by the SDN controller. •\nThe interface to the network-control application layer. The controller\ninteracts with network-control applications through its “northbound”"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 718,
    "text": "interface. This API allows network-control applications to read/write\nnetwork state and flow tables within the state-management layer. Applications can register to be notified when state-change events occur,\nso that they can take actions in response to network event notifications\nsent from SDN-controlled devices. Different types of APIs may be\nprovided; we’ll see that two popular SDN controllers communicate with\ntheir applications using a REST [Fielding 2000] request-response\ninterface. We have noted several times that an SDN controller can be considered\nto be ­“logically centralized,” that is, that the controller may be viewed\nexternally (for example, from the point of view of SDN-controlled devices\nand external network-control applications) as a single, monolithic service. However, these services and the databases used to hold state information\nare implemented in practice by a distributed set of servers for fault\ntolerance, high availability, or for performance reasons. With controller\nfunctions being implemented by a set of servers, the semantics of the\ncontroller’s internal operations (e.g., maintaining logical time ordering of\nevents, consistency, consensus, and more) must be considered [Panda\n2013]. Such concerns are common across many different distributed\nsystems; see [Lamport 1989, Lampson 1996] for elegant solutions to these\nchallenges. Modern controllers such as OpenDaylight [OpenDaylight 2020]\nand ONOS [ONOS 2020] (see sidebar) have placed considerable emphasis\non architecting a logically centralized but physically distributed controller\nplatform that provides scalable services and high availability to the\ncontrolled devices and network-control applications alike. The architecture depicted in Figure 5.15 closely resembles the\narchitecture of the originally proposed NOX controller in 2008 [Gude\n2008], as well as that of today’s OpenDaylight [OpenDaylight 2020] and"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 719,
    "text": "ONOS [ONOS 2020] SDN controllers (see sidebar). We’ll cover an\nexample of controller operation in Section 5.5.3. First, however, let’s\nexamine the OpenFlow protocol, the earliest and now one of several pro­-\ntocols that can be used for communication between an SDN controller and a\ncontrolled device, which lies in the controller’s communication layer. 5.5.2 OpenFlow Protocol\nThe OpenFlow protocol [OpenFlow 2009, ONF 2020] operates between an\nSDN controller and an SDN-controlled switch or other device\nimplementing the OpenFlow API that we studied earlier in Section 4.4. The\nOpenFlow protocol operates over TCP, with a default port number of 6653. Among the important messages flowing from the controller to the\ncontrolled switch are the following:\n•\nConfiguration. This message allows the controller to query and set a\nswitch’s configuration parameters. •\nModify-State. This message is used by a controller to add/delete or\nmodify entries in the switch’s flow table, and to set switch port\nproperties. •\nRead-State. This message is used by a controller to collect statistics and\ncounter values from the switch’s flow table and ports. •\nSend-Packet. This message is used by the controller to send a specific\npacket out of a specified port at the controlled switch. The message\nitself contains the packet to be sent in its payload. Among the messages flowing from the SDN-controlled switch to the\ncontroller are the following:"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 720,
    "text": "•\nFlow-Removed. This message informs the controller that a flow table\nentry has been removed, for example by a timeout or as the result of a\nreceived modify-state message. •\nPort-status. This message is used by a switch to inform the controller of\na change in port status. •\nPacket-in. Recall from Section 4.4 that a packet arriving at a switch port\nand not matching any flow table entry is sent to the controller for\nadditional processing. Matched packets may also be sent to the\ncontroller, as an action to be taken on a match. The packet-in message is\nused to send such packets to the controller. Additional OpenFlow messages are defined in [OpenFlow 2009, ONF\n2020]. PRINCIPLES IN\nPRACTICE\nGOOGLE’S SOFTWARE-DEFINED GLOBAL NETWORK\nRecall from the case study in Section 2.6 that Google deploys a dedicated wide-area\nnetwork (WAN) that interconnects its data centers and server clusters (in IXPs and ISPs). This network, called B4, has a Google-designed SDN control plane built on OpenFlow. Google’s network is able to drive WAN links at near 70% utilization over the long run (a two\nto three fold increase over typical link utilizations) and split application flows among multiple\npaths based on application priority and existing flow demands [Jain 2013]. The Google B4 network is particularly it well-suited for SDN: (i) Google controls all\ndevices from the edge servers in IXPs and ISPs to routers in their network core; (ii) the\nmost bandwidth-intensive applications are large-scale data copies between sites that can"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 721,
    "text": "defer to higher-priority interactive applications during times of resource congestion; (iii) with\nonly a few dozen data centers being connected, centralized control is feasible. Google’s B4 network uses custom-built switches, each implementing a slightly extended\nversion of OpenFlow, with a local Open Flow Agent (OFA) that is similar in spirit to the\ncontrol agent we encountered in Figure 5.2. Each OFA in turn connects to an Open Flow\nController (OFC) in the network control server (NCS), using a separate “out of band”\nnetwork, distinct from the network that carries data-center traffic between data centers. The\nOFC thus provides the services used by the NCS to communicate with its controlled\nswitches, similar in spirit to the lowest layer in the SDN architecture shown in Figure 5.15. In\nB4, the OFC also performs state management functions, keeping node and link status in a\nNetwork Information Base (NIB). Google’s implementation of the OFC is based on the ONIX\nSDN controller [Koponen 2010]. Two routing protocols, BGP (for routing between the data\ncenters) and IS-IS (a close relative of OSPF, for routing within a data center), are\nimplemented. Paxos [Chandra 2007] is used to execute hot replicas of NCS components to\nprotect against failure. A traffic engineering network-control application, sitting logically above the set of network\ncontrol servers, interacts with these servers to provide global, network-wide bandwidth\nprovisioning for groups of application flows. With B4, SDN made an important leap forward\ninto the operational networks of a global network provider. See [Jain 2013; Hong 2018] for a\ndetailed description of B4. 5.5.3 Data and Control Plane Interaction: An\nExample\nIn order to solidify our understanding of the interaction between SDN-\ncontrolled switches and the SDN controller, let’s consider the example\nshown in Figure 5.16, in which Dijkstra’s algorithm (which we studied in"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 722,
    "text": "Section 5.2) is used to determine shortest path routes. The SDN scenario in\nFigure 5.16 has two important differences from the earlier per-router-\ncontrol scenario of Sections 5.2.1 and 5.3, where ­Dijkstra’s algorithm was\nimplemented in each and every router and link-state updates were flooded\namong all network routers:\nFigure 5.16 ♦SDN controller scenario: Link-state change"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 723,
    "text": "•\nDijkstra’s algorithm is executed as a separate application, outside of the\npacket switches. •\nPacket switches send link updates to the SDN controller and not to each\nother. In this example, let’s assume that the link between switch s1 and s2\ngoes down; that shortest path routing is implemented, and consequently and\nthat incoming and outgoing flow forwarding rules at s1, s3, and s4 are\naffected, but that s2’s operation is unchanged. Let’s also assume that\nOpenFlow is used as the communication layer protocol, and that the control\nplane performs no other function other than link-state routing. 1. Switch s1, experiencing a link failure between itself and s2, notifies the\nSDN controller of the link-state change using the OpenFlow port-status\nmessage. 2. The SDN controller receives the OpenFlow message indicating the link-\nstate change, and notifies the link-state manager, which updates a link-\nstate ­database. 3. The network-control application that implements Dijkstra’s link-state\nrouting has previously registered to be notified when link state changes. That application receives the notification of the link-state change. 4. The link-state routing application interacts with the link-state manager\nto get updated link state; it might also consult other components in the\nstate-­management layer. It then computes the new least-cost paths. 5. The link-state routing application then interacts with the flow table\nmanager, which determines the flow tables to be updated. 6. The flow table manager then uses the OpenFlow protocol to update flow\ntable entries at affected switches—s1 (which will now route packets\ndestined to s2 via s4), s2 (which will now begin receiving packets from"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 724,
    "text": "s1 via intermediate switch s4), and s4 (which must now forward packets\nfrom s1 destined to s2). This example is simple but illustrates how the SDN control plane provides\ncontrol-plane services (in this case, network-layer routing) that had been\npreviously implemented with per-router control exercised in each and every\nnetwork router. One can now easily appreciate how an SDN-enabled ISP\ncould easily switch from least-cost path routing to a more hand-tailored\napproach to routing. Indeed, since the controller can tailor the flow tables as\nit pleases, it can implement any form of forwarding that it pleases—simply\nby changing its application-control software. This ease of change should be\ncontrasted to the case of a traditional per-router control plane, where\nsoftware in all routers (which might be provided to the ISP by multiple\nindependent vendors) must be changed. 5.5.4 SDN: Past and Future\nAlthough the intense interest in SDN is a relatively recent phenomenon, the\ntechnical roots of SDN, and the separation of the data and control planes in\nparticular, go back considerably further. In 2004, [Feamster 2004,\nLakshman 2004, RFC 3746] all argued for the separation of the network’s\ndata and control planes. [van der Merwe 1998] describes a control\nframework for ATM networks [Black 1995] with multiple controllers, each\ncontrolling a number of ATM switches. The Ethane project [Casado 2007]\npioneered the notion of a network of simple flow-based Ethernet switches\nwith  match-plus-action flow tables, a centralized controller that managed\nflow admission and routing, and the forwarding of unmatched packets from\nthe switch to the controller. A network of more than 300 Ethane switches"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 725,
    "text": "was operational in 2007. Ethane quickly evolved into the OpenFlow\nproject, and the rest (as the saying goes) is history! Numerous research efforts are aimed at developing future SDN\narchitectures and capabilities. As we have seen, the SDN revolution is\nleading to the disruptive replacement of dedicated monolithic switches and\nrouters (with both data and control planes) by simple commodity switching\nhardware and a sophisticated software control plane. A generalization of\nSDN known as network functions virtualization (NFV) (which we\ndiscussed earlier in Section 4.5) similarly aims at disruptive replacement of\nsophisticated middleboxes (such as middleboxes with dedicated hardware\nand proprietary software for media caching/service) with simple commodity\nservers, switching, and storage. A second area of important research seeks\nto extend SDN concepts from the intra-AS setting to the inter-AS setting\n[Gupta 2014]. PRINCIPLES IN\nPRACTICE\nSDN CONTROLLER CASE STUDIES: THE OPENDAYLIGHT AND ONOS\nCONTROLLERS\nIn the earliest days of SDN, there was a single SDN protocol (OpenFlow [McKeown 2008;\nOpenFlow 2009]) and a single SDN controller (NOX [Gude 2008]). Since then, the number\nof SDN controllers in particular has grown significantly [Kreutz 2015]. Some SDN controllers\nare company-specific and proprietary, particularly when used to control internal proprietary\nnetworks (e.g., within or among a company’s data centers). But many more controllers are\nopen-source and implemented in a variety of programming languages [Erickson 2013]. Most\nrecently, the OpenDaylight controller [OpenDaylight 2020] and the ONOS controller [ONOS"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 726,
    "text": "2020] have found considerable industry support. They are both open-source and are being\ndeveloped in partnership with the Linux Foundation. The OpenDaylight Controller\nFigure 5.17 presents a simplified view of the OpenDaylight (ODL) controller platform\n[OpenDaylight 2020, Eckel 2017]. Figure 5.17 ♦A simplified view of the OpenDaylight controller\nODL’s Basic Network Functions are at the heart of the controller, and correspond closely\nto the network-wide state management capabilities that we encountered in Figure 5.15. The\nService Abstraction Layer (SAL) is the controller’s nerve center, allowing controller\ncomponents and applications to invoke each other’s services, access configuration and"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 727,
    "text": "operational data, and to subscribe to events they generate. The SAL also provides a\nuniform abstract interface to specific protocols operating between the ODL controller and\nthe controlled devices. These protocols include OpenFlow (which we covered in Section\n4.5), and the Simple Network Management Protocol (SNMP) and the Network Configuration\n(NETCONF) protocol, both of which we’ll cover in Section 5.7. The Open vSwitch Database\nManagement Protocol (OVSDB) is used to manage data center switching, an important\napplication area for SDN technology. We’ll introduce data center networking in Chapter 6. Network Orchestrations and Applications determine how data-plane forwarding and other\nservices, such as firewalling and load balancing, are accomplished in the controlled\ndevices. ODL provides two ways in which applications can interoperate with native\ncontroller services (and hence devices) and with each other. In the API-Driven (AD-SAL)\napproach, shown in Figure 5.17, applications communicate with controller modules using a\nREST request-response API running over HTTP. Initial releases of the OpenDaylight\ncontroller provided only the AD-SAL. As ODL became increasingly used for network\nconfiguration and management, later ODL releases introduced a Model-Driven (MD-SAL)\napproach. Here, the YANG data modeling language [RFC 6020] defines models of device,\nprotocol, and network configuration and operational state data. Devices are then configured\nand managed by manipulating this data using the NETCONF protocol. The ONOS Controller\nFigure 5.18 presents a simplified view of the ONOS controller ONOS 2020]. Similar to the\ncanonical controller in Figure 5.15, three layers can be identified in the ONOS ­controller:"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 728,
    "text": "Figure 5.18 ♦ONOS controller architecture\n•\nNorthbound abstractions and protocols. A unique feature of ONOS is its intent\nframework, which allows an application to request a high-level service (e.g., to setup a\nconnection between host A and Host B, or conversely to not allow Host A and host B to\ncommunicate) without having to know the details of how this service is performed. State\ninformation is provided to network-control applications across the northbound API either\nsynchronously (via query) or asynchronously (via listener callbacks, e.g., when network\nstate changes). •\nDistributed core. The state of the network’s links, hosts, and devices is maintained in\nONOS’s distributed core. ONOS is deployed as a service on a set of interconnected"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 729,
    "text": "servers, with each server running an identical copy of the ONOS software; an increased\nnumber of servers offers an increased service capacity. The ONOS core provides the\nmechanisms for service replication and coordination among instances, providing the\napplications above and the network devices below with the abstraction of logically\ncentralized core services. •\nSouthbound abstractions and protocols. The southbound abstractions mask the\nheterogeneity of the underlying hosts, links, switches, and protocols, allowing the\ndistributed core to be both device and protocol agnostic. Because of this abstraction, the\nsouthbound interface below the distributed core is logically higher than in our canonical\ncontroller in Figure 5.14 or the ODL controller in Figure 5.17."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 730,
    "text": "5.6 ICMP: The Internet Control Message Protocol\nThe Internet Control Message Protocol (ICMP), specified in [RFC 792], is\nused by hosts and routers to communicate network-layer information to\neach other. The most typical use of ICMP is for error reporting. For\nexample, when running an HTTP session, you may have encountered an\nerror message such as “Destination network unreachable.” This message\nhad its origins in ICMP. At some point, an IP router was unable to find a\npath to the host specified in your HTTP request. That router created and\nsent an ICMP message to your host indicating the error. ICMP is often considered part of IP, but architecturally it lies just above\nIP, as ICMP messages are carried inside IP datagrams. That is, ICMP\nmessages are carried as IP payload, just as TCP or UDP segments are\ncarried as IP payload. Similarly, when a host receives an IP datagram with\nICMP specified as the upper-layer protocol (an upper-layer protocol number\nof 1), it demultiplexes the datagram’s contents to ICMP, just as it would\ndemultiplex a datagram’s content to TCP or UDP. ICMP messages have a type and a code field, and contain the header\nand the first 8 bytes of the IP datagram that caused the ICMP message to be\ngenerated in the first place (so that the sender can determine the datagram\nthat caused the error). Selected ICMP message types are shown in Figure\n5.19. Note that ICMP messages are used not only for signaling error\nconditions."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 731,
    "text": "Figure 5.19 ♦ICMP message types\nThe well-known ping program sends an ICMP type 8 code 0 message\nto the specified host. The destination host, seeing the echo request, sends\nback a type 0 code 0 ICMP echo reply. Most TCP/IP implementations\nsupport the ping server directly in the operating system; that is, the server is\nnot a process. Chapter 11 of [Stevens 1990] provides the source code for the\nping client program. Note that the client program needs to be able to\ninstruct the operating system to generate an ICMP message of type 8 code\n0. Another interesting ICMP message is the source quench message. This\nmessage is seldom used in practice. Its original purpose was to perform\ncongestion control—to allow a congested router to send an ICMP source"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 732,
    "text": "quench message to a host to force that host to reduce its transmission rate. We have seen in Chapter 3 that TCP has its own congestion-control\nmechanism that operates at the transport layer, and that Explicit Congestion\nNotification bits can be used by network-later devices to signal congestion. In Chapter 1, we introduced the Traceroute program, which allows us to\ntrace a route from a host to any other host in the world. Interestingly,\nTraceroute is implemented with ICMP messages. To determine the names\nand addresses of the routers between source and destination, Traceroute in\nthe source sends a series of ordinary IP datagrams to the destination. Each\nof these datagrams carries a UDP segment with an unlikely UDP port\nnumber. The first of these datagrams has a TTL of 1, the second of 2, the\nthird of 3, and so on. The source also starts timers for each of the\ndatagrams. When the nth datagram arrives at the nth router, the nth router\nobserves that the TTL of the datagram has just expired. According to the\nrules of the IP protocol, the router discards the datagram and sends an\nICMP warning message to the source (type 11 code 0). This warning\nmessage includes the name of the router and its IP address. When this\nICMP message arrives back at the source, the source obtains the round-trip\ntime from the timer and the name and IP address of the nth router from the\nICMP message. How does a Traceroute source know when to stop sending UDP\nsegments? Recall that the source increments the TTL field for each\ndatagram it sends. Thus, one of the datagrams will eventually make it all the\nway to the destination host. Because this datagram contains a UDP segment\nwith an unlikely port number, the destination host sends a port unreachable\nICMP message (type 3 code 3) back to the source. When the source host\nreceives this particular ICMP message, it knows it does not need to send\nadditional probe packets. (The standard Traceroute program actually sends"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 733,
    "text": "sets of three packets with the same TTL; thus, the Traceroute output\nprovides three results for each TTL.) In this manner, the source host learns the number and the identities of\nrouters that lie between it and the destination host and the round-trip time\nbetween the two hosts. Note that the Traceroute client program must be able\nto instruct the operating system to generate UDP datagrams with specific\nTTL values and must also be able to be notified by its operating system\nwhen ICMP messages arrive. Now that you understand how Traceroute\nworks, you may want to go back and play with it some more. A new version of ICMP has been defined for IPv6 in RFC 4443. In\naddition to reorganizing the existing ICMP type and code definitions,\nICMPv6 also added new types and codes required by the new IPv6\nfunctionality. These include the “Packet Too Big” type and an\n“unrecognized IPv6 options” error code."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 734,
    "text": "5.7 Network Management and SNMP,\nNETCONF/YANG\nHaving now made our way to the end of our study of the network layer,\nwith only the link-layer before us, we’re well aware that a network consists\nof many complex, interacting pieces of hardware and software—from the\nlinks, switches, routers, hosts, and other devices that comprise the physical\ncomponents of the network to the many protocols that control and\ncoordinate these devices. When hundreds or thousands of such components\nare brought together by an organization to form a network, the job of the\nnetwork administrator to keep the network “up and running” is surely a\nchallenge. We saw in Section  5.5 that the logically centralized controller\ncan help with this process in an SDN context. But the challenge of network\nmanagement has been around long before SDN, with a rich set of network\nmanagement tools and approaches that help the network administrator\nmonitor, manage, and control the network. We’ll study these tools and\ntechniques in this section, as well as new tools and techniques that have co-\nevolved along with SDN. An often-asked question is “What is network management?” A well-\nconceived, single-sentence (albeit a rather long run-on sentence) definition\nof network management from [Saydam 1996] is:\nNetwork management includes the deployment, integration, and\ncoordination of the hardware, software, and human elements to\nmonitor, test, poll, configure, analyze, evaluate, and control the network\nand element resources to meet the real-time, operational performance,\nand Quality of Service requirements at a reasonable cost."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 735,
    "text": "Given this broad definition, we’ll cover only the rudiments of network\nmanagement in this section—the architecture, protocols, and data used by a\nnetwork administrator in performing their task. We’ll not cover the\nadministrator’s decision-making processes, where topics such as fault\nidentification [Labovitz 1997; Steinder 2002; Feamster 2005; Wu 2005;\nTeixeira 2006], anomaly detection [Lakhina 2005; Barford 2009], network\ndesign/engineering to meet contracted Service Level Agreements (SLA’s)\n[Huston 1999a], and more come into consideration. Our focus is thus\npurposefully narrow; the interested reader should consult these references,\nthe excellent overviews in [Subramanian 2000; Schonwalder 2010; Claise\n2019], and the more detailed treatment of network management available\non the Web site for this text. 5.7.1 The Network Management Framework\nFigure 5.20 shows the key components of network management:"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 736,
    "text": "Figure 5.20 ♦Elements of network management\n•\nManaging server. The managing server is an application, typically with\nnetwork managers (humans) in the loop, running in a centralized\nnetwork management station in the network operations center (NOC). The managing server is the locus of activity for network management: it\ncontrols the collection, processing, analysis, and dispatching of network\nmanagement information and commands. It is here that actions are\ninitiated to configure, monitor, and control the network’s managed"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 737,
    "text": "devices. In practice, a network may have several such managing\nservers. •\nManaged device. A managed device is a piece of network equipment\n(including its software) that resides on a managed network. A managed\ndevice might be a host, router, switch, middlebox, modem,\nthermometer, or other network-connected device. The device itself will\nhave many manageable components (e.g., a network interface is but one\ncomponent of a host or router), and configuration parameters for these\nhardware and software components (e.g., an intra-AS routing protocol,\nsuch as OSPF). •\nData. Each managed device will have data, also known as “state,”\nassociated with it. There are several different types of data. Configuration data is device information explicitly configured by the\nnetwork manager, for example, a manager-assigned/configured IP\naddress or interface speed for a device interface. Operational data is\ninformation that the device acquires as it operates, for example, the list\nof immediate neighbors in OSPF protocol. Device statistics are status\nindicators and counts that are updated as the device operators (e.g., the\nnumber of dropped packets on an interface, or the device’s cooling fan\nspeed). The network manager can query remote device data, and in\nsome cases, control the remote device by writing device data values, as\ndiscussed below. As shown in Figure 5.17, the managing server also\nmaintains its own copy of configuration, operational and statistics data\nfrom its managed devices as well as network-wide data (e.g., the\nnetwork’s topology). •\nNetwork management agent. The network management agent is a\nsoftware process running in the managed device that communicates\nwith the managing server, taking local actions at the managed device"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 738,
    "text": "under the command and control of the managing server. The network\nmanagement agent is similar to the routing agent that we saw in Figure\n5.2. •\nNetwork management protocol. The final component of a network\nmanagement framework is the network management protocol. This\nprotocol runs between the managing server and the managed devices,\nallowing the managing server to query the status of managed devices\nand take actions at these devices via its agents. Agents can use the\nnetwork management protocol to inform the managing server of\nexceptional events (e.g., component failures or violation of performance\nthresholds). It’s important to note that the network management\nprotocol does not itself manage the network. Instead, it provides\ncapabilities that network managers can use to manage (“monitor, test,\npoll, configure, analyze, evaluate, and control”) the network. This is a\nsubtle, but important, distinction. In practice, there are three commonly used ways in a network operator\ncan manage the network, using the components described above:\n•\nCLI. A network operator may issue direct Command Line Interface\n(CLI) commands to the device. These commands can be typed directly\non a managed device’s console (if the operator is physically present at\nthe device), or over a Telnet or secure shell (SSH) connection, possibly\nvia scripting, between the ­managing server/controller and the managed\ndevice. CLI commands are vendor- and device-specific and can be\nrather arcane. While seasoned network wizards may be able to use CLI\nto flawlessly configure network devices, CLI use is prone to errors, and\nit is difficult to automate or efficiently scale for large networks. Consumer-oriented network devices, such as your wireless home router,"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 739,
    "text": "may export a management menu that you (the network manager!) can\naccess via HTTP to configure that device. While this approach may\nwork well for single, simple devices and is less error-prone than CLI, it\nalso doesn’t scale to larger-sized networks. •\nSNMP/MIB. In this approach, the network operator can query/set the\ndata contained in a device’s Management Information Base (MIB)\nobjects using the Simple Network Management Protocol (SNMP). Some MIBs are device- and vendor-specific, while other MIBs (e.g., the\nnumber of IP datagrams discarded at a router due to errors in an IP\ndatagram header, or the number of UDP segments received at a host)\nare device-agnostic, providing abstraction and generality. A network\noperator would most typically use this approach to query and monitor\noperational state and device statistics, and then use CLI to actively\ncontrol/configure the device. We note, importantly, that both approaches\nmanage devices individually. We’ll cover the SNMP and MIBs, which\nhave been in use since the late 1980s, in Section 5.7.2 below. A\nnetwork-management workshop convened by the Internet Architecture\nBoard in 2002 [RFC 3535] noted not only the value of the SNMP/MIB\napproach for device monitoring but also noted its shortcomings,\nparticularly for device configuration and network management at scale. This gave rise to the most recent approach for network management,\nusing NETCONF and YANG. •\nNETCONF/YANG. The NETCONF/YANG approach takes a more\nabstract, network-wide, and holistic view toward network management,\nwith a much stronger emphasis on configuration management, including\nspecifying correctness constraints and providing atomic management\noperations over multiple controlled devices. YANG [RFC 6020] is a\ndata modeling language used to model configuration and operational"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 740,
    "text": "data. The NETCONF protocol [RFC 6241] is used to communicate\nYANG-compatible actions and data to/from/among remote devices. We\nbriefly encountered NETCONF and YANG in our case study of\nOpenDaylight Controller in Figure 5.17 and will study them in Section\n5.7.3 below. 5.7.2 The Simple Network Management Protocol\n(SNMP) and the Management Information\nBase (MIB)\nThe Simple Network Management Protocol version 3 (SNMPv3) [RFC\n3410] is an application-layer protocol used to convey network-management\ncontrol and information messages between a managing server and an agent\nexecuting on behalf of that managing server. The most common usage of\nSNMP is in a request-response mode in which an SNMP managing server\nsends a request to an SNMP agent, who receives the request, performs some\naction, and sends a reply to the request. Typically, a request will be used to\nquery (retrieve) or modify (set) MIB object values associated with a\nmanaged device. A second common usage of SNMP is for an agent to send\nan unsolicited message, known as a trap message, to a managing server. Trap messages are used to notify a managing server of an exceptional\nsituation (e.g., a link interface going up or down) that has resulted in\nchanges to MIB object values. MIB objects are specified in a data description language known as SMI\n(Structure of Management Information) [RFC 2578; RFC 2579; RFC\n2580], a rather oddly named component of the network management\nframework whose name gives no hint  of its functionality. A formal"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 741,
    "text": "definition language is used to ensure that the syntax and semantics of the\nnetwork management data are well defined and unambiguous. Related MIB\nobjects are gathered into MIB modules. As of late 2019, there are more than\n400 MIB-related RFCs and a much larger number of vendor-specific\n(private) MIB modules. SNMPv3 defines seven types of messages, known generically as\nprotocol data units—PDUs—as shown in Table 5.2 and described below. The format of the PDU is shown in Figure 5.21. Table 5.2 ♦SNMPv3 PDU types\nFigure 5.21 ♦SNMP PDU format\n•\nThe GetRequest, GetNextRequest, and GetBulkRequest\nPDUs are all sent from a managing server to an agent to request the\nvalue of one or more MIB objects at the agent’s managed device. The\nMIB objects whose values are being requested are specified in the\nvariable \nbinding \nportion \nof \nthe \nPDU. ­GetRequest,"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 742,
    "text": "GetNextRequest, and GetBulkRequest differ in the granularity\nof their data requests. GetRequest can request an arbitrary set of\nMIB values; multiple GetNextRequests can be used to sequence\nthrough a list or table of MIB objects; GetBulkRequest allows a\nlarge block of data to be returned, avoiding the overhead incurred if\nmultiple GetRequest or ­GetNextRequest messages were to be\nsent. In all three cases, the agent responds with a Response PDU\ncontaining the object identifiers and their associated values. •\nThe SetRequest PDU is used by a managing server to set the value\nof one or more MIB objects in a managed device. An agent replies with\na Response PDU with the “noError” error status to confirm that the\nvalue has indeed been set. •\nThe InformRequest PDU is used by a managing server to notify\nanother managing server of MIB information that is remote to the\nreceiving server. •\nThe Response PDU is typically sent from a managed device to the\nmanaging server in response to a request message from that server,\nreturning the requested information. •\nThe final type of SNMPv3 PDU is the trap message. Trap messages are\ngenerated asynchronously; that is, they are not generated in response to\na received request but rather in response to an event for which the\nmanaging server requires notification. RFC 3418 defines well-known\ntrap types that include a cold or warm start by a device, a link going up\nor down, the loss of a neighbor, or an authentication failure event. A\nreceived trap request has no required response from a managing server. Given the request-response nature of SNMP, it is worth noting here that\nalthough SNMP PDUs can be carried via many different transport"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 743,
    "text": "protocols, the SNMP PDU is typically carried in the payload of a UDP\ndatagram. Indeed, RFC 3417 states that UDP is “the ­preferred transport\nmapping.” However, since UDP is an unreliable transport protocol, there is\nno guarantee that a request, or its response, will be received at the intended\ndestination. The request ID field of the PDU (see Figure 5.21) is used by the\nmanaging server to number its requests to an agent; the agent’s response\ntakes its request ID from that of the received request. Thus, the request ID\nfield can be used by the managing server to detect lost requests or replies. It\nis up to the managing server to decide whether to retransmit a request if no\ncorresponding response is received after a given amount of time. In\nparticular, the SNMP standard does not mandate any particular procedure\nfor retransmission, or even if retransmission is to be done in the first place. It only requires that the managing server “needs to act responsibly in\nrespect to the frequency and duration of retransmissions.” This, of course,\nleads one to wonder how a “responsible” protocol should act! SNMP has evolved through three versions. The designers of SNMPv3\nhave said that “SNMPv3 can be thought of as SNMPv2 with additional\nsecurity and administration capabilities” [RFC 3410]. Certainly, there are\nchanges in SNMPv3 over SNMPv2, but nowhere are those changes more\nevident than in the area of administration and security. The central role of\nsecurity in SNMPv3 was particularly important, since the lack of adequate\nsecurity resulted in SNMP being used primarily for monitoring rather than\ncontrol (for example, SetRequest is rarely used in SNMPv1). Once\nagain, we see that ­security—a topic we’ll cover in detail in Chapter 8 — is\nof critical concern, but once again a concern whose importance had been\nrealized perhaps a bit late and only then “added on.”\nThe Management Information Base (MIB)"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 744,
    "text": "We learned earlier that a managed device’s operational state data (and to\nsome extent its configuration data) in the SNMP/MIB approach to network\nmanagement are represented as objects that are gathered together into an\nMIB for that device. An MIB object might be a counter, such as the number\nof IP datagrams discarded at a router due to errors in an IP datagram header;\nor the number of carrier sense errors in an Ethernet interface card;\ndescriptive information such as the version of the software running on a\nDNS server; status information such as whether a particular device is\nfunctioning correctly; or protocol-specific information such as a routing\npath to a destination. Related MIB objects are gathered into MIB modules. There are over 400 MIB modules defined in various IETC RFC’s; there are\nmany more device- and vendor-specific MIBs. [RFC 4293] specifies the\nMIB \nmodule \nthat \ndefines \nmanaged \nobjects \n(including\nipSystemStatsInDelivers) for managing implementations of the Internet\nProtocol (IP) and its associated Internet Control Message Protocol (ICMP). [RFC 4022] specifies the MIB module for TCP, and [RFC 4113] specifies\nthe MIB module for UDP. While MIB-related RFCs make for rather tedious and dry reading, it is\nnonetheless instructive (i.e., like eating vegetables, it is “good for you”) to\nconsider \nan \nexample \nof \na \nMIB \nobject, \nThe \nipSystem-\nStatsInDelivers object-type definition from [RFC 4293] defines a\n32-bit read-only counter that keeps track of the number of IP datagrams that\nwere received at the managed device and were successfully delivered to an\nupper-layer protocol. In the example below, Counter32 is one of the basic\ndata types defined in the SMI. ipSystemStatsInDelivers OBJECT-TYPE\n     SYNTAX Counter32\n     MAX-ACCESS read-only"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 745,
    "text": "STATUS current\n     DESCRIPTION\n“The total number of datagrams\nsuccessfully delivered to IPuser-\nprotocols (including ICMP). When tracking interface statistics, the\ncounter of the interface to which these\ndatagrams were addressed is\nincremented. This interface might not\nbe the same as the input interface for\nsome of the datagrams. Discontinuities in the value of this\ncounter can occur at re-initialization\nof the management system, and at other\ntimes as indicated by the value of\nipSystemStatsDiscontinuityTime.”\n::= { ipSystemStatsEntry 18 }\n5.7.3 The Network Configuration Protocol\n(NETCONF) and YANG\nThe NETCONF protocol operates between the managing server and the\nmanaged network devices, providing messaging to (i) retrieve, set, and\nmodify configuration data at managed devices; (ii) to query operational data\nand statistics at managed devices; and (iii) to subscribe to notifications\ngenerated by managed devices. The managing server actively controls a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 746,
    "text": "managed device by sending it configurations, which are specified in a\nstructured XML document, and activating a configuration at the managed\ndevice. NETCONF uses a remote procedure call (RPC) paradigm, where\nprotocol messages are also encoded in XML and exchanged between the\nmanaging server and a managed device over a secure, connection-oriented\nsession such as the TLS (Transport Layer Security) protocol (discussed in\nChapter 8) over TCP. Figure 5.22 shows an example NETCONF session. First, the managing\nserver establishes a secure connection to the managed device. (In\nNETCONF parlance, the managing server is actually referred to as the\n“client” and the managed device as the “server,” since the managing server\nestablishes the connection to the managed device. But we’ll ignore that here\nfor consistency with the longer-standing network-management server/client\nterminology shown in Figure 5.20.) Once a secure connection has been\nestablished, the managing server and the managed device exchange <hello>\nmessages, declaring their “capabilities”—NETCONF functionality that\nsupplements the base NETCONF specification in [RFC 6241]. Interactions\nbetween the managing server and managed device take the form of a remote\nprocedure call, using the <rpc> and <rpc-response> messages. These\nmessages are used to retrieve, set, query and modify device configurations,\noperational data and statistics, and to subscribe to device notifications. Device notifications themselves are proactively sent from managed device\nto the managing server using NETCONF <notification> messages. A\nsession is closed with the <session-close message>."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 747,
    "text": "Figure 5.22 ♦NETCONF session between managing\nserver/controller and managed device\nTable 5.3 shows a number of the important NETCONF operations that\na managing server can perform at a managed device. As in the case of\nSNMP, we see operations for retrieving operational state data (<get>), and\nfor event notification. However, the <get-config>, <edit-config>, <lock>\nand <unlock> operation demon­strate NETCONF’s particular emphasis on\ndevice configuration. Using the basic operations shown in Table 5.3, it is\nalso possible to create a set of more sophisticated network management"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 748,
    "text": "transactions that either complete atomically (i.e., as a group) and\nsuccessfully on a set of devices, or are fully reversed and leave the devices\nin their pre-transaction state. Such multi-device transactions—“enabl[ing]\noperators to concentrate on the configuration of the network as a whole\nrather than individual devices” was an important operator requirement put\nforth in [RFC 3535]. Table 5.3 ♦Selected NETCONF operations\nA full description of NETCONF is beyond our scope here; [RFC 6241,\nRFC 5277, Claise 2019; Schonwalder 2010] provide more in-depth\ncoverage. But since this is the first time we’ve seen protocol messages formatted\nas an XML document (rather than the traditional message with header fields\nand message body, e.g., as shown in Figure 5.21 for the SNMP PDU), let’s\nconclude our brief study of NETCONF with two examples. In the first example, the XML document sent from the managing server\nto the managed device is a NETCONF <get> command requesting all\ndevice configuration and operational data. With this command, the server\ncan learn about the device’s configuration. 01 <?xml version=”1.0” encoding=”UTF-8”?>\n02 <rpc message-id=”101”\n03    xmlns=”urn:ietf:params:xml:ns:netconf:base\n:1.0”>\n04 <get/>\n05 </rpc>\nAlthough few people can completely parse XML directly, we see that\nthe NETCONF command is relatively human-readable, and is much more"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 749,
    "text": "reminiscent of HTTP and HTML than the protocol message formats that we\nsaw for SNMP PDU format in Figure 5.21. The RPC message itself spans\nlines 02–05 (we have added line numbers here for pedagogical purposes). The RPC has a message ID value of 101, declared in line 02, and contains a\nsingle NETCONF <get> command. The reply from the device contains a\nmatching ID number (101), and all of the device’s configuration data (in\nXML format, of course), starting in line 04, ultimately with a closing </rpc-\nreply>. 01 <?xml version=”1.0” encoding=”UTF-8”?>\n02 <rpc-reply message-id=”101”\n03    xmlns=”urn:ietf:params:xml:ns:netconf:base\n:1.0”>\n04  <!-- . . . all configuration data\nreturned... -->\n . . . </rpc-reply>\nIn the second example below, adapted from [RFC 6241], the XML\ndocument sent from the managing server to the managed device sets the\nMaximum Transmission Unit (MTU) of an interface named “Ethernet0/0”\nto 1500 bytes:\n01 <?xml version=”1.0” encoding=”UTF-8”?>\n02 <rpc message-id=”101”\n  xmlns=”urn:ietf:params:xml:ns:netconf:base:1.0\n”>\n04   <edit-config>"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 750,
    "text": "05     <target>\n06       <running/>\n07     </target>\n08     <config>\n09       <top\nxmlns=”http://example.com/schema/1.2/config”>\n10          <interface>\n11             <name>Ethernet0/0</name>\n12             <mtu>1500</mtu>\n13          </interface>\n14       </top>\n15     </config>\n16   </edit-config>\n17 </rpc>\nThe RPC message itself spans lines 02–17, has a message ID value of\n101, and contains a single NETCONF <edit-config> command, spanning\nlines 04–15. Line 06 indicates that the running device configuration at the\nmanaged device will be changed. Lines 11 and 12 specify the MTU size to\nbe set of the Ethernet0/0 interface. Once the managed device has changed the interface’s MTU size in the\nconfiguration, it responds back to the managing server with an OK reply\n(line 04 below), again within an XML document:\n01 <?xml version=”1.0” encoding=”UTF-8”?>\n02 <rpc-reply message-id=”101”\nxmlns=”urn:ietf:params:xml:ns:netconf:base:1.0”>\n04 <ok/>"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 751,
    "text": "05 </rpc-reply>\nYANG\nYANG is the data modeling language used to precisely specify the\nstructure, syntax, and semantics of network management data used by\nNETCONF, in much the same way that the SMI is used to specify MIBs in\nSNMP. All YANG definitions are contained in modules, and an XML\ndocument describing a device and its capabilities can be generated from a\nYANG module. YANG features a small set of built-in data types (as in the case of SMI)\nand also allows data modelers to express constraints that must be satisfied\nby a valid NETCONF configuration—a powerful aid in helping ensure that\nNETCONF configurations satisfy specified correctness and consistency\nconstraints. YANG is also used to specify NETCONF notifications. A fuller discussion of YANG is beyond our scope here. For more\ninformation, we refer the interested reader to the excellent book [Claise\n2019]."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 752,
    "text": "5.8 Summary\nWe have now completed our two-chapter journey into the network core—a\njourney that began with our study of the network layer’s data plane in\nChapter 4 and finished here with our study of the network layer’s control\nplane. We learned that the control plane is the network-wide logic that\ncontrols not only how a datagram is forwarded among routers along an end-\nto-end path from the source host to the destination host, but also how\nnetwork-layer components and services are configured and managed. We learned that there are two broad approaches towards building a\ncontrol plane: traditional per-router control (where a routing algorithm runs\nin each and every router and the routing component in the router\ncommunicates with the routing components in other routers) and software-\ndefined networking (SDN) control (where a logically centralized controller\ncomputes and distributes the forwarding tables to be used by each and every\nrouter). We studied two fundamental routing algorithms for computing least\ncost paths in a graph—link-state routing and distance-vector routing—in\nSection 5.2; these algorithms find application in both per-router control and\nin SDN control. These algorithms are the basis for two widely deployed\nInternet routing protocols, OSPF and BGP, that we covered in Sections 5.3\nand 5.4. We covered the SDN approach to the network-layer control plane\nin Section 5.5, investigating SDN network-control applications, the SDN\ncontroller, and the OpenFlow protocol for communicating between the\ncontroller and SDN-controlled devices. In Sections 5.6 and 5.7, we covered\nsome of the nuts and bolts of managing an IP network: ICMP (the Internet\nControl Message Protocol) and network management using SNMP and\nNETCONF/YANG."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 753,
    "text": "Having completed our study of the network layer, our journey now\ntakes us one step further down the protocol stack, namely, to the link layer. Like the network layer, the link layer is part of each and every network-\nconnected device. But we will see in the next chapter that the link layer has\nthe much more localized task of moving packets between nodes on the\nsame link or LAN. Although this task may appear on the surface to be\nrather simple compared with that of the network layer’s tasks, we will see\nthat the link layer involves a number of important and fascinating issues\nthat can keep us busy for a long time."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 754,
    "text": "Homework Problems and Questions\nChapter 5\nSECTION 5.1\nR1. What is meant by a control plane that is based on per-router control? In such cases, when we say the network control and data planes are\nimplemented “monolithically,” what do we mean? R2. What is meant by a control plane that is based on logically\ncentralized control? In such cases, are the data plane and the control\nplane implemented within the same device or in separate devices? Explain. SECTION 5.2\nR3. Compare and contrast the properties of a centralized and a distributed\nrouting algorithm. Give an example of a routing protocol that takes a\ncentralized and a decentralized approach. R4. Compare and contrast static and dynamic routing algorithms. R5. What is the “count to infinity” problem in distance vector routing? R6. How is a least cost path calculated in a decentralized routing\nalgorithm? SECTIONS 5.3-5.4\nR7. Why are different inter-AS and intra-AS protocols used in the\nInternet? R8. True or false: When an OSPF route sends its link state information, it\nis sent only to those nodes directly attached neighbors. Explain."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 755,
    "text": "R9. What is meant by an area in an OSPF autonomous system? Why was\nthe concept of an area introduced? R10. Define and contrast the following terms: subnet, prefix, and BGP\nroute. R11. How does BGP use the NEXT-HOP attribute? How does it use the\nAS-PATH attribute? R12. Describe how a network administrator of an upper-tier ISP can\nimplement policy when configuring BGP. R13. True or false: When a BGP router receives an advertised path from its\nneighbor, it must add its own identity to the received path and then\nsend that new path on to all of its neighbors. Explain. SECTION 5.5\nR14. Describe the main role of the communication layer, the network-wide\nstate-­management layer, and the network-control application layer in\nan SDN controller. R15. Suppose you wanted to implement a new routing protocol in the SDN\ncontrol plane. At which layer would you implement that protocol? Explain. R16. What types of messages flow across an SDN controller’s northbound\nand southbound APIs? Who is the recipient of these messages sent\nfrom the controller across the southbound interface, and who sends\nmessages to the controller across the northbound interface? R17. Describe the purpose of two types of OpenFlow messages (of your\nchoosing) that are sent from a controlled device to the controller. Describe the purpose of two types of Openflow messages (of your\nchoosing) that are send from the controller to a controlled device. R18. What is the purpose of the service abstraction layer in the\nOpenDaylight SDN controller?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 756,
    "text": "SECTIONS 5.6-5.7\nR19. Names four different types of ICMP messages\nR20. What two types of ICMP messages are received at the sending host\nexecuting the Traceroute program? R21. Define the following terms in the context of SNMP: managing server,\nmanaged device, network management agent and MIB. R22. What are the purposes of the SNMP GetRequest and SetRequest\nmessages? R23. What is the purpose of the SNMP trap message? Problems\nP1. Consider the figure below. Enumerate all paths from A to D that do not contain any loops\nP2. Repeat Problem P1 for paths from C to D, B to F, and C to F.\nP3. Consider the following network. With the indicated link costs, use\nDijkstra’s shortest-path algorithm to compute the shortest path from x"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 757,
    "text": "to all network nodes. Show how the algorithm works by computing a\ntable similar to Table 5.1. VideoNote\nDijkstra’s algorithm: discussion and example\nP4. Consider the network shown in Problem P3. Using Dijkstra’s\nalgorithm, and showing your work using a table similar to Table 5.1,\ndo the following:\na. Compute the shortest path from t to all network nodes. b. Compute the shortest path from u to all network nodes. a. Compute the shortest path from v to all network nodes."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 758,
    "text": "d. Compute the shortest path from w to all network nodes. e. Compute the shortest path from y to all network nodes. f. Compute the shortest path from z to all network nodes. P5. Consider the network shown below. Assume that each node initially\nknows the costs to each of its neighbors. Consider the distance-\nvector ­algorithm and show the distance table entries at node z.\nP6. Consider a general topology (that is, not the specific network shown\nabove) and a synchronous version of the distance-vector algorithm. Suppose that at each iteration, a node exchanges its distance vectors\nwith its neighbors and receives their distance vectors. Assuming that\nthe algorithm begins with each node knowing only the costs to its\nimmediate neighbors, what is the maximum number of iterations\nrequired before the distributed algorithm converges? Justify your\nanswer. P7. Consider the network fragment shown below. x has only two\nattached ­neighbors, w and y. w has a minimum-cost path to\ndestination u ­(illustrated with the dotted line through the remaining\nnetwork) of 9, and y has a minimum-cost path to u of 11. The\ncomplete paths from w and y to u (and between w and y) are pictured\nwith dotted lines, as they are irrelevant to the solution."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 759,
    "text": "a. Give x’s distance vector for destinations w, y, and u.\nb. Give a link-cost change for either c(x,w) or c(x,y) such that x will\ninform its neighbors of a new minimum-cost path to u as a result\nof executing the distance-vector algorithm. c. Give a link-cost change for either c(x,w) or c(x,y) such that x will\nnot inform its neighbors of a new minimum-cost path to u as a\nresult of executing the distance-vector algorithm. P8. Consider the three-node topology shown in Figure 5.6. Rather than\nhaving the link costs shown in Figure 5.6, the link costs are c(x,y) = 3,\nc(y,z) = 6, c(z,x) = 4. Compute the distance tables after the\ninitialization step and after each iteration of a synchronous version of\nthe distance-vector algorithm (as we did in our earlier discussion of\nFigure 5.6). P9. Can the poisoned reverse solve the general count-to-infinity problem? Justify your answer. P10. Argue that for the distance-vector algorithm in Figure 5.6, each value\nin the distance vector D(x) is non-increasing and will eventually\nstabilize in a finite number of steps. P11. Consider Figure 5.7. Suppose there is another router w, connected to\nrouter y and z. The costs of all links are given as follows: c(x,y) = 4,"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 760,
    "text": "c(x,z) = 50, c(y,w) = 1, c(z,w) = 1, c(y,z) = 3. Suppose that poisoned\nreverse is used in the distance-vector routing algorithm. a. When the distance vector routing is stabilized, router w, y, and z\ninform their distances to x to each other. What distance values do\nthey tell each other? b. Now suppose that the link cost between x and y increases to 60. Will there be a count-to-infinity problem even if poisoned\nreverse is used? Why or why not? If there is a count-to-infinity\nproblem, then how many iterations are needed for the distance-\nvector routing to reach a stable state again? Justify your answer. c. How do you modify c(y,z) such that there is no count-to-infinity\nproblem at all if c(y,x) changes from 4 to 60? P12. What is the message complexity of LS routing algorithm? P13. Will a BGP router always choose the loop-free route with the shortest\nASpath length? Justify your answer. P14. Consider the network shown below. Suppose AS3 and AS2 are\nrunning OSPF for their intra-AS routing protocol. Suppose AS1 and\nAS4 are running RIP for their intra-AS routing protocol. Suppose\neBGP and iBGP are used for the inter-AS routing protocol. Initially\nsuppose there is no physical link between AS2 and AS4. a. Router 3c learns about prefix x from which routing protocol:\nOSPF, RIP, eBGP, or iBGP? b. Router 3a learns about x from which routing protocol? c. Router 1c learns about x from which routing protocol? d. Router 1d learns about x from which routing protocol?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 761,
    "text": "P15. Referring to the previous problem, once router 1d learns about x it\nwill put an entry (x, I) in its forwarding table. a. Will I be equal to I  or I  for this entry? Explain why in one\nsentence. b. Now suppose that there is a physical link between AS2 and AS4,\nshown by the dotted line. Suppose router 1d learns that x is\naccessible via AS2 as well as via AS3. Will I be set to I  or I ? Explain why in one sentence. c. Now suppose there is another AS, called AS5, which lies on the\npath between AS2 and AS4 (not shown in diagram). Suppose\nrouter 1d learns that x is accessible via AS2 AS5 AS4 as well as\nvia AS3 AS4. Will I be set to I  or I ? Explain why in one\nsentence. P16. Consider the following network. ISP B provides national backbone\nservice to regional ISP A. ISP C provides national backbone service\nto regional ISP D. Each ISP consists of one AS. B and C peer with\neach other in two places using BGP. Consider traffic going from A to\nD. B would prefer to hand that traffic over to C on the West Coast (so\nthat C would have to absorb the cost of carrying the traffic cross-\n2\n2\n2"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 762,
    "text": "country), while C would prefer to get the traffic via its East Coast\npeering point with B (so that B would have carried the traffic across\nthe country). What BGP mechanism might C use, so that B would\nhand over A-to-D traffic at its East Coast peering point? To answer\nthis question, you will need to dig into the BGP ­specification. P17. In Figure 5.13, consider the path information that reaches stub\nnetworks W, X, and Y. Based on the information available at W and\nX, what are their respective views of the network topology? Justify\nyour answer. The topology view at Y is shown below."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 763,
    "text": "P18. Consider Figure 5.13. B would never forward traffic destined to Y via\nX based on BGP routing. But there are some very popular\napplications for which data packets go to X first and then flow to Y. Identify one such application, and describe how data packets follow a\npath not given by BGP routing. P19. In Figure 5.13, suppose that there is another stub network V that is a\ncustomer of ISP A. Suppose that B and C have a peering relationship,\nand A is a customer of both B and C. Suppose that A would like to\nhave the traffic destined to W to come from B only, and the traffic\ndestined to V from either B or C. How should A advertise its routes to\nB and C? What AS routes does C receive? P20. Suppose ASs X and Z are not directly connected but instead are\nconnected by AS Y. Further suppose that X has a peering agreement\nwith Y, and that Y has a peering agreement with Z. Finally, suppose\nthat Z wants to transit all of Y’s traffic but does not want to transit X’s\ntraffic. Does BGP allow Z to ­implement this policy? P21. Consider the two ways in which communication occurs between a\nmanaging entity and a managed device: request-response mode and\ntrapping. What are the pros and cons of these two approaches, in\nterms of (1) overhead, (2) notification time when exceptional events\noccur, and (3) robustness with respect to lost messages between the\nmanaging entity and the device?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 764,
    "text": "P22. In Section 5.7, we saw that it was preferable to transport SNMP\nmessages in unreliable UDP datagrams. Why do you think the\ndesigners of SNMP chose UDP rather than TCP as the transport\nprotocol of choice for SNMP?"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 766,
    "text": "Programming Assignment: Routing\nIn this programming assignment, you will be writing a “distributed” set of\nprocedures that implements a distributed asynchronous distance-vector\nrouting for the network shown below. You are to write the following routines that will “execute”\nasynchronously within the emulated environment provided for this\nassignment. For node 0, you will write the routines:\n•\nrtinit0(). This routine will be called once at the beginning of the\nemulation. rtinit0() has no arguments. It should initialize your distance\ntable in node 0 to reflect the direct costs of 1, 3, and 7 to nodes 1, 2, and\n3, respectively. In the figure above, all links are bidirectional and the\ncosts in both directions are identical. After initializing the distance table\nand any other data structures needed by your node 0 routines, it should\nthen send its directly connected neighbors (in this case, 1, 2, and 3) the\ncost of its minimum-cost paths to all other network nodes. This\nminimum-cost information is sent to neighboring nodes in a routing\nupdate packet by calling the routine tolayer2(), as described in the full\nassignment. The format of the routing update packet is also described in\nthe full assignment."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 769,
    "text": "AN INTERVIEW WITH…\nJennifer Rexford\nJennifer Rexford is a Professor in the Computer Science\ndepartment at Princeton University. Her research has the\nbroad goal of making computer networks easier to design and\nmanage, with particular emphasis on programmable neworks. From 1996–2004, she was a member of the Network\nManagement and Performance department at AT&T Labs–\nResearch. While at AT&T, she designed techniques and tools\nfor network measurement, traffic engineering, and router\nconfiguration that were deployed in AT&T’s backbone\nnetwork. Jennifer is co-author of the book “Web Protocols\nand Practice: Networking Protocols, Caching, and Traffic\nMeasurement,” published by Addison-Wesley in May 2001. She served as the chair of ACM SIGCOMM from 2003 to\n2007. She received her BSE degree in electrical engineering\nfrom Princeton University in 1991, and her PhD degree in\nelectrical engineering and computer science from the\nUniversity of Michigan in 1996. Jennifer was the 2004 winner\nof ACM’s Grace Murray Hopper Award for outstanding young\ncomputer professional, the ACM Athena Lecturer Award\n(2016), the NCWIT Harrold and Notkin Research and\nGraduate Mentoring Award (2017), the ACM SIGCOMM"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 770,
    "text": "award for lifetime contributions (2018), and the IEEE Internet\nAward (2019). She is an ACM Fellow (2008), an IEEE Fellow\n(2018), and the National Academy of Engineering (2014). Courtesy of Jennifer Rexford\nPlease describe one or two of the most\nexciting projects you have worked on\nduring your career. What were the biggest\nchallenges? When I was a researcher at AT&T, a group of us\ndesigned a new way to manage routing in Internet\nService Provider backbone networks. Traditionally,\nnetwork operators configure each router\nindividually, and these routers run distributed\nprotocols to compute paths through the network. We believed that network management would be\nsimpler and more flexible if network operators\ncould exercise direct control over how routers\nforward traffic based on a network-wide view of"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 771,
    "text": "the topology and traffic. The Routing Control\nPlatform (RCP) we designed and built could\ncompute the routes for all of AT&T’s backbone on\na single commodity computer, and could control\nlegacy routers without modification. To me, this\nproject was exciting because we had a provocative\nidea, a working system, and ultimately a real\ndeployment in an operational network. Fast\nforward a few years, and software-defined\nnetworking (SDN) has become a mainstream\ntechnology, and standard protocols (like standard\nprotocols (like OpenFlow) and languages (like P4)\nhave made it much easier to tell the underlying\nswitches what to do. How do you think software-defined\nnetworking should evolve in the future? In a major break from the past, the software\ncontrolling network devices can be created by\nmany different programmers, not just at companies\nselling network equipment. Yet, unlike the\napplications running on a server or a smart phone,\nSDN applications must work together to handle the\nsame traffic. Network operators do not want to\nperform load balancing on some traffic and routing\non other traffic; instead, they want to perform load\nbalancing and routing, together, on the same\ntraffic. Future SDN platforms should offer good"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 772,
    "text": "programming abstractions for composing\nindependently written multiple applications\ntogether. More broadly, good programming\nabstractions can make it easier to create\napplications, without having to worry about low-\nlevel details like flow table entries, traffic counters,\nbit patterns in packet headers, and so on. Also,\nwhile an SDN controller is logically centralized,\nthe network still consists of a distributed collection\nof devices. Future programmable networks should\noffer good abstractions for updating a distributed\nset of devices, so network administrators can\nreason about what happens to packets in flight\nwhile the devices are updated. Programming\nabstractions for programmable network is an\nexciting area for interdisciplinary\nresearch between computer networking, distributed\nsystems, and programming languages, with a real\nchance for practical impact in the years ahead. Where do you see the future of networking\nand the Internet? Networking is an exciting field because the\napplications and the underlying technologies\nchange all the time. We are always reinventing\nourselves! Who would have predicted even ten\nyears ago the dominance of smart phones, allowing\nmobile users to access existing applications as well"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 773,
    "text": "as new location-based services? The emergence of\ncloud computing is fundamentally changing the\nrelationship between users and the applications\nthey run, and networked sensors and actuators (the\n“Internet of Things”) are enabling a wealth of new\napplications (and security vulnerabilities!). The\npace of innovation is truly inspiring. The underlying network is a crucial\ncomponent in all of these innovations. Yet, the\nnetwork is notoriously “in the way”—limiting\nperformance, compromising reliability,\nconstraining applications, and complicating the\ndeployment and management of services. We\nshould strive to make the network of the future as\ninvisible as the air we breathe, so it never stands in\nthe way of new ideas and valuable services. To do\nthis, we need to raise the level of abstraction above\nindividual network devices and protocols (and\ntheir attendant acronyms! ), so we can reason about\nthe network and the user’s high-level goals as a\nwhole. What people inspired you professionally? I’ve long been inspired by Sally Floyd who\nworked for many years at the International\nComputer Science Institute. Her research was\nalways purposeful, focusing on the important\nchallenges facing the Internet. She dug deeply into"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 774,
    "text": "hard questions until she understood the problem\nand the space of solutions completely, and she\ndevoted serious energy into “making things\nhappen,” such as pushing her ideas into protocol\nstandards and network equipment. Also, she gave\nback to the community, through professional\nservice in numerous standards and research\norganizations and by creating tools (such as the\nwidely used ns-2 and ns-3 simulators) that enable\nother researchers to succeed. She retired in 2009,\nand passed away in 2019, but her influence on the\nfield will be felt for years to come. What are your recommendations for\nstudents who want careers in computer\nscience and networking? Networking is an inherently interdisciplinary field. Applying techniques from other discipline’s\nbreakthroughs in networking come from such\ndiverse areas as queuing theory, game theory,\ncontrol theory, distributed systems, network\noptimization, programming languages, machine\nlearning, algorithms, data structures, and so on. I\nthink that becoming conversant in a related field,\nor collaborating closely with experts in those\nfields, is a wonderful way to put networking on a\nstronger foundation, so we can learn how to build\nnetworks that are worthy of society’s trust. Beyond"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 775,
    "text": "the theoretical disciplines, networking is exciting\nbecause we create real artifacts that real people\nuse. Mastering how to design and build systems—\nby gaining experience in operating systems,\ncomputer architecture, and so on—is another\nfantastic way to amplify your knowledge of\nnetworking to help make the world a better place."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 776,
    "text": "The Link Layer and\nLANs\nIn the previous two chapters, we learned that the network layer\nprovides a communication service between any two network hosts. Between the two hosts, datagrams travel over a series of\ncommunication links, some wired and some wireless, starting at the\nsource host, passing through a series of packet switches (switches and\nrouters) and ending at the destination host. As we continue down the\nprotocol stack, from the network layer to the link layer, we naturally\nwonder how packets are sent across the individual links that make up\nthe end-to-end communication path. How are the network-layer\ndatagrams encapsulated in the link-layer frames for transmission over\na single link? Are different link-layer protocols used in the different\nlinks along the communication path? How are transmission conflicts in\nbroadcast links resolved? Is there addressing at the link layer and, if\nso, how does the link-layer addressing operate with the network-layer\naddressing we learned about in Chapter 4? And what exactly is the\ndifference between a switch and a router? We’ll answer these and other\nimportant questions in this chapter. In discussing the link layer, we’ll see that there are two\nfundamentally ­different types of link-layer channels. The first type are\nbroadcast channels, which connect multiple hosts in wireless LANs, in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 777,
    "text": "satellite networks, and in hybrid fiber-coaxial cable (HFC) access\nnetworks. Since many hosts are connected to the same broadcast\ncommunication channel, a so-called medium access protocol is needed\nto coordinate frame transmission. In some cases, a central controller\nmay be used to coordinate transmissions; in other cases, the hosts\nthemselves coordinate transmissions. The second type of link-layer\nchannel is the point-to-point communication link, such as that often\nfound between two routers connected by a long-distance link, or\nbetween a user’s office computer and the nearby Ethernet switch to\nwhich it is connected. Coordinating access to a point-to-point link is\nsimpler; the reference material on this book’s Web site has a detailed\ndiscussion of the Point-to-Point Protocol (PPP), which is used in\nsettings ranging from dial-up service over a telephone line to high-\nspeed point-to-point frame transport over fiber-optic links. We’ll explore several important link-layer concepts and technologies in\nthis ­chapter. We’ll dive deeper into error detection and correction, a topic\nwe touched on briefly in Chapter 3. We’ll consider multiple access\nnetworks and switched LANs, including Ethernet—by far the most\nprevalent wired LAN technology. We’ll also look at virtual LANs, and data\ncenter networks. Although WiFi, and more generally wireless LANs, are\nlink-layer topics, we’ll postpone our study of these important topics until\nChapter 7."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 778,
    "text": "6.1 Introduction to the Link Layer\nLet’s begin with some important terminology. We’ll find it convenient in\nthis chapter to refer to any device that runs a link-layer (i.e., layer 2)\nprotocol as a node. Nodes include hosts, routers, switches, and WiFi access\npoints (discussed in Chapter 7). We will also refer to the communication\nchannels that connect adjacent nodes along the communication path as\nlinks. In order for a datagram to be transferred from source host to\ndestination host, it must be moved over each of the individual links in the\nend-to-end path. As an example, in the company network shown at the\nbottom of Figure 6.1, consider sending a datagram from one of the wireless\nhosts to one of the servers. This datagram will actually pass through six\nlinks: a WiFi link between sending host and WiFi access point, an Ethernet\nlink between the access point and a link-layer switch; a link between the\nlink-layer switch and the router, a link between the two routers; an Ethernet\nlink between the router and a link-layer switch; and finally an Ethernet link\nbetween the switch and the server. Over a given link, a transmitting node\nencapsulates the datagram in a link-layer frame and transmits the frame\ninto the link."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 779,
    "text": "Figure 6.1 ♦Six link-layer hops between wireless host and server\nIn order to gain further insight into the link layer and how it relates to\nthe ­network layer, let’s consider a transportation analogy. Consider a travel"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 780,
    "text": "agent who is planning a trip for a tourist traveling from Princeton, New\nJersey, to Lausanne, Switzerland. The travel agent decides that it is most\nconvenient for the tourist to take a limousine from Princeton to JFK airport,\nthen a plane from JFK airport to Geneva’s airport, and finally a train from\nGeneva’s airport to Lausanne’s train station. Once the travel agent makes\nthe three reservations, it is the responsibility of the Princeton limousine\ncompany to get the tourist from Princeton to JFK; it is the responsibility of\nthe airline company to get the tourist from JFK to Geneva; and it is the\nresponsibility of the Swiss train service to get the tourist from Geneva to\nLausanne. Each of the three segments of the trip is “direct” between two\n“adjacent” locations. Note that the three transportation segments are\nmanaged by different companies and use entirely different transportation\nmodes (limousine, plane, and train). Although the transportation modes are\ndifferent, they each provide the basic service of moving passengers from\none location to an adjacent location. In this transportation analogy, the\ntourist is a datagram, each transportation segment is a link, the\ntransportation mode is a link-layer protocol, and the travel agent is a routing\nprotocol. 6.1.1 The Services Provided by the Link Layer\nAlthough the basic service of any link layer is to move a datagram from one\nnode to an adjacent node over a single communication link, the details of\nthe provided service can vary from one link-layer protocol to the next. Possible services that can be offered by a link-layer protocol include:\n•\nFraming. Almost all link-layer protocols encapsulate each network-\nlayer datagram within a link-layer frame before transmission over the\nlink. A frame consists of a data field, in which the network-layer"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 781,
    "text": "datagram is inserted, and a number of header fields. The structure of the\nframe is specified by the link-layer protocol. We’ll see several different\nframe formats when we examine specific link-layer protocols in the\nsecond half of this chapter. •\nLink access. A medium access control (MAC) protocol specifies the\nrules by which a frame is transmitted onto the link. For point-to-point\nlinks that have a single sender at one end of the link and a single\nreceiver at the other end of the link, the MAC protocol is simple (or\nnonexistent)—the sender can send a frame whenever the link is idle. The more interesting case is when multiple nodes share a single\nbroadcast link—the so-called multiple access problem. Here, the MAC\nprotocol serves to coordinate the frame transmissions of the many\nnodes. •\nReliable delivery. When a link-layer protocol provides reliable delivery\nservice, it guarantees to move each network-layer datagram across the\nlink without error. Recall that certain transport-layer protocols (such as\nTCP) also provide a reliable delivery service. Similar to a transport-\nlayer reliable delivery service, a link-layer reliable delivery service can\nbe achieved with acknowledgments and retransmissions (see Section\n3.4). A link-layer reliable delivery service is often used for links that are\nprone to high error rates, such as a wireless link, with the goal of\ncorrecting an error locally—on the link where the error occurs—rather\nthan forcing an end-to-end retransmission of the data by a transport- or\napplication-layer protocol. However, link-layer reliable delivery can be\nconsidered an unnecessary overhead for low bit-error links, including\nfiber, coax, and many twisted-pair copper links. For this reason, many\nwired link-layer protocols do not provide a reliable delivery service."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 782,
    "text": "•\nError detection and correction. The link-layer hardware in a receiving\nnode can incorrectly decide that a bit in a frame is zero when it was\ntransmitted as a one, and vice versa. Such bit errors are introduced by\nsignal attenuation and electromagnetic noise. Because there is no need\nto forward a datagram that has an error, many link-layer protocols\nprovide a mechanism to detect such bit errors. This is done by having\nthe transmitting node include error-detection bits in the frame, and\nhaving the receiving node perform an error check. Recall from Chapters\n3 and 4 that the Internet’s transport layer and network layer also provide\na limited form of error detection—the Internet checksum. Error\ndetection in the link layer is usually more sophisticated and is\nimplemented in hardware. Error correction is similar to error detection,\nexcept that a receiver not only detects when bit errors have occurred in\nthe frame but also determines exactly where in the frame the errors have\noccurred (and then corrects these errors). 6.1.2 Where Is the Link Layer Implemented? Before diving into our detailed study of the link layer, let’s conclude this\nintroduction by considering the question of where the link layer is\nimplemented. Is a host’s link layer implemented in hardware or software? Is\nit implemented on a separate card or chip, and how does it interface with\nthe rest of a host’s hardware and operating system components? Figure 6.2 shows a typical host architecture. The Ethernet capabilities\nare either integrated into the motherboard chipset or implemented via a low-\ncost dedicated Ethernet chip. For the most part, the link layer is\nimplemented on a chip called the network adapter, also sometimes known\nas a network interface controller (NIC). The network adapter implements"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 783,
    "text": "many link layer services including framing, link access, error detection, and\nso on. Thus, much of a link-layer controller’s functionality is implemented\nin hardware. For example, Intel’s 700 series adapters [Intel 2020]\nimplements the Ethernet protocols we’ll study in Section 6.5; the Atheros\nAR5006 [Atheros 2020] controller implements the 802.11 WiFi protocols\nwe’ll study in Chapter 7. Figure 6.2 ♦Network adapter: Its relationship to other host\ncomponents and to protocol stack functionality\nOn the sending side, the controller takes a datagram that has been\ncreated and stored in host memory by the higher layers of the protocol"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 784,
    "text": "stack, encapsulates the datagram in a link-layer frame (filling in the frame’s\nvarious fields), and then transmits the frame into the communication link,\nfollowing the link-access protocol. On the receiving side, a controller\nreceives the entire frame, and extracts the network-layer datagram. If the\nlink layer performs error detection, then it is the sending controller that sets\nthe error-detection bits in the frame header and it is the receiving controller\nthat performs error detection. Figure 6.2 shows that while most of the link layer is implemented in\nhardware, part of the link layer is implemented in software that runs on the\nhost’s CPU. The software components of the link layer implement higher-\nlevel link-layer functionality such as assembling link-layer addressing\ninformation and activating the controller hardware. On the receiving side,\nlink-layer software responds to controller interrupts (for example, due to the\nreceipt of one or more frames), handling error conditions and passing a\ndatagram up to the network layer. Thus, the link layer is a combination of\nhardware and software—the place in the protocol stack where software\nmeets hardware. [Intel 2020] provides a readable overview (as well as a\ndetailed description) of the XL710 controller from a software-programming\npoint of view."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 785,
    "text": "6.2 Error-Detection and -Correction Techniques\nIn the previous section, we noted that bit-level error detection and\ncorrection—detecting and correcting the corruption of bits in a link-layer\nframe sent from one node to another physically connected neighboring node\n—are two services often ­provided by the link layer. We saw in Chapter 3\nthat error-detection and -correction services are also often offered at the\ntransport layer as well. In this section, we’ll examine a few of the simplest\ntechniques that can be used to detect and, in some cases, correct such bit\nerrors. A full treatment of the theory and implementation of this topic is\nitself the topic of many textbooks (e.g., [Schwartz 1980] or [Bertsekas\n1991]), and our treatment here is necessarily brief. Our goal here is to\ndevelop an intuitive feel for the capabilities that error-detection and -\ncorrection techniques provide and to see how a few simple techniques work\nand are used in practice in the link layer. Figure 6.3 illustrates the setting for our study. At the sending node,\ndata, D, to be protected against bit errors is augmented with error-detection\nand -correction bits (EDC). Typically, the data to be protected includes not\nonly the datagram passed down from the network layer for transmission\nacross the link, but also link-level addressing information, sequence\nnumbers, and other fields in the link frame header. Both D and EDC are\nsent to the receiving node in a link-level frame. At the receiving node, a\nsequence of bits, D' and EDC' is received. Note that D' and EDC' may differ\nfrom the original D and EDC as a result of in-transit bit flips."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 786,
    "text": "Figure 6.3 ♦Error-detection and -correction scenario\nThe receiver’s challenge is to determine whether or not D' is the same\nas the original D, given that it has only received D' and EDC'. The exact\nwording of the receiver’s decision in Figure 6.3 (we ask whether an error is\ndetected, not whether an error has occurred!) is important. Error-detection\nand -correction techniques allow the receiver to sometimes, but not always,\ndetect that bit errors have occurred. Even with the use of error-detection bits\nthere still may be undetected bit errors; that is, the receiver may be\nunaware that the received information contains bit errors. As a\nconsequence, the receiver might deliver a corrupted datagram to the\nnetwork layer, or be unaware that the contents of a field in the frame’s\nheader has been corrupted. We thus want to choose an error-detection\nscheme that keeps the probability of such occurrences small. Generally,\nmore sophisticated error-detection and -correction techniques (that is, those"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 787,
    "text": "that have a smaller probability of allowing undetected bit errors) incur a\nlarger overhead—more computation is needed to compute and transmit a\nlarger number of error-detection and -correction bits. Let’s now examine three techniques for detecting errors in the\ntransmitted data—parity checks (to illustrate the basic ideas behind error\ndetection and correction), checksumming methods (which are more\ntypically used in the transport layer), and cyclic redundancy checks (which\nare more typically used in the link layer in an adapter). 6.2.1 Parity Checks\nPerhaps the simplest form of error detection is the use of a single parity bit. Suppose that the information to be sent, D in Figure 6.4, has d bits. In an\neven parity scheme, the sender simply includes one additional bit and\nchooses its value such that the total number of 1s in the d + 1 bits (the\noriginal information plus a parity bit) is even. For odd parity schemes, the\nparity bit value is chosen such that there is an odd number of 1s. Figure 6.4\nillustrates an even parity scheme, with the single parity bit being stored in a\nseparate field. Figure 6.4 ♦One-bit even parity"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 788,
    "text": "Receiver operation is also simple with a single parity bit. The receiver\nneed only count the number of 1s in the received d + 1 bits. If an odd\nnumber of 1-valued bits are found with an even parity scheme, the receiver\nknows that at least one bit error has occurred. More precisely, it knows that\nsome odd number of bit errors have occurred. But what happens if an even number of bit errors occur? You should\nconvince yourself that this would result in an undetected error. If the\nprobability of bit errors is small and errors can be assumed to occur\nindependently from one bit to the next, the probability of multiple bit errors\nin a packet would be extremely small. In this case, a single parity bit might\nsuffice. However, measurements have shown that, rather than occurring\nindependently, errors are often clustered together in “bursts.” Under burst\nerror conditions, the probability of undetected errors in a frame protected by\nsingle-bit parity can approach 50 percent [Spragins 1991]. Clearly, a more\nrobust error-detection scheme is needed (and, fortunately, is used in\npractice!). But before examining error-detection schemes that are used in\npractice, let’s consider a simple generalization of one-bit parity that will\nprovide us with insight into error-correction techniques. Figure 6.5 shows a two-dimensional generalization of the single-bit\nparity scheme. Here, the d bits in D are divided into i rows and j columns. A\nparity value is computed for each row and for each column. The resulting i\n+ j + 1 parity bits comprise the link-layer frame’s error-detection bits."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 789,
    "text": "Figure 6.5 ♦Two-dimensional even parity\nSuppose now that a single bit error occurs in the original d bits of\ninformation. With this two-dimensional parity scheme, the parity of both\nthe column and the row containing the flipped bit will be in error. The\nreceiver can thus not only detect the fact that a single bit error has occurred,\nbut can use the column and row indices of the column and row with parity\nerrors to actually identify the bit that was corrupted and correct that error!"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 790,
    "text": "Figure 6.5 shows an example in which the 1-valued bit in position (2,2) is\ncorrupted and switched to a 0—an error that is both detectable and\ncorrectable at the receiver. Although our discussion has focused on the\noriginal d bits of information, a single error in the parity bits themselves is\nalso detectable and correctable. Two-dimensional parity can also detect (but\nnot correct!) any combination of two errors in a packet. Other properties of\nthe two-dimensional parity scheme are explored in the problems at the end\nof the chapter. The ability of the receiver to both detect and correct errors is known as\nforward error correction (FEC). These techniques are commonly used in\naudio storage and playback devices such as audio CDs. In a network\nsetting, FEC techniques can be used by themselves, or in conjunction with\nlink-layer ARQ techniques similar to those we examined in Chapter 3. FEC\ntechniques are valuable because they can decrease the number of sender\nretransmissions required. Perhaps more important, they allow for immediate\ncorrection of errors at the receiver. This avoids having to wait for the round-\ntrip propagation delay needed for the sender to receive a NAK packet and\nfor the retransmitted packet to propagate back to the receiver—a potentially\nimportant advantage for real-time network applications [Rubenstein 1998]\nor links (such as deep-space links) with long propagation delays. Research\nexamining the use of FEC in error-control protocols includes [Biersack\n1992; Nonnenmacher 1998; Byers 1998; Shacham 1990]. 6.2.2 Checksumming Methods\nIn checksumming techniques, the d bits of data in Figure 6.4 are treated as a\nsequence of k-bit integers. One simple checksumming method is to simply\nsum these k-bit integers and use the resulting sum as the error-detection"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 791,
    "text": "bits. The Internet checksum is based on this approach—bytes of data are\ntreated as 16-bit integers and summed. The 1s complement of this sum then\nforms the Internet checksum that is carried in the segment header. As\ndiscussed in Section 3.3, the receiver checks the checksum by taking the 1s\ncomplement of the sum of the received data (including the checksum) and\nchecking whether the result is all 0 bits. If any of the bits are 1, an error is\nindicated. RFC 1071 discusses the Internet checksum algorithm and its\nimplementation in detail. In the TCP and UDP protocols, the Internet\nchecksum is computed over all fields (header and data fields included). In\nIP, the checksum is computed over the IP header (since the UDP or TCP\nsegment has its own checksum). In other protocols, for example, XTP\n[Strayer 1992], one checksum is computed over the header and another\nchecksum is computed over the entire packet. Checksumming methods require relatively little packet overhead. For\nexample, the checksums in TCP and UDP use only 16 bits. However, they\nprovide relatively weak protection against errors as compared with cyclic\nredundancy check, which is discussed below and which is often used in the\nlink layer. A natural question at this point is, Why is checksumming used at\nthe transport layer and cyclic redundancy check used at the link layer? Recall that the transport layer is typically implemented in software in a host\nas part of the host’s operating system. Because transport-layer error\ndetection is implemented in software, it is important to have a simple and\nfast error-detection scheme such as checksumming. On the other hand, error\ndetection at the link layer is implemented in dedicated hardware in adapters,\nwhich can rapidly perform the more complex CRC operations. Feldmeier\n[Feldmeier 1995] presents fast software implementation techniques for not\nonly weighted checksum codes, but CRC (see below) and other codes as\nwell."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 792,
    "text": "6.2.3 Cyclic Redundancy Check (CRC)\nAn error-detection technique used widely in today’s computer networks is\nbased on cyclic redundancy check (CRC) codes. CRC codes are also\nknown as polynomial codes, since it is possible to view the bit string to be\nsent as a polynomial whose coefficients are the 0 and 1 values in the bit\nstring, with operations on the bit string interpreted as polynomial\narithmetic. CRC codes operate as follows. Consider the d-bit piece of data, D, that\nthe sending node wants to send to the receiving node. The sender and\nreceiver must first agree on an r + 1 bit pattern, known as a generator,\nwhich we will denote as G. We will require that the most significant\n(leftmost) bit of G be a 1. The key idea behind CRC codes is shown in\nFigure 6.6. For a given piece of data, D, the sender will choose r additional\nbits, R, and append them to D such that the resulting d + r bit pattern\n(interpreted as a binary number) is exactly divisible by G (i.e., has no\nremainder) using modulo-2 arithmetic. The process of error checking with\nCRCs is thus simple: The receiver divides the d + r received bits by G. If\nthe remainder is nonzero, the receiver knows that an error has occurred;\notherwise the data is accepted as being correct. All CRC calculations are done in modulo-2 arithmetic without carries\nin addition or borrows in subtraction. This means that addition and\nsubtraction are identical, and both are equivalent to the bitwise exclusive-or\n(XOR) of the operands. Thus, for example,\n1011 XOR 0101 = 1110\n1001 XOR 1101 = 0100\nAlso, we similarly have"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 793,
    "text": "1011 − 0101 = 1110\n1001 − 1101 = 0100\nMultiplication and division are the same as in base-2 arithmetic, except that\nany required addition or subtraction is done without carries or borrows. As\nin regular binary arithmetic, multiplication by 2  left shifts a bit pattern by k\nplaces. Thus, given D and R, the quantity D · 2  XOR R yields the d + r bit\npattern shown in Figure 6.6. We’ll use this algebraic characterization of the\nd + r bit pattern from Figure 6.6 in our discussion below. Figure 6.6 ♦CRC\nLet us now turn to the crucial question of how the sender computes R.\nRecall that we want to find R such that there is an n such that\nD ⋅2r XOR R = nG\nThat is, we want to choose R such that G divides into D · 2  XOR R\nwithout remainder. If we XOR (that is, add modulo-2, without carry) R to\nboth sides of the above equation, we get\nD ⋅2r = nG XOR R\nk\nr\nr"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 794,
    "text": "This equation tells us that if we divide D · 2  by G, the value of the\nremainder is precisely R. In other words, we can calculate R as\nR = remainder D⋅2r\nG\nFigure 6.7 illustrates this calculation for the case of D = 101110, d = 6,\nG = 1001, and r = 3. The 9 bits transmitted in this case are 101 110 011. You should check these calculations for yourself and also check that indeed\nD · 2  = 101011 · G XOR R.\nFigure 6.7 ♦A sample CRC calculation\nInternational standards have been defined for 8-, 12-, 16-, and 32-bit\ngenerators, G. The CRC-32 32-bit standard, which has been adopted in a\nnumber of link-level IEEE protocols, uses a generator of\nGCRC-32 = 100000100110000010001110110110111\nr\nr"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 795,
    "text": "Each of the CRC standards can detect burst errors of fewer than r + 1\nbits. (This means that all consecutive bit errors of r bits or fewer will be\ndetected.) Furthermore, under appropriate assumptions, a burst of length\ngreater than r + 1 bits is detected with probability 1 − 0.5 . Also, each of the\nCRC standards can detect any odd number of bit errors. See [Williams\n1993] for a discussion of implementing CRC checks. The theory behind\nCRC codes and even more powerful codes is beyond the scope of this text. The text [Schwartz 1980] provides an excellent introduction to this topic. r"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 796,
    "text": "6.3 Multiple Access Links and Protocols\nIn the introduction to this chapter, we noted that there are two types of\nnetwork links: point-to-point links and broadcast links. A point-to-point\nlink consists of a single sender at one end of the link and a single receiver\nat the other end of the link. Many link-layer protocols have been designed\nfor point-to-point links; the point-to-point protocol (PPP) and high-level\ndata link control (HDLC) are two such protocols. The second type of link, a\nbroadcast link, can have multiple sending and receiving nodes all\nconnected to the same, single, shared broadcast channel. The term\nbroadcast is used here because when any one node transmits a frame, the\nchannel broadcasts the frame and each of the other nodes receives a copy. Ethernet and wireless LANs are examples of broadcast link-layer\ntechnologies. In this section, we’ll take a step back from specific link-layer\nprotocols and first examine a problem of central importance to the link\nlayer: how to coordinate the access of multiple sending and receiving nodes\nto a shared broadcast channel—the multiple access problem. Broadcast\nchannels are often used in LANs, networks that are geographically\nconcentrated in a single building (or on a corporate or university campus). Thus, we’ll look at how multiple access channels are used in LANs at the\nend of this section. We are all familiar with the notion of broadcasting—television has been\nusing it since its invention. But traditional television is a one-way broadcast\n(that is, one fixed node transmitting to many receiving nodes), while nodes\non a computer network broadcast channel can both send and receive. Perhaps a more apt human analogy for a broadcast channel is a cocktail\nparty, where many people gather in a large room (the air providing the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 797,
    "text": "broadcast medium) to talk and listen. A second good analogy is something\nmany readers will be familiar with—a classroom—where teacher(s) and\nstudent(s) similarly share the same, single, broadcast medium. A central\nproblem in both scenarios is that of determining who gets to talk (that is,\ntransmit into the channel) and when. As humans, we’ve evolved an\nelaborate set of protocols for sharing the broadcast channel:\n“Give everyone a chance to speak.”\n“Don’t speak until you are spoken to.”\n“Don’t monopolize the conversation.”\n“Raise your hand if you have a question.”\n“Don’t interrupt when someone is speaking.”\n“Don’t fall asleep when someone is talking.”\nComputer networks similarly have protocols—so-called multiple\naccess ­protocols—by which nodes regulate their transmission into the\nshared broadcast channel. As shown in Figure 6.8, multiple access protocols\nare needed in a wide variety of network settings, including both wired and\nwireless access networks, and satellite networks. Although technically each\nnode accesses the broadcast channel through its adapter, in this section, we\nwill refer to the node as the sending and receiving device. In practice,\nhundreds or even thousands of nodes can directly communicate over a\nbroadcast channel."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 798,
    "text": "Figure 6.8 ♦Various multiple access channels\nBecause all nodes are capable of transmitting frames, more than two\nnodes can transmit frames at the same time. When this happens, all of the\nnodes receive multiple frames at the same time; that is, the transmitted\nframes collide at all of the receivers. Typically, when there is a collision,\nnone of the receiving nodes can make any sense of any of the frames that\nwere transmitted; in a sense, the signals of the colliding frames become\ninextricably tangled together. Thus, all the frames involved in the collision\nare lost, and the broadcast channel is wasted during the collision interval. Clearly, if many nodes want to transmit frames frequently, many"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 799,
    "text": "transmissions will result in collisions, and much of the bandwidth of the\nbroadcast channel will be wasted. In order to ensure that the broadcast channel performs useful work\nwhen multiple nodes are active, it is necessary to somehow coordinate the\ntransmissions of the active nodes. This coordination job is the responsibility\nof the multiple access protocol. Over the past 40 years, thousands of papers\nand hundreds of PhD dissertations have been written on multiple access\nprotocols; a comprehensive survey of the first 20 years of this body of work\nis [Rom 1990]. Furthermore, active research in multiple access protocols\ncontinues due to the continued emergence of new types of links, particularly\nnew wireless links. Over the years, dozens of multiple access protocols have been\nimplemented in a variety of link-layer technologies. Nevertheless, we can\nclassify just about any multiple access protocol as belonging to one of three\ncategories: channel partitioning protocols, random access protocols, and\ntaking-turns protocols. We’ll cover these categories of multiple access\nprotocols in the following three subsections. Let’s conclude this overview by noting that, ideally, a multiple access\nprotocol for a broadcast channel of rate R bits per second should have the\nfollowing desirable characteristics:\n1. When only one node has data to send, that node has a throughput of R\nbps. 2. When M nodes have data to send, each of these nodes has a throughput\nof R/M bps. This need not necessarily imply that each of the M nodes\nalways has an instantaneous rate of R/M, but rather that each node\nshould have an average transmission rate of R/M over some suitably\ndefined interval of time."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 800,
    "text": "3. The protocol is decentralized; that is, there is no master node that\nrepresents a single point of failure for the network. 4. The protocol is simple, so that it is inexpensive to implement. 6.3.1 Channel Partitioning Protocols\nRecall from our early discussion back in Section 1.3 that time-division ­-\nmultiplexing (TDM) and frequency-division multiplexing (FDM) are two\ntechniques that can be used to partition a broadcast channel’s bandwidth\namong all nodes sharing that channel. As an example, suppose the channel\nsupports N nodes and that the transmission rate of the channel is R bps. TDM divides time into time frames and further divides each time frame\ninto N time slots. (The TDM time frame should not be confused with the\nlink-layer unit of data exchanged between sending and receiving adapters,\nwhich is also called a frame. In order to reduce confusion, in this subsection\nwe’ll refer to the link-layer unit of data exchanged as a packet.) Each time\nslot is then assigned to one of the N nodes. Whenever a node has a packet to\nsend, it transmits the packet’s bits during its assigned time slot in the\nrevolving TDM frame. Typically, slot sizes are chosen so that a single\npacket can be transmitted during a slot time. Figure 6.9 shows a simple\nfour-node TDM example. Returning to our cocktail party analogy, a TDM-\nregulated cocktail party would allow one partygoer to speak for a fixed\nperiod of time, then allow another partygoer to speak for the same amount\nof time, and so on. Once everyone had had a chance to talk, the ­pattern\nwould repeat."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 801,
    "text": "Figure 6.9 ♦A four-node TDM and FDM example\nTDM is appealing because it eliminates collisions and is perfectly fair:\nEach node gets a dedicated transmission rate of R/N bps during each frame\ntime. However, it has two major drawbacks. First, a node is limited to an\naverage rate of R/N bps even when it is the only node with packets to send. A second drawback is that a node must always wait for its turn in the\ntransmission sequence—again, even when it is the only node with a frame\nto send. Imagine the partygoer who is the only one with anything to say\n(and imagine that this is the even rarer circumstance where everyone wants\nto hear what that one person has to say). Clearly, TDM would be a poor\nchoice for a multiple access protocol for this particular party. While TDM shares the broadcast channel in time, FDM divides the R\nbps channel into different frequencies (each with a bandwidth of R/N) and"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 802,
    "text": "assigns each frequency to one of the N nodes. FDM thus creates N smaller\nchannels of R/N bps out of the single, larger R bps channel. FDM shares\nboth the advantages and drawbacks of TDM. It avoids collisions and\ndivides the bandwidth fairly among the N nodes. However, FDM also\nshares a principal disadvantage with TDM—a node is limited to a\nbandwidth of R/N, even when it is the only node with packets to send. A third channel partitioning protocol is code division multiple access\n(CDMA). While TDM and FDM assign time slots and frequencies,\nrespectively, to the nodes, CDMA assigns a different code to each node. Each node then uses its unique code to encode the data bits it sends. If the\ncodes are chosen carefully, CDMA networks have the wonderful property\nthat different nodes can transmit simultaneously and yet have their\nrespective receivers correctly receive a sender’s encoded data bits\n(assuming the receiver knows the sender’s code) in spite of interfering\ntransmissions by other nodes. CDMA has been used in military systems for\nsome time (due to its anti-jamming properties) and now has widespread\ncivilian use, particularly in cellular telephony. Because CDMA’s use is so\ntightly tied to wireless channels, we’ll save our discussion of the technical\ndetails of CDMA until Chapter 7. For now, it will suffice to know that\nCDMA codes, like time slots in TDM and frequencies in FDM, can be\nallocated to the multiple access channel users. 6.3.2 Random Access Protocols\nThe second broad class of multiple access protocols are random access\nprotocols. In a random access protocol, a transmitting node always\ntransmits at the full rate of the channel, namely, R bps. When there is a\ncollision, each node involved in the collision repeatedly retransmits its"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 803,
    "text": "frame (that is, packet) until its frame gets through without a collision. But\nwhen a node experiences a collision, it doesn’t necessarily retransmit the\nframe right away. Instead it waits a random delay before retransmitting the\nframe. Each node involved in a collision chooses independent random\ndelays. Because the random delays are independently chosen, it is possible\nthat one of the nodes will pick a delay that is sufficiently less than the\ndelays of the other colliding nodes and will therefore be able to sneak its\nframe into the channel without a collision. There are dozens if not hundreds of random access protocols described\nin the literature [Rom 1990; Bertsekas 1991]. In this section we’ll describe\na few of the most commonly used random access protocols—the ALOHA\nprotocols [Abramson 1970; Abramson 1985; Abramson 2009] and the\ncarrier sense multiple access (CSMA) protocols [Kleinrock 1975b]. Ethernet [Metcalfe 1976] is a popular and widely deployed CSMA protocol. Slotted ALOHA\nLet’s begin our study of random access protocols with one of the simplest\nrandom access protocols, the slotted ALOHA protocol. In our description of\nslotted ALOHA, we assume the following:\n•\nAll frames consist of exactly L bits. •\nTime is divided into slots of size L/R seconds (that is, a slot equals the\ntime to transmit one frame). •\nNodes start to transmit frames only at the beginnings of slots. •\nThe nodes are synchronized so that each node knows when the slots\nbegin. •\nIf two or more frames collide in a slot, then all the nodes detect the\ncollision event before the slot ends."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 804,
    "text": "Let p be a probability, that is, a number between 0 and 1. The operation of\nslotted ALOHA in each node is simple:\n•\nWhen the node has a fresh frame to send, it waits until the beginning of\nthe next slot and transmits the entire frame in the slot. •\nIf there isn’t a collision, the node has successfully transmitted its frame\nand thus need not consider retransmitting the frame. (The node can\nprepare a new frame for transmission, if it has one.) •\nIf there is a collision, the node detects the collision before the end of the\nslot. The node retransmits its frame in each subsequent slot with\nprobability p until the frame is transmitted without a collision. By retransmitting with probability p, we mean that the node effectively\ntosses a biased coin; the event heads corresponds to “retransmit,” which\noccurs with probability p. The event tails corresponds to “skip the slot and\ntoss the coin again in the next slot”; this occurs with probability (1 − p). All\nnodes involved in the collision toss their coins independently. Slotted ALOHA would appear to have many advantages. Unlike\nchannel partitioning, slotted ALOHA allows a node to transmit\ncontinuously at the full rate, R, when that node is the only active node. (A\nnode is said to be active if it has frames to send.) Slotted ALOHA is also\nhighly \ndecentralized, \nbecause \neach \nnode \ndetects \ncollisions \nand\nindependently decides when to retransmit. (Slotted ALOHA does, however,\nrequire the slots to be synchronized in the nodes; shortly we’ll discuss an\nunslotted version of the ALOHA protocol, as well as CSMA protocols, none\nof which require such synchronization.) Slotted ALOHA is also an\nextremely simple protocol. Slotted ALOHA works well when there is only one active node, but\nhow ­efficient is it when there are multiple active nodes? There are two"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 805,
    "text": "possible efficiency concerns here. First, as shown in Figure 6.10, when\nthere are multiple active nodes, a certain fraction of the slots will have\ncollisions and will therefore be “wasted.” The second concern is that\nanother fraction of the slots will be empty because all active nodes refrain\nfrom transmitting as a result of the probabilistic transmission policy. The\nonly “unwasted” slots will be those in which exactly one node transmits. A\nslot in which exactly one node transmits is said to be a successful slot. The\nefficiency of a slotted multiple access protocol is defined to be the long-run\nfraction of successful slots in the case when there are a large number of\nactive nodes, each always having a large number of frames to send. Note\nthat if no form of access control were used, and each node were to\nimmediately retransmit after each collision, the efficiency would be zero. Slotted ALOHA clearly increases the efficiency beyond zero, but by how\nmuch? Figure 6.10 ♦Nodes 1, 2, and 3 collide in the first slot. Node 2\nfinally succeeds in the fourth slot, node 1 in the eighth"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 806,
    "text": "slot, and node 3 in the ninth slot\nWe now proceed to outline the derivation of the maximum efficiency of\nslotted ALOHA. To keep this derivation simple, let’s modify the protocol a\nlittle and assume that each node attempts to transmit a frame in each slot\nwith probability p. (That is, we assume that each node always has a frame\nto send and that the node transmits with probability p for a fresh frame as\nwell as for a frame that has already suffered a collision.) Suppose there are\nN nodes. Then the probability that a given slot is a successful slot is the\nprobability that one of the nodes transmits and that the remaining N − 1\nnodes do not transmit. The probability that a given node transmits is p; the\nprobability that the remaining nodes do not transmit is (1 − p)\n. Therefore,\nthe probability a given node has a success is p(1 − p)\n. Because there are\nN nodes, the probability that any one of the N nodes has a success is Np(1 −\np)\n. Thus, when there are N active nodes, the efficiency of slotted ALOHA\nis Np(1 − p)\n. To obtain the maximum efficiency for N active nodes, we\nhave to find the p* that maximizes this expression. (See the homework\nproblems for a general outline of this derivation.) And to obtain the\nmaximum efficiency for a large number of active nodes, we take the limit of\nNp*(1 − p*)\n as N approaches infinity. (Again, see the homework\nproblems.) After performing these calculations, we’ll find that the\nmaximum efficiency of the protocol is given by 1/e = 0.37. That is, when a\nlarge number of nodes have many frames to transmit, then (at best) only 37\npercent of the slots do useful work. Thus, the effective transmission rate of\nthe channel is not R bps but only 0.37 R bps! A similar analysis also shows\nthat 37 percent of the slots go empty and 26 percent of slots have collisions. Imagine the poor network administrator who has purchased a 100-Mbps\nN−1\nN−1\nN−1\nN−1\nN−1"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 807,
    "text": "slotted ALOHA system, expecting to be able to use the network to transmit\ndata among a large number of users at an aggregate rate of, say, 80 Mbps! Although the channel is capable of transmitting a given frame at the full\nchannel rate of 100 Mbps, in the long run, the successful throughput of this\nchannel will be less than 37 Mbps. ALOHA\nThe slotted ALOHA protocol required that all nodes synchronize their\ntransmissions to start at the beginning of a slot. The first ALOHA protocol\n[Abramson 1970] was actually an unslotted, fully decentralized protocol. In\npure ALOHA, when a frame first arrives (that is, a network-layer datagram\nis passed down from the network layer at the sending node), the node\nimmediately transmits the frame in its entirety into the broadcast channel. If\na transmitted frame experiences a collision with one or more other\ntransmissions, the node will then immediately (after completely\ntransmitting its collided frame) retransmit the frame with probability p.\nOtherwise, the node waits for a frame transmission time. After this wait, it\nthen transmits the frame with probability p, or waits (remaining idle) for\nanother frame time with probability 1 – p.\nTo determine the maximum efficiency of pure ALOHA, we focus on an\nindividual node. We’ll make the same assumptions as in our slotted\nALOHA analysis and take the frame transmission time to be the unit of\ntime. At any given time, the probability that a node is transmitting a frame\nis p. Suppose this frame begins transmission at time t . As shown in Figure\n6.11, in order for this frame to be successfully transmitted, no other nodes\ncan begin their transmission in the interval of time [t  − 1, t ]. Such a\ntransmission would overlap with the beginning of the transmission of node\ni’s frame. The probability that all other nodes do not begin a transmission in\n0"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 808,
    "text": "this interval is (1 − p)\n. Similarly, no other node can begin a transmission\nwhile node i is transmitting, as such a transmission would overlap with the\nlatter part of node i’s transmission. The probability that all other nodes do\nnot begin a transmission in this interval is also (1 − p)\n. Thus, the\nprobability that a given node has a successful transmission is p(1 − p)\n. By taking limits as in the slotted ALOHA case, we find that the maximum\nefficiency of the pure ALOHA protocol is only 1/(2e)—exactly half that of\nslotted ALOHA. This then is the price to be paid for a fully decentralized\nALOHA protocol. Figure 6.11 ♦Interfering transmissions in pure ALOHA\nCarrier Sense Multiple Access (CSMA)\nIn both slotted and pure ALOHA, a node’s decision to transmit is made\nindependently of the activity of the other nodes attached to the broadcast\nchannel. In particular, a node neither pays attention to whether another node\nhappens to be transmitting when it begins to transmit, nor stops transmitting\nif another node begins to interfere with its transmission. In our cocktail\nN−1\nN−1\n2(N−1)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 809,
    "text": "party analogy, ALOHA protocols are quite like a boorish partygoer who\ncontinues to chatter away regardless of whether other people are talking. As\nhumans, we have human protocols that allow us not only to behave with\nmore civility, but also to decrease the amount of time spent “colliding” with\neach other in conversation and, consequently, to increase the amount of data\nwe exchange in our conversations. Specifically, there are two important\nrules for polite human conversation:\n•\nListen before speaking. If someone else is speaking, wait until they are\nfinished. In the networking world, this is called carrier sensing—a\nnode listens to the channel before transmitting. If a frame from another\nnode is currently being transmitted into the channel, a node then waits\nuntil it detects no transmissions for a short amount of time and then\nbegins transmission. •\nIf someone else begins talking at the same time, stop talking. In the\nnetworking world, this is called collision detection—a transmitting\nnode listens to the channel while it is transmitting. If it detects that\nanother node is transmitting an interfering frame, it stops transmitting\nand waits a random amount of time before repeating the sense-and-\ntransmit-when-idle cycle. These two rules are embodied in the family of carrier sense multiple\naccess (CSMA) and CSMA with collision detection (CSMA/CD)\nprotocols [Kleinrock 1975b; Metcalfe 1976; Lam 1980; Rom 1990]. Many\nvariations on CSMA and CSMA/CD have been proposed. Here, we’ll\nconsider a few of the most important, and fundamental, characteristics of\nCSMA and CSMA/CD. CASE HISTORY"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 810,
    "text": "NORM ABRAMSON AND\nALOHANET\nNorm Abramson, a PhD engineer, had a passion for surfing and an interest in packet\nswitching. This combination of interests brought him to the University of Hawaii in\n1969. Hawaii consists of many mountainous islands, making it difficult to install and\noperate land-based networks. When not surfing, Abramson thought about how to\ndesign a network that does packet switching over radio. The network he designed had\none central host and several secondary nodes scattered over the Hawaiian Islands. The network had two channels, each using a different frequency band. The downlink\nchannel broadcasted packets from the central host to the secondary hosts; and the\nupstream channel sent packets from the secondary hosts to the central host. In\naddition to sending informational packets, the central host also sent on the downstream\nchannel an acknowledgment for each packet successfully received from the secondary\nhosts. Because the secondary hosts transmitted packets in a decentralized fashion, collisions\non the upstream channel inevitably occurred. This observation led Abramson to devise\nthe pure ALOHA protocol, as described in this chapter. In 1970, with continued funding\nfrom ARPA, Abramson connected his ALOHAnet to the ARPAnet. Abramson’s work is\nimportant not only because it was the first example of a radio packet network, but also\nbecause it inspired Bob Metcalfe. A few years later, Metcalfe modified the ALOHA\nprotocol to create the CSMA/CD protocol and the Ethernet LAN. The first question that you might ask about CSMA is why, if all nodes\nperform carrier sensing, do collisions occur in the first place? After all, a\nnode will refrain from transmitting whenever it senses that another node is\ntransmitting. The answer to the question can best be illustrated using space-\ntime diagrams [Molle 1987]. ­Figure 6.12 shows a space-time diagram of"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 811,
    "text": "four nodes (A, B, C, D) attached to a linear broadcast bus. The horizontal\naxis shows the position of each node in space; the vertical axis represents\ntime. At time t , node B senses the channel is idle, as no other nodes are\ncurrently transmitting. Node B thus begins transmitting, with its bits\npropagating in both directions along the broadcast medium. The downward\npropagation of B’s bits in Figure 6.12 with increasing time indicates that a\nnonzero amount of time is needed for B’s bits actually to propagate (albeit\nat near the speed of light) along the broadcast medium. At time t  (t  > t ),\nnode D has a frame to send. Although node B is currently transmitting at\ntime t , the bits being transmitted by B have yet to reach D, and thus D\nsenses the channel idle at t . In accordance with the CSMA protocol, D thus\nbegins transmitting its frame. A short time later, B’s transmission begins to\ninterfere with D’s transmission at D. From Figure 6.12, it is evident that the\nend-to-end channel propagation delay of a broadcast channel—the time it\ntakes for a signal to propagate from one of the nodes to another—will play\na crucial role in determining its performance. The longer this propagation\ndelay, the larger the chance that a carrier-sensing node is not yet able to\nsense a transmission that has already begun at another node in the network. 1\n0\n1"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 812,
    "text": "Figure 6.12 ♦Space-time diagram of two CSMA nodes with\ncolliding transmissions\nCarrier Sense Multiple Access with Collision Detection\n(CSMA/CD)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 813,
    "text": "In Figure 6.12, nodes do not perform collision detection; both B and D\ncontinue to transmit their frames in their entirety even though a collision\nhas occurred. When a node performs collision detection, it ceases\ntransmission as soon as it detects a collision. Figure 6.13 shows the same\nscenario as in Figure 6.12, except that the two nodes each abort their\ntransmission a short time after detecting a collision. Clearly, adding\ncollision detection to a multiple access protocol will help protocol\nperformance by not transmitting a useless, damaged (by interference with a\nframe from another node) frame in its entirety."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 814,
    "text": "Figure 6.13 ♦CSMA with collision detection\nBefore analyzing the CSMA/CD protocol, let us now summarize its\noperation from the perspective of an adapter (in a node) attached to a\nbroadcast channel:"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 815,
    "text": "1. The adapter obtains a datagram from the network layer, prepares a link-\nlayer frame, and puts the frame adapter buffer. 2. If the adapter senses that the channel is idle (that is, there is no signal\nenergy entering the adapter from the channel), it starts to transmit the\nframe. If, on the other hand, the adapter senses that the channel is busy,\nit waits until it senses no signal energy and then starts to transmit the\nframe. 3. While transmitting, the adapter monitors for the presence of signal\nenergy coming from other adapters using the broadcast channel. 4. If the adapter transmits the entire frame without detecting signal energy\nfrom other adapters, the adapter is finished with the frame. If, on the\nother hand, the adapter detects signal energy from other adapters while\ntransmitting, it aborts the transmission (that is, it stops transmitting its\nframe). 5. After aborting, the adapter waits a random amount of time and then\nreturns to step 2. The need to wait a random (rather than fixed) amount of time is hopefully\nclear—if two nodes transmitted frames at the same time and then both\nwaited the same fixed amount of time, they’d continue colliding forever. But what is a good interval of time from which to choose the random\nbackoff time? If the interval is large and the number of colliding nodes is\nsmall, nodes are likely to wait a large amount of time (with the channel\nremaining idle) before repeating the sense-and-transmit-when-idle step. On\nthe other hand, if the interval is small and the number of colliding nodes is\nlarge, it’s likely that the chosen random values will be nearly the same, and\ntransmitting nodes will again collide. What we’d like is an interval that is\nshort when the number of colliding nodes is small, and long when the\nnumber of colliding nodes is large."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 816,
    "text": "The binary exponential backoff algorithm, used in Ethernet as well as\nin DOCSIS cable network multiple access protocols [DOCSIS 3.1 2014],\nelegantly solves this problem. Specifically, when transmitting a frame that\nhas already experienced n collisions, a node chooses the value of K at\nrandom from {0,1,2, . . . . 2 −1}. Thus, the more collisions experienced by a\nframe, the larger the interval from which K is chosen. For Ethernet, the\nactual amount of time a node waits is K · 512 bit times (i.e., K times the\namount of time needed to send 512 bits into the Ethernet) and the maximum\nvalue that n can take is capped at 10. Let’s look at an example. Suppose that a node attempts to transmit a\nframe for the first time and while transmitting it detects a collision. The\nnode then chooses K = 0 with probability 0.5 or chooses K = 1 with\nprobability 0.5. If the node chooses K = 0, then it immediately begins\nsensing the channel. If the node chooses K = 1, it waits 512 bit times (e.g.,\n5.12 microseconds for a 100 Mbps Ethernet) before beginning the sense-\nand-transmit-when-idle cycle. After a second collision, K is chosen with\nequal probability from {0,1,2,3}. After three collisions, K is chosen with\nequal probability from {0,1,2,3,4,5,6,7}. After 10 or more collisions, K is\nchosen with equal probability from {0,1,2, . . . , 1023}. Thus, the size of the\nsets from which K is chosen grows exponentially with the number of\ncollisions; for this reason this algorithm is referred to as binary exponential\nbackoff. We also note here that each time a node prepares a new frame for\ntransmission, it runs the CSMA/CD algorithm, not taking into account any\ncollisions that may have occurred in the recent past. So it is possible that a\nnode with a new frame will immediately be able to sneak in a successful\ntransmission while several other nodes are in the exponential backoff state. n"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 817,
    "text": "CSMA/CD Efficiency\nWhen only one node has a frame to send, the node can transmit at the full\nchannel rate (e.g., for Ethernet typical rates are 10 Mbps, 100 Mbps, or 1\nGbps). However, if many nodes have frames to transmit, the effective\ntransmission rate of the channel can be much less. We define the efficiency\nof CSMA/CD to be the long-run fraction of time during which frames are\nbeing transmitted on the channel without collisions when there is a large\nnumber of active nodes, with each node having a large number of frames to\nsend. In order to present a closed-form approximation of the efficiency of\nEthernet, let d\n denote the maximum time it takes signal energy to\npropagate between any two adapters. Let d\n be the time to transmit a\nmaximum-size frame (approximately 1.2 msecs for a 10 Mbps Ethernet). A\nderivation of the efficiency of CSMA/CD is beyond the scope of this book\n(see [Lam 1980] and [Bertsekas 1991]). Here we simply state the following\napproximation:\nEfficiency =\n1+5dprop/dtrans\nWe see from this formula that as d\n approaches 0, the efficiency\napproaches 1. This matches our intuition that if the propagation delay is\nzero, colliding nodes will abort immediately without wasting the channel. Also, as d\n becomes very large, efficiency approaches 1. This is also\nintuitive because when a frame grabs the channel, it will hold on to the\nchannel for a very long time; thus, the channel will be doing productive\nwork most of the time. 6.3.3 Taking-Turns Protocols\nprop\ntrans\nprop\ntrans"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 818,
    "text": "Recall that two desirable properties of a multiple access protocol are (1)\nwhen only one node is active, the active node has a throughput of R bps,\nand (2) when M nodes are active, then each active node has a throughput of\nnearly R/M bps. The ALOHA and CSMA protocols have this first property\nbut not the second. This has motivated researchers to create another class of\nprotocols—the taking-turns protocols. As with random access protocols,\nthere are dozens of taking-turns protocols, and each one of these protocols\nhas many variations. We’ll discuss two of the more important protocols\nhere. The first one is the polling protocol. The polling protocol requires\none of the nodes to be designated as a master node. The master node polls\neach of the nodes in a round-robin fashion. In particular, the master node\nfirst sends a message to node 1, saying that it (node 1) can transmit up to\nsome maximum number of frames. After node 1 transmits some frames, the\nmaster node tells node 2 it (node 2) can transmit up to the maximum\nnumber of frames. (The master node can determine when a node has\nfinished sending its frames by observing the lack of a signal on the\nchannel.) The procedure continues in this manner, with the master node\npolling each of the nodes in a cyclic manner. The polling protocol eliminates the collisions and empty slots that\nplague random access protocols. This allows polling to achieve a much\nhigher efficiency. But it also has a few drawbacks. The first drawback is\nthat the protocol introduces a polling delay—the amount of time required to\nnotify a node that it can transmit. If, for example, only one node is active,\nthen the node will transmit at a rate less than R bps, as the master node must\npoll each of the inactive nodes in turn each time the active node has sent its\nmaximum number of frames. The second drawback, which is potentially\nmore serious, is that if the master node fails, the entire channel becomes"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 819,
    "text": "inoperative. The Bluetooth protocol, which we will study in Section 6.3, is\nan example of a polling protocol. The second taking-turns protocol is the token-passing protocol. In this\nprotocol there is no master node. A small, special-purpose frame known as a\ntoken is exchanged among the nodes in some fixed order. For example,\nnode 1 might always send the token to node 2, node 2 might always send\nthe token to node 3, and node N might always send the token to node 1. When a node receives a token, it holds onto the token only if it has some\nframes to transmit; otherwise, it immediately forwards the token to the next\nnode. If a node does have frames to transmit when it receives the token, it\nsends up to a maximum number of frames and then forwards the token to\nthe next node. Token passing is decentralized and highly efficient. But it has\nits problems as well. For example, the failure of one node can crash the\nentire channel. Or if a node accidentally neglects to release the token, then\nsome recovery procedure must be invoked to get the token back in\ncirculation. Over the years many token-passing protocols have been\ndeveloped, including the fiber distributed data interface (FDDI) protocol\n[Jain 1994] and the IEEE 802.5 token ring protocol [IEEE 802.5 2012], and\neach one had to address these as well as other sticky issues. 6.3.4 DOCSIS: The Link-Layer Protocol for Cable\nInternet Access\nIn the previous three subsections, we’ve learned about three broad classes\nof multiple access protocols: channel partitioning protocols, random access\nprotocols, and taking turns protocols. A cable access network will make for\nan excellent case study here, as we’ll find aspects of each of these three\nclasses of multiple access protocols with the cable access network!"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 820,
    "text": "Recall from Section 1.2.1 that a cable access network typically\nconnects several thousand residential cable modems to a cable modem\ntermination system (CMTS) at the cable network headend. The Data-Over-\nCable Service Interface Specifications (DOCSIS) [DOCSIS 3.1 2014;\nHamzeh 2015] specifies the cable data network architecture and its\nprotocols. DOCSIS uses FDM to divide the downstream (CMTS to modem)\nand upstream (modem to CMTS) network segments into multiple frequency\nchannels. Each downstream channel is between 24 MHz and 192 MHz\nwide, with a maximum throughput of approximately 1.6 Gbps per channel;\neach upstream channel has channel widths ranging from 6.4 MHz to 96\nMHz, with a maximum upstream throughput of approximately 1 Gbps. Each upstream and downstream channel is a broadcast channel. Frames\ntransmitted on the downstream channel by the CMTS are received by all\ncable modems receiving that channel; since there is just a single CMTS\ntransmitting into the downstream channel, however, there is no multiple\naccess problem. The upstream direction, however, is more interesting and\ntechnically challenging, since multiple cable modems share the same\nupstream channel (frequency) to the CMTS, and thus collisions can\npotentially occur. As illustrated in Figure 6.14, each upstream channel is divided into\nintervals of time (TDM-like), each containing a sequence of mini-slots\nduring which cable modems can transmit to the CMTS. The CMTS\nexplicitly grants permission to individual cable modems to transmit during\nspecific mini-slots. The CMTS accomplishes this by sending a control\nmessage known as a MAP message on a downstream channel to specify\nwhich cable modem (with data to send) can transmit during which mini-slot\nfor the interval of time specified in the control message. Since mini-slots"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 821,
    "text": "are explicitly allocated to cable modems, the CMTS can ensure there are no\ncolliding transmissions during a mini-slot. Figure 6.14 ♦Upstream and downstream channels between CMTS\nand cable modems\nBut how does the CMTS know which cable modems have data to send\nin the first place? This is accomplished by having cable modems send mini-\nslot-request frames to the CMTS during a special set of interval mini-slots\nthat are dedicated for this purpose, as shown in Figure 6.14. These mini-\nslot-request frames are transmitted in a random access manner and so may\ncollide with each other. A cable modem can neither sense whether the\nupstream channel is busy nor detect collisions. Instead, the cable modem\ninfers that its mini-slot-request frame experienced a collision if it does not\nreceive a response to the requested allocation in the next downstream\ncontrol message. When a collision is inferred, a cable modem uses binary\nexponential backoff to defer the retransmission of its mini-slot-request"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 822,
    "text": "6.4 Switched Local Area Networks\nHaving covered broadcast networks and multiple access protocols in the\nprevious section, let’s turn our attention next to switched local networks. Figure 6.15 shows a switched local network connecting three departments,\ntwo servers and a router with four switches. Because these switches operate\nat the link layer, they switch ­link-layer frames (rather than network-layer\ndatagrams), don’t recognize network-layer addresses, and don’t use routing\nalgorithms like OSPF to determine paths  through the network of layer-2\nswitches. Instead of using IP addresses, we will soon see that they use link-\nlayer addresses to forward link-layer frames through the network of\nswitches. We’ll begin our study of switched LANs by first covering link-\nlayer addressing (Section 6.4.1). We then examine the celebrated Ethernet\nprotocol (Section 6.4.2). After examining link-layer addressing and\nEthernet, we’ll look at how link-layer switches operate (Section 6.4.3), and\nthen see (Section 6.4.4) how these switches are often used to build large-\nscale LANs."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 823,
    "text": "Figure 6.15 ♦An institutional network connected together by four\nswitches\n6.4.1 Link-Layer Addressing and ARP\nHosts and routers have link-layer addresses. Now you might find this\nsurprising, recalling from Chapter 4 that hosts and routers have network-\nlayer addresses as well. You might be asking, why in the world do we need\nto have addresses at both the network and link layers? In addition to\ndescribing the syntax and function of the link-layer addresses, in this\nsection we hope to shed some light on why the two layers of addresses are\nuseful and, in fact, indispensable. We’ll also cover the Address Resolution\nProtocol (ARP), which provides a mechanism to translate IP addresses to\nlink-layer addresses."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 824,
    "text": "MAC Addresses\nIn truth, it is not hosts and routers that have link-layer addresses but rather\ntheir adapters (that is, network interfaces) that have link-layer addresses. A\nhost or router with multiple network interfaces will thus have multiple link-\nlayer addresses associated with it, just as it would also have multiple IP\naddresses associated with it. It’s important to note, however, that link-layer\nswitches do not have link-layer addresses associated with their interfaces\nthat connect to hosts and routers. This is because the job of the link-layer\nswitch is to carry datagrams between hosts and routers; a switch does this\njob transparently, that is, without the host or router having to explicitly\naddress the frame to the intervening switch. This is illustrated in Figure\n6.16. A link-layer address is variously called a LAN address, a physical\naddress, or a MAC address. Because MAC address seems to be the most\npopular term, we’ll henceforth refer to link-layer addresses as MAC\naddresses. For most LANs (including Ethernet and 802.11 wireless LANs),\nthe MAC address is 6 bytes long, giving 2  possible MAC addresses. As\nshown in Figure 6.16, these 6-byte addresses are typically expressed in\nhexadecimal notation, with each byte of the address expressed as a pair of\nhexadecimal numbers. Although MAC addresses were designed to be\npermanent, it is now possible to change an adapter’s MAC address via\nsoftware. For the rest of this section, however, we’ll assume that an\nadapter’s MAC address is fixed. One interesting property of MAC addresses is that no two adapters\nhave the same address. This might seem surprising given that adapters are\nmanufactured in many countries by many companies. How does a company\nmanufacturing adapters in Taiwan make sure that it is using different\naddresses from a company manufacturing adapters in Belgium? The answer\nis that the IEEE manages the MAC address space. In particular, when a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 825,
    "text": "company wants to manufacture adapters, it purchases a chunk of the\naddress space consisting of 2  addresses for a nominal fee. IEEE allocates\nthe chunk of 2  addresses by fixing the first 24 bits of a MAC address and\nletting the company create unique combinations of the last 24 bits for each\nadapter. An adapter’s MAC address has a flat structure (as opposed to a\nhierarchical structure) and doesn’t change no matter where the adapter goes. A laptop with an Ethernet interface always has the same MAC address, no\nmatter where the computer goes. A smartphone with an 802.11 interface\nalways has the same MAC address, no matter where the smartphone goes. Recall that, in contrast, IP addresses have a hierarchical structure (that is, a\nnetwork part and a host part), and a host’s IP addresses needs to be changed\nwhen the host moves, i.e., changes the network to which it is attached. An\nadapter’s MAC address is analogous to a person’s social security number,\nwhich also has a flat addressing structure and which doesn’t change no\nmatter where the person goes. An IP address is analogous to a person’s\npostal address, which is hierarchical and which must be changed whenever\na person moves. Just as a person may find it useful to have both a postal\naddress and a social security number, it is useful for a host and router\ninterfaces to have both a network-layer address and a MAC address. 24"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 826,
    "text": "Figure 6.16 ♦Each interface connected to a LAN has a unique\nMAC address\nWhen an adapter wants to send a frame to some destination adapter, the\nsending adapter inserts the destination adapter’s MAC address into the\nframe and then sends the frame into the LAN. As we will soon see, a switch\noccasionally broadcasts an incoming frame onto all of its interfaces. We’ll\nsee in Chapter 7 that 802.11 also broadcasts frames. Thus, an adapter may\nreceive a frame that isn’t addressed to it. Thus, when an adapter receives a\nframe, it will check to see whether the destination MAC address in the\nframe matches its own MAC address. If there is a match, the adapter\nextracts the enclosed datagram and passes the datagram up the protocol\nstack. If there isn’t a match, the adapter discards the frame, without passing"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 827,
    "text": "the network-layer datagram up. Thus, the destination only will be\ninterrupted when the frame is received. However, sometimes a sending adapter does want all the other adapters\non the LAN to receive and process the frame it is about to send. In this case,\nthe sending adapter inserts a special MAC broadcast address into the\ndestination address field of the frame. For LANs that use 6-byte addresses\n(such as Ethernet and 802.11), the broadcast address is a string of 48\nconsecutive 1s (that is, FF-FF-FF-FF-FF-FF in hexadecimal notation). Address Resolution Protocol (ARP)\nBecause there are both network-layer addresses (for example, Internet IP\naddresses) and link-layer addresses (that is, MAC addresses), there is a need\nto translate between them. For the Internet, this is the job of the Address\nResolution Protocol (ARP) [RFC 826]. To understand the need for a protocol such as ARP, consider the\nnetwork shown in Figure 6.17. In this simple example, each host and router\nhas a single IP address and single MAC address. As usual, IP addresses are\nshown in dotted-decimal notation and MAC addresses are shown in\nhexadecimal notation. For the purposes of this discussion, we will assume\nin this section that the switch broadcasts all frames; that is, whenever a\nswitch receives a frame on one interface, it forwards the frame on all of its\nother interfaces. In the next section, we will provide a more accurate\nexplanation of how switches operate."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 828,
    "text": "Figure 6.17 ♦Each interface on a LAN has an IP address and a\nMAC address\nPRINCIPLES IN\nPRACTICE\nKEEPING THE LAYERS INDEPENDENT\nThere are several reasons why hosts and router interfaces have MAC addresses in ­addition\nto network-layer addresses. First, LANs are designed for arbitrary network-layer protocols,\nnot just for IP and the Internet. If adapters were assigned IP addresses rather than “neutral”\nMAC addresses, then adapters would not easily be able to support other network-layer\nprotocols (for example, IPX or DECnet). Second, if adapters were to use network-layer\naddresses instead of MAC addresses, the network-layer address would have to be stored in\nthe adapter RAM and reconfigured every time the adapter was moved (or powered up). Another option is to not use any addresses in the adapters and have each adapter pass the\ndata (typically, an IP datagram) of each frame it receives up the protocol stack. The network"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 222",
    "source": "kurose",
    "page": 829,
    "text": "layer could then check for a matching network-layer address. One problem with this option\nis that the host would be interrupted by every frame sent on the LAN, including by frames\nthat were destined for other hosts on the same broadcast LAN. In summary, in order for the\nlayers to be largely independent building blocks in a network architecture, different layers\nneed to have their own addressing scheme. We have now seen three types of addresses:\nhost names for the application layer, IP addresses for the network layer, and MAC\naddresses for the link layer. Now suppose that the host with IP address 222.222.222.220 wants to\nsend an IP datagram to host 222.222.222.222. In this example, both the\nsource and destination are in the same subnet, in the addressing sense of\nSection 4.3.3. To send a datagram, the source must give its adapter not only\nthe IP datagram but also the MAC address for destination 222.222.222.222. The sending adapter will then construct a link-layer frame containing the\ndestination’s MAC address and send the frame into the LAN. The important question addressed in this section is, How does the\nsending host determine the MAC address for the destination host with IP\naddress 222.222.222.222? As you might have guessed, it uses ARP. An ARP\nmodule in the sending host takes any IP address on the same LAN as input,\nand returns the corresponding MAC address. In the example at hand,\nsending host 222.222.222.220 provides its ARP module the IP address\n222.222.222.222, and the ARP module returns the corresponding MAC\naddress 49-BD-D2-C7-56-2A. So we see that ARP resolves an IP address to a MAC address. In many\nways it is analogous to DNS (studied in Section 2.5), which resolves host\nnames to IP addresses. However, one important difference between the two\nresolvers is that DNS resolves host names for hosts anywhere in the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 830,
    "text": "Internet, whereas ARP resolves IP addresses only for hosts and router\ninterfaces on the same subnet. If a node in California were to try to use ARP\nto resolve the IP address for a node in Mississippi, ARP would return with\nan error. Now that we have explained what ARP does, let’s look at how it works. Each host and router has an ARP table in its memory, which contains\nmappings of IP addresses to MAC addresses. Figure 6.18 shows what an\nARP table in host 222.222.222.220 might look like. The ARP table also\ncontains a time-to-live (TTL) value, which indicates when each mapping\nwill be deleted from the table. Note that a table does not necessarily contain\nan entry for every host and router on the subnet; some may have never been\nentered into the table, and others may have expired. A typical expiration\ntime for an entry is 20 minutes from when an entry is placed in an ARP\ntable. Figure 6.18 ♦A possible ARP table in 222.222.222.220\nNow suppose that host 222.222.222.220 wants to send a datagram that\nis IP-addressed to another host or router on that subnet. The sending host\nneeds to obtain the MAC address of the destination given the IP address. This task is easy if the sender’s ARP table has an entry for the destination\nnode. But what if the ARP table doesn’t currently have an entry for the\ndestination? In particular, suppose 222.222.222.220 wants to send a\ndatagram to 222.222.222.222. In this case, the sender uses the ARP protocol\nto resolve the address. First, the sender constructs a special packet called an"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 222",
    "source": "kurose",
    "page": 831,
    "text": "ARP packet. An ARP packet has several fields, including the sending and\nreceiving IP and MAC addresses. Both ARP query and response packets\nhave the same format. The purpose of the ARP query packet is to query all\nthe other hosts and routers on the subnet to determine the MAC address\ncorresponding to the IP address that is being resolved. Returning to our example, 222.222.222.220 passes an ARP query\npacket to the adapter along with an indication that the adapter should send\nthe packet to the MAC broadcast address, namely, FF-FF-FF-FF-FF-FF. The adapter encapsulates the ARP packet in a link-layer frame, uses the\nbroadcast address for the frame’s destination address, and transmits the\nframe into the subnet. Recalling our social security ­number/postal address\nanalogy, an ARP query is equivalent to a person shouting out in a crowded\nroom of cubicles in some company (say, AnyCorp): “What is the social\nsecurity number of the person whose postal address is Cubicle 13, Room\n112, AnyCorp, Palo Alto, California?” The frame containing the ARP query\nis received by all the other adapters on the subnet, and (because of the\nbroadcast address) each adapter passes the ARP packet within the frame up\nto its ARP module. Each of these ARP modules checks to see if its IP\naddress matches the destination IP address in the ARP packet. The one with\na match sends back to the querying host a response ARP packet with the\ndesired mapping. The querying host 222.222.222.220 can then update its\nARP table and send its IP datagram, encapsulated in a link-layer frame\nwhose destination MAC is that of the host or router responding to the\nearlier ARP query. There are a couple of interesting things to note about the ARP protocol. First, the query ARP message is sent within a broadcast frame, whereas the\nresponse ARP message is sent within a standard frame. Before reading on\nyou should think about why this is so. Second, ARP is plug-and-play; that"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 832,
    "text": "is, an ARP table gets built ­automatically—it doesn’t have to be configured\nby a system administrator. And if a host becomes disconnected from the\nsubnet, its entry is eventually deleted from the other ARP tables in the\nsubnet. Students often wonder if ARP is a link-layer protocol or a network-\nlayer protocol. As we’ve seen, an ARP packet is encapsulated within a link-\nlayer frame and thus lies architecturally above the link layer. However, an\nARP packet has fields containing link-layer addresses and thus is arguably a\nlink-layer protocol, but it also contains network-layer addresses and thus is\nalso arguably a network-layer protocol. In the end, ARP is probably best\nconsidered a protocol that straddles the boundary between the link and\nnetwork layers—not fitting neatly into the simple layered protocol stack we\nstudied in Chapter 1. Such are the complexities of real-world protocols! Sending a Datagram off the Subnet\nIt should now be clear how ARP operates when a host wants to send a\ndatagram to another host on the same subnet. But now let’s look at the more\ncomplicated situation when a host on a subnet wants to send a network-\nlayer datagram to a host off the subnet (that is, across a router onto another\nsubnet). Let’s discuss this issue in the context of Figure 6.19, which shows\na simple network consisting of two subnets interconnected by a router. There are several interesting things to note about Figure 6.19. Each host\nhas exactly one IP address and one adapter. But, as discussed in Chapter 4,\na router has an IP address for each of its interfaces. For each router interface\nthere is also an ARP module (in the router) and an adapter. Because the\nrouter in Figure 6.19 has two interfaces, it has two IP addresses, two ARP\nmodules, and two adapters. Of course, each adapter in the network has its\nown MAC address."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 833,
    "text": "Figure 6.19 ♦Two subnets interconnected by a router\nAlso note that Subnet 1 has the network address 111.111.111/24 and\nthat Subnet 2 has the network address 222.222.222/24. Thus, all of the\ninterfaces connected to Subnet 1 have addresses of the form\n111.111.111.xxx and all of the interfaces connected to Subnet 2 have\naddresses of the form 222.222.222.xxx. Now let’s examine how a host on Subnet 1 would send a datagram to a\nhost on Subnet 2. Specifically, suppose that host 111.111.111.111 wants to\nsend an IP datagram to a host 222.222.222.222. The sending host passes the\ndatagram to its adapter, as usual. But the sending host must also indicate to\nits adapter an appropriate destination MAC address. What MAC address\nshould the adapter use? One might be tempted to guess that the appropriate\nMAC address is that of the adapter for host 222.222.222.222, namely, 49-\nBD-D2-C7-56-2A. This guess, however, would be wrong! If the sending\nadapter were to use that MAC address, then none of the ­adapters on Subnet\n1 would bother to pass the IP datagram up to its network layer, since the\nframe’s destination address would not match the MAC address of any\nadapter on Subnet 1. The datagram would just die and go to datagram\nheaven. If we look carefully at Figure 6.19, we see that in order for a datagram\nto go from 111.111.111.111 to a host on Subnet 2, the datagram must first be"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 834,
    "text": "sent to the router interface 111.111.111.110, which is the IP address of the\nfirst-hop router on the path to the final destination. Thus, the appropriate\nMAC address for the frame is the address of the adapter for router interface\n111.111.111.110, namely, E6-E9-00-17-BB-4B. How does the sending host\nacquire the MAC address for 111.111.111.110? By using ARP, of course! Once the sending adapter has this MAC address, it creates a frame\n(containing the datagram addressed to 222.222.222.222) and sends the\nframe into Subnet 1. The router adapter on Subnet 1 sees that the link-layer\nframe is addressed to it, and therefore passes the frame to the network layer\nof the router. Hooray—the IP datagram has successfully been moved from\nsource host to the router! But we are not finished. We still have to move the\ndatagram from the router to the destination. The router now has to\ndetermine the correct interface on which the datagram is to be forwarded. As discussed in Chapter 4, this is done by consulting a forwarding table in\nthe router. The forwarding table tells the router that the datagram is to be\nforwarded via router interface 222.222.222.220. This interface then passes\nthe datagram to its adapter, which encapsulates the datagram in a new frame\nand sends the frame into Subnet 2. This time, the destination MAC address\nof the frame is indeed the MAC address of the ultimate destination. And\nhow does the router obtain this destination MAC address? From ARP, of\ncourse! ARP for Ethernet is defined in RFC 826. A nice introduction to ARP is\ngiven in the TCP/IP tutorial, RFC 1180. We’ll explore ARP in more detail in\nthe homework problems. 6.4.2 Ethernet"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 835,
    "text": "Ethernet has pretty much taken over the wired LAN market. In the 1980s\nand the early 1990s, Ethernet faced many challenges from other LAN\ntechnologies, ­including token ring, FDDI, and ATM. Some of these other\ntechnologies succeeded in capturing a part of the LAN market for a few\nyears. But since its invention in the mid-1970s, Ethernet has continued to\nevolve and grow and has held on to its dominant position. Today, Ethernet\nis by far the most prevalent wired LAN technology, and it is likely to\nremain so for the foreseeable future. One might say that Ethernet has been\nto local area networking what the Internet has been to global networking. There are many reasons for Ethernet’s success. First, Ethernet was the\nfirst widely deployed high-speed LAN. Because it was deployed early,\nnetwork administrators became intimately familiar with Ethernet—its\nwonders and its quirks—and were reluctant to switch over to other LAN\ntechnologies when they came on the scene. Second, token ring, FDDI, and\nATM were more complex and expensive than Ethernet, which further\ndiscouraged network administrators from switching over. Third, the most\ncompelling reason to switch to another LAN technology (such as FDDI or\nATM) was usually the higher data rate of the new technology; however,\nEthernet always fought back, producing versions that operated at equal data\nrates or higher. Switched Ethernet was also introduced in the early 1990s,\nwhich further increased its effective data rates. Finally, because Ethernet\nhas been so popular, Ethernet hardware (in particular, adapters and\nswitches) has become a commodity and is remarkably cheap. The original Ethernet LAN was invented in the mid-1970s by Bob\nMetcalfe and David Boggs. The original Ethernet LAN used a coaxial bus\nto interconnect the nodes. Bus topologies for Ethernet actually persisted\nthroughout the 1980s and into the mid-1990s. Ethernet with a bus topology\nis a broadcast LAN—all transmitted frames travel to and are processed by"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 836,
    "text": "all adapters connected to the bus. Recall that we covered Ethernet’s\nCSMA/CD multiple access protocol with binary exponential backoff in\nSection 6.3.2. By the late 1990s, most companies and universities had replaced their\nLANs with Ethernet installations using a hub-based star topology. In such\nan installation the hosts (and routers) are directly connected to a hub with\ntwisted-pair copper wire. A hub is a physical-layer device that acts on\nindividual bits rather than frames. When a bit, representing a zero or a one,\narrives from one interface, the hub simply re-creates the bit, boosts its\nenergy strength, and transmits the bit onto all the other interfaces. Thus,\nEthernet with a hub-based star topology is also a broadcast LAN—\nwhenever a hub receives a bit from one of its interfaces, it sends a copy out\non all of its other interfaces. In particular, if a hub receives frames from two\ndifferent interfaces at the same time, a collision occurs and the nodes that\ncreated the frames must retransmit. In the early 2000s, Ethernet experienced yet another major evolutionary\nchange. Ethernet installations continued to use a star topology, but the hub\nat the center was replaced with a switch. We’ll be examining switched\nEthernet in depth later in this chapter. For now, we only mention that a\nswitch is not only “collision-less” but is also a bona-fide store-and-forward\npacket switch; but unlike routers, which operate up through layer 3, a\nswitch operates only up through layer 2. Ethernet Frame Structure\nWe can learn a lot about Ethernet by examining the Ethernet frame, which\nis shown in Figure 6.20. To give this discussion about Ethernet frames a\ntangible context, let’s consider sending an IP datagram from one host to\nanother host, with both hosts on the same Ethernet LAN (for example, the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 837,
    "text": "Ethernet LAN in Figure 6.17.) (Although the payload of our Ethernet frame\nis an IP datagram, we note that an Ethernet frame can carry other network-\nlayer packets as well.) Let the sending adapter, adapter A, have the MAC\naddress AA-AA-AA-AA-AA-AA and the receiving adapter, adapter B, have\nthe \nMAC \naddress \nBB-BB-BB-BB-BB-BB. The \nsending \nadapter\nencapsulates the IP datagram within an Ethernet frame and passes the frame\nto the physical layer. The receiving adapter receives the frame from the\nphysical layer, extracts the IP datagram, and passes the IP datagram to the\nnetwork layer. In this context, let’s now examine the six fields of the\nEthernet frame, as shown in Figure 6.20. Figure 6.20 ♦Ethernet frame structure\n•\nData field (46 to 1,500 bytes). This field carries the IP datagram. The\nmaximum transmission unit (MTU) of Ethernet is 1,500 bytes. This\nmeans that if the IP datagram exceeds 1,500 bytes, then the host has to\nfragment the datagram, as discussed in Section 4.3.2. The minimum size\nof the data field is 46 bytes. This means that if the IP datagram is less\nthan 46 bytes, the data field has to be “stuffed” to fill it out to 46 bytes. When stuffing is used, the data passed to the network layer contains the\nstuffing as well as an IP datagram. The network layer uses the length\nfield in the IP datagram header to remove the stuffing. •\nDestination address (6 bytes). This field contains the MAC address of\nthe destination adapter, BB-BB-BB-BB-BB-BB. When adapter B\nreceives an Ethernet frame whose destination address is either BB-BB-"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 838,
    "text": "BB-BB-BB-BB or the MAC broadcast address, it passes the contents of\nthe frame’s data field to the network layer; if it receives a frame with\nany other MAC address, it discards the frame. •\nSource address (6 bytes). This field contains the MAC address of the\nadapter that transmits the frame onto the LAN, in this example, AA-\nAA-AA-AA-AA-AA. •\nType field (2 bytes). The type field permits Ethernet to multiplex\nnetwork-layer protocols. To understand this, we need to keep in mind\nthat hosts can use other network-layer protocols besides IP. In fact, a\ngiven host may support multiple network-layer protocols using different\nprotocols for different applications. For this reason, when the Ethernet\nframe arrives at adapter B, adapter B needs to know to which network-\nlayer protocol it should pass (that is, demultiplex) the contents of the\ndata field. IP and other network-layer protocols (for example, Novell\nIPX or AppleTalk) each have their own, standardized type number. Furthermore, the ARP protocol (discussed in the previous section) has\nits own type number, and if the arriving frame contains an ARP packet\n(i.e., has a type field of 0806 hexadecimal), the ARP packet will be\ndemultiplexed up to the  ARP protocol. Note that the type field is\nanalogous to the protocol field in the network-layer datagram and the\nport-number fields in the transport-layer segment; all of these fields\nserve to glue a protocol at one layer to a protocol at the layer above. •\nCyclic redundancy check (CRC) (4 bytes). As discussed in Section\n6.2.3, the purpose of the CRC field is to allow the receiving adapter,\nadapter B, to detect bit errors in the frame. •\nPreamble (8 bytes). The Ethernet frame begins with an 8-byte preamble\nfield. Each of the first 7 bytes of the preamble has a value of 10101010;\nthe last byte is 10101011. The first 7 bytes of the preamble serve to"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 839,
    "text": "“wake up” the receiving adapters and to synchronize their clocks to that\nof the sender’s clock. Why should the clocks be out of synchronization? Keep in mind that adapter A aims to transmit the frame at 10 Mbps, 100\nMbps, or 1 Gbps, depending on the type of Ethernet LAN. However,\nbecause nothing is absolutely perfect, adapter A will not transmit the\nframe at exactly the target rate; there will always be some drift from the\ntarget rate, a drift which is not known a priori by the other adapters on\nthe LAN. A receiving adapter can lock onto adapter A’s clock simply by\nlocking onto the bits in the first 7 bytes of the preamble. The last 2 bits\nof the eighth byte of the preamble (the first two consecutive 1s) alert\nadapter B that the “important stuff” is about to come. All of the Ethernet technologies provide connectionless service to the\nnetwork layer. That is, when adapter A wants to send a datagram to adapter\nB, adapter A encapsulates the datagram in an Ethernet frame and sends the\nframe into the LAN, without first handshaking with adapter B. This layer-2\nconnectionless service is analogous to IP’s layer-3 datagram service and\nUDP’s layer-4 connectionless service. Ethernet technologies provide an unreliable service to the network\nlayer. Specifically, when adapter B receives a frame from adapter A, it runs\nthe frame through a CRC check, but neither sends an acknowledgment\nwhen a frame passes the CRC check nor sends a negative acknowledgment\nwhen a frame fails the CRC check. When a frame fails the CRC check,\nadapter B simply discards the frame. Thus, adapter A has no idea whether\nits transmitted frame reached adapter B and passed the CRC check. This\nlack of reliable transport (at the link layer) helps to make Ethernet simple\nand cheap. But it also means that the stream of datagrams passed to the\nnetwork layer can have gaps."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 840,
    "text": "CASE HISTORY\nBOB METCALFE AND ETHERNET\nAs a PhD student at Harvard University in the early 1970s, Bob Metcalfe worked on the\nARPAnet at MIT. During his studies, he also became exposed to Abramson’s work on\nALOHA and random access protocols. After completing his PhD and just before\nbeginning a job at Xerox Palo Alto Research Center (Xerox PARC), he visited\nAbramson and his University of Hawaii colleagues for three months, getting a firsthand\nlook at ALOHAnet. At Xerox PARC, Metcalfe became exposed to Alto computers,\nwhich in many ways were the forerunners of the personal computers of the 1980s. Metcalfe saw the need to network these computers in an inexpensive manner. So\narmed with his knowledge about ARPAnet, ALOHAnet, and random access protocols,\nMetcalfe—along with colleague David Boggs—invented Ethernet. Metcalfe and Boggs’s original Ethernet ran at 2.94 Mbps and linked up to 256 hosts\nseparated by up to one mile. Metcalfe and Boggs succeeded at getting most of the\nresearchers at Xerox PARC to communicate through their Alto computers. Metcalfe\nthen forged an alliance between Xerox, Digital, and Intel to establish Ethernet as a 10\nMbps Ethernet standard, ratified by the IEEE. Xerox did not show much interest in\ncommercializing Ethernet. In 1979, Metcalfe formed his own company, 3Com, which\ndeveloped and commercialized networking technology, including Ethernet technology. In particular, 3Com developed and marketed Ethernet cards in the early 1980s for the\nimmensely popular IBM PCs. If there are gaps due to discarded Ethernet frames, does the application\nat Host B see gaps as well? As we learned in Chapter 3, this depends on\nwhether the application is using UDP or TCP. If the application is using\nUDP, then the application in Host B will indeed see gaps in the data. On the\nother hand, if the application is using TCP, then TCP in Host B will not"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 841,
    "text": "acknowledge the data contained in discarded frames, causing TCP in Host A\nto retransmit. Note that when TCP retransmits data, the data will eventually\nreturn to the Ethernet adapter at which it was discarded. Thus, in this sense,\nEthernet does retransmit data, although Ethernet is unaware of whether it is\ntransmitting a brand-new datagram with brand-new data, or a datagram that\ncontains data that has already been transmitted at least once. Ethernet Technologies\nIn our discussion above, we’ve referred to Ethernet as if it were a single\nprotocol standard. But in fact, Ethernet comes in many different flavors,\nwith somewhat bewildering acronyms such as 10BASE-T, 10BASE-2,\n100BASE-T, 1000BASE-LX, 10GBASE-T and 40GBASE-T. These and\nmany other Ethernet technologies have been standardized over the years by\nthe IEEE 802.3 CSMA/CD (Ethernet) working group [IEEE 802.3 2020]. While these acronyms may appear bewildering, there is actually\nconsiderable order here. The first part of the acronym refers to the speed of\nthe standard: 10, 100, 1000, or 10G, for 10 Megabit (per second), 100\nMegabit, Gigabit, 10 Gigabit and 40 Gigibit Ethernet, respectively. “BASE”\nrefers to baseband Ethernet, meaning that the physical media only carries\nEthernet traffic; almost all of the 802.3 standards are for baseband Ethernet. The final part of the acronym refers to the physical media itself; Ethernet is\nboth a link-layer and a physical-layer specification and is carried over a\nvariety of physical media including coaxial cable, copper wire, and fiber. Generally, a “T” refers to twisted-pair copper wires. Historically, an Ethernet was initially conceived of as a segment of\ncoaxial cable. The early 10BASE-2 and 10BASE-5 standards specify 10\nMbps Ethernet over two types of coaxial cable, each limited in length to\n500 meters. Longer runs could be obtained by using a repeater—a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 842,
    "text": "physical-layer device that receives a signal on the input side, and\nregenerates the signal on the output side. A coaxial cable corresponds nicely\nto our view of Ethernet as a broadcast medium—all frames transmitted by\none interface are received at other interfaces, and Ethernet’s CDMA/CD\nprotocol nicely solves the multiple access problem. Nodes simply attach to\nthe cable, and voila, we have a local area network! Ethernet has passed through a series of evolutionary steps over the\nyears, and today’s Ethernet is very different from the original bus-topology\ndesigns using coaxial cable. In most installations today, nodes are\nconnected to a switch via point-to-point segments made of twisted-pair\ncopper wires or fiber-optic cables, as shown in Figures 6.15–6.17. In the mid-1990s, Ethernet was standardized at 100 Mbps, 10 times\nfaster than 10 Mbps Ethernet. The original Ethernet MAC protocol and\nframe format were preserved, but higher-speed physical layers were defined\nfor copper wire (100BASE-T) and fiber (100BASE-FX, 100BASE-SX,\n100BASE-BX). Figure 6.21 shows these different standards and the\ncommon Ethernet MAC protocol and frame format. 100 Mbps Ethernet is\nlimited to a 100-meter distance over twisted pair, and to several kilometers\nover fiber, allowing Ethernet switches in different buildings to be\nconnected."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 843,
    "text": "Figure 6.21 ♦100 Mbps Ethernet standards: A common link layer,\ndifferent physical layers\nGigabit Ethernet is an extension to the highly successful 10 Mbps and\n100 Mbps Ethernet standards. Offering a raw data rate of 40,000 Mbps, 40\nGigabit Ethernet maintains full compatibility with the huge installed base of\nEthernet equipment. The standard for Gigabit Ethernet, referred to as IEEE\n802.3z, does the following:\n•\nUses the standard Ethernet frame format (Figure 6.20) and is backward\ncompatible with 10BASE-T and 100BASE-T technologies. This allows\nfor easy integration of Gigabit Ethernet with the existing installed base\nof Ethernet equipment. •\nAllows for point-to-point links as well as shared broadcast channels. Point-to-point links use switches while broadcast channels use hubs, as\ndescribed earlier. In Gigabit Ethernet jargon, hubs are called buffered\ndistributors. •\nUses CSMA/CD for shared broadcast channels. In order to have\nacceptable efficiency, the maximum distance between nodes must be\nseverely restricted. •\nAllows for full-duplex operation at 40 Gbps in both directions for point-\nto-point channels. Initially operating over optical fiber, Gigabit Ethernet is now able to run\nover category 5 UTP cabling (for 1000BASE-T and 10GBASE-T). Let’s conclude our discussion of Ethernet technology by posing a\nquestion that may have begun troubling you. In the days of bus topologies\nand hub-based star topologies, Ethernet was clearly a broadcast link (as\ndefined in Section 6.3) in which frame collisions occurred when nodes"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 844,
    "text": "transmitted at the same time. To deal with these collisions, the Ethernet\nstandard included the CSMA/CD protocol, which is particularly effective\nfor a wired broadcast LAN spanning a small geographical region. But if the\nprevalent use of Ethernet today is a switch-based star topology, using store-\nand-forward packet switching, is there really a need anymore for an\nEthernet MAC protocol? As we’ll see shortly, a switch coordinates its\ntransmissions and never forwards more than one frame onto the same\ninterface at any time. Furthermore, modern switches are full-duplex, so that\na switch and a node can each send frames to each other at the same time\nwithout interference. In other words, in a switch-based Ethernet LAN there\nare no collisions and, therefore, there is no need for a MAC protocol! As we’ve seen, today’s Ethernets are very different from the original\nEthernet conceived by Metcalfe and Boggs more than 40 years ago—speeds\nhave increased by three orders of magnitude, Ethernet frames are carried\nover a variety of media, switched-Ethernets have become dominant, and\nnow even the MAC protocol is often unnecessary! Is all of this really still\nEthernet? The answer, of course, is “yes, by definition.” It is interesting to\nnote, however, that through all of these changes, there has indeed been one\nenduring constant that has remained unchanged over 30 years—Ethernet’s\nframe format. Perhaps this then is the one true and timeless centerpiece of\nthe Ethernet standard. 6.4.3 Link-Layer Switches\nUp until this point, we have been purposefully vague about what a switch\nactually does and how it works. The role of the switch is to receive\nincoming link-layer frames and forward them onto outgoing links; we’ll\nstudy this forwarding function in detail in this subsection. We’ll see that the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 845,
    "text": "switch itself is transparent to the hosts and routers in the subnet; that is, a\nhost/router addresses a frame to another host/router (rather than addressing\nthe frame to the switch) and happily sends the frame into the LAN, unaware\nthat a switch will be receiving the frame and forwarding it. The rate at\nwhich frames arrive to any one of the switch’s output interfaces may\ntemporarily exceed the link capacity of that interface. To accommodate this\nproblem, switch output interfaces have buffers, in much the same way that\nrouter output interfaces have buffers for datagrams. Let’s now take a closer\nlook at how switches operate. Forwarding and Filtering\nFiltering is the switch function that determines whether a frame should be\nforwarded to some interface or should just be dropped. Forwarding is the\nswitch function that determines the interfaces to which a frame should be\ndirected, and then moves the frame to those interfaces. Switch filtering and\nforwarding are done with a switch table. The switch table contains entries\nfor some, but not necessarily all, of the hosts and routers on a LAN. An\nentry in the switch table contains (1)  a  MAC address, (2) the switch\ninterface that leads toward that MAC address, and (3) the time at which the\nentry was placed in the table. An example switch table for the uppermost\nswitch in Figure 6.15 is shown in Figure 6.22. This description of frame\nforwarding may sound similar to our discussion of datagram forwarding in\nChapter 4. Indeed, in our discussion of generalized forwarding in Section\n4.4, we learned that many modern packet switches can be configured to\nforward on the basis of layer-2 destination MAC addresses (i.e., function as\na layer-2 switch) or layer-3 IP destination addresses (i.e., function as a\nlayer-3 router). Nonetheless, we’ll make the important distinction that\nswitches forward packets based on MAC addresses rather than on IP"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 846,
    "text": "addresses. We will also see that a traditional (i.e., in a non-SDN context)\nswitch table is constructed in a very different manner from a router’s\nforwarding table. Figure 6.22 ♦Portion of a switch table for the uppermost switch in\nFigure 6.15\nTo understand how switch filtering and forwarding work, suppose a\nframe with destination address DD-DD-DD-DD-DD-DD arrives at the\nswitch on interface x. The switch indexes its table with the MAC address\nDD-DD-DD-DD-DD-DD. There are three possible cases:\n•\nThere is no entry in the table for DD-DD-DD-DD-DD-DD. In this case,\nthe switch forwards copies of the frame to the output buffers preceding\nall interfaces except for interface x. In other words, if there is no entry\nfor the destination address, the switch broadcasts the frame. •\nThere is an entry in the table, associating DD-DD-DD-DD-DD-DD\nwith interface x. In this case, the frame is coming from a LAN segment\nthat contains adapter DD-DD-DD-DD-DD-DD. There being no need to\nforward the frame to any of the other interfaces, the switch performs the\nfiltering function by discarding the frame. •\nThere is an entry in the table, associating DD-DD-DD-DD-DD-DD\nwith interface x. In this case, the frame needs to be forwarded to the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 847,
    "text": "LAN segment attached to interface y. The switch performs its\nforwarding function by putting the frame in an output buffer that\nprecedes interface y.\nLet’s walk through these rules for the uppermost switch in Figure 6.15\nand its switch table in Figure 6.22. Suppose that a frame with destination\naddress 62-FE-F7-11-89-A3 arrives at the switch from interface 1. The\nswitch examines its table and sees that the destination is on the LAN\nsegment connected to interface 1 (that is, Electrical Engineering). This\nmeans that the frame has already been broadcast on the LAN segment that\ncontains the destination. The switch therefore filters (that is, discards) the\nframe. Now suppose a frame with the same destination address arrives from\ninterface 2. The switch again examines its table and sees that the destination\nis in the direction of interface 1; it therefore forwards the frame to the\noutput buffer preceding interface 1. It should be clear from this example\nthat as long as the switch table is complete and accurate, the switch\nforwards frames toward destinations without any broadcasting. In this sense, a switch is “smarter” than a hub. But how does this switch\ntable get configured in the first place? Are there link-layer equivalents to\nnetwork-layer routing protocols? Or must an overworked manager\nmanually configure the switch table? Self-Learning\nA switch has the wonderful property (particularly for the already-\noverworked network administrator) that its table is built automatically,\ndynamically, and autonomously—without any intervention from a network\nadministrator or from a configuration protocol. In other words, switches are\nself-learning. This capability is accomplished as follows:"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 848,
    "text": "1. The switch table is initially empty. 2. For each incoming frame received on an interface, the switch stores in\nits table (1) the MAC address in the frame’s source address field, (2) the\ninterface from which the frame arrived, and (3) the current time. In this\nmanner, the switch records in its table the LAN segment on which the\nsender resides. If every host in the LAN eventually sends a frame, then\nevery host will eventually get recorded in the table. 3. The switch deletes an address in the table if no frames are received with\nthat address as the source address after some period of time (the aging\ntime). In this manner, if a PC is replaced by another PC (with a different\nadapter), the MAC address of the original PC will eventually be purged\nfrom the switch table. Let’s walk through the self-learning property for the uppermost switch\nin Figure 6.15 and its corresponding switch table in Figure 6.22. Suppose at\ntime 9:39 a frame with source address 01-12-23-34-45-56 arrives from\ninterface 2. Suppose that this address is not in the switch table. Then the\nswitch adds a new entry to the table, as shown in Figure 6.23. Figure 6.23 ♦Switch learns about the location of an adapter with\naddress 01-12-23-34-45-56"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 849,
    "text": "Continuing with this same example, suppose that the aging time for this\nswitch is 60 minutes, and no frames with source address 62-FE-F7-11-89-\nA3 arrive to the switch between 9:32 and 10:32. Then at time 10:32, the\nswitch removes this address from its table. Switches are plug-and-play devices because they require no\nintervention from a network administrator or user. A network administrator\nwanting to install a switch need do nothing more than connect the LAN\nsegments to the switch interfaces. The administrator need not configure the\nswitch tables at the time of installation or when a host is removed from one\nof the LAN segments. Switches are also full-duplex, meaning any switch\ninterface can send and receive at the same time. Properties of Link-Layer Switching\nHaving described the basic operation of a link-layer switch, let’s now\nconsider their features and properties. We can identify several advantages of\nusing switches, rather than broadcast links such as buses or hub-based star\ntopologies:\n•\nElimination of collisions. In a LAN built from switches (and without\nhubs), there is no wasted bandwidth due to collisions! The switches\nbuffer frames and never transmit more than one frame on a segment at\nany one time. As with a router, the maximum aggregate throughput of a\nswitch is the sum of all the switch interface rates. Thus, switches\nprovide a significant performance improvement over LANs with\nbroadcast links. •\nHeterogeneous links. Because a switch isolates one link from another,\nthe different links in the LAN can operate at different speeds and can\nrun over different media. For example, the uppermost switch in Figure"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 850,
    "text": "6.15 might have three1 Gbps 1000BASE-T copper links, two 100 Mbps\n100BASE-FX fiber links, and one 100BASE-T copper link. Thus, a\nswitch is ideal for mixing legacy equipment with new equipment. •\nManagement. In addition to providing enhanced security (see sidebar on\nFocus on Security), a switch also eases network management. For\nexample, if an adapter malfunctions and continually sends Ethernet\nframes (called a jabbering adapter), a switch can detect the problem and\ninternally disconnect the malfunctioning adapter. With this feature, the\nnetwork administrator need not get out of bed and drive back to work in\norder to correct the problem. Similarly, a cable cut disconnects only that\nhost that was using the cut cable to connect to the switch. In the days of\ncoaxial cable, many a network manager spent hours “walking the line”\n(or more accurately, “crawling the floor”) to find the cable break that\nbrought down the entire network. Switches also gather statistics on\nbandwidth usage, collision rates, and traffic types, and make this\ninformation available to the network manager. This information can be\nused to debug and correct problems, and to plan how the LAN should\nevolve in the future. Researchers are exploring adding yet more\nmanagement \nfunctionality \ninto \nEthernet \nLANs \nin \nprototype\ndeployments [Casado 2007; Koponen 2011]. FOCUS ON\nSECURITY\nSNIFFING A SWITCHED LAN: SWITCH POISONING\nWhen a host is connected to a switch, it typically only receives frames that are\nintended for it. For example, consider a switched LAN in Figure 6.17. When host A\nsends a frame to host B, and there is an entry for host B in the switch table, then the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 851,
    "text": "switch will forward the frame only to host B. If host C happens to be running a sniffer,\nhost C will not be able to sniff this A-to-B frame. Thus, in a switched-LAN environment\n(in contrast to a broadcast link environment such as 802.11 LANs or hub–based\nEthernet LANs), it is more difficult for an attacker to sniff frames. However, because the\nswitch broadcasts frames that have destination addresses that are not in the switch\ntable, the sniffer at C can still sniff some frames that are not intended for C.\nFurthermore, a sniffer will be able sniff all Ethernet broadcast frames with broadcast\ndestination address FF–FF–FF–FF–FF–FF. A well-known attack against a switch,\ncalled switch poisoning, is to send tons of packets to the switch with many different\nbogus source MAC addresses, thereby filling the switch table with bogus entries and\nleaving no room for the MAC addresses of the legitimate hosts. This causes the switch\nto broadcast most frames, which can then be picked up by the sniffer [Skoudis 2006]. As this attack is rather involved even for a sophisticated attacker, switches are\nsignificantly less vulnerable to sniffing than are hubs and wireless LANs. Switches Versus Routers\nAs we learned in Chapter 4, routers are store-and-forward packet switches\nthat forward packets using network-layer addresses. Although a switch is\nalso a store-and-forward packet switch, it is fundamentally different from a\nrouter in that it forwards packets using MAC addresses. Whereas a router is\na layer-3 packet switch, a switch is a layer-2 packet switch. Recall,\nhowever, that we learned in Section 4.4 that modern switches using the\n“match plus action” operation can be used to forward a layer-2 frame based\non the frame's destination MAC address, as well as a layer-3 datagram\nusing the datagram's destination IP address. Indeed, we saw that switches\nusing the OpenFlow standard can perform generalized packet forwarding\nbased on any of eleven different frame, datagram, and transport-layer\nheader fields."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 852,
    "text": "Even though switches and routers are fundamentally different, network\nadministrators must often choose between them when installing an\ninterconnection device. For example, for the network in Figure 6.15, the\nnetwork administrator could just as easily have used a router instead of a\nswitch to connect the department LANs, servers, and internet gateway\nrouter. Indeed, a router would permit interdepartmental communication\nwithout creating collisions. Given that both switches and routers are\ncandidates for interconnection devices, what are the pros and cons of the\ntwo approaches? First consider the pros and cons of switches. As mentioned above,\nswitches are plug-and-play, a property that is cherished by all the\noverworked network administrators of the world. Switches can also have\nrelatively high filtering and forwarding rates—as shown in Figure 6.24,\nswitches have to process frames only up through layer 2, whereas routers\nhave to process datagrams up through layer 3. On the other hand, to prevent\nthe cycling of broadcast frames, the active topology of a switched network\nis restricted to a spanning tree. Also, a large switched network would\nrequire large ARP tables in the hosts and routers and would generate\nsubstantial ARP traffic and processing. Furthermore, switches are\nsusceptible to broadcast storms—if one host goes haywire and transmits an\nendless stream of Ethernet broadcast frames, the switches will forward all\nof these frames, causing the entire network to collapse."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 853,
    "text": "Figure 6.24 ♦Packet processing in switches, routers, and hosts\nNow consider the pros and cons of routers. Because network addressing\nis often hierarchical (and not flat, as is MAC addressing), packets do not\nnormally cycle through routers even when the network has redundant paths. (However, packets can cycle when router tables are misconfigured; but as\nwe learned in Chapter 4, IP uses a special datagram header field to limit the\ncycling.) Thus, packets are not restricted to a spanning tree and can use the\nbest path between source and destination. Because routers do not have the\nspanning tree restriction, they have allowed the Internet to be built with a\nrich topology that includes, for example, multiple active links between\nEurope and North America. Another feature of routers is that they provide\nfirewall protection against layer-2 broadcast storms. Perhaps the most\nsignificant drawback of routers, though, is that they are not plug-and-play—\nthey and the hosts that connect to them need their IP addresses to be\nconfigured. Also, routers often have a larger per-packet processing time\nthan switches, because they have to process up through the layer-3 fields. Finally, there are two different ways to pronounce the word router, either as\n“rootor” or as “rowter,” and people waste a lot of time arguing over the\nproper pronunciation [Perlman 1999]."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 854,
    "text": "Given that both switches and routers have their pros and cons (as\nsummarized in Table 6.1), when should an institutional network (for\nexample, a university campus network or a corporate campus network) use\nswitches, and when should it use routers? Typically, small networks\nconsisting of a few hundred hosts have a few LAN segments. Switches\nsuffice for these small networks, as they localize traffic and increase\naggregate throughput without requiring any configuration of IP addresses. But larger networks consisting of thousands of hosts typically include\nrouters within the network (in addition to switches). The routers provide a\nmore robust isolation of traffic, control broadcast storms, and use more\n“intelligent” routes among the hosts in the network. Table 6.1 ♦Comparison of the typical features of popular\ninterconnection devices\nFor more discussion of the pros and cons of switched versus routed\nnetworks, as well as a discussion of how switched LAN technology can be\nextended to accommodate two orders of magnitude more hosts than today’s\nEthernets, see [Meyers 2004; Kim 2008]. 6.4.4 Virtual Local Area Networks (VLANs)\nIn our earlier discussion of Figure 6.15, we noted that modern institutional\nLANs are often configured hierarchically, with each workgroup\n(department) having its own switched LAN connected to the switched\nLANs of other groups via a switch hierarchy. While such a configuration\nworks well in an ideal world, the real world is often far from ideal. Three\ndrawbacks can be identified in the configuration in Figure 6.15:"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 10",
    "source": "kurose",
    "page": 855,
    "text": "•\nLack of traffic isolation. Although the hierarchy localizes group traffic\nto within a single switch, broadcast traffic (e.g., frames carrying ARP\nand DHCP messages or frames whose destination has not yet been\nlearned by a self-learning switch) must still traverse the entire\ninstitutional network. Limiting the scope of such broadcast traffic would\nimprove LAN performance. Perhaps more importantly, it also may be\ndesirable to limit LAN broadcast traffic for security/privacy reasons. For example, if one group contains the company’s executive\nmanagement team and another group contains disgruntled employees\nrunning Wireshark packet sniffers, the network manager may well\nprefer that the executives’ traffic never even reaches employee hosts. This type of isolation could be provided by replacing the center switch\nin Figure 6.15 with a router. We’ll see shortly that this isolation also can\nbe achieved via a switched (layer 2) solution. •\nInefficient use of switches. If instead of three groups, the institution had\n10 groups, then 10 first-level switches would be required. If each group\nwere small, say less than 10 people, then a single 96-port switch would\nlikely be large enough to accommodate everyone, but this single switch\nwould not provide traffic isolation. •\nManaging users. If an employee moves between groups, the physical\ncabling must be changed to connect the employee to a different switch\nin Figure 6.15. Employees belonging to two groups make the problem\neven harder. Fortunately, each of these difficulties can be handled by a switch that\nsupports virtual local area networks (VLANs). As the name suggests, a\nswitch that supports VLANs allows multiple virtual local area networks to\nbe defined over a single physical local area network infrastructure. Hosts\nwithin a VLAN communicate with each other as if they (and no other hosts)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 856,
    "text": "were connected to the switch. In a port-based VLAN, the switch’s ports\n(interfaces) are divided into groups by the network manager. Each group\nconstitutes a VLAN, with the ports in each VLAN forming a broadcast\ndomain (i.e., broadcast traffic from one port can only reach other ports in\nthe group). Figure 6.25 shows a single switch with 16 ports. Ports 2 to 8\nbelong to the EE VLAN, while ports 9 to 15 belong to the CS VLAN (ports\n1 and 16 are unassigned). This VLAN solves all of the difficulties noted\nabove—EE and CS VLAN frames are isolated from each other, the two\nswitches in Figure 6.15 have been replaced by a single switch, and if the\nuser at switch port 8 joins the CS Department, the network operator simply\nreconfigures the VLAN software so that port 8 is now associated with the\nCS VLAN. One can easily imagine how the VLAN switch is configured\nand operates—the network manager declares a port to belong to a given\nVLAN (with undeclared ports belonging to a default VLAN) using switch\nmanagement software, a table of port-to-VLAN mappings is maintained\nwithin the switch; and switch hardware only delivers frames between ports\nbelonging to the same VLAN."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 857,
    "text": "Figure 6.25 ♦A single switch with two configured VLANs\nBut by completely isolating the two VLANs, we have introduced a new\ndifficulty! How can traffic from the EE Department be sent to the CS\nDepartment? One way to handle this would be to connect a VLAN switch\nport (e.g., port 1 in Figure 6.25) to an external router and configure that port\nto belong both the EE and CS VLANs. In this case, even though the EE and\nCS departments share the same physical switch, the logical configuration\nwould look as if the EE and CS departments had separate switches\nconnected via a router. An IP datagram going from the EE to the CS\ndepartment would first cross the EE VLAN to reach the router and then be\nforwarded by the router back over the CS VLAN to the CS host. Fortunately, switch vendors make such configurations easy for the network\nmanager by building a single device that contains both a VLAN switch and\na router, so a separate external router is not needed. A homework problem at\nthe end of the chapter explores this scenario in more detail. Returning again to Figure 6.15, let’s now suppose that rather than\nhaving a separate Computer Engineering department, some EE and CS\nfaculty are housed in a separate building, where (of course!) they need\nnetwork access, and (of course!) they’d like to be part of their department’s\nVLAN. Figure 6.26 shows a second 8-port switch, where the switch ports\nhave been defined as belonging to the EE or the CS VLAN, as needed. But\nhow should these two switches be interconnected? One easy solution would\nbe to define a port belonging to the CS VLAN on each switch (similarly for\nthe EE VLAN) and to connect these ports to each other, as shown in Figure\n6.26(a). This solution doesn’t scale, however, since N VLANS would\nrequire N ports on each switch simply to interconnect the two switches."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 858,
    "text": "Figure 6.26 ♦Connecting two VLAN switches with two VLANs: (a)\ntwo cables (b) trunked\nFigure 6.27 ♦Original Ethernet frame (top), 802.1Q-tagged\nEthernet VLAN frame (below)\nA more scalable approach to interconnecting VLAN switches is known\nas VLAN trunking. In the VLAN trunking approach shown in Figure"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 859,
    "text": "6.26(b), a special port on each switch (port 16 on the left switch and port 1\non the right switch) is configured as a trunk port to interconnect the two\nVLAN switches. The trunk port belongs to all VLANs, and frames sent to\nany VLAN are forwarded over the trunk link to the other switch. But this\nraises yet another question: How does a switch know that a frame arriving\non a trunk port belongs to a particular VLAN? The IEEE has defined an\nextended Ethernet frame format, 802.1Q, for frames crossing a VLAN\ntrunk. As shown in Figure 6.27, the 802.1Q frame consists of the standard\nEthernet frame with a four-byte VLAN tag added into the header that\ncarries the identity of the VLAN to which the frame belongs. The VLAN\ntag is added into a frame by the switch at the sending side of a VLAN trunk,\nparsed, and removed by the switch at the receiving side of the trunk. The\nVLAN tag itself consists of a 2-byte Tag Protocol Identifier (TPID) field\n(with a fixed hexadecimal value of 81-00), a 2-byte Tag Control\nInformation field that contains a 12-bit VLAN identifier field, and a 3-bit\npriority field that is similar in intent to the IP datagram TOS field. In this discussion, we’ve only briefly touched on VLANs and have\nfocused on port-based VLANs. We should also mention that VLANs can be\ndefined in several other ways. In MAC-based VLANs, the network manager\nspecifies the set of MAC addresses that belong to each VLAN; whenever a\ndevice attaches to a port, the port is connected into the appropriate VLAN\nbased on the MAC address of the device. VLANs can also be defined based\non network-layer protocols (e.g., IPv4, IPv6, or Appletalk) and other\ncriteria. It is also possible for VLANs to be extended across IP routers,\nallowing islands of LANs to be connected together to form a single VLAN\nthat could span the globe [Yu 2011]. See the 802.1Q standard [IEEE 802.1q\n2005] for more details."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 860,
    "text": "6.5 Link Virtualization: A Network as a Link Layer\nBecause this chapter concerns link-layer protocols, and given that we’re\nnow nearing the chapter’s end, let’s reflect on how our understanding of the\nterm link has evolved. We began this chapter by viewing the link as a\nphysical wire connecting two communicating hosts. In studying multiple\naccess protocols, we saw that multiple hosts could be connected by a shared\nwire and that the “wire” connecting the hosts could be radio spectra or other\nmedia. This led us to consider the link a bit more abstractly as a channel,\nrather than as a wire. In our study of Ethernet LANs (Figure 6.15), we saw\nthat the interconnecting media could actually be a rather complex switched\ninfrastructure. Throughout this evolution, however, the hosts themselves\nmaintained the view that the interconnecting medium was simply a link-\nlayer channel connecting two or more hosts. We saw, for example, that an\nEthernet host can be blissfully unaware of whether it is connected to other\nLAN hosts by a single short LAN segment (Figure 6.17) or by a\ngeographically dispersed switched LAN (Figure 6.15) or by a VLAN\n(Figure 6.26). In the case of a dialup modem connection between two hosts, the link\nconnecting the two hosts is actually the telephone network—a logically\nseparate, global telecommunications network with its own switches, links,\nand protocol stacks for data transfer and signaling. From the Internet link-\nlayer point of view, however, the dial-up connection through the telephone\nnetwork is viewed as a simple “wire.” In this sense, the Internet virtualizes\nthe telephone network, viewing the telephone network as a link-layer\ntechnology providing link-layer connectivity between two Internet hosts. You may recall from our discussion of overlay networks in Chapter 2 that"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 861,
    "text": "an overlay network similarly views the Internet as a means for providing\nconnectivity between overlay nodes, seeking to overlay the Internet in the\nsame way that the Internet overlays the telephone network. In this section, we’ll consider Multiprotocol Label Switching (MPLS)\nnetworks. Unlike the circuit-switched telephone network, MPLS is a\npacket-switched, virtual-circuit network in its own right. It has its own\npacket formats and forwarding behaviors. Thus, from a pedagogical\nviewpoint, a discussion of MPLS fits well into a study of either the network\nlayer or the link layer. From an Internet viewpoint, however, we can\nconsider MPLS, like the telephone network and switched-­Ethernets, as a\nlink-layer technology that serves to interconnect IP devices. Thus, we’ll\nconsider MPLS in our discussion of the link layer. Frame-relay and ATM\nnetworks can also be used to interconnect IP devices, though they represent\na slightly older (but still deployed) technology and will not be covered here;\nsee the very readable book [Goralski 1999] for details. Our treatment of\nMPLS will be necessarily brief, as entire books could be (and have been)\nwritten on these networks. We recommend [Davie 2000] for details on\nMPLS. We’ll focus here primarily on how MPLS ­servers interconnect to IP\ndevices, although we’ll dive a bit deeper into the underlying technologies as\nwell. 6.5.1 Multiprotocol Label Switching (MPLS)\nMultiprotocol Label Switching (MPLS) evolved from a number of industry\nefforts in the mid-to-late 1990s to improve the forwarding speed of IP\nrouters by adopting a key concept from the world of virtual-circuit\nnetworks: a fixed-length label. The goal was not to abandon the destination-\nbased IP datagram-forwarding infrastructure for one based on fixed-length"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 862,
    "text": "labels and virtual circuits, but to augment it by selectively labeling\ndatagrams and allowing routers to forward datagrams based on fixed-length\nlabels (rather than destination IP addresses) when possible. Importantly,\nthese techniques work hand-in-hand with IP, using IP addressing and\nrouting. The IETF unified these efforts in the MPLS protocol [RFC 3031,\nRFC 3032], effectively blending VC techniques into a routed datagram\nnetwork. Let’s begin our study of MPLS by considering the format of a link-\nlayer frame that is handled by an MPLS-capable router. Figure 6.28 shows\nthat a link-layer frame transmitted between MPLS-capable devices has a\nsmall MPLS header added between the layer-2 (e.g., Ethernet) header and\nlayer-3 (i.e., IP) header. RFC 3032 defines the format of the MPLS header\nfor such links; headers are defined for ATM and frame-relayed networks as\nwell in other RFCs. Among the fields in the MPLS header are the label, 3\nbits reserved for experimental use, a single S bit, which is used to indicate\nthe end of a series of “stacked” MPLS headers (an advanced topic that we’ll\nnot cover here), and a time-to-live field. Figure 6.28 ♦MPLS header: Located between link- and network-\nlayer headers\nIt’s immediately evident from Figure 6.28 that an MPLS-enhanced\nframe can only be sent between routers that are both MPLS capable (since a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 863,
    "text": "non-MPLS-capable router would be quite confused when it found an MPLS\nheader where it had expected to find the IP header!). An MPLS-capable\nrouter is often referred to as a label-switched router, since it forwards an\nMPLS frame by looking up the MPLS label in its forwarding table and then\nimmediately passing the datagram to the appropriate output interface. Thus,\nthe MPLS-capable router need not extract the destination IP address and\nperform a lookup of the longest prefix match in the forwarding table. But\nhow does a router know if its neighbor is indeed MPLS capable, and how\ndoes a router know what label to associate with the given IP destination? To\nanswer these questions, we’ll need to take a look at the interaction among a\ngroup of MPLS-capable routers. In the example in Figure 6.29, routers R1 through R4 are MPLS\ncapable. R5 and R6 are standard IP routers. R1 has advertised to R2 and R3\nthat it (R1) can route to destination A, and that a received frame with MPLS\nlabel 6 will be forwarded to destination A. Router R3 has advertised to\nrouter R4 that it can route to destinations A and D, and that incoming\nframes with MPLS labels 10 and 12, respectively, will be switched toward\nthose destinations. Router R2 has also advertised to router R4 that it (R2)\ncan reach destination A, and that a received frame with MPLS label 8 will\nbe switched toward A. Note that router R4 is now in the interesting position\nof having two MPLS paths to reach A: via interface 0 with outbound MPLS\nlabel 10, and via interface 1 with an MPLS label of 8. The broad picture\npainted in Figure 6.29 is that IP devices R5, R6, A, and D are connected\ntogether via an MPLS infrastructure (MPLS-capable routers R1, R2, R3,\nand R4) in much the same way that a switched LAN or an ATM network\ncan connect together IP devices. And like a switched LAN or ATM network,\nthe MPLS-capable routers R1 through R4 do so without ever touching the\nIP header of a packet."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 864,
    "text": "Figure 6.29 ♦MPLS-enhanced forwarding\nIn our discussion above, we’ve not specified the specific protocol used\nto distribute labels among the MPLS-capable routers, as the details of this\nsignaling are well beyond the scope of this book. We note, however, that the\nIETF working group on MPLS has specified in [RFC 3468] that an\nextension of the RSVP protocol, known as RSVP-TE [RFC 3209], will be\nthe focus of its efforts for MPLS signaling. We’ve also not discussed how\nMPLS actually computes the paths for packets among MPLS capable\nrouters, nor how it gathers link-state information (e.g., amount of link\nbandwidth unreserved by MPLS) to use in these path computations. Existing link-state routing algorithms (e.g., OSPF) have been extended to\nflood this information to MPLS-capable routers. Interestingly, the actual\npath computation algorithms are not standardized, and are currently vendor-\nspecific."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 865,
    "text": "Thus far, the emphasis of our discussion of MPLS has been on the fact\nthat MPLS performs switching based on labels, without needing to consider\nthe IP address of a packet. The true advantages of MPLS and the reason for\ncurrent interest in MPLS, however, lie not in the potential increases in\nswitching speeds, but rather in the new traffic management capabilities that\nMPLS enables. As noted above, R4 has two MPLS paths to A. If forwarding\nwere performed up at the IP layer on the basis of IP address, the IP routing\nprotocols we studied in Chapter 5 would specify only a single, least-cost\npath to A. Thus, MPLS provides the ability to forward packets along routes\nthat would not be possible using standard IP routing protocols. This is one\nsimple form of traffic engineering using MPLS [RFC 3346; RFC 3272;\nRFC 2702; Xiao 2000], in which a network operator can override normal IP\nrouting and force some of the traffic headed toward a given destination\nalong one path, and other traffic destined toward the same destination along\nanother path (whether for policy, performance, or some other reason). It is also possible to use MPLS for many other purposes as well. It can\nbe used to perform fast restoration of MPLS forwarding paths, e.g., to\nreroute traffic over a precomputed failover path in response to link failure\n[Kar 2000; Huang 2002; RFC 3469]. Finally, we note that MPLS can, and\nhas, been used to implement so-called ­virtual private networks (VPNs). In\nimplementing a VPN for a customer, an ISP uses its MPLS-enabled\nnetwork to connect together the customer’s various networks. MPLS can be\nused to isolate both the resources and addressing used by the customer’s\nVPN from that of other users crossing the ISP’s network; see [DeClercq\n2002] for details. Our discussion of MPLS has been brief, and we encourage you to\nconsult the references we’ve mentioned. We note that MPLS rose to\nprominence before the development of software-defined networking, which"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 866,
    "text": "we studied in Chapter 5, and that many of MPLS’ traffic engineering\ncapabilities can also be achieved via SDN and the generalized forwarding\nparadigm we studied in Chapter 4. Only the future will tell whether MPLS\nand SDN will continue to co-exist, or whether newer technologies (such as\nSDN) will eventually replace MPLS."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 867,
    "text": "6.6 Data Center Networking\nInternet companies such as Google, Microsoft, Amazon, and Alibaba have\nbuilt massive data centers, each housing tens to hundreds of thousands of\nhosts. As briefly discussed in the sidebar in Section 1.2, data centers are not\nonly connected to the Internet, but also internally include complex\ncomputer networks, called data center networks, which interconnect their\ninternal hosts. In this section, we provide a brief introduction to data center\nnetworking for cloud applications. Broadly speaking, data centers serve three purposes. First, they provide\ncontent such as Web pages, search results, e-mail, or streaming video to\nusers. Second, they serve as massively-parallel computing infrastructures\nfor specific data processing tasks, such as distributed index computations\nfor search engines. Third, they provide cloud computing to other\ncompanies. Indeed, today a major trend in computing is for companies to\nuse a cloud provider such as Amazon Web Services, Microsoft Azure, and\nAlibaba Cloud to handle essentially all of their IT needs. 6.6.1 Data Center Architectures\nData center designs are carefully kept company secrets, as they often\nprovide critical competitive advantages to leading cloud computing\ncompanies. The cost of a large data center is huge, exceeding $12 million\nper month for a 100,000 host data center in 2009 [Greenberg 2009a]. Of\nthese costs, about 45 percent can be attributed to the hosts themselves\n(which need to be replaced every 3–4 years); 25 percent to infrastructure,\nincluding transformers, uninterruptable power supplies (UPS) systems,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 868,
    "text": "generators for long-term outages, and cooling systems; 15 percent for\nelectric utility costs for the power draw; and 15 percent for networking,\nincluding network gear (switches, routers, and load balancers), external\nlinks, and transit traffic costs. (In these percentages, costs for equipment are\namortized so that a common cost metric is applied for one-time purchases\nand ongoing expenses such as power.) While networking is not the largest\ncost, networking innovation is the key to reducing overall cost and\nmaximizing performance [Greenberg 2009a]. The worker bees in a data center are the hosts. The hosts in data\ncenters, called blades and resembling pizza boxes, are generally commodity\nhosts that include CPU, memory, and disk storage. The hosts are stacked in\nracks, with each rack typically having 20 to 40 blades. At the top of each\nrack, there is a switch, aptly named the Top of Rack (TOR) switch, that\ninterconnects the hosts in the rack with each other and with other switches\nin the data center. Specifically, each host in the rack has a network interface\nthat connects to its TOR switch, and each TOR switch has additional ports\nthat can be connected to other switches. Today, hosts typically have 40\nGbps or 100 Gbps Ethernet connections to their TOR switches [FB 2019;\nGreenberg 2015; Roy 2015; Singh 2015]. Each host is also assigned its own\ndata-center-internal IP address. The data center network supports two types of traffic: traffic flowing\nbetween external clients and internal hosts and traffic flowing between\ninternal hosts. To handle flows between external clients and internal hosts,\nthe data center network includes one or more border routers, connecting\nthe data center network to the public Internet. The data center network\ntherefore interconnects the racks with each other and connects the racks to\nthe border routers. Figure 6.30 shows an example of a data center network. Data center network design, the art of designing the interconnection"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 869,
    "text": "network and protocols that connect the racks with each other and with the\nborder routers, has become an important branch of computer networking\nresearch in recent years. (See references in this section.) Figure 6.30 ♦A data center network with a hierarchical topology\nLoad Balancing\nA cloud data center, such as one operated by Google, Microsoft, Amazon,\nand Alibaba, provides many applications concurrently, such as search, e-\nmail, and video applications. To support requests from external clients, each\napplication is associated with a publicly visible IP address to which clients\nsend their requests and from which they receive responses. Inside the data\ncenter, the external requests are first directed to a load balancer whose job it\nis to distribute requests to the hosts, balancing the load across the hosts as a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 870,
    "text": "function of their current load [Patel 2013; Eisenbud 2016]. A large data\ncenter will often have several load balancers, each one devoted to a set of\nspecific cloud applications. Such a load balancer is sometimes referred to as\na “layer-4 switch” since it makes decisions based on the destination port\nnumber (layer 4) as well as destination IP address in the packet. Upon\nreceiving a request for a particular application, the load balancer forwards it\nto one of the hosts that handles the application. (A host may then invoke the\nservices of other hosts to help process the request.) The load balancer not\nonly balances the work load across hosts, but also provides a NAT-like\nfunction, translating the public external IP address to the internal IP address\nof the appropriate host, and then translating back for packets traveling in the\nreverse direction back to the clients. This prevents clients from contacting\nhosts directly, which has the security benefit of hiding the internal network\nstructure and preventing clients from directly interacting with the hosts. Hierarchical Architecture\nFor a small data center housing only a few thousand hosts, a simple\nnetwork consisting of a border router, a load balancer, and a few tens of\nracks all interconnected by a single Ethernet switch could possibly suffice. But to scale to tens to hundreds of thousands of hosts, a data center often\nemploys a hierarchy of routers and switches, such as the topology shown in\nFigure 6.30. At the top of the hierarchy, the border router connects to access\nrouters (only two are shown in Figure 6.30, but there can be many more). Below each access router, there are three tiers of switches. Each access\nrouter connects to a top-tier switch, and each top-tier switch connects to\nmultiple second-tier switches and a load balancer. Each second-tier switch\nin turn connects to multiple racks via the racks’ TOR switches (third-tier\nswitches). All links typically use Ethernet for their link-layer and physical-"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 871,
    "text": "layer protocols, with a mix of copper and fiber cabling. With such a\nhierarchical design, it is possible to scale a data center to hundreds of\nthousands of hosts. Because it is critical for a cloud application provider to continually\nprovide applications with high availability, data centers also include\nredundant network equipment and redundant links in their designs (not\nshown in Figure 6.30). For example, each TOR switch can connect to two\ntier-2 switches, and each access router, tier-1 switch, and tier-2 switch can\nbe duplicated and integrated into the design [Cisco 2012; Greenberg\n2009b]. In the hierarchical design in Figure 6.30, observe that the hosts\nbelow each access router form a single subnet. In order to localize ARP\nbroadcast traffic, each of these subnets is further partitioned into smaller\nVLAN subnets, each comprising a few hundred hosts [Greenberg 2009a]. Although the conventional hierarchical architecture just described\nsolves the problem of scale, it suffers from limited host-to-host capacity\n[Greenberg 2009b]. To understand this limitation, consider again Figure\n6.30, and suppose each host connects to its TOR switch with a 10 Gbps\nlink, whereas the links between switches are 100 Gbps Ethernet links. Two\nhosts in the same rack can always communicate at a full 10 Gbps, limited\nonly by the rate of the hosts’ network interface controllers. However, if\nthere are many simultaneous flows in the data center network, the\nmaximum rate between two hosts in different racks can be much less. To\ngain insight into this issue, consider a traffic pattern consisting of 40\nsimultaneous flows between 40  pairs of hosts in different racks. Specifically, suppose each of 10 hosts in rack 1 in Figure 6.30 sends a flow\nto a corresponding host in rack 5. Similarly, there are ten simultaneous\nflows between pairs of hosts in racks 2 and 6, ten simultaneous flows\nbetween racks 3 and 7, and ten simultaneous flows between racks 4 and 8."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 872,
    "text": "If each flow evenly shares a link’s capacity with other flows traversing that\nlink, then the 40 flows crossing the 100 Gbps A-to-B link (as well as the\n100 Gbps B-to-C link) will each only receive 100 Gbps / 40 = 2.5 Gbps,\nwhich is significantly less than the 10 Gbps network interface rate. The\nproblem becomes even more acute for flows between hosts that need to\ntravel higher up the hierarchy. There are several possible solutions to this problem:\nFigure 6.31 ♦Highly interconnected data network topology\n•\nOne possible solution to this limitation is to deploy higher-rate switches\nand routers. But this would significantly increase the cost of the data\ncenter, because switches and routers with high port speeds are very\nexpensive. •\nA second solution to this problem, which can be adopted whenever\npossible, is to co-locate related services and data as close to one another\nas possible (e.g., in the same rack or in a nearby rack) [Roy 2015; Singh\n2015] in order to minimize inter-rack communication via tier-2 or tier-1\nswitches. But this can only go so far, as a key requirement in data\ncenters is flexibility in placement of computation and services\n[Greenberg 2009b; Farrington 2010]. For example, a large-scale"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 873,
    "text": "Internet search engine may run on thousands of hosts spread across\nmultiple racks with significant bandwidth requirements between all\npairs of hosts. Similarly, a cloud computing service (such Amazon Web\nServices or Microsoft Azure) may wish to place the multiple virtual\nmachines comprising a customer’s service on the physical hosts with\nthe most capacity irrespective of their location in the data center. If\nthese physical hosts are spread across multiple racks, network\nbottlenecks as described above may result in poor performance. •\nA final piece of the solution is to provide increased connectivity\nbetween the TOR switches and tier-2 switches, and between tier-2\nswitches and tier-1 switches. For example, as shown in Figure 6.31,\neach TOR switch could be connected to two tier-2 switches, which then\nprovide for multiple link- and switch-disjoint paths between racks. In\nFigure 6.31, there are four distinct paths between the first tier-2 switch\nand the second tier-2 switch, together providing an aggregate capacity\nof 400 Gbps between the first two tier-2 switches. Increasing the degree\nof connectivity between tiers has two significant benefits: there is both\nincreased capacity and increased reliability (because of path diversity)\nbetween switches. In Facebook’s data center [FB 2014; FB 2019], each\nTOR is connected to four different tier-2 switches, and each tier-2\nswitch is connected to four different tier-1 switches. •\nA direct consequence of the increased connectivity between tiers in data\ncenter networks is that multi-path routing can become a first-class\ncitizen in these networks. Flows are by default multipath flows. A very\nsimple scheme to achieve multi-path routing is Equal Cost Multi Path\n(ECMP) [RFC 2992], which performs a randomized next-hop selection\nalong the switches between source and destination. Advanced schemes\nusing finer-grained load balancing have also been proposed [Alizadeh"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 874,
    "text": "2014; Noormohammadpour 2018]. While these schemes perform multi-\npath routing at the flow level, there are also designs that route\nindividual packets within a flow among multiple paths [He 2015; Raiciu\n2010]. 6.6.2 Trends in Data Center Networking\nData center networking is evolving rapidly, with the trends being driven by\ncost reduction, virtualization, physical constraints, modularity, and\ncustomization. Cost Reduction\nIn order to reduce the cost of data centers, and at the same time improve\ntheir delay and throughput performance, as well as ease of expansion and\ndeployment, Internet cloud giants are continually deploying new data center\nnetwork designs. Although some of these designs are proprietary, others\n(e.g., [FB 2019]) are explicitly open or described in the open literature (e.g.,\n[Greenberg 2009b; Singh 2015]). Many important trends can thus be\nidentified. Figure 6.31 illustrates one of the most important trends in data center\nnetworking—the \nemergence \nof \na \nhierarchical, \ntiered \nnetwork\ninterconnecting the data center hosts. This hierarchy conceptually serves the\nsame purpose as a single (very, very! ), large crossbar switch that we studied\nin Section 4.2.2, allowing any host in the data center to communicate with\nany other host. But as we have seen, this tiered interconnection network has\nmany advantages over a conceptual crossbar switch, including multiple\npaths from source to destination and the increased capacity (due to"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 875,
    "text": "multipath routing) and reliability (due to multiple switch- and link-disjoint\npaths between any two hosts). The data center interconnection network is comprised of a large number\nof small-sized switches. For example, in Google’s Jupiter datacenter fabric,\none configuration has 48 links between the ToR switch and its servers\nbelow, and connections up to 8 tier-2 switches; a tier-2 switch has links to\n256 ToR switches and links up to 16 tier-1 switches [Singh 2015]. In\nFacebook’s data center architecture, each ToR switch connects up to four\ndifferent tier-2 switches (each in a different “spline plane”), and each tier-2\nswitch connects up to 4 of the 48 tier-1 switches in its spline plane; there\nare four spline planes. Tier-1 and tier-2 switches connect down to a larger,\nscalable number of tier-2 or ToR switches, respectively, below [FB 2019]. For some of the largest data center operators, these switches are being built\nin-house from commodity, off-the-shelf, merchant silicon [Greenberg\n2009b; Roy 2015; Singh 2015] rather than being purchased from switch\nvendors. A multi-switch layered (tiered, multistage) interconnection network\nsuch as that in Figure 6.31 and as implemented in the data center\narchitectures discussed above is known as Clos networks, named after\nCharles Clos, who studied such networks [Clos 1953] in the context of\ntelephony switching. Since then, a rich theory of Clos networks has been\ndeveloped, finding additional use in data center networking and in\nmultiprocessor interconnection networks. Centralized SDN Control and Management\nBecause a data center is managed by a single organization, it is perhaps\nnatural that a number of the largest data center operators, including Google,\nMicrosoft, and Facebook, are embracing the notion of SDN-like logically"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 876,
    "text": "centralized control. Their architectures also reflect a clear separation of a\ndata plane (comprised of relatively simple, commodity switches) and a\nsoftware-based control plane, as we saw in Section 5.5. Due to the\nimmense-scale of their data centers, automated configuration and\noperational state management, as we encountered in Section 5.7, are also\ncrucial. Virtualization\nVirtualization has been a driving force for much of the growth of cloud\ncomputing and data center networks more generally. Virtual Machines\n(VMs) decouple software running applications from the physical hardware. This decoupling also allows seamless migration of VMs between physical\nservers, which might be located on different racks. Standard Ethernet and IP\nprotocols have limitations in enabling the movement of VMs while\nmaintaining active network connections across servers. Since all data center\nnetworks are managed by a single administrative authority, an elegant\nsolution to the problem is to treat the entire data center network as a single,\nflat, layer-2 network. Recall that in a typical Ethernet network, the ARP\nprotocol maintains the binding between the IP address and hardware (MAC)\naddress on an interface. To emulate the effect of having all hosts connect to\na “single” switch, the ARP mechanism is modified to use a DNS style query\nsystem instead of a broadcast, and the directory maintains a mapping of the\nIP address assigned to a VM and which physical switch the VM is currently\nconnected to in the data center network. Scalable schemes that implement\nthis basic design have been proposed in [Mysore 2009; Greenberg 2009b]\nand have been successfully deployed in modern data centers. Physical Constraints"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 877,
    "text": "Unlike the wide area Internet, data center networks operate in environments\nthat not only have very high capacity (40 Gbps and 100 Gbps links are now\ncommonplace) but also have extremely low delays (microseconds). Consequently, buffer sizes are small and congestion control protocols such\nas TCP and its variants do not scale well in data centers. In data centers,\ncongestion control protocols have to react fast and operate in extremely low\nloss regimes, as loss recovery and timeouts can lead to extreme inefficiency. Several approaches to tackle this issue have been proposed and deployed,\nranging from data center-specific TCP variants [Alizadeh 2010] to\nimplementing Remote Direct Memory Access (RDMA) technologies on\nstandard Ethernet [Zhu 2015; Moshref 2016; Guo 2016]. Scheduling theory\nhas also been applied to develop mechanisms that decouple flow scheduling\nfrom rate control, enabling very simple congestion control protocols while\nmaintaining high utilization of the links [Alizadeh 2013; Hong 2012]. Hardware Modularity and Customization\nAnother major trend is to employ shipping container–based modular data\ncenters (MDCs) [YouTube 2009; Waldrop 2007]. In an MDC, a factory\nbuilds, within a standard 12-meter shipping container, a “mini data center”\nand ships the container to the data center location. Each container has up to\na few thousand hosts, stacked in tens of racks, which are packed closely\ntogether. At the data center location, multiple containers are interconnected\nwith each other and also with the Internet. Once a prefabricated container is\ndeployed at a data center, it is often difficult to service. Thus, each container\nis designed for graceful performance degradation: as components (servers\nand switches) fail over time, the container continues to operate but with\ndegraded performance. When many components have failed and"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 878,
    "text": "performance has dropped below a threshold, the entire container is removed\nand replaced with a fresh one. Building a data center out of containers creates new networking\nchallenges. With an MDC, there are two types of networks: the container-\ninternal networks within each of the containers and the core network\nconnecting each container [Guo 2009; Farrington 2010]. Within each\ncontainer, at the scale of up to a few thousand hosts, it is possible to build a\nfully connected network using inexpensive commodity Gigabit Ethernet\nswitches. However, the design of the core network, interconnecting\nhundreds to thousands of containers while providing high host-to-host\nbandwidth across containers for typical workloads, remains a challenging\nproblem. A hybrid electrical/optical switch architecture for interconnecting\nthe containers is described in [Farrington 2010]. Another important trend is that large cloud providers are increasingly\nbuilding or customizing just about everything that is in their data centers,\nincluding network adapters, switches routers, TORs, software, and\nnetworking protocols [Greenberg 2015; Singh 2015]. Another trend,\npioneered by Amazon, is to improve reliability with “availability zones,”\nwhich essentially replicate distinct data centers in different nearby\nbuildings. By having the buildings nearby (a few kilometers apart),\ntransactional data can be synchronized across the data centers in the same\navailability zone while providing fault tolerance [Amazon 2014]. Many\nmore innovations in data center design are likely to continue to come."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 879,
    "text": "6.7 Retrospective: A Day in the Life of a Web Page\nRequest\nNow that we’ve covered the link layer in this chapter, and the network,\ntransport and application layers in earlier chapters, our journey down the\nprotocol stack is complete! In the very beginning of this book (Section 1.1),\nwe wrote “much of this book is concerned with computer network\nprotocols,” and in the first five chapters, we’ve certainly seen that this is\nindeed the case! Before heading into the topical chapters in second part of\nthis book, we’d like to wrap up our journey down the protocol stack by\ntaking an integrated, holistic view of the protocols we’ve learned about so\nfar. One way then to take this “big picture” view is to identify the many\n(many!) protocols that are involved in satisfying even the simplest request:\ndownloading a Web page. Figure 6.32 illustrates our setting: a student, Bob,\nconnects a laptop to his school’s Ethernet switch and downloads a Web\npage (say the home page of www.google.com). As we now know, there’s a\nlot going on “under the hood” to satisfy this seemingly simple request. A\nWireshark lab at the end of this chapter examines trace files containing a\nnumber of the packets involved in similar scenarios in more detail. 6.7.1 Getting Started: DHCP, UDP, IP, and Ethernet\nLet’s suppose that Bob boots up his laptop and then connects it to an\nEthernet cable connected to the school’s Ethernet switch, which in turn is\nconnected to the school’s router, as shown in Figure 6.32. The school’s\nrouter is connected to an ISP, in this example, comcast.net. In this example,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 880,
    "text": "comcast.net is providing the DNS service for the school; thus, the DNS\nserver resides in the Comcast network rather than the school network. We’ll\nassume that the DHCP server is running within the router, as is often the\ncase. When Bob first connects his laptop to the network, he can’t do anything\n(e.g., download a Web page) without an IP address. Thus, the first network-\nrelated action taken by Bob’s laptop is to run the DHCP protocol to obtain\nan IP address, as well as other information, from the local DHCP server:\nFigure 6.32 ♦A day in the life of a Web page request: Network\nsetting and actions"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 881,
    "text": "1. The operating system on Bob’s laptop creates a DHCP request message\n­(Section 4.3.3) and puts this message within a UDP segment (Section\n3.3) with destination port 67 (DHCP server) and source port 68 (DHCP\nclient). The UDP segment is then placed within an IP datagram\n(Section 4.3.1) with a broadcast IP destination address\n(255.255.255.255) and a source IP address of 0.0.0.0, since Bob’s laptop\ndoesn’t yet have an IP address. 2. The IP datagram containing the DHCP request message is then placed\nwithin an Ethernet frame (Section 6.4.2). The Ethernet frame has a\ndestination MAC addresses of FF:FF:FF:FF:FF:FF so that the frame\nwill be broadcast to all devices connected to the switch (hopefully\nincluding a DHCP server); the frame’s source MAC address is that of\nBob’s laptop, 00:16:D3:23:68:8A. 3. The broadcast Ethernet frame containing the DHCP request is the first\nframe sent by Bob’s laptop to the Ethernet switch. The switch\nbroadcasts the incoming frame on all outgoing ports, including the port\nconnected to the router. 4. The router receives the broadcast Ethernet frame containing the DHCP\nrequest on its interface with MAC address 00:22:6B:45:1F:1B and the\nIP datagram is extracted from the Ethernet frame. The datagram’s\nbroadcast IP destination address indicates that this IP datagram should\nbe processed by upper layer protocols at this node, so the datagram’s\npayload (a UDP segment) is thus demultiplexed (Section 3.2) up to\nUDP, and the DHCP request message is extracted from the UDP\nsegment. The DHCP server now has the DHCP request message. 5. Let’s suppose that the DHCP server running within the router can\nallocate IP addresses in the CIDR (Section 4.3.3) block 68.85.2.0/24. In\nthis example, all IP addresses used within the school are thus within"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 882,
    "text": "Comcast’s address block. Let’s suppose the DHCP server allocates\naddress 68.85.2.101 to Bob’s laptop. The DHCP server creates a DHCP\nACK message (Section 4.3.3) containing this IP address, as well as the\nIP address of the DNS server (68.87.71.226), the IP address for the\ndefault gateway router (68.85.2.1), and the subnet block (68.85.2.0/24)\n(equivalently, the “network mask”). The DHCP message is put inside a\nUDP segment, which is put inside an IP datagram, which is put inside an\nEthernet frame. The Ethernet frame has a source MAC address of the\nrouter’s interface to the home network (00:22:6B:45:1F:1B) and a\ndestination MAC address of Bob’s laptop (00:16:D3:23:68:8A). 6. The Ethernet frame containing the DHCP ACK is sent (unicast) by the\nrouter to the switch. Because the switch is self-learning (Section 6.4.3)\nand previously received an Ethernet frame (containing the DHCP\nrequest) from Bob’s laptop, the switch knows to forward a frame\naddressed to 00:16:D3:23:68:8A only to the output port leading to Bob’s\nlaptop. 7. Bob’s laptop receives the Ethernet frame containing the DHCP ACK,\nextracts the IP datagram from the Ethernet frame, extracts the UDP\nsegment from the IP datagram, and extracts the DHCP ACK message\nfrom the UDP segment. Bob’s DHCP client then records its IP address\nand the IP address of its DNS server. It also installs the address of the\ndefault gateway into its IP forwarding table (Section 4.1). Bob’s laptop\nwill send all datagrams with destination address outside of its subnet\n68.85.2.0/24 to the default gateway. At this point, Bob’s laptop has\ninitialized its networking components and is ready to begin processing\nthe Web page fetch. (Note that only the last two DHCP steps of the four\npresented in Chapter 4 are actually necessary.)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 883,
    "text": "6.7.2 Still Getting Started: DNS and ARP\nWhen Bob types the URL for www.google.com into his Web browser, he\nbegins the long chain of events that will eventually result in Google’s home\npage being displayed by his Web browser. Bob’s Web browser begins the\nprocess by creating a TCP socket (Section 2.7) that will be used to send the\nHTTP request (Section 2.2) to  www.google.com. In order to create the\nsocket, Bob’s laptop will need to know the IP address of www.google.com. We learned in Section 2.5, that the DNS ­protocol is used to provide this\nname-to-IP-address translation service. 8. The operating system on Bob’s laptop thus creates a DNS query\nmessage (Section 2.5.3), putting the string “www.google.com” in the\nquestion section of the DNS message. This DNS message is then placed\nwithin a UDP segment with a destination port of 53 (DNS server). The\nUDP segment is then placed within an IP datagram with an IP\ndestination address of 68.87.71.226 (the address of the DNS server\nreturned in the DHCP ACK in step 5) and a source IP address of\n68.85.2.101. 9. Bob’s laptop then places the datagram containing the DNS query\nmessage in an Ethernet frame. This frame will be sent (addressed, at the\nlink layer) to the gateway router in Bob’s school’s network. However,\neven though Bob’s laptop knows the IP address of the school’s gateway\nrouter (68.85.2.1) via the DHCP ACK message in step 5 above, it\ndoesn’t know the gateway router’s MAC address. In order to obtain the\nMAC address of the gateway router, Bob’s ­laptop will need to use the\nARP protocol (Section 6.4.1). 10. Bob’s laptop creates an ARP query message with a target IP address of\n68.85.2.1 (the default gateway), places the ARP message within an"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 68",
    "source": "kurose",
    "page": 884,
    "text": "Ethernet frame with a broadcast destination address\n(FF:FF:FF:FF:FF:FF) and sends the Ethernet frame to the switch, which\ndelivers the frame to all connected devices, including the gateway router. 11. The gateway router receives the frame containing the ARP query\nmessage on the interface to the school network, and finds that the target\nIP address of 68.85.2.1 in the ARP message matches the IP address of its\ninterface. The gateway router thus prepares an ARP reply, indicating that\nits MAC address of 00:22:6B:45:1F:1B corresponds to IP address\n68.85.2.1. It places the ARP reply message in an Ethernet frame, with a\ndestination address of 00:16:D3:23:68:8A (Bob’s laptop) and sends the\nframe to the switch, which delivers the frame to Bob’s laptop. 12. Bob’s laptop receives the frame containing the ARP reply message and\nextracts the MAC address of the gateway router (00:22:6B:45:1F:1B)\nfrom the ARP reply message. 13. Bob’s laptop can now (finally!) address the Ethernet frame containing\nthe DNS query to the gateway router’s MAC address. Note that the IP\ndatagram in this frame has an IP destination address of 68.87.71.226 (the\nDNS server), while the frame has a destination address of\n00:22:6B:45:1F:1B (the gateway router). Bob’s laptop sends this frame to\nthe switch, which delivers the frame to the gateway router. 6.7.3 Still Getting Started: Intra-Domain Routing to\nthe DNS Server\n14. The gateway router receives the frame and extracts the IP datagram\ncontaining the DNS query. The router looks up the destination address of\nthis datagram (68.87.71.226) and determines from its forwarding table"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 885,
    "text": "that the datagram should be sent to the leftmost router in the Comcast\nnetwork in Figure 6.32. The IP datagram is placed inside a link-layer\nframe appropriate for the link connecting the school’s router to the\nleftmost Comcast router and the frame is sent over this link. 15. The leftmost router in the Comcast network receives the frame, extracts\nthe IP datagram, examines the datagram’s destination address\n(68.87.71.226) and determines the outgoing interface on which to\nforward the datagram toward the DNS server from its forwarding table,\nwhich has been filled in by ­Comcast’s intra-domain protocol (such as\nRIP, OSPF or IS-IS, Section 5.3) as well as the Internet’s inter-\ndomain protocol, BGP (Section 5.4). 16. Eventually the IP datagram containing the DNS query arrives at the\nDNS server. The DNS server extracts the DNS query message, looks up\nthe name www.google.com in its DNS database (Section 2.5), and finds\nthe DNS resource record that contains the IP address (64.233.169.105)\nfor www.google.com. (assuming that it is currently cached in the DNS\nserver). Recall that this cached data originated in the authoritative DNS\nserver (Section 2.5) for google.com. The DNS server forms a DNS reply\nmessage containing this hostname-to-IP-address mapping, and places the\nDNS reply message in a UDP segment, and the segment within an IP\ndatagram addressed to Bob’s laptop (68.85.2.101). This datagram will be\nforwarded back through the Comcast network to the school’s router and\nfrom there, via the Ethernet switch to Bob’s laptop. 17. Bob’s laptop extracts the IP address of the server www.google.com from\nthe DNS message. Finally, after a lot of work, Bob’s laptop is now ready\nto contact the www.google.com server!"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 886,
    "text": "6.7.4 Web Client-Server Interaction: TCP and HTTP\n18. Now that Bob’s laptop has the IP address of www.google.com, it can\ncreate the TCP socket (Section 2.7) that will be used to send the HTTP\nGET message (Section 2.2.3) to www.google.com. When Bob creates the\nTCP socket, the TCP in Bob’s laptop must first perform a three-way\nhandshake (Section 3.5.6) with the TCP in www.google.com. Bob’s\nlaptop thus first creates a TCP SYN segment with destination port 80\n(for HTTP), places the TCP segment inside an IP datagram with a\ndestination IP address of 64.233.169.105 (www.google.com), places the\ndatagram inside a frame with a destination MAC address of\n00:22:6B:45:1F:1B (the gateway router) and sends the frame to the\nswitch. 19. The routers in the school network, Comcast’s network, and Google’s\nnetwork forward the datagram containing the TCP SYN toward\nwww.google.com, using the forwarding table in each router, as in steps\n14–16 above. Recall that the router forwarding table entries governing\nforwarding of packets over the inter-domain link between the Comcast\nand Google networks are determined by the BGP protocol (Chapter 5). 20. Eventually, the datagram containing the TCP SYN arrives at\nwww.google.com. The TCP SYN message is extracted from the datagram\nand demultiplexed to the welcome socket associated with port 80. A\nconnection socket (Section 2.7) is created for the TCP connection\nbetween the Google HTTP server and Bob’s laptop. A TCP SYNACK\n(Section 3.5.6) segment is generated, placed inside a datagram addressed\nto Bob’s laptop, and finally placed inside a link-layer frame appropriate\nfor the link connecting www.google.com to its first-hop router."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 887,
    "text": "21. The datagram containing the TCP SYNACK segment is forwarded\nthrough the Google, Comcast, and school networks, eventually arriving\nat the Ethernet controller in Bob’s laptop. The datagram is demultiplexed\nwithin the operating system to the TCP socket created in step 18, which\nenters the connected state. 22. With the socket on Bob’s laptop now (finally!) ready to send bytes to\nwww.google.com, Bob’s browser creates the HTTP GET message\n(Section 2.2.3) containing the URL to be fetched. The HTTP GET\nmessage is then written into the socket, with the GET message becoming\nthe payload of a TCP segment. The TCP segment is placed in a datagram\nand sent and delivered to www.google.com as in steps 18–20 above. 23. The HTTP server at www.google.com reads the HTTP GET message\nfrom the TCP socket, creates an HTTP response message (Section 2.2),\nplaces the requested Web page content in the body of the HTTP response\nmessage, and sends the message into the TCP socket. 24. The datagram containing the HTTP reply message is forwarded through\nthe Google, Comcast, and school networks, and arrives at Bob’s laptop. Bob’s Web browser program reads the HTTP response from the socket,\nextracts the html for the Web page from the body of the HTTP response,\nand finally (finally!) displays the Web page! Our scenario above has covered a lot of networking ground! If you’ve\nunderstood most or all of the above example, then you’ve also covered a lot\nof ground since you first read Section 1.1, where we wrote “much of this\nbook is concerned with computer network protocols” and you may have\nwondered what a protocol actually was! As detailed as the above example\nmight seem, we’ve omitted a number of possible additional protocols (e.g.,\nNAT running in the school’s gateway router, wireless access to the school’s\nnetwork, security protocols for accessing the school network or encrypting"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 888,
    "text": "segments \nor \ndatagrams, \nnetwork \nmanagement \nprotocols), \nand\nconsiderations (Web caching, the DNS hierarchy) that one would encounter\nin the public ­Internet. We’ll cover a number of these topics and more in the\nsecond part of this book. Lastly, we note that our example above was an integrated and holistic,\nbut also very “nuts and bolts,” view of many of the protocols that we’ve\nstudied in the first part of this book. The example focused more on the\n“how” than the “why.” For a broader, more reflective view on the design of\nnetwork protocols in general, you might want to re-read the “Architectural\nPrinciples of the Internet” in Section 4.5, and the references therein."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 889,
    "text": "6.8 Summary\nIn this chapter, we’ve examined the link layer—its services, the principles\nunderlying its operation, and a number of important specific protocols that\nuse these principles in implementing link-layer services. We saw that the basic service of the link layer is to move a network-\nlayer datagram from one node (host, switch, router, WiFi access point) to an\nadjacent node. We saw that all link-layer protocols operate by encapsulating\na network-layer datagram within a link-layer frame before transmitting the\nframe over the link to the adjacent node. Beyond this common framing\nfunction, however, we learned that different link-layer protocols provide\nvery different link access, delivery, and transmission services. These\ndifferences are due in part to the wide variety of link types over which link-\nlayer protocols must operate. A simple point-to-point link has a single\nsender and receiver communicating over a single “wire.” A multiple access\nlink is shared among many senders and receivers; consequently, the link-\nlayer protocol for a multiple access channel has a protocol (its multiple\naccess protocol) for coordinating link access. In the case of MPLS, the\n“link” connecting two adjacent nodes (for example, two IP routers that are\nadjacent in an IP sense—that they are next-hop IP routers toward some\ndestination) may actually be a network in and of itself. In one sense, the\nidea of a network being considered as a link should not seem odd. A\ntelephone link connecting a home modem/computer to a remote\nmodem/router, for example, is actually a path through a sophisticated and\ncomplex telephone network. Among the principles underlying link-layer communication, we\nexamined error-detection and -correction techniques, multiple access"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 890,
    "text": "protocols, link-layer addressing, virtualization (VLANs), and the\nconstruction of extended switched LANs and data center networks. Much of\nthe focus today at the link layer is on these switched networks. In the case\nof error detection/correction, we examined how it is possible to add\nadditional bits to a frame’s header in order to detect, and in some cases\ncorrect, bit-flip errors that might occur when the frame is transmitted over\nthe link. We covered simple parity and checksumming schemes, as well as\nthe more robust cyclic redundancy check. We then moved on to the topic of\nmultiple access protocols. We identified and studied three broad approaches\nfor coordinating access to a broadcast channel: channel partitioning\napproaches (TDM, FDM), random access approaches (the ALOHA\nprotocols and CSMA protocols), and taking-turns approaches (polling and\ntoken passing). We studied the cable access network and found that it uses\nmany of these multiple access methods. We saw that a consequence of\nhaving multiple nodes share a single broadcast channel was the need to\nprovide node addresses at the link layer. We learned that link-layer\naddresses were quite different from ­network-layer addresses and that, in the\ncase of the Internet, a special protocol (ARP—the Address Resolution\nProtocol) is used to translate between these two forms of addressing and\nstudied the hugely successful Ethernet protocol in detail. We then examined\nhow nodes sharing a broadcast channel form a LAN and how multiple\nLANs can be connected together to form larger LANs—all without the\nintervention of network-layer routing to interconnect these local nodes. We\nalso learned how ­multiple virtual LANs can be created on a single physical\nLAN infrastructure. We ended our study of the link layer by focusing on how MPLS\nnetworks provide link-layer services when they interconnect IP routers and\nan overview of the network designs for today’s massive data centers. We"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 891,
    "text": "wrapped up this chapter (and indeed the first five chapters) by identifying\nthe many protocols that are needed to fetch a simple Web page. Having\ncovered the link layer, our journey down the protocol stack is now over! Certainly, the physical layer lies below the link layer, but the details of the\nphysical layer are probably best left for another course (e.g., in\ncommunication theory, rather than computer networking). We have,\nhowever, touched upon several aspects of the physical layer in this chapter\nand in Chapter 1 (our discussion of physical media in Section 1.2). We’ll\nconsider the physical layer again when we study wireless link\ncharacteristics in the next chapter. Although our journey down the protocol stack is over, our study of\ncomputer networking is not yet at an end. In the following three chapters,\nwe cover wireless networking, network security, and multimedia\nnetworking. These four topics do not fit conveniently into any one layer;\nindeed, each topic crosscuts many layers. Understanding these topics (billed\nas advanced topics in some networking texts) thus requires a firm\nfoundation in all layers of the protocol stack—a foundation that our study\nof the link layer has now completed!"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 892,
    "text": "Homework Problems and Questions\nChapter 6 Review Questions\nSECTION 6.1-6.2\nR1. What is framing in link layer? R2. If all the links in the Internet were to provide reliable delivery\nservice, would the TCP reliable delivery service be redundant? Why\nor why not? R3. Name three error-detection strategies employed by link layer. SECTION 6.3\nR4. Suppose two nodes start to transmit at the same time a packet of\nlength L over a broadcast channel of rate R. Denote the propagation\ndelay between the two nodes as d\n. Will there be a collision if d\n <\nL/R? Why or why not? R5. In Section 6.3, we listed four desirable characteristics of a broadcast\nchannel. Which of these characteristics does slotted ALOHA have? Which of these characteristics does token passing have? R6. In CSMA/CD, after the fifth collision, what is the probability that a\nnode chooses K = 4? The result K = 4 corresponds to a delay of how\nmany ­seconds on a 10 Mbps Ethernet? R7. While TDM and FDM assign time slots and frequencies, CDMA\nassigns a ­different code to each node. Explain the basic principle in\nwhich CDMA works. R8. Why does collision occur in CSMA, if all nodes perform carrier\nsensing before transmission? prop\nprop"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 893,
    "text": "SECTION 6.4\nR9. How big is the MAC address space? The IPv4 address space? The\nIPv6 address space? R10. Suppose nodes A, B, and C each attach to the same broadcast LAN\n(through their adapters). If A sends thousands of IP datagrams to B\nwith each encapsulating frame addressed to the MAC address of B,\nwill C’s adapter process these frames? If so, will C’s adapter pass the\nIP datagrams in these frames to the network layer C? How would\nyour answers change if A sends frames with the MAC broadcast\naddress? R11. IEEE manages the MAC address space, allocating chunks of it to\ncompanies manufacturing network adapters. The first half of the bits\nof the addresses in these chunks are fixed, ensuring that the address\nspace is unique. How long will a chunk last for a company\nmanufacturing 1,000,000 network adapters per year? R12. For the network in Figure 6.19, the router has two ARP modules,\neach with its own ARP table. Is it possible that the same MAC\naddress appears in both tables? R13. What is a hub used for? R14. Consider Figure 6.15. How many subnetworks are there, in the\naddressing sense of Section 4.3? R15. Each host and router has an ARP table in its memory. What are the\ncontents of this table? R16. The Ethernet frame begins with an 8-byte preamble field. The\npurpose of the first 7 bytes is to “wake up” the receiving adapters and\nto synchronize their clocks to that of the sender’s clock. What are the\ncontents of the 8 bytes? What is the purpose of the last byte?"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 894,
    "text": "Problems\nP1. Suppose the information content of a packet is the bit pattern 1010\n0111 0101 1001 and an even parity scheme is being used. What\nwould the value of the field containing the parity bits be for the case\nof a two-dimensional parity scheme? Your answer should be such that\na minimum-length checksum field is used. P2. For the two-dimensional parity check matrix below, show that:\na. a single-bit error that can be corrected. b. a double-bit error that can be detected, but not corrected. 1010\n1010\nP3. Suppose the information portion of a packet contains six bytes\nconsisting of the 8-bit unsigned binary ASCII representation of string\n“CHKSUM”; ­compute the Internet checksum for this data. P4. Compute the Internet checksum for each of the following:\na. the binary representation of the numbers 1 through 6.\nb. the ASCII representation of the letters C through H (uppercase). c. the ASCII representation of the letters c through h (lowercase). P5. Consider the generator, G = 1001, and suppose that D has the value\n11000111010. What is the value of R? P6. Rework the previous problem, but suppose that D has the value\na. 01101010101.\nb. 11111010101.\nc. 10001100001."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 895,
    "text": "P7. In this problem, we explore some of the properties of the CRC. For\nthe ­generator G (= 1001) given in Section 6.2.3, answer the following\nquestions. a. Why can it detect any single bit error in data D? b. Can the above G detect any odd number of bit errors? Why? P8. In Section 6.3, we provided an outline of the derivation of the\nefficiency of slotted ALOHA. In this problem we’ll complete the\nderivation. a. Recall that when there are N active nodes, the efficiency of\nslotted ALOHA is Np(1 − p)\n. Find the value of p that\nmaximizes this expression. b. Using the value of p found in (a), find the efficiency of slotted\nALOHA by letting N approach infinity. Hint: (1 − 1/N)\napproaches 1/e as N approaches infinity. P9. Show that the maximum efficiency of pure ALOHA is 1/(2e). Note:\nThis problem is easy if you have completed the problem above! P10. Consider two nodes, A and B, that use the slotted ALOHA protocol to\ncontend for a channel. Suppose node A has more data to transmit than\nnode B, and node A’s retransmission probability p  is greater than\nnode B’s retransmission probability, p . a. Provide a formula for node A’s average throughput. What is the\ntotal efficiency of the protocol with these two nodes? b. If p  = 2p , is node A’s average throughput twice as large as that\nof node B? Why or why not? If not, how can you choose p  and\np  to make that happen? c. In general, suppose there are N nodes, among which node A has\nretransmission probability 2p and all other nodes have\nN−1\nN\nA\nB\nA\nB\nA\nB"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 896,
    "text": "retransmission probability p. Provide expressions to compute the\naverage throughputs of node A and of any other node. P11. Suppose four active nodes—nodes A, B, C and D—are competing for\naccess to a channel using slotted ALOHA. Assume each node has an\ninfinite number of packets to send. Each node attempts to transmit in\neach slot with probability p. The first slot is numbered slot 1, the\nsecond slot is numbered slot 2, and so on. a. What is the probability that node A succeeds for the first time in\nslot 4? b. What is the probability that some node (either A, B, C or D)\nsucceeds in slot 5? c. What is the probability that the first success occurs in slot 4? d. What is the efficiency of this four-node system? P12. Graph the efficiency of slotted ALOHA and pure ALOHA as a\nfunction of p for the following values of N:\na. N = 10.\nb. N = 30.\nc. N = 50. P13. Consider a broadcast channel with N nodes and a transmission rate of\nR bps. Suppose the broadcast channel uses polling (with an additional\npolling node) for multiple access. Suppose the amount of time from\nwhen a node completes transmission until the subsequent node is\npermitted to transmit (that is, the polling delay) is d\n. Suppose that\nwithin a polling round, a given node is allowed to transmit at most Q\nbits. What is the maximum throughput of the broadcast channel? P14. Consider three LANs interconnected by two routers, as shown in\nFigure 6.33.\npoll"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 192",
    "source": "kurose",
    "page": 897,
    "text": "a. Assign IP addresses to all of the interfaces. For Subnet 1 use\naddresses of the form 192.168.1.xxx; for Subnet 2 uses addresses\nof the form 192.168.2.xxx; and for Subnet 3 use addresses of the\nform 192.168.3.xxx. b. Assign MAC addresses to all of the adapters. c. Consider sending an IP datagram from Host E to Host B. Suppose all of the ARP tables are up to date. Enumerate all the\nsteps, as done for the single-router example in Section 6.4.1.\nd. Repeat (c), now assuming that the ARP table in the sending host\nis empty (and the other tables are up to date). Figure 6.33 ♦Three subnets, interconnected by routers\nP15. Consider Figure 6.33. Now we replace the router between subnets 1\nand 2 with a switch S1, and label the router between subnets 2 and 3"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 192",
    "source": "kurose",
    "page": 898,
    "text": "as R1. a. Consider sending an IP datagram from Host E to Host F. Will\nHost E ask router R1 to help forward the datagram? Why? In the\nEthernet frame containing the IP datagram, what are the source\nand destination IP and MAC addresses? b. Suppose E would like to send an IP datagram to B, and assume\nthat E’s ARP cache does not contain B’s MAC address. Will E\nperform an ARP query to find B’s MAC address? Why? In the\nEthernet frame (containing the IP datagram destined to B) that is\ndelivered to router R1, what are the source and destination IP\nand MAC addresses? c. Suppose Host A would like to send an IP datagram to Host B,\nand neither A’s ARP cache contains B’s MAC address nor does\nB’s ARP cache contain A’s MAC address. Further suppose that\nthe switch S1’s forwarding table contains entries for Host B and\nrouter R1 only. Thus, A will broadcast an ARP request message. What actions will switch S1 perform once it receives the ARP\nrequest message? Will router R1 also receive this ARP request\nmessage? If so, will R1 forward the message to Subnet 3? Once\nHost B receives this ARP request message, it will send back to\nHost A an ARP response message. But will it send an ARP query\nmessage to ask for A’s MAC address? Why? What will switch S1\ndo once it receives an ARP response message from Host B? P16. Consider the previous problem, but suppose now that the router\nbetween subnets 2 and 3 is replaced by a switch. Answer questions\n(a)–(c) in the previous problem in this new context. P17. Recall that with the CSMA/CD protocol, the network adapter waits K\n· 512 bit times after a collision, where K is drawn randomly. For K ="
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 192",
    "source": "kurose",
    "page": 899,
    "text": "115, how long does the adapter wait until returning to Step 2 for:\na. a 10 Mbps broadcast channel? b. a 100 Mbps broadcast channel? P18. Suppose nodes A and B are on the same 12 Mbps broadcast channel,\nand the propagation delay between the two nodes is 316 bit times. Suppose CSMA/CD and Ethernet packets are used for this broadcast\nchannel. Suppose node A begins transmitting a frame and, before it\nfinishes, node B begins transmitting a frame. Can A finish\ntransmitting before it detects that B has transmitted? Why or why not? If the answer is yes, then A incorrectly believes that its frame was\nsuccessful transmitted without a collision. Hint: Suppose at time t = 0\nbits, A begins transmitting a frame. In the worst case, Atransmits a\nminimum-sized frame of 512 + 64 bit times. So A would finish\ntransmitting the frame at t = 512 + 64 bit times. Thus, the answer is\nno, if B’s signal reaches A before bit time t = 512 + 64 bits. In the\nworst case, when does B’s signal reach A? P19. Suppose nodes A and B are on the same 10 Mbps broadcast channel,\nand the propagation delay between the two nodes is 245 bit times. Suppose A and B send Ethernet frames at the same time, the frames\ncollide, and then A and B choose different values of K in the\nCSMA/CD algorithm. Assuming no other nodes are active, can the\nretransmissions from A and B collide? For our purposes, it suffices to\nwork out the following example. Suppose A and B begin transmission\nat t = 0 bit times. They both detect collisions at t = 245 t bit times. Suppose K  = 0 and K  = 1. At what time does B schedule its\nretransmission? At what time does A begin transmission? (Note: The\nnodes must wait for an idle channel after returning to Step 2—see\nA\nB"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 192",
    "source": "kurose",
    "page": 900,
    "text": "protocol.) At what time does A’s signal reach B? Does B refrain from\ntransmitting at its scheduled time? P20. In this problem, you will derive the efficiency of a CSMA/CD-like\nmultiple access protocol. In this protocol, time is slotted and all\nadapters are synchronized to the slots. Unlike slotted ALOHA,\nhowever, the length of a slot (in seconds) is much less than a frame\ntime (the time to transmit a frame). Let S be the length of a slot. Suppose all frames are of constant length L = kRS, where R is the\ntransmission rate of the channel and k is a large integer. ­Suppose there\nare N nodes, each with an infinite number of frames to send. We also\nassume that d\n < S, so that all nodes can detect a collision before the\nend of a slot time. The protocol is as follows:\n•\nIf, for a given slot, no node has possession of the channel, all\nnodes contend for the channel; in particular, each node transmits\nin the slot with probability p. If exactly one node transmits in the\nslot, that node takes possession of the channel for the subsequent k\n− 1 slots and transmits its entire frame. •\nIf some node has possession of the channel, all other nodes refrain\nfrom transmitting until the node that possesses the channel has\nfinished transmitting its frame. Once this node has transmitted its\nframe, all nodes contend for the channel. Note that the channel alternates between two states: the productive\nstate, which lasts exactly k slots, and the nonproductive state, which\nlasts for a random number of slots. Clearly, the channel efficiency is\nthe ratio of k/(k + x), where x is the expected number of consecutive\nunproductive slots. a. For fixed N and p, determine the efficiency of this protocol. prop"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 901,
    "text": "b. For fixed N, determine the p that maximizes the efficiency. c. Using the p (which is a function of N) found in (b), determine the\nefficiency as N approaches infinity. d. Show that this efficiency approaches 1 as the frame length\nbecomes large. P21. Consider Figure 6.33 in problem P14. Provide MAC addresses and IP\naddresses for the interfaces at Host A, both routers, and Host F.\nSuppose Host A sends a datagram to Host F. Give the source and\ndestination MAC addresses in the frame encapsulating this IP\ndatagram as the frame is transmitted (i) from A to the left router, (ii)\nfrom the left router to the right router, (iii) from the right router to F.\nAlso give the source and destination IP addresses in the IP datagram\nencapsulated within the frame at each of these points in time. P22. Suppose now that the leftmost router in Figure 6.33 is replaced by a\nswitch. Hosts A, B, C, and D and the right router are all star-\nconnected into this switch. Give the source and destination MAC\naddresses in the frame encapsulating this IP datagram as the frame is\ntransmitted (i) from A to the switch, (ii) from the switch to the right\nrouter, (iii) from the right router to F. Also give the source and\ndestination IP addresses in the IP datagram encapsulated within the\nframe at each of these points in time. P23. Consider Figure 5.15. Suppose that all links are 120 Mbps. What is\nthe ­maximum total aggregate throughput that can be achieved among\n12 hosts (4 in each department) and 2 servers in this network? You\ncan assume that any host or server can send to any other host or\nserver. Why? P24. Suppose the three departmental switches in Figure 5.15 are replaced\nby hubs. All links are 120 Mbps. Now answer the questions posed in"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 902,
    "text": "Problem P23. P25. Suppose that all the switches in Figure 5.15 are replaced by hubs. All\nlinks are 120 Mbps. Now answer the questions posed in Problem P23. P26. Let’s consider the operation of a learning switch in the context of a\nnetwork in which 6 nodes labeled A through F are star connected into\nan Ethernet switch. Suppose that (i) B sends a frame to E, (ii) E\nreplies with a frame to B, (iii) A sends a frame to B, (iv) B replies\nwith a frame to A. The switch table is initially empty. Show the state\nof the switch table before and after each of these events. For each of\nthese events, identify the link(s) on which the transmitted frame will\nbe forwarded, and briefly justify your answers. P27. In this problem, we explore the use of small packets for Voice-over-IP\napplications. One of the drawbacks of a small packet size is that a\nlarge fraction of link bandwidth is consumed by overhead bytes. To\nthis end, suppose that the packet consists of P bytes and 5 bytes of\nheader. a. Consider sending a digitally encoded voice source directly. Suppose the source is encoded at a constant rate of 128 kbps. Assume each packet is entirely filled before the source sends the\npacket into the network. The time required to fill a packet is the\npacketization delay. In terms of L, determine the packetization\ndelay in milliseconds. b. Packetization delays greater than 20 msec can cause a noticeable\nand unpleasant echo. Determine the packetization delay for L =\n1,500 bytes (roughly corresponding to a maximum-sized\nEthernet packet) and for L = 50 (corresponding to an ATM\npacket)."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 903,
    "text": "c. Calculate the store-and-forward delay at a single switch for a\nlink rate of R = 622 Mbps for L = 1,500 bytes, and for L = 50\nbytes. d. Comment on the advantages of using a small packet size. P28. Consider the single switch VLAN in Figure 6.25, and assume an\nexternal router is connected to switch port 1. Assign IP addresses to\nthe EE and CS hosts and router interface. Trace the steps taken at both\nthe network layer and the link layer to transfer an IP datagram from\nan EE host to a CS host (Hint: Reread the discussion of Figure 6.19 in\nthe text). P29. Consider the MPLS network shown in Figure 6.29, and suppose that\nrouters R5 and R6 are now MPLS enabled. Suppose that we want to\nperform traffic engineering so that packets from R6 destined for A are\nswitched to A via R6-R4-R3-R1, and packets from R5 destined for A\nare switched via R5-R4-R2-R1. Show the MPLS tables in R5 and R6,\nas well as the modified table in R4, that would make this possible. P30. Consider again the same scenario as in the previous problem, but\nsuppose that packets from R6 destined for D are switched via R6-R4-\nR3, while packets from R5 destined to D are switched via R4-R2-R1-\nR3. Show the MPLS tables in all routers that would make this\npossible. P31. In this problem, you will put together much of what you have learned\nabout Internet protocols. Suppose you walk into a room, connect to\nEthernet, and want to download a Web page. What are all the protocol\nsteps that take place, starting from powering on your PC to getting the\nWeb page? Assume there is nothing in our DNS or browser caches\nwhen you power on your PC. (Hint: The steps include the use of\nEthernet, DHCP, ARP, DNS, TCP, and HTTP protocols.) Explicitly"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 904,
    "text": "indicate in your steps how you obtain the IP and MAC addresses of a\ngateway router. P32. Consider the data center network with hierarchical topology in Figure\n6.30. Suppose now there are 80 pairs of flows, with ten flows between\nthe first and ninth rack, ten flows between the second and tenth rack,\nand so on. Further suppose that all links in the network are 10 Gbps,\nexcept for the links between hosts and TOR switches, which are 1\nGbps. a. Each flow has the same data rate; determine the maximum rate\nof a flow. b. For the same traffic pattern, determine the maximum rate of a\nflow for the highly interconnected topology in Figure 6.31.\nc. Now suppose there is a similar traffic pattern, but involving 20\nhosts on each rack and 160 pairs of flows. Determine the\nmaximum flow rates for the two topologies. P33. Consider the hierarchical network in Figure 6.30 and suppose that the\ndata center needs to support e-mail and video distribution among\nother applications. Suppose four racks of servers are reserved for e-\nmail and four racks are reserved for video. For each of the\napplications, all four racks must lie below a single tier-2 switch since\nthe tier-2 to tier-1 links do not have sufficient bandwidth to support\nthe intra-application traffic. For the e-mail application, suppose that\nfor 99.9 percent of the time only three racks are used, and that the\nvideo application has identical usage patterns. a. For what fraction of time does the e-mail application need to use\na fourth rack? How about for the video application? b. Assuming e-mail usage and video usage are independent, for\nwhat fraction of time do (equivalently, what is the probability"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 905,
    "text": "that) both applications need their fourth rack? c. Suppose that it is acceptable for an application to have a shortage\nof servers for 0.001 percent of time or less (causing rare periods\nof performance degradation for users). Discuss how the topology\nin Figure 6.31 can be used so that only seven racks are\ncollectively assigned to the two applications (assuming that the\ntopology can support all the traffic)."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 907,
    "text": "AN INTERVIEW WITH…\nAlbert Greenberg\nAlbert Greenberg is Microsoft Corporate Vice President for\nAzure Networking. He leads development for the Azure\nNetworking team, which is responsible for networking R&D at\nMicrosoft - within and across data centers and edge sites;\nglobal terrestrial and subsea networks; optical networking;\nFPGA and SmartNIC offloads; access and hybrid cloud\nnetworking; host networking and network virtualization;\napplication load balancers and network virtual appliances;\nnetwork services and analytics; security services; container\nnetworking; content distribution networks; edge networking\nincluding application acceleration and 5G, and first party\nnetworks. To meet the challenges of agility and quality that\ncomes with cloud scale, his team has developed and"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 908,
    "text": "embraced custom hardware, machine learning, and open\nsource. Albert moved to Microsoft in 2007 to innovate on\nCloud and bring networking to the host (network\nvirtualization), ideas that appeared, among many, in his VL2\npaper, and which underly Cloud networking today. Prior to joining Microsoft, Albert worked at Bell Labs and\nAT&T Labs as an AT&T Fellow. He helped build the systems\nand tools that run AT&T’s networks, and pioneered the\narchitecture and systems at the foundations of software-\ndefined networking. He holds an AB in Mathematics from\nDartmouth College and a PhD in Computer Science from the\nUniversity of Washington. Albert is a member of the National Academy of\nEngineering, and an ACM Fellow. He has received the IEEE\nKoji Kobayashi Computer and Communication Award, ACM\nSigcomm Award, and ACM Sigcomm and Sigmetrics Test of\nTime paper awards. Albert and wife Kathryn are proud\nparents of four daughters. He grew up in New Orleans. While\nthe Seattle Seahawks are his team, he cannot shake his\nfondness for the Saints. What brought you to specialize in\nnetworking? I’ve always liked solving real-world problems, and\nalso liked mathematics. I’ve found that the field of\nnetworking has lots of room and scope to do both. That mix was very appealing to me. While\nworking on a PhD at the University of Washington,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 909,
    "text": "I benefited from the influence of Ed Lazowska on\nthe systems side, and Richard Ladner and Martin\nTompa on the mathematical and theoretical side. One of my MS course projects was to get two\nmachines from the same vendor to talk to each\nother. Now it seems you can’t stop machines from\ncommunicating! Do you have any advice for students\nentering the networking/Internet field? The face of networking is changing. It’s becoming\na very diverse, inclusive and open environment. I\nmean that in two ways. First, we will see far much\nmore diversity among our network developers and\nresearchers, including women and other\nunderrepresented groups in technology. I’m proud\nof the diversity and inclusivity of the team at\nMicrosoft, and my earlier teams at AT&T. Diversity makes us more resilient, better able to\nadapt to change, and makes our decisions better. Second, one can bring a diversity of technical\nskills and interests to networking. Those interests\nmight be in architecture, programming languages,\noptics, formal methods, data science, AI, or in fault\ntolerant and reliable system design. Open source\nsystems are having enormous impact. SONiC, a\nLinux-based an open source initiative for\nnetworking operating systems, is a great example."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 910,
    "text": "Read this book, and bring your whole set of skills,\nexperience and knowledge set to creating the\nnetworks of the future. SDN and Disaggregation\nbrings diversity and openness. So exciting. Can you describe one or two of the most\nexciting projects you have worked on\nduring your career? What were the biggest\nchallenges? The cloud is by far the biggest thing to come along\nin a long time. The challenges there are head and\nshoulders above other system challenges I’ve\nworked on, in part because the cloud incorporate\nso many aspects of systems. Cloud scenarios\nstretch tremendously the challenge of networking. Traditional networking technology is only part of\nit; in practice today there’s operating systems and\ndistributed systems, architecture, performance,\nsecurity, reliability, machine learning, data science,\nand management–the whole stack. If we used to\nthink of these individual areas as “gardens”, we\ncan think of the cloud as a “farm” made up of all\nof these wonderful gardens. And the operational\nconcerns of designing, monitoring and managing\nan ultra-reliable global-scale system are crucial, as\nthe cloud provides critically important\ninfrastructure for government, industry, education\nand more. All of that has to be rock solid; it needs"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 911,
    "text": "to be secure; it needs to be trustworthy. Software\nis, of course, key to effectively monitoring and\nmanaging such a massive cloud. Here, SDN plays\nthe central role in managing and provisioning at\nscale, creating, in essence, a software-defined data\ncenter. Software allows us to also innovate rapidly. How do you envision the future of\nnetworking and the Internet? What major\nchallenges/obstacles do you think lie\nahead in their development, particularly in\nthe areas of data center networking, and\nedge networks? I’ve already talked about Cloud, and we are just\nsay 10% into its evolution. Yet, it’s clear that the\ndivision of work in the end-to-end system will be\nan increasingly important issue. How much\ncomputation and storage will happen in the\napplication and at the end-host? How much will\nhappen in cloud components at the network’s\n“edge”, at or near the end host or container? And\nhow much will happen in the data centers\nthemselves. How will all of this be orchestrated? We’ll see cloud computing being pushed closer to\nthe edge and we’ll see “horizontal” growth–a\nricher end-to-end computing/data/networking\necosystem–\nnot just growth, say within a data center. This will"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 912,
    "text": "be an area of great innovation. 5G wireless will be\nan important part of this mix. Who has inspired you professionally? I’ve learned a tremendous amount, at both\nMicrosoft and AT&T, from customers and from the\nlive site. Interacting with engineers inspires me, for\ntheir passion for dev and dev-ops of the entire\nlifecycle (invention to development to deployment\nto ultimate decommission) of operational services\nand systems. These are the people who know\narchitecture and systems from end to end, inside\nout. They’re great to work with and have so much\ninsight, experience and knowledge to share,\nwhether that be Microsoft’s Azure Cloud or earlier\nin my career AT&T’s networks. I’ve also loved\nworking with the researchers who have established\nsome of the principles underlying the design and\nmanagement of these at-scale systems."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 913,
    "text": "Wireless and Mobile\nNetworks\nIn the telephony world, the past 25 years have been the golden years of\ncellular telephony. The number of worldwide mobile cellular\nsubscribers increased from 34 million in 1993 to 8.3 billion subscribers\nin 2019. There are now a larger number of mobile phone subscriptions\nthan there are people on our planet. The many advantages of cell\nphones are evident to all—anywhere, anytime, untethered access to the\nglobal telephone network via a highly portable lightweight device. More recently, smartphones, tablets, and laptops have become\nwirelessly connected to the Internet via a cellular or WiFi network. And increasingly, devices such as gaming consoles, thermostats, home\nsecurity systems, home appliances, watches, eye glasses, cars, traffic\ncontrol systems and more are being wirelessly connected to the\nInternet. From a networking standpoint, the challenges posed by\nnetworking these wireless and mobile devices, particularly at the link\nlayer and the network layer, are so different from traditional wired\ncomputer networks that an individual chapter devoted to the study of\nwireless and mobile networks (i.e., this chapter) is appropriate. We’ll begin this chapter with a discussion of mobile users,\nwireless links, and networks, and their relationship to the larger"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 914,
    "text": "(typically wired) networks to which they connect. We’ll draw a\ndistinction between the challenges posed by the ­wireless nature of the\ncommunication links in such networks, and by the mobility that these\nwireless links enable. Making this important distinction—between\nwireless and mobility—will allow us to better isolate, identify, and\nmaster the key concepts in each area. We will begin with an overview of wireless access infrastructure\nand associated terminology. We’ll then consider the characteristics of\nthis wireless link in Section 7.2. We include a brief introduction to\ncode division multiple access (CDMA), a shared-medium access\nprotocol that is often used in wireless networks, in Section 7.2. In\nSection 7.3, we’ll examine the link-level aspects of the IEEE 802.11\n(WiFi) wireless LAN standard in some depth; we’ll also say a few\nwords about Bluetooth wireless personal area networks. In Section 7.4,\nwe’ll provide an overview of cellular Internet access, including 4G and\nemerging 5G cellular technologies that provide both voice and high-\nspeed Internet access. In Section 7.5, we’ll turn our attention to\nmobility, focusing on the problems of locating a mobile user, routing to\nthe mobile user, and “handing over” the mobile user who dynamically\nmoves from one point of attachment to the network to another. We’ll\nexamine how these mobility services are implemented in the 4G/5G\ncellular networks, and the in the Mobile IP standard in Section 7.6. Finally, we’ll consider the impact of wireless links and mobility on\ntransport-layer protocols and networked applications in Section 7.7."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 915,
    "text": "7.1 Introduction\nFigure 7.1 shows the setting in which we’ll consider the topics of wireless\ndata communication and mobility. We’ll begin by keeping our discussion\ngeneral enough to cover a wide range of networks, including both wireless\nLANs such as WiFi and 4G and 5G cellular networks; we’ll drill down into\na more detailed discussion of specific wireless architectures in later\nsections. We can identify the following elements in a wireless network:\n•\nWireless hosts. As in the case of wired networks, hosts are the end-\nsystem devices that run applications. A wireless host might be a\nsmartphone, tablet, or laptop, or it could be an Internet of Things (IoT)\ndevice such as a sensor, appliance, automobile, or any other of the\nmyriad devices being connected to the Internet. The hosts themselves\nmay or may not be mobile. •\nWireless links. A host connects to a base station (defined below) or to\nanother wireless host through a wireless communication link. Different wireless link technologies have different transmission rates\nand can transmit over different distances. Figure 7.2 shows two key\ncharacteristics, link transmission rates and coverage ranges, of the more\npopular wireless network standards. (The figure is only meant to\nprovide a rough idea of these characteristics. For example, some of\nthese types of networks are only now being deployed, and some link\nrates can increase or decrease beyond the values shown depending on\ndistance, channel conditions, and the number of users in the wireless\nnetwork.) We’ll cover these standards later in the first half of this"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 916,
    "text": "chapter; we’ll also consider other wireless link characteristics (such as\ntheir bit error rates and the causes of bit errors) in Section 7.2. In Figure 7.1, wireless links connect wireless hosts located at the edge\nof the network into the larger network infrastructure. We hasten to add\nthat wireless links are also sometimes used within a network to connect\nrouters, switches, and other network equipment. However, our focus in\nthis chapter will be on the use of wireless communication at the\nnetwork edge, as it is here that many of the most exciting technical\nchallenges, and most of the growth, are occurring. •\nBase station. The base station is a key part of the wireless network\ninfrastructure. Unlike the wireless host and wireless link, a base station\nhas no obvious counterpart in a wired network. A base station is\nresponsible for sending and receiving data (e.g., packets) to and from a\nwireless host that is associated with that base station. A base station will\noften be responsible for coordinating the transmission of multiple\nwireless hosts with which it is associated. When we say a wireless host\nis “associated” with a base station, we mean that (1) the host is within\nthe wireless communication distance of the base station, and (2) the\nhost uses that base station to relay data between it (the host) and the\nlarger network. Cell towers in cellular networks and access points in\n802.11 wireless LANs are examples of base stations. In Figure 7.1, the base station is connected to the larger network (e.g., the ­-\nInternet, corporate or home network), thus functioning as a link-layer relay\nbetween the wireless host and the rest of the world with which the host\ncommunicates."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 917,
    "text": "Figure 7.1 ♦Elements of a wireless network\nHosts associated with a base station are often referred to as operating in ­-\ninfrastructure mode, since all traditional network services (e.g., address\nassignment and routing) are provided by the network to which a host is\nconnected via the base station. In ad hoc networks, wireless hosts have no\nsuch infrastructure with which to connect. In the absence of such\ninfrastructure, the hosts themselves must provide for services such as\nrouting, address assignment, DNS-like name translation, and more. When a mobile host moves beyond the range of one base station and into\nthe range of another, it will change its point of attachment into the larger"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 918,
    "text": "network (i.e., change the base station with which it is associated)—a\nprocess referred to as handoff or handover. Such mobility raises many\nchallenging questions. If a host can move, how does one find the mobile\nhost’s current location in the network so that data can be forwarded to that\nmobile host? How is addressing performed, given that a host can be in one\nof many possible locations? If the host moves during a TCP connection or\nphone call, how is data routed so that the connection continues\nuninterrupted? These and many (many!) other questions make wireless and\nmobile networking an area of exciting networking research. Figure 7.2 ♦Wireless transmission rates and range for WiFi,\ncellular 4G/5G and Bluetooth standards (note: axes\nare not linear)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 919,
    "text": "•\nNetwork infrastructure. This is the larger network with which a wireless\nhost may wish to communicate. Having discussed the “pieces” of a wireless network, we note that these\npieces can be combined in many different ways to form different types of\nwireless networks. You may find a taxonomy of these types of wireless\nnetworks useful as you read on in this chapter, or read/learn more about\nwireless networks beyond this book. At the highest level we can classify\nwireless networks according to two criteria: (i) whether a packet in the\nwireless network crosses exactly one wireless hop or multiple wireless\nhops, and (ii) whether there is infrastructure such as a base station in the\nnetwork:\n•\nSingle-hop, infrastructure-based. These networks have a base station\nthat is connected to a larger wired network (e.g., the Internet). Furthermore, all communication is between this base station and a\nwireless host over a single wireless hop. The 802.11 networks you use\nin the classroom, café, or library; and the 4G LTE data networks that we\nwill learn about shortly all fall in this category. The vast majority of our\ndaily interactions are with single-hop, infrastructure-based ­wireless\nnetworks. •\nSingle-hop, infrastructure-less. In these networks, there is no base\nstation that is connected to a wireless network. However, as we will see,\none of the nodes in this single-hop network may coordinate the\ntransmissions of the other nodes. ­Bluetooth networks (that connect\nsmall wireless devices such as keyboards, speakers, and headsets, and\nwhich we will study in Section 7.3.6) are single-hop, infrastructure-less\nnetworks."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 920,
    "text": "•\nMulti-hop, infrastructure-based. In these networks, a base station is\npresent that is wired to the larger network. However, some wireless\nnodes may have to relay their communication through other wireless\nnodes in order to communicate via the base station. Some wireless\nsensor networks and so-called wireless mesh networks deployed in\nhomes fall in this category. •\nMulti-hop, infrastructure-less. There is no base station in these\nnetworks, and nodes may have to relay messages among several other\nnodes in order to reach a destination. Nodes may also be mobile, with\nconnectivity changing among nodes—a class of networks known as\nmobile ad hoc networks (MANETs). If the mobile nodes are vehicles,\nthe network is a vehicular ad hoc network (VANET). As you might\nimagine, the development of protocols for such networks is challenging\nand is the subject of much ongoing research. In this chapter, we’ll mostly confine ourselves to single-hop networks, and\nthen mostly to infrastructure-based networks. Let’s now dig deeper into the technical challenges that arise in wireless\nand mobile networks. We’ll begin by first considering the individual\nwireless link, deferring our discussion of mobility until later in this chapter."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 921,
    "text": "7.2 Wireless Links and Network Characteristics\nWireless links differ from their wired counterparts in a number important\nways:\n•\nDecreasing signal strength. Electromagnetic radiation attenuates as it\npasses through matter (e.g., a radio signal passing through a wall). Even\nin free space, the signal will disperse, resulting in decreased signal\nstrength (sometimes referred to as path loss) as the distance between\nsender and receiver increases. •\nInterference from other sources. Radio sources transmitting in the same\nfrequency band will interfere with each other. For example, 2.4 GHz\nwireless phones and 802.11b wireless LANs transmit in the same\nfrequency band. Thus, the 802.11b wireless LAN user talking on a 2.4\nGHz wireless phone can expect that neither the network nor the phone\nwill perform particularly well. In addition to interference from\ntransmitting sources, electromagnetic noise within the environment\n(e.g., a nearby motor, a microwave) can result in interference. For this\nreason, a number of more recent 802.11 standards operate in the 5GHz\nfrequency band. •\nMultipath propagation. Multipath propagation occurs when portions\nof the electromagnetic wave reflect off objects and the ground, taking\npaths of different lengths between a sender and receiver. This results in\nthe blurring of the received signal at the receiver. Moving objects\nbetween the sender and receiver can cause multipath propagation to\nchange over time."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 922,
    "text": "For a detailed discussion of wireless channel characteristics, models, and\nmeasurements, see [Anderson 1995; Almers 2007]. The discussion above suggests that bit errors will be more common in\nwireless links than in wired links. For this reason, it is perhaps not\nsurprising that wireless link protocols (such as the 802.11 protocol we’ll\nexamine in the following section) employ not only powerful CRC error\ndetection codes, but also link-level reliable-data-transfer protocols that\nretransmit corrupted frames. Having considered the impairments that can occur on a wireless\nchannel, let’s next turn our attention to the host receiving the wireless\nsignal. This host receives an electromagnetic signal that is a combination of\na degraded form of the original signal transmitted by the sender (degraded\ndue to the attenuation and multipath propagation effects that we discussed\nabove, among others) and background noise in the environment. The\nsignal-to-noise ratio (SNR) is a relative measure of the strength of the\nreceived signal (i.e., the information being transmitted) and this noise. The\nSNR is typically measured in units of decibels (dB), a unit of measure that\nsome think is used by electrical engineers primarily to confuse computer\nscientists. The SNR, measured in dB, is 20 times the ratio of the base-10\nlogarithm of the amplitude of the received signal to the amplitude of the\nnoise. For our purposes here, we need only know that a larger SNR makes it\neasier for the receiver to extract the transmitted signal from the background\nnoise. Figure 7.3 (adapted from [Holland 2001]) shows the bit error rate\n(BER)—roughly speaking, the probability that a transmitted bit is received\nin error at the receiver—versus the SNR for three different modulation\ntechniques for encoding information for transmission on an idealized\nwireless channel. The theory of modulation and coding, as well as signal"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 923,
    "text": "extraction and BER, is well beyond the scope of this text (see [Schwartz\n1980; Goldsmith 2005] for a discussion of these topics). Nonetheless,\nFigure 7.3 illustrates several physical-layer characteristics that are\nimportant in understanding higher-layer wireless communication protocols:\nFigure 7.3 ♦Bit error rate, transmission rate, and SNR\n•\nFor a given modulation scheme, the higher the SNR, the lower the BER. Since a sender can increase the SNR by increasing its transmission\npower, a sender can decrease the probability that a frame is received in\nerror by increasing its transmission power. Note, however, that there is\narguably little practical gain in increasing the power beyond a certain\nthreshold, say to decrease the BER from 10\n to 10\n. There are also\n−12\n−13"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 924,
    "text": "disadvantages associated with increasing the ­transmission power: More\nenergy must be expended by the sender (an important concern for\nbattery-powered mobile users), and the sender’s transmissions are more\nlikely to interfere with the transmissions of another sender (see Figure\n7.4(b)). •\nFor a given SNR, a modulation technique with a higher bit transmission\nrate (whether in error or not) will have a higher BER. For example, in\nFigure 7.3, with an SNR of 10 dB, BPSK modulation with a\ntransmission rate of 1 Mbps has a BER of less than 10 , while with\nQAM16 modulation with a transmission rate of 4 Mbps, the BER is\n10 , far too high to be practically useful. However, with an SNR of 20\ndB, QAM16 modulation has a transmission rate of 4 Mbps and a BER\nof 10 , while BPSK modulation has a transmission rate of only 1 Mbps\nand a BER that is so low as to be (literally) “off the charts.” If one can\ntolerate a BER of 10 , the higher transmission rate offered by QAM16\nwould make it the preferred modulation technique in this situation. These considerations give rise to the final characteristic, described next. •\nDynamic selection of the physical-layer modulation technique can be\nused to adapt the modulation technique to channel conditions. The SNR\n(and hence the BER) may change as a result of mobility or due to\nchanges in the environment. Adaptive modulation and coding are used\nin the 802.11 WiFi and in 4G and 5G cellular data networks that we’ll\nstudy in Sections 7.3 and 7.4. This allows, for example, the selection of\na modulation technique that provides the highest transmission rate\npossible subject to a constraint on the BER, for given channel\ncharacteristics. −7\n−1\n−7\n−7"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 925,
    "text": "Figure 7.4 ♦Hidden terminal problem caused by obstacle (a) and\nfading (b)\nA higher and time-varying bit error rate is not the only difference\nbetween a wired and wireless link. Recall that in the case of wired\nbroadcast links, all nodes receive the transmissions from all other nodes. In\nthe case of wireless links, the situation is not as simple, as shown in Figure\n7.4. Suppose that Station A is transmitting to Station B. Suppose also that\nStation C is transmitting to Station B. With the so-called hidden terminal\nproblem, physical obstructions in the environment (for example, a\nmountain or a building) may prevent A and C from hearing each other’s\ntransmissions, even though A’s and C’s transmissions are indeed interfering\nat the destination, B. This is shown in Figure 7.4(a). A second scenario that\nresults in undetectable collisions at the receiver results from the fading of a\nsignal’s strength as it propagates through the wireless medium. Figure\n7.4(b) illustrates the case where A and C are placed such that their signals\nare not strong enough to detect each other’s transmissions, yet their signals\nare strong enough to interfere with each other at station B. As we’ll see in"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 926,
    "text": "Section 7.3, the hidden terminal problem and fading make multiple access\nin a wireless network considerably more complex than in a wired network. 7.2.1 CDMA\nRecall from Chapter 6 that when hosts communicate over a shared medium,\na protocol is needed so that the signals sent by multiple senders do not\ninterfere at the receivers. In Chapter 6, we described three classes of\nmedium access protocols: channel partitioning, random access, and taking\nturns. Code division multiple access (CDMA) belongs to the family of\nchannel partitioning protocols. It is prevalent in wireless LAN and cellular\ntechnologies. Because CDMA is so important in the wireless world, we’ll\ntake a quick look at CDMA now, before getting into specific wireless access\ntechnologies in the subsequent sections. In a CDMA protocol, each bit being sent is encoded by multiplying the\nbit by a signal (the code) that changes at a much faster rate (known as the\nchipping rate) than the original sequence of data bits. Figure 7.5 shows a\nsimple, idealized CDMA encoding/decoding scenario. Suppose that the rate\nat which original data bits reach the CDMA encoder defines the unit of\ntime; that is, each original data bit to be transmitted requires a one-bit slot\ntime. Let d  be the value of the data bit for the ith bit slot. For mathematical\nconvenience, we represent a data bit with a 0 value as −1. Each bit slot is\nfurther subdivided into M mini-slots; in Figure 7.5, M = 8, although in\npractice M is much larger. The CDMA code used by the sender consists of a\nsequence of M values, c , m = 1, . . . , M, each taking a +1 or −1 value. In\nthe example in Figure 7.5, the M-bit CDMA code being used by the sender\nis (1, 1, 1, −1, 1, −1, −1, −1). i\nm"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 927,
    "text": "Figure 7.5 ♦A simple CDMA example: Sender encoding, receiver\ndecoding\nTo illustrate how CDMA works, let us focus on the ith data bit, d . For\nthe mth mini-slot of the bit-transmission time of d , the output of the CDMA\nencoder, Z , is the value of d  multiplied by the mth bit in the assigned\nCDMA code, c :\ni\ni\ni,m\ni\nm\nZi,m = di ⋅cm\n(7.1)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 928,
    "text": "In a simple world, with no interfering senders, the receiver would receive\nthe encoded bits, Z , and recover the original data bit, d , by computing:\nThe reader might want to work through the details of the example in Figure\n7.5 to see that the original data bits are indeed correctly recovered at the\nreceiver using Equation 7.2. The world is far from ideal, however, and as noted above, CDMA must\nwork in the presence of interfering senders that are encoding and\ntransmitting their data using a different assigned code. But how can a\nCDMA receiver recover a sender’s original data bits when those data bits\nare being tangled with bits being transmitted by other senders? CDMA\nworks under the assumption that the interfering transmitted bit signals are\nadditive. This means, for example, that if three senders send a 1 value, and a\nfourth sender sends a −1 value during the same mini-slot, then the received\nsignal at all receivers during that mini-slot is a 2 (since 1 + 1 + 1 − 1 = 2). In the presence of multiple senders, sender s computes its encoded\ntransmissions, Z s\ni,m, in exactly the same manner as in Equation 7.1. The\nvalue received at a receiver during the\nmth mini-slot of the ith bit slot, however, is now the sum of the transmitted\nbits from all N senders during that mini-slot:\nZ\n*\ni, m =\nN\n∑\ns=1\nZ s\ni,m\nAmazingly, if the senders’ codes are chosen carefully, each receiver can\nrecover the data sent by a given sender out of the aggregate signal simply\ni,m\ni\ndi =\nM\nM\n∑\nm=1\nZi,m ⋅cm\n(7.2)"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 929,
    "text": "by using the sender’s code in exactly the same manner as in Equation 7.2:\nas shown in Figure 7.6, for a two-sender CDMA example. The M-bit\nCDMA code being used by the upper sender is (1, 1, 1, −1, 1, −1, −1, −1),\nwhile the CDMA code being used by the lower sender is (1, −1, 1, 1, 1, −1,\n1, 1). Figure 7.6 illustrates a receiver recovering the original data bits from\nthe upper sender. Note that the receiver is able to extract the data from\nsender 1 in spite of the interfering transmission from sender 2.\ndi =\nM\nM\n∑\nm=1\nZ\n*\ni,m ⋅cm\n(7.3)"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 930,
    "text": "Figure 7.6 ♦A two-sender CDMA example\nRecall our cocktail analogy from Chapter 6. A CDMA protocol is\nsimilar to having partygoers speaking in multiple languages; in such\ncircumstances humans are actually quite good at locking into the\nconversation in the language they understand, while filtering out the\nremaining conversations. We see here that CDMA is a partitioning protocol"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 931,
    "text": "in that it partitions the codespace (as opposed to time or frequency) and\nassigns each node a dedicated piece of the codespace. Our discussion here of CDMA is necessarily brief; in practice a number\nof difficult issues must be addressed. First, in order for the CDMA receivers\nto be able to extract a particular sender’s signal, the CDMA codes must be\ncarefully chosen. ­Second, our discussion has assumed that the received\nsignal strengths from various senders are the same; in reality, this can be\ndifficult to achieve. There is a considerable body of literature addressing\nthese and other issues related to CDMA; see ­[Pickholtz 1982; Viterbi 1995]\nfor details."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 932,
    "text": "7.3 WiFi: 802.11 Wireless LANs\nPervasive in the workplace, the home, educational institutions, cafés,\nairports, and street corners, wireless LANs are now one of the most\nimportant access network technologies in the Internet today. Although many\ntechnologies and standards for wireless LANs were developed in the 1990s,\none particular class of standards has clearly emerged as the winner: the\nIEEE 802.11 wireless LAN, also known as WiFi. In this section, we’ll take\na close look at 802.11 wireless LANs, examining its frame structure, its\nmedium access protocol, and its internetworking of 802.11 LANs with\nwired Ethernet LANs. As summarized in Table 7.1, there are several 802.11 standards [IEEE\n802.11 2020]. The 802.11 b, g, n, ac, ax are successive generations of\n802.11 technology aimed for wireless local area networks (WLANs),\ntypically less than 70 m range in a home office, workplace, or business\nsetting. The 802.11 n, ac, and ax standards have recently been branded as\nWiFi 4, 5 and 6, respectively—no doubt competing with 4G and 5G cellular\nnetwork branding. The 802.11 af, ah standards operate over longer distances\nand are aimed at Internet of Things, sensor networks, and metering\napplications. The different 802.11 b, g, n, ac, ax standards all share some common\ncharacteristics, including the 802.11 frame format that we will study shortly,\nand are backward compatible, meaning, for example, that a mobile capable\nonly of 802.11 g may still interact with a newer 802.11 ac or 802.11 ax base\nstation. They also all use the same medium access protocol, CSMA/CA,\nwhich we’ll also discuss shortly, while also 802.11 ax also supports"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 933,
    "text": "centralized scheduling by the base station of transmissions from associated\nwireless devices. However, as shown in Table 7.1, the standards have some major\ndifferences at the physical layer. 802.11 devices operate in two different\nfrequency ranges: 2.4–2.485 GHz (referred to as the 2.4 GHz range) and\n5.1–5.8 GHz (referred to as the 5 GHz range). The 2.4 GHz range is an\nunlicensed frequency band, where 802.11 devices may compete for\nfrequency spectrum with 2.4 GHz phones and appliances such as\nmicrowave ovens. At 5 GHz, 802.11 LANs have a shorter transmission\ndistance for a given power level and suffer more from multipath\npropagation. The 802.11n, 802.11ac, and 802.11ax standards use multiple\ninput multiple-output (MIMO) antennas; that is, two or more antennas on\nthe sending side and two or more antennas on the receiving side that are\ntransmitting/receiving different signals [Diggavi 2004]. 802.11ac and\n802.11 ax base stations may transmit to multiple stations simultaneously,\nand use “smart” antennas to adaptively beamform to target transmissions in\nthe direction of a receiver. This decreases interference and increases the\ndistance reached at a given data rate. The data rates shown in Table 7.1 are\nfor an idealized environment, for example, a receiver close to the base\nstation, with no ­interference—a scenario that we’re unlikely to experience\nin practice! So as the saying goes, YMMV: Your Mileage (or in this case\nyour wireless data rate) May Vary. Table 7.1 ♦Summary of IEEE 802.11 standards\n7.3.1 The 802.11 Wireless LAN Architecture\nFigure 7.7 illustrates the principal components of the 802.11 wireless LAN\narchitecture. The fundamental building block of the 802.11 architecture is"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 934,
    "text": "the basic service set (BSS). A BSS contains one or more wireless stations\nand a central base station, known as an access point (AP) in 802.11\nparlance. Figure 7.7 shows the AP in each of two BSSs connecting to an\ninterconnection device (such as a switch or router), which in turn leads to\nthe Internet. In a typical home network, there is one AP and one router\n(typically integrated together as one unit) that connects the BSS to the\nInternet. Figure 7.7 ♦IEEE 802.11 LAN architecture\nAs with Ethernet devices, each 802.11 wireless station has a 6-byte\nMAC address that is stored in the firmware of the station’s adapter (that is,\n802.11 network interface card). Each AP also has a MAC address for its"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 935,
    "text": "wireless interface. As with Ethernet, these MAC addresses are administered\nby IEEE and are (in theory) ­globally unique. As noted in Section 7.1, wireless LANs that deploy APs are often\nreferred to as infrastructure wireless LANs, with the “infrastructure”\nbeing the APs along with the wired Ethernet infrastructure that\ninterconnects the APs and a router. Figure 7.8 shows that IEEE 802.11\nstations can also group themselves together to form an ad hoc network—a\nnetwork with no central control and with no connections to the ­“outside\nworld.” Here, the network is formed “on the fly,” by mobile devices that\nhave found themselves in proximity to each other, that have a need to\ncommunicate, and that find no preexisting network infrastructure in their\nlocation. An ad hoc network might be formed when people with laptops get\ntogether (e.g., in a conference room, a train, or a car) and want to exchange\ndata in the absence of a centralized AP. There has been tremendous interest\nin ad hoc networking, as communicating portable devices continue to\nproliferate. In this section, though, we’ll focus our attention on\ninfrastructure wireless LANs."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 936,
    "text": "Figure 7.8 ♦An IEEE 802.11 ad hoc network\nChannels and Association\nIn 802.11, each wireless station needs to associate with an AP before it can\nsend or receive network-layer data. Although all of the 802.11 standards use\nassociation, we’ll discuss this topic specifically in the context of IEEE\n802.11b, g, n, ac, ax. When a network administrator installs an AP, the administrator assigns\na one- or two-word Service Set Identifier (SSID) to the access point. (When you choose Wi-Fi under Setting on your iPhone, for example, a list\nis displayed showing the SSID of each AP in range.) The administrator must\nalso assign a channel number to the AP. To understand channel numbers,\nrecall that 802.11 operates in the frequency range of 2.4 GHz to 2.4835\nGHz. Within this 85 MHz band, 802.11 defines 11 partially overlapping\nchannels. Any two channels are non-overlapping if and only if they are\nseparated by four or more channels. In particular, the set of channels 1, 6,\nand 11 is the only set of three non-overlapping channels. This means that an\nadministrator could create a wireless LAN with an aggregate maximum\ntransmission rate of three times the maximum transmission rate shown in\nTable 7.1 by installing three 802.11 APs at the same physical location,\nassigning channels 1, 6, and 11 to the APs, and interconnecting each of the\nAPs with a switch. Now that we have a basic understanding of 802.11 channels, let’s\ndescribe an interesting (and not completely uncommon) situation—that of a\nWiFi jungle. A WiFi jungle is any physical location where a wireless\nstation receives a sufficiently strong signal from two or more APs. For\nexample, in many cafés in New York City, a wireless station can pick up a\nsignal from numerous nearby APs. One of the APs might be managed by"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 937,
    "text": "the café, while the other APs might be in residential apartments near the\ncafé. Each of these APs would likely be located in a different IP subnet and\nwould have been independently assigned a channel. Now suppose you enter such a WiFi jungle with your smartphone,\ntablet, or ­laptop, seeking wireless Internet access and a blueberry muffin. Suppose there are five APs in the WiFi jungle. To gain Internet access, your\nwireless device needs to join exactly one of the subnets and hence needs to\nassociate with exactly one of the APs. ­Associating means the wireless\ndevice creates a virtual wire between itself and the AP. Specifically, only the\nassociated AP will send data frames (that is, frames containing data, such as\na datagram) to your wireless device, and your wireless device will send data\nframes into the Internet only through the associated AP. But how does your\nwireless device associate with a particular AP? And more fundamentally,\nhow does your wireless device know which APs, if any, are out there in the\njungle? The 802.11 standard requires that an AP periodically send beacon\nframes, each of which includes the AP’s SSID and MAC address. Your\nwireless device, knowing that APs are sending out beacon frames, scans the\n11 channels, seeking beacon frames from any APs that may be out there\n(some of which may be transmitting on the same channel—it’s a jungle out\nthere!). Having learned about available APs from the beacon frames, you\n(or your wireless device) select one of the APs for association. The 802.11 standard does not specify an algorithm for selecting which\nof the available APs to associate with; that algorithm is left up to the\ndesigners of the 802.11 firmware and software in your wireless device. Typically, the device chooses the AP whose beacon frame is received with\nthe highest signal strength. While a high signal strength is good (see, e.g.,\nFigure 7.3), signal strength is not the only AP characteristic that will"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 938,
    "text": "determine the performance a device receives. In particular, it’s possible that\nthe selected AP may have a strong signal, but may be overloaded with other\naffiliated devices (that will need to share the wireless bandwidth at that AP),\nwhile an unloaded AP is not selected due to a slightly weaker signal. A\nnumber of alternative ways of choosing APs have thus recently been\nproposed [Vasudevan 2005; Nicholson 2006; Sundaresan 2006]. For an\ninteresting and down-to-earth discussion of how signal strength is\nmeasured, see [Bardwell 2004]. The process of scanning channels and listening for beacon frames is\nknown as passive scanning (see Figure 7.9a). A wireless device can also\nperform active scanning, by broadcasting a probe frame that will be\nreceived by all APs within the wireless device’s range, as shown in Figure\n7.9b. APs respond to the probe request frame with a probe response frame. The wireless device can then choose the AP with which to associate from\namong the responding APs. Figure 7.9 ♦Active and passive scanning for access points"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 939,
    "text": "After selecting the AP with which to associate, the wireless device\nsends an association request frame to the AP, and the AP responds with an\nassociation response frame. Note that this second request/response\nhandshake is needed with active scanning, since an AP responding to the\ninitial probe request frame doesn’t know which of the (possibly many)\nresponding APs the device will choose to associate with, in much the same\nway that a DHCP client can choose from among multiple DHCP servers\n(see Figure 4.21). Once associated with an AP, the device will want to join\nthe subnet (in the IP addressing sense of Section 4.3.3) to which the AP\nbelongs. Thus, the device will typically send a DHCP discovery message\n(see Figure 4.21) into the subnet via the AP in order to obtain an IP address\non the subnet. Once the address is obtained, the rest of the world then views\nthat device simply as another host with an IP address in that subnet. In order to create an association with a particular AP, the wireless\ndevice may be required to authenticate itself to the AP. 802.11 wireless\nLANs provide a number of alternatives for authentication and access. One\napproach, used by many companies, is to permit access to a wireless\nnetwork based on a device’s MAC address. A second approach, used by\nmany Internet cafés, employs usernames and passwords. In both cases, the\nAP typically communicates with an authentication server, relaying\ninformation between the wireless device and the authentication server using\na protocol such as RADIUS [RFC 2865] or DIAMETER [RFC 6733]. Separating the authentication server from the AP allows one authentication\nserver to serve many APs, centralizing the (often sensitive) decisions of\nauthentication and access within the single server, and keeping AP costs and\ncomplexity low. We’ll see in Chapter 8 that the new IEEE 802.11i protocol\ndefining security aspects of the 802.11 protocol family takes precisely this\napproach."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 940,
    "text": "7.3.2 The 802.11 MAC Protocol\nOnce a wireless device is associated with an AP, it can start sending and\nreceiving data frames to and from the access point. But because multiple\nwireless devices, or the AP itself may want to transmit data frames at the\nsame time over the same channel, a multiple access protocol is needed to\ncoordinate the transmissions. In the following, we'll refer to the devices or\nthe AP as wireless “stations” that share the multiple access channel. As\ndiscussed in Chapter 6 and Section 7.2.1, broadly speaking there are three\nclasses of multiple access protocols: channel partitioning (including\nCDMA), random access, and taking turns. Inspired by the huge success of\nEthernet and its random access protocol, the designers of 802.11 chose a\nrandom access protocol for 802.11 wireless LANs. This random access\nprotocol is referred to as CSMA with collision avoidance, or more\nsuccinctly as CSMA/CA. As with Ethernet’s CSMA/CD, the “CSMA” in\nCSMA/CA stands for “carrier sense multiple access,” meaning that each\nstation senses the channel before transmitting, and refrains from\ntransmitting when the channel is sensed busy. Although both ­Ethernet and\n802.11 use carrier-sensing random access, the two MAC protocols have\nimportant differences. First, instead of using collision detection, 802.11 uses\ncollision-avoidance techniques. Second, because of the relatively high bit\nerror rates of wireless channels, 802.11 (unlike Ethernet) uses a link-layer\nacknowledgment/retransmission (ARQ) scheme. We’ll describe 802.11’s\ncollision-avoidance and link-layer acknowledgment schemes below. Recall from Sections 6.3.2 and 6.4.2 that with Ethernet’s collision-\ndetection algorithm, an Ethernet station listens to the channel as it transmits. If, while transmitting, it detects that another station is also transmitting, it\naborts its transmission and tries to transmit again after waiting a small,\nrandom amount of time. Unlike the 802.3 Ethernet protocol, the 802.11"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 941,
    "text": "MAC protocol does not implement collision detection. There are two\nimportant reasons for this:\n•\nThe ability to detect collisions requires the ability to send (the station’s\nown ­signal) and receive (to determine whether another station is also\ntransmitting) at the same time. Because the strength of the received\nsignal is typically very small compared to the strength of the transmitted\nsignal at the 802.11 adapter, it is costly to build hardware that can detect\na collision. •\nMore importantly, even if the adapter could transmit and listen at the\nsame time (and presumably abort transmission when it senses a busy\nchannel), the adapter would still not be able to detect all collisions, due\nto the hidden terminal problem and fading, as discussed in Section 7.2. Because 802.11wireless LANs do not use collision detection, once a\nstation begins to transmit a frame, it transmits the frame in its entirety; that\nis, once a station gets started, there is no turning back. As one might expect,\ntransmitting entire frames (particularly long frames) when collisions are\nprevalent can significantly degrade a multiple access protocol’s\nperformance. In order to reduce the likelihood of collisions, 802.11 employs\nseveral collision-avoidance techniques, which we’ll shortly discuss. Before considering collision avoidance, however, we’ll first need to\nexamine 802.11’s link-layer acknowledgment scheme. Recall from\nSection 7.2 that when a station in a wireless LAN sends a frame, the frame\nmay not reach the destination station intact for a variety of reasons. To deal\nwith this non-negligible chance of failure, the 802.11 MAC protocol uses\nlink-layer acknowledgments. As shown in Figure 7.10, when the destination\nstation receives a frame that passes the CRC, it waits a short period of time\nknown as the Short Inter-frame Spacing (SIFS) and then sends back an"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 942,
    "text": "acknowledgment frame. If the transmitting station does not receive an\nacknowledgment within a given amount of time, it assumes that an error has\noccurred and retransmits the frame, using the CSMA/CA protocol to access\nthe channel. If an acknowledgment is not received after some fixed number\nof retransmissions, the transmitting station gives up and discards the frame. Figure 7.10 ♦802.11 uses link-layer acknowledgments\nHaving discussed how 802.11 uses link-layer acknowledgments, we’re\nnow in a position to describe the 802.11 CSMA/CA protocol. Suppose that\na station (wireless device or an AP) has a frame to transmit."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 943,
    "text": "1. If initially the station senses the channel idle, it transmits its frame after\na short period of time known as the Distributed Inter-frame Space\n(DIFS); see ­Figure 7.10. 2. Otherwise, the station chooses a random backoff value using binary\nexponential backoff (as we encountered in Section 6.3.2) and counts\ndown this value after DIFS when the channel is sensed idle. While the\nchannel is sensed busy, the counter value remains frozen. 3. When the counter reaches zero (note that this can only occur while the\nchannel is sensed idle), the station transmits the entire frame and then\nwaits for an acknowledgment. 4. If an acknowledgment is received, the transmitting station knows that its\nframe has been correctly received at the destination station. If the station\nhas another frame to send, it begins the CSMA/CA protocol at step 2. If\nthe acknowledgment isn’t received, the transmitting station reenters the\nbackoff phase in step 2, with the random value chosen from a larger\ninterval. Recall that under Ethernet’s CSMA/CD, multiple access protocol\n(Section 6.3.2), a station begins transmitting as soon as the channel is\nsensed idle. With CSMA/CA, however, the station refrains from\ntransmitting while counting down, even when it senses the channel to be\nidle. Why do CSMA/CD and CDMA/CA take such different approaches\nhere? To answer this question, let’s consider a scenario in which two stations\neach have a data frame to transmit, but neither station transmits\nimmediately because each senses that a third station is already transmitting. With Ethernet’s CSMA/CD, the two stations would each transmit as soon as\nthey detect that the third station has finished transmitting. This would cause\na collision, which isn’t a serious issue in CSMA/CD, since both stations"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 944,
    "text": "would abort their transmissions and thus avoid the useless transmissions of\nthe remainders of their frames. In 802.11, however, the situation is quite\ndifferent. Because 802.11 does not detect a collision and abort transmission,\na frame suffering a collision will be transmitted in its entirety. The goal in\n802.11 is thus to avoid collisions whenever possible. In 802.11, if the two\nstations sense the channel busy, they both immediately enter random\nbackoff, hopefully choosing different backoff values. If these values are\nindeed different, once the channel becomes idle, one of the two stations will\nbegin transmitting before the other, and (if the two stations are not hidden\nfrom each other) the “losing station” will hear the “winning station’s”\nsignal, freeze its counter, and refrain from transmitting until the winning\nstation has completed its transmission. In this manner, a costly collision is\navoided. Of course, collisions can still occur with 802.11 in this scenario:\nThe two stations could be hidden from each other, or the two stations could\nchoose random backoff values that are close enough that the transmission\nfrom the station starting first have yet to reach the second station. Recall\nthat we encountered this problem earlier in our discussion of random access\nalgorithms in the context of Figure 6.12. Dealing with Hidden Terminals: RTS and CTS\nThe 802.11 MAC protocol also includes a nifty (but optional) reservation\nscheme that helps avoid collisions even in the presence of hidden terminals. Let’s investigate this scheme in the context of Figure 7.11, which shows\ntwo wireless ­stations and one access point. Both of the wireless stations are\nwithin range of the AP (whose ­coverage is shown as a shaded circle) and\nboth have associated with the AP. ­However, due to fading, the signal ranges\nof wireless stations are limited to the interiors of the shaded circles shown"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 945,
    "text": "in Figure 7.11. Thus, each of the wireless stations is hidden from the other,\nalthough neither is hidden from the AP. Figure 7.11 ♦Hidden terminal example: H1 is hidden from H2, and\nvice versa\nLet’s now consider why hidden terminals can be problematic. Suppose\nStation H1 is transmitting a frame and halfway through H1’s transmission,\nStation H2 wants to send a frame to the AP. H2, not hearing the\ntransmission from H1, will first wait a DIFS interval and then transmit the\nframe, resulting in a collision. The channel will therefore be wasted during\nthe entire period of H1’s transmission as well as during H2’s transmission. In order to avoid this problem, the IEEE 802.11 protocol allows a\nstation to use a short Request to Send (RTS) control frame and a short\nClear to Send (CTS) control frame to reserve access to the channel. When\na sender wants to send a DATA frame, it can first send an RTS frame to the\nAP, indicating the total time required to transmit the DATA frame and the\nacknowledgment (ACK) frame. When the AP receives the RTS frame, it"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 946,
    "text": "responds by broadcasting a CTS frame. This CTS frame serves two\npurposes: It gives the sender explicit permission to send and also instructs\nthe other stations not to send for the reserved duration. Thus, in Figure 7.12, before transmitting a DATA frame, H1 first\nbroadcasts an RTS frame, which is heard by all stations in its circle,\nincluding the AP. The AP then responds with a CTS frame, which is heard\nby all stations within its range, including H1 and H2. Station H2, having\nheard the CTS, refrains from transmitting for the time specified in the CTS\nframe. The RTS, CTS, DATA, and ACK frames are shown in Figure 7.12."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 947,
    "text": "Figure 7.12 ♦Collision avoidance using the RTS and CTS frames"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 948,
    "text": "The use of the RTS and CTS frames can improve performance in two\nimportant ways:\n•\nThe hidden station problem is mitigated, since a long DATA frame is\ntransmitted only after the channel has been reserved. •\nBecause the RTS and CTS frames are short, a collision involving an\nRTS or CTS frame will last only for the duration of the short RTS or\nCTS frame. Once the RTS and CTS frames are correctly transmitted,\nthe following DATA and ACK frames should be transmitted without\ncollisions. You are encouraged to check out the 802.11 animation in the textbook’s\nWeb site. This interactive animation illustrates the CSMA/CA protocol,\nincluding the RTS/CTS exchange sequence. Although the RTS/CTS exchange can help reduce collisions, it also\nintroduces delay and consumes channel resources. For this reason, the\nRTS/CTS exchange is only used (if at all) to reserve the channel for the\ntransmission of a long DATA frame. In practice, each wireless station can\nset an RTS threshold such that the RTS/CTS sequence is used only when\nthe frame is longer than the threshold. For many wireless stations, the\ndefault RTS threshold value is larger than the maximum frame length, so\nthe RTS/CTS sequence is skipped for all DATA frames sent. Using 802.11 as a Point-to-Point Link\nOur discussion so far has focused on the use of 802.11 in a multiple access\nsetting. We should mention that if two nodes each have a directional\nantenna, they can point their directional antennas at each other and run the\n802.11 protocol over what is essentially a point-to-point link. Given the low\ncost of commodity 802.11 hardware, the use of directional antennas and an"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 949,
    "text": "increased transmission power allow 802.11 to be used as an inexpensive\nmeans of providing wireless point-to-point connections over tens of\nkilometers distance. [Raman 2007] describes one of the first such multi-hop\nwireless networks, operating in the rural Ganges plains in India using point-\nto-point 802.11 links. 7.3.3 The IEEE 802.11 Frame\nAlthough the 802.11 frame shares many similarities with an Ethernet frame,\nit also contains a number of fields that are specific to its use for wireless\nlinks. The 802.11 frame is shown in Figure 7.13. The numbers above each\nof the fields in the frame represent the lengths of the fields in bytes; the\nnumbers above each of the subfields in the frame control field represent the\nlengths of the subfields in bits. Let’s now examine the fields in the frame as\nwell as some of the more important subfields in the frame’s control field. Figure 7.13 ♦The 802.11 frame\nPayload and CRC Fields\nAt the heart of the frame is the payload, which typically consists of an IP\ndatagram or an ARP packet. Although the field is permitted to be as long as"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 950,
    "text": "2,312 bytes, it is typically fewer than 1,500 bytes, holding an IP datagram\nor an ARP packet. As with an Ethernet frame, an 802.11 frame includes a\n32-bit cyclic redundancy check (CRC) so that the receiver can detect bit\nerrors in the received frame. As we’ve seen, bit errors are much more\ncommon in wireless LANs than in wired LANs, so the CRC is even more\nuseful here. Address Fields\nPerhaps the most striking difference in the 802.11 frame is that it has four\naddress fields, each of which can hold a 6-byte MAC address. But why four\naddress fields? Doesn’t a source MAC field and destination MAC field\nsuffice, as they do for ­Ethernet? It turns out that three address fields are\nneeded for internetworking ­purposes—specifically, for moving the\nnetwork-layer datagram from a wireless station through an AP to a router\ninterface. The fourth address field is used when APs ­forward frames to each\nother in ad hoc mode. Since we are only considering infrastructure\nnetworks here, let’s focus our attention on the first three address fields. The\n802.11 standard defines these fields as follows:\n•\nAddress 2 is the MAC address of the station that transmits the frame. Thus, if a wireless station transmits the frame, that station’s MAC\naddress is inserted in the address 2 field. Similarly, if an AP transmits\nthe frame, the AP’s MAC address is inserted in the address 2 field. •\nAddress 1 is the MAC address of the wireless station that is to receive\nthe frame. Thus if a mobile wireless station transmits the frame, address\n1 contains the MAC address of the destination AP. Similarly, if an AP\ntransmits the frame, address 1 contains the MAC address of the\ndestination wireless station."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 951,
    "text": "•\nTo understand address 3, recall that the BSS (consisting of the AP and\nwireless stations) is part of a subnet, and that this subnet connects to\nother subnets via some router interface. Address 3 contains the MAC\naddress of this router ­interface. To gain further insight into the purpose of address 3, let’s walk through\nan internetworking example in the context of Figure 7.14. In this figure,\nthere are two APs, each of which is responsible for a number of wireless\nstations. Each of the APs has a direct connection to a router, which in turn\nconnects to the global Internet. We should keep in mind that an AP is a link-\nlayer device, and thus neither “speaks” IP nor understands IP addresses. Consider now moving a datagram from the router interface R1 to the\nwireless Station H1. The router is not aware that there is an AP between it\nand H1; from the router’s perspective, H1 is just a host in one of the subnets\nto which it (the router) is connected."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 952,
    "text": "Figure 7.14 ♦The use of address fields in 802.11 frames: Sending\nframes between H1 and R1\n•\nThe router, which knows the IP address of H1 (from the destination\naddress of the datagram), uses ARP to determine the MAC address of\nH1, just as in an ordinary Ethernet LAN. After obtaining H1’s MAC\naddress, router interface R1 encapsulates the datagram within an\nEthernet frame. The source address field of this frame contains R1’s\nMAC address, and the destination address field contains H1’s MAC\naddress. •\nWhen the Ethernet frame arrives at the AP, the AP converts the 802.3\nEthernet frame to an 802.11 frame before transmitting the frame into the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 953,
    "text": "wireless channel. The AP fills in address 1 and address 2 with H1’s\nMAC address and its own MAC address, respectively, as described\nabove. For address 3, the AP inserts the MAC address of R1. In this\nmanner, H1 can determine (from address 3) the MAC address of the\nrouter interface that sent the datagram into the subnet. Now consider what happens when the wireless station H1 responds by\nmoving a datagram from H1 to R1. •\nH1 creates an 802.11 frame, filling the fields for address 1 and address 2\nwith the AP’s MAC address and H1’s MAC address, respectively, as\ndescribed above. For address 3, H1 inserts R1’s MAC address. •\nWhen the AP receives the 802.11 frame, it converts the frame to an\nEthernet frame. The source address field for this frame is H1’s MAC\naddress, and the destination address field is R1’s MAC address. Thus,\naddress 3 allows the AP to determine the appropriate destination MAC\naddress when constructing the Ethernet frame. In summary, address 3 plays a crucial role for internetworking the BSS with\na wired LAN. Sequence Number, Duration, and Frame Control Fields\nRecall that in 802.11, whenever a station correctly receives a frame from\nanother \nstation, \nit \nsends \nback \nan \nacknowledgment. Because\nacknowledgments can get lost, the sending station may send multiple copies\nof a given frame. As we saw in our discussion of the rdt2.1 protocol\n(Section 3.4.1), the use of sequence numbers allows the receiver to\ndistinguish between a newly transmitted frame and the retransmission of a\nprevious frame. The sequence number field in the 802.11 frame thus serves"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 954,
    "text": "exactly the same purpose here at the link layer as it did in the transport layer\nin Chapter 3. Recall that the 802.11 protocol allows a transmitting station to reserve\nthe channel for a period of time that includes the time to transmit its data\nframe and the time to transmit an acknowledgment. This duration value is\nincluded in the frame’s duration field (both for data frames and for the RTS\nand CTS frames). As shown in Figure 7.13, the frame control field includes many\nsubfields. We’ll say just a few words about some of the more important\nsubfields; for a more complete discussion, you are encouraged to consult\nthe 802.11 specification [Held 2001; Crow 1997; IEEE 802.11 1999]. The\ntype and subtype fields are used to distinguish the association, RTS, CTS,\nACK, and data frames. The to and from fields are used to define the\nmeanings of the different address fields. (These meanings change\ndepending on whether ad hoc or infrastructure modes are used and, in the\ncase of infrastructure mode, whether a wireless station or an AP is sending\nthe frame.) Finally the WEP field indicates whether encryption is being\nused or not (WEP is discussed in Chapter 8). 7.3.4 Mobility in the Same IP Subnet\nIn order to increase the physical range of a wireless LAN, companies and\nuniversities will often deploy multiple BSSs within the same IP subnet. This\nnaturally raises the issue of mobility among the BSSs—how do wireless\nstations seamlessly move from one BSS to another while maintaining\nongoing TCP sessions? As we’ll see in this subsection, mobility can be\nhandled in a relatively straightforward manner when the BSSs are part of\nthe subnet. When stations move between subnets, more sophisticated"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 955,
    "text": "mobility management protocols will be needed, such as those we’ll study in\nSections 7.5 and 7.6. Let’s now look at a specific example of mobility between BSSs in the\nsame subnet. Figure 7.15 shows two interconnected BSSs with a host, H1,\nmoving from BSS1 to BSS2. Because in this example the interconnection\ndevice that connects the two BSSs is not a router, all of the stations in the\ntwo BSSs, including the APs, belong to the same IP subnet. Thus, when H1\nmoves from BSS1 to BSS2, it may keep its IP address and all of its ongoing\nTCP connections. If the interconnection device were a router, then H1\nwould have to obtain a new IP address in the subnet in which it was\nmoving. This address change would disrupt (and eventually terminate) any\non-going TCP connections at H1. In Section 7.6, we’ll see how a network-\nlayer mobility protocol, such as mobile IP, can be used to avoid this\nproblem. Figure 7.15 ♦Mobility in the same subnet"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 956,
    "text": "But what specifically happens when H1 moves from BSS1 to BSS2? As\nH1 wanders away from AP1, H1 detects a weakening signal from AP1 and\nstarts to scan for a stronger signal. H1 receives beacon frames from AP2\n(which in many corporate and university settings will have the same SSID\nas AP1). H1 then disassociates with AP1 and associates with AP2, while\nkeeping its IP address and maintaining its ongoing TCP sessions. This addresses the handover problem from the host and AP viewpoint. But what about the switch in Figure 7.15? How does it know that the host\nhas moved from one AP to another? As you may recall from Chapter 6,\nswitches are “self-learning” and automatically build their forwarding tables. This self-learning feature nicely handles occasional moves (for example,\nwhen an employee gets transferred from one department to another);\nhowever, switches were not designed to support highly mobile users who\nwant to maintain TCP connections while moving between BSSs. To\nappreciate the problem here, recall that before the move, the switch has an\nentry in its forwarding table that pairs H1’s MAC address with the outgoing\nswitch interface through which H1 can be reached. If H1 is initially in\nBSS1, then a datagram destined to H1 will be directed to H1 via AP1. Once\nH1 associates with BSS2, however, its frames should be directed to AP2. One solution (a bit of a hack, really) is for AP2 to send a broadcast Ethernet\nframe with H1’s source address to the switch just after the new association. When the switch receives the frame, it updates its forwarding table,\nallowing H1 to be reached via AP2. The 802.11f standards group is\ndeveloping an inter-AP protocol to handle these and related issues. Our discussion above has focused on mobility with the same LAN\nsubnet. Recall that VLANs, which we studied in Section 6.4.4, can be used\nto connect together islands of LANs into a large virtual LAN that can span a"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 6",
    "source": "kurose",
    "page": 957,
    "text": "large geographical region. Mobility among base stations within such a\nVLAN can be handled in exactly the same manner as above [Yu 2011]. CASE HISTORY\nLOCATION DISCOVERY: GPS AND WIFI POSITIONING\nMany of the most useful and important smartphone apps today are location-based\nmobile apps, including Foursquare, Yelp, Uber, Pokémon Go, and Waze. These ­-\nsoftware apps all make use of an API that allows them to extract their current\ngeographical position directly from the smartphone. Have you ever wondered how your\nsmartphone obtains its geographical position? Today, it is done by combining two\nsystems, the Global Positioning System (GPS) and the WiFi Positioning System\n(WPS). The GPS, with a constellation of 30+ satellites, broadcasts satellite location and\ntiming information, which in turn is used by each GPS receiver to estimate its\ngeolocation. The United States government created the system, maintains it, and\nmakes it freely accessible to anyone with a GPS receiver. The satellites have very\nstable atomic clocks that are synchronized with one another and with ground clocks. The satellites also know their locations with great precision. Each GPS satellite\ncontinuously broadcasts a radio signal containing its current time and position. If a\nGPS receiver obtains this information from at least four satellites, it can solve\ntriangulation equations to estimate its position. GPS, however, cannot always provide accurate geolocations if it does not have line-\nof-sight with at least four GPS satellites or when there is interference from other high-\nfrequency communication systems. This is particularly true in urban environments,\nwhere tall buildings frequently block GPS signals. This is where WiFi positioning ­-\nsystems come to the rescue. WiFi positioning systems make use of databases of WiFi\naccess points, which are independently maintained by various Internet companies,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 958,
    "text": "including Google, Apple, and Microsoft. Each database contains information about\nmillions of WiFi access points, including each access point’s SSID and an estimate of\nits geographic location. To understand how a WiFi positioning system makes use of\nsuch a database, consider an Android smartphone along with the Google location\nservice. From each nearby access point, the smartphone receives and measures the\nsignal strength of beacon signals (see Section 7.3.1), which contain the access point’s\nSSID. The smartphone can therefore continually send messages to the Google\nlocation service (in the cloud) that include the SSIDs of nearby access points and the\ncorresponding signal strengths. It will also send its GPS position (obtained via the\nsatellite broadcast signals, as described above) when available. Using the signal-\nstrength information, Google will estimate the distance between the smartphone and\neach of the WiFi access points. Leveraging these estimated distances, it can then\nsolve triangulation equations to estimate the smartphone’s geolocation. Finally, this\nWiFi-based estimate is combined with the GPS satellite-based estimate to form an\naggregate estimate, which is then sent back to the smartphone and used by the\nlocation-based mobile apps. But you may still be wondering how Google (and Apple, Microsoft, and so on) obtain\nand maintain the database of access points, and in particular, the access point’s\ngeographic location? Recall that for a given access point, every nearby Android\nsmartphone will send to the Google location service the strength of the ­signal received\nfrom the access point as well as the smartphone’s estimated location. Given that\nthousands of smartphones may be passing by the access point during any single day,\nGoogle’s location service will have lots of data at its disposition to use in estimating the\naccess point’s position, again by solving triangulation equations. Thus, the access\npoints help the smartphones determine their locations, and in turn the smartphones\nhelp the access points determine their locations!"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 959,
    "text": "7.3.5 Advanced Features in 802.11\nWe’ll wrap up our coverage of 802.11 with a short discussion of two\nadvanced capabilities found in 802.11 networks. As we’ll see, these\ncapabilities are not completely specified in the 802.11 standard, but rather\nare made possible by mechanisms specified in the standard. This allows\ndifferent vendors to implement these capabilities using their own\n(proprietary) approaches, presumably giving them an edge over the\ncompetition. 802.11 Rate Adaptation\nWe saw earlier in Figure 7.3 that different modulation techniques (with the\ndifferent transmission rates that they provide) are appropriate for different\nSNR scenarios. Consider, for example, a mobile 802.11 user who is initially\n20 meters away from the base station, with a high signal-to-noise ratio. Given the high SNR, the user can communicate with the base station using\na physical-layer modulation technique that provides high transmission rates\nwhile maintaining a low BER. This is one happy user! Suppose now that the\nuser becomes mobile, walking away from the base station, with the SNR\nfalling as the distance from the base station increases. In this case, if the\nmodulation technique used in the 802.11 protocol operating between the\nbase station and the user does not change, the BER will become\nunacceptably high as the SNR decreases, and eventually no transmitted\nframes will be received correctly. For this reason, some 802.11 implementations have a rate adaptation\ncapability that adaptively selects the underlying physical-layer modulation\ntechnique to use based on current or recent channel characteristics. If a node\nsends two frames in a row without receiving an acknowledgment (an"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 960,
    "text": "implicit indication of bit errors on the channel), the transmission rate falls\nback to the next lower rate. If 10 frames in a row are acknowledged, or if a\ntimer that tracks the time since the last fallback expires, the transmission\nrate increases to the next higher rate. This rate adaptation mechanism shares\nthe same “probing” philosophy as TCP’s congestion-control mechanism—\nwhen conditions are good (reflected by ACK receipts), the transmission rate\nis increased until something “bad” happens (the lack of ACK receipts);\nwhen something “bad” happens, the transmission rate is reduced. 802.11\nrate adaptation and TCP congestion control are thus similar to the young\nchild who is constantly pushing his/her parents for more and more (say\ncandy for a young child, later curfew hours for the teenager) until the\nparents finally say “Enough!” and the child backs off (only to try again later\nafter conditions have hopefully improved!). A number of other schemes\nhave also been proposed to improve on this basic automatic rate-adjustment\nscheme [Kamerman 1997; Holland 2001; Lacage 2004]. Power Management\nPower is a precious resource in mobile devices, and thus the 802.11\nstandard provides power-management capabilities that allow 802.11 nodes\nto minimize the amount of time that their sense, transmit, and receive\nfunctions and other circuitry need to be “on.” 802.11 power management\noperates as follows. A node is able to explicitly alternate between sleep and\nwake states (not unlike a sleepy student in a classroom!). A node indicates\nto the access point that it will be going to sleep by setting the power-\nmanagement bit in the header of an 802.11 frame to 1. A timer in the node is\nthen set to wake up the node just before the AP is scheduled to send its\nbeacon frame (recall that an AP typically sends a beacon frame every 100\nmsec). Since the AP knows from the set power-transmission bit that the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 961,
    "text": "node is going to sleep, it (the AP) knows that it should not send any frames\nto that node, and will buffer any frames destined for the sleeping host for\nlater transmission. A node will wake up just before the AP sends a beacon frame, and\nquickly enter the fully active state (unlike the sleepy student, this wakeup\nrequires only 250 microseconds [Kamerman 1997]!). The beacon frames\nsent out by the AP contain a list of nodes whose frames have been buffered\nat the AP. If there are no buffered frames for the node, it can go back to\nsleep. Otherwise, the node can explicitly request that the buffered frames be\nsent by sending a polling message to the AP. With an inter-beacon time of\n100 msec, a wakeup time of 250 microseconds, and a similarly small time\nto receive a beacon frame and check to ensure that there are no buffered\nframes, a node that has no frames to send or receive can be asleep 99% of\nthe time, resulting in a significant energy savings. 7.3.6 Personal Area Networks: Bluetooth\nBluetooth networks seem to have quickly become part of everyday life. Perhaps you’ve used a Bluetooth network as a “cable replacement”\ntechnology to interconnect your computer with a wireless keyboard, mouse,\nor other peripheral device. Or perhaps you’ve used a Bluetooth network to\nconnect your wireless earbuds, speaker, watch, or health monitoring band to\nyour smartphone or to connect your smartphone to a car’s audio system. In\nall of these cases, Bluetooth operates over short ranges (tens of meters or\nless), at low power, and at low cost. For this reason, Bluetooth networks are\nsometimes referred to as wireless personal area networks (WPANs) or\npiconets."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 962,
    "text": "Although Bluetooth networks are small and relatively simple by design,\nthey’re packed with many of the link-level networking techniques that\nwe’ve studied earlier including time division multiplexing (TDM) and\nfrequency division (Section 6.3.1), randomized backoff (Section 6.3.2),\npolling (Section 6.3.3), error detection and correction (Section 6.2), reliable\ndata transfer via ACKs and NAKS (Section 3.4.1). And that’s just\nconsidering Bluetooth’s link layer! Bluetooth networks operate in the unlicensed 2.4 GHz Industrial,\nScientific and Medical (ISM) radio band along with other home appliances\nsuch as microwaves, garage door openers, and cordless phones. As a result,\nBluetooth networks are designed explicitly with noise and interference in\nmind. The Bluetooth wireless channel is operated in a TDM manner, with\ntime slots of 625 microseconds. During each time slot, a sender transmits\non one of 79 channels, with the channel (frequency) changing in a known\nbut pseudo-random manner from slot to slot. This form of channel hopping,\nknown as frequency-hopping spread spectrum (FHSS), is used so that\ninterference from another device or appliance operating in the ISM band\nwill only interfere with Bluetooth communications in at most a subset of the\nslots. Bluetooth data rates can reach up to 3 Mbps. Bluetooth networks are ad hoc networks—no network infrastructure\n(e.g., an access point) is needed. Instead, Bluetooth devices must organize\nthemselves into a piconet of up to eight active devices, as shown in Figure\n7.16. One of these devices is designated as the centralized controller, with\nthe remaining devices acting as ­clients. The centralized controller node\ntruly rules the piconet—its clock ­determines time in the piconet (e.g.,\ndetermines TDM slot boundaries), it determine the ­slot-to-slot frequency\nhopping sequence, it controls entry of client devices into the piconet, it\ncontrols the power (100 mW, 2.5mW, or 1 mW) at which client devices"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 963,
    "text": "transmit; and uses polling to grant clients permission to transmit once\nadmitted to the network. In addition to the active devices, there can also be\nup to 255 “parked” devices in the piconet. These parked devices are often in\nsome form of “sleep mode” to conserve energy (as we saw with 802.11\npower management) and will awaken periodically, according to the\ncentralized controller’s schedule, to receive beacon messages from the\ncentralized controller. A parked device cannot communicate until its ­status\nhas been changed from parked to active by the centralized controller node. Figure 7.16 ♦A Bluetooth piconet\nBecause Bluetooth ad hoc networks must be self-organizing, it’s worth\nlooking into how they bootstrap their network structure. When a centralized\ncontroller node wants to form a Bluetooth network, it must first determine\nwhich other Bluetooth devices are within range; this is the neighbor\ndiscovery problem. The centralized controller does this by broadcasting a\nseries of 32 inquiry messages, each on a different frequency channel, and"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 964,
    "text": "repeats the transmission sequence for up to 128 times. A client device\nlistens on its chosen frequency, hoping to hear one of the centralized\ncontroller’s inquiry messages on this frequency. When it hears an inquiry\nmessage, it backs off a random amount of time between 0 and 0.3 seconds\n(to avoid collisions with other responding nodes, reminiscent of Ethernet’s\nbinary backoff) and then responds to the centralized controller with a\nmessage containing its device ID. Once the Bluetooth centralized controller has discovered all of the\npotential ­clients within range, it then invites those clients that it wishes to\njoin the piconet. This second phase is known as Bluetooth paging, and is\nreminiscent of 802.11 ­clients associating with a base station. Through the\npaging process, the centralized controller will inform the client of the\nfrequency-hopping pattern to be used, and the sender’s clock. The\ncentralized controller begins the paging process by again sending 32\nidentical paging invitation messages, each now addressed to a specific\nclient, but again using different frequencies, since that client has yet to learn\nthe frequency-hopping pattern. Once the client replies with an ACK\nmessage to the paging invitation message, the centralized controller sends\nfrequency-hopping information, clock synchronization information and an\nactive member address to the client, and then finally polls the client, now\nusing the frequency-hopping pattern, to ensure that the client is connected\ninto the network. In our discussion above, we have only touched on Bluetooth’s wireless\nnetworking. Higher level protocols provide for reliable data packet transfer,\ncircuit-like streaming of audio and video, changing transmission power\nlevels, changing active/parked state (and other states), and more. More\nrecent versions of Bluetooth have addressed low energy and security"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 966,
    "text": "7.4 Cellular Networks: 4G and 5G\nIn the previous section, we examined how a host can access the Internet when within the\nvicinity of an 802.11 WiFi access point (AP). But as we’ve seen, APs have small\ncoverage areas, and a host certainly will not be able to associate with every AP it\nencounters. As a result, WiFi access is hardly ubiquitous for a user on the move. By contrast, 4G cellular network access has rapidly become pervasive. A recent\nmeasurement study of more than one million US mobile cellular network subscribers\nfound that they can find 4G signals more than 90% of the time, with download speeds of\n20 Mbps and higher. Users of Korea’s three major cellular carriers are able to find a 4G\nsignal between 95 and 99.5% of the time [Open Signal 2019]. As a result, it is now\ncommonplace to stream HD videos or participate in videoconferences while on the move\nin a car, bus, or high-speed train. The ubiquity of 4G Internet access has also enabled\nmyriad new IoT applications such as Internet-connected shared bike and scooter systems,\nand smartphone applications such as mobile payments (commonplace in China since\n2018) and Internet-based messaging (WeChat, WhatsApp, and more). The term cellular refers to the fact that the region covered by a cellular network is\npartitioned into a number of geographic coverage areas, known as cells. Each cell\ncontains a base station that transmits signals to, and receives signals from, the mobile\ndevices currently in its cell. The coverage area of a cell depends on many factors,\nincluding the transmitting power of the base station, the transmitting power of the\ndevices, obstructing buildings in the cell, and the height and type of the base station\nantennas. In this section, we provide an overview of the current 4G and emerging 5G cellular\nnetworks. We’ll consider the wireless first hop between the mobile device and the base\nstation, as well as the cellular carrier’s all-IP core network that connects the wireless first\nhop into the carrier’s network, other carrier networks, and the larger Internet. Perhaps\nsurprisingly (given the origins of mobile cellular networks in the telephony world, which\nhad a very different network architecture from the Internet), we’ll encounter many of the\narchitectural principles in 4G networks that we encountered in our Internet-focused\nstudies in Chapters 1–6, including protocol layering, an edge/core distinction, the\ninterconnection of multiple provider networks to form a global “network of networks,”"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 967,
    "text": "and the clear separation of data and control planes with logically centralized control. We’ll now see these principles through the lens of mobile cellular networks (rather than\nthrough an Internet lens) and thus see these principles instantiated in different ways. And\nof course, with a carrier’s network having an all-IP core, we’ll also encounter many of\nthe Internet protocols that we now know well. We’ll cover additional 4G topics—\nmobility management in Section 7.6, and 4G security in Section 8.8—later, after\ndeveloping the basic principles needed for these topics. Our discussion here of 4G and 5G networks will be relatively brief. Mobile cellular\nnetworking is an area with great breadth and depth, with many universities offering\nseveral courses on the topic. Readers seeking a deeper understanding are encouraged to\nsee [Goodman 1997; Kaaranen 2001; Lin 2001; Korhonen 2003; Schiller 2003; Palat\n2009; Scourias 2012; Turner 2012; Akyildiz 2010], as well as the particularly excellent\nand exhaustive books [Mouly 1992; Sauter 2014]. Just as Internet RFCs define Internet-standard architecture and protocols, 4G and 5G\nnetworks are also defined by standards documents known as Technical Specifications. These documents are freely available online at [3GPP 2020]. Just like RFCs, technical\nspecifications can make for rather dense and detailed reading. But when you have a\nquestion, they are the definitive source for answers! 7.4.1 4G LTE Cellular Networks: Architecture and Elements\nThe 4G networks that are pervasive as of this writing in 2020 implement the 4G Long-\nTerm Evolution standard, or more succinctly 4G LTE. In this section, we’ll describe 4G\nLTE networks. Figure 7.17 shows the major elements of the 4G LTE network\narchitecture. The network broadly divides into the radio network at the cellular network’s\nedge and the core network. All network elements communicate with each other using the\nIP protocol we studied in Chapter 4. As with earlier 2G and 3G networks, 4G LTE is full\nof rather obtuse acronyms and element names. We’ll try to cut through that jumble by\nfirst focusing on element functions and how the various elements of a 4G LTE network\ninteract with each other in both the data and the control planes:\n•\nMobile Device. This is a smartphone, tablet, laptop, or IoT device that connects into\na cellular carrier’s network. This is where applications such as web browsers, map\napps, voice and videoconference apps, mobile payment apps, and so much more are"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 968,
    "text": "run. The mobile device typically implements the full 5-layer Internet protocol stack,\nincluding the transport and application layers, as we saw with hosts at the Internet’s\nnetwork edge. The mobile device is a network endpoint, with an IP address (obtained\nthrough NAT, as we’ll see). The mobile device also has a globally unique 64-bit\nidentifier called the International Mobile ­Subscriber Identity (IMSI), which is\nstored on its SIM (Subscriber Identity Module) card. The IMSI identifies the\nsubscriber in the worldwide cellular carrier network system, including the country\nand home cellular carrier network to which the subscriber belongs. In some ways, the\nIMSI is analogous to a MAC address. The SIM card also stores information about the\nservices that the subscriber is able to access and encryption key information for that\nsubscriber. In the official 4G LTE jargon, the mobile device is referred to as User\nEquipment (UE). However, in this textbook, we’ll use the more reader-friendly term\n“mobile device” throughout. We also note here that a mobile device is not always\nmobile; for example, the device might be a fixed temperature sensor or a surveillance\ncamera. •\nBase Station. The base station sits at the “edge” of the carrier’s network and is\nresponsible for managing the wireless radio resources and the mobile devices with its\ncoverage area (shown as a hexagonal cell in Figure 7.17). As we’ll see, a mobile\ndevice will interact with a base station to attach to the carrier’s network. The base\nstation coordinates device authentication and allocation of resources (channel access)\nin the radio access network. In this sense, cellular base station functions are\ncomparable (but by no means identical) to those of APs in wireless LANs. But\ncellular base stations have several other important roles not found in wireless LANs. In particular, base stations create device-specific IP tunnels from the mobile device to\ngateways and interact among themselves to handle device mobility among cells. Nearby base stations also coordinate among themselves to manage the radio\nspectrum to minimize interference between cells. In the official 4G LTE terminology,\nthe base station is referred to as an “eNode-B,” which is rather opaque and non-\ndescriptive. In this textbook, we will instead use the reader-friendlier term “base\nstation” throughout. As an aside, if you find LTE terminology a bit opaque, you aren’t alone! The\netymology of “eNode-B” is rooted in earlier 3G terminology, where network function\npoints were referred to as “nodes,” with “B” harkening back to earlier “Base Station"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 969,
    "text": "(BS)” 1G terminology or “Base Transceiver Station (BTS)” in 2G terminology. 4G\nLTE is an “e”volution over 3G, and hence, an “e” now precedes “Node-B” in 4G LTE\nterminology. This name opaqueness shows no signs in stopping! In 5G systems,\neNode-B functions are now referred to as “ng-eNB”; perhaps you can guess what that\nacronym stands for! Figure 7.17 ♦Elements of the 4G LTE architecture\n•\nHome Subscriber Server (HSS). As shown in Figure 7.18, the HSS is a ­control-\nplane element. The HSS is a database, storing information about the mobile devices\nfor which the HSS’s network is their home network. It is used in conjunction with the\nMME (discussed below) for device authentication. •\nServing Gateway (S-GW), Packet Data Network Gateway (P-GW), and\nother  network routers. As shown in Figure 7.18, the Serving Gateway and the\nPacket Data Network Gateway are two routers (often collocated in practice) that lie\non the data path between the mobile device and the Internet. The PDN Gateway also\nprovides NAT IP addresses to mobile devices and performs NAT functions (see\nSection 4.3.4). The PDN Gateway is the last LTE element that a datagram originating\nat a mobile device encounters before entering the larger Internet. To the outside\nworld, the P-GW looks like any other gateway router; the mobility of the mobile\nnodes within the cellular carrier’s LTE network is hidden from the outside world"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 970,
    "text": "behind the P-GW. In addition to these gateway routers, a cellular carrier’s all-IP core\nwill have additional routers whose role is similar to that of traditional IP routers—to\nforward IP datagrams among themselves along paths that will typically terminate at\nelements of the LTE core network. •\nMobility Management Entity (MME). The MME is also a control-plane element,\nas shown in Figure 7.18. Along with the HSS, it plays an important role in\nauthenticating a device wanting to connect into its network. It also sets up the tunnels\non the data path from/to the device and the PDN Internet gateway router, and\nmaintains information about an active mobile device’s cell location within the\ncarrier’s cellular network. But, as shown in Figure 7.18, it is not in the forwarding\npath for the mobile device’s datagrams being sent to and from the Internet. º\nAuthentication. It is important for the network and the mobile device attaching to\nthe network to mutually authenticate each other—for the network to know that\nthe attaching device is indeed the device associated with a given IMSI, and for\nthe mobile device to know that the network to which it is attaching is also a\nlegitimate cellular carrier network. We will cover authentication in Chapter 8 and\ncover 4G authentication in Section 8.8. Here, we simply note that the MME plays\na middleman role between the mobile and Home Subscriber Service (HSS) in the\nmobile’s home network. Specifically, after receiving an attach request from\nmobile device, the local MME contacts the HSS in the mobile’s home network. The mobile’s home HSS then returns enough encrypted information to the local\nMME to prove to the mobile device that the home HSS is performing\nauthentication through this MME, and for the mobile device to prove to the MME\nthat it is indeed the mobile associated with that IMSI. When a mobile device is\nattached to its home network, the HSS to be contacted during authentication is\nlocated within that same home network. However, when a mobile device is\nroaming on a visited network operated by a different cellular network carrier, the\nMME in that roaming network will need to contact the HSS in the mobile\ndevice’s home network. º\nPath setup. As shown in the bottom half of Figure 7.18, the data path from the\nmobile device to the carrier’s gateway router consists of a wireless first hop\nbetween the mobile device and the base station, and concatenated IP tunnels\nbetween the base station and the Serving Gateway, and the Serving Gateway and"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 971,
    "text": "the PDN Gateway. Tunnels are setup under the control of the MME and used for\ndata forwarding (rather than direct forwarding among network routers) to\nfacilitate device mobility—when a device moves, only the tunnel endpoint\nterminating at the base station needs to be changed, while other tunnel endpoints,\nand the Quality of Service associated with a tunnel, remain unchanged. º\nCell location tracking. As the device moves between cells, the base stations will\nupdate the MME on the device’s location. If the mobile device is in a sleep mode\nbut nonetheless moving between cells, the base stations can no longer track the\ndevice’s location. In this case, it will be the responsibility of the MME to locate\nthe device for wakeup, through a process known as paging. Figure 7.18 ♦LTE data-plane and control-plane elements\nTable 7.2 summarizes the key LTE architectural elements that we have discussed\nabove and compares these functions with those we encountered in our study of WiFi\nwireless LANs (WLANs). Table 7.2 ♦LTE Elements, and similar WLAN (WiFi) functions\nCASE HISTORY\nTHE ARCHITECTURAL EVOLUTION FROM 2G TO 3G TO 4G"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 973,
    "text": "packet-switched data services. Here, the transition from a voice-only network to a combined voice and\ndata network is clear: the existing core 2G cellular voice network elements remained untouched. However, additional cellular data functionality was added in parallel to, and functioned independently\nfrom, the existing core voice network at that time. As shown in Figure 7.20, the splitting point into these\ntwo separate core voice and data networks happened at the network edge, at the base station in the\nradio access network. The alternative—integrating new data services directly into the core elements of\nthe existing cellular voice network—would have raised the same challenges encountered in integrating\nnew (IPv6) and legacy (IPv4) technologies in the Internet. The carriers also wanted to leverage and\nexploit their considerable investment of existing infrastructure (and profitable services!) in their existing\ncellular voice network. Figure 7.20 ♦3G system architecture: supporting separate circuit-switched\nvoice service and packet-switched data service with the\ncarrier’s core network\n7.4.2 LTE Protocols Stacks"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 974,
    "text": "Since the 4G LTE architecture is an all-IP architecture, we’re already very familiar with\nthe higher-layer protocols in the LTE protocol stack, in particular IP, TCP, UDP, and\nvarious application layer protocols, from our studies in Chapters 2 through 5. Consequently, the new LTE protocols that we’ll focus on here are primarily at the link\nand physical layers, and in mobility management. Figure 7.21 shows the user-plane protocol stacks at the LTE mobile node, the base\nstation, and the serving gateway. We’ll touch on several of LTE’s control-plane protocols\nlater when we study LTE mobility management (Section 7.6) and security (Section 8.8). As we can see from Figure 7.21, most of the new and interesting user-plane protocol\nactivity is happening at the wireless radio link between the mobile device and the base\nstation. Figure 7.21 ♦LTE data-plane protocol stacks\nLTE divides the mobile device’s link layer into three sublayers:\n•\nPacket Data Convergence. This uppermost sublayer of the link layer sits just below\nIP. The Packet Data Convergence Protocol (PDCP) [3GPP PDCP 2019] performs IP\nheader/compression in order to decrease the number of bits sent over the wireless\nlink, and encryption/decryption of the IP datagram using keys that were established\nvia signaling messages between the LTE mobile device and the Mobility"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 975,
    "text": "Management Entity (MME) when the mobile device first attached to the network;\nwe’ll cover aspects of LTE security in Section 8.8.2. •\nRadio Link Control. The Radio Link Control (RLC) Protocol [3GPP RLCP\n2018] performs two important functions: (i) fragmenting (on the sending side) and\nreassembly (on the receiving) of IP datagrams that are too large to fit into the\nunderlying link-layer frames, and (ii) link-layer reliable data transfer at the through\nthe use of an ACK/NAK-based ARQ protocol. Recall the we’ve studied the basic\nelements of ARQ protocols in Section 3.4.1. •\nMedium Access Control (MAC). The MAC layer performs transmission scheduling,\nthat is, the requesting and use of the radio transmission slots described in Section\n7.4.4. The MAC sublayer also performs additional error detection/­correction\nfunctions, including the use of redundant bit transmission as a forward error-\ncorrection technique. The amount of redundancy can be adapted to channel\nconditions. Figure 7.21 also shows the use of tunnels in the user data path. As discussed above,\nthese tunnels are established, under MME control, when the mobile device first attaches\nto the network. Each tunnel between two endpoints has a unique tunnel endpoint\nidentifier (TEID). When the base station receives datagrams from the mobile device, it\nencapsulates them using the GPRS Tunneling Protocol [3GPP GTPv1-U 2019], including\nthe TEID, and sends them in UDP segments to the Serving Gateway at the other end of\nthe tunnel. On the receiving side, the base station decapsulates tunneled UDP datagrams,\nextracts the encapsulated IP datagram destined for the mobile device, and forwards that\nIP datagram over the wireless hop to the mobile device. 7.4.3 LTE Radio Access Network\nLTE uses a combination of frequency division multiplexing and time division\nmultiplexing on the downstream channel, known as orthogonal frequency division\nmultiplexing (OFDM) [Hwang 2009]. (The term “orthogonal” comes from the fact the\nsignals being sent on different frequency channels are created so that they interfere very\nlittle with each other, even when channel frequencies are tightly spaced). In LTE, each\nactive mobile device is allocated one or more 0.5 ms time slots in one or more of the\nchannel frequencies. Figure 7.22 shows an allocation of eight time slots over four"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 976,
    "text": "frequencies. By being allocated increasingly more time slots (whether on the same\nfrequency or on different frequencies), a mobile device is able to achieve increasingly\nhigher transmission rates. Slot (re)allocation among mobile devices can be performed as\noften as once every millisecond. Different modulation schemes can also be used to\nchange the transmission rate; see our earlier discussion of Figure 7.3 and dynamic\nselection of modulation schemes in WiFi networks. Figure 7.22 ♦Twenty 0.5-ms slots organized into 10 ms frames at each\nfrequency. An eight-slot allocation is shown shaded. The particular allocation of time slots to mobile devices is not mandated by the LTE\nstandard. Instead, the decision of which mobile devices will be allowed to transmit in a\ngiven time slot on a given frequency is determined by the scheduling algorithms\nprovided by the LTE equipment vendor and/or the network operator. With opportunistic\nscheduling [Bender 2000; Kolding 2003; Kulkarni 2005], matching the physical-layer\nprotocol to the channel conditions between the sender and receiver and choosing the\nreceivers to which packets will be sent based on channel conditions allow the base station\nto make best use of the wireless medium. In addition, user priorities and contracted levels\nof service (e.g., silver, gold, or platinum) can be used in scheduling downstream packet\ntransmissions. In addition to the LTE capabilities described above, LTE-Advanced allows"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 977,
    "text": "for downstream bandwidths of hundreds of Mbps by allocating aggregated channels to a\nmobile device [Akyildiz 2010]. 7.4.4 Additional LTE Functions: Network Attachment and\nPower Management\nLet’s conclude or study of 4G LTE here by considering two additional important LTE\nfunctions: (i) the process with which a mobile device first attaches to the network and (ii)\nthe techniques used by the mobile device, in conjunction with core network elements, to\nmanage its power use. Network Attachment\nThe process by which a mobile device attaches to the cellular carrier’s network divides\nbroadly into three phases:\n•\nAttachment to a Base Station. This first phase of device attachment is similar in\npurpose to, but quite different in practice from, the 802.11 association protocol that\nwe studied in Section 7.3.1. A mobile device wishing to attach to a cellular carrier\nnetwork will begin a bootstrap process to learn about, and then associate with, a\nnearby base station. The mobile device initially searches all channels in all frequency\nbands for a primary synchronization signal that is periodically broadcast every 5 ms\nby a base station. Once this signal is found, the mobile device remains on this\nfrequency and locates the secondary synchronization signal. With information found\nin this second signal, the device can locate (following several further steps)\nadditional information such as channel bandwidth, channel configurations, and the\ncellular carrier information of that base station. Armed with this information, the\nmobile device can select a base station to associate with (preferentially attaching to\nits home network, if available) and establish a control-plane signaling connection\nacross the wireless hop with that base station. This mobile-to-base-station channel\nwill be used through the remainder of the network attachment process. •\nMutual Authentication. In our earlier description of the Mobility Management Entity\n(MME) in Section 7.4.1, we noted that the base station contacts the local MME to\nperform mutual authentication—a process that we’ll study in further detail in Section"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 978,
    "text": "8.8.2. This is the second phase of network attachment, allowing the network to know\nthat the attaching device is indeed the device associated with a given IMSI, and the\nmobile device to know that the network to which it is attaching is also a legitimate\ncellular carrier network. Once this second phase of network attachment is complete,\nthe MME and mobile device have mutually authenticated each other, and the MME\nalso knows the identity of the base station to which the mobile is attached. Armed\nwith this information, the MME is now ready to configure the Mobile-device-to-\nPDN-gateway data path. •\nMobile-device-to-PDN-gateway Data Path Configuration. The MME contacts the\nPDN gateway (which also provides a NAT address for the mobile device), the\nServing gateway, and the base station to establish the two tunnels shown in Figure\n7.21. Once this phase is complete, the mobile device is able to send/receive IP\ndatagrams via the base station through these tunnels to and from the Internet! Power Management: Sleep Modes\nRecall in our earlier discussion of advanced features in 802.11 (Section 7.3.5) and\nBluetooth (Section 7.3.6) that a radio in a wireless device may enter a sleep state to save\npower when it is not transmitting or receiving in order to minimize the amount of time\nthat the mobile device’s circuitry needs to be “on” for sending/receiving data, and for\nchannel sensing. In 4G LTE, a sleeping mobile device can be in one of two different\nsleep states. In the discontinuous reception state, which is typically entered after several\nhundred milliseconds of inactivity [Sauter 2014], the mobile device and the base station\nwill schedule periodic times in advance (typically several hundred milliseconds apart) at\nwhich the mobile device will wake up and actively monitor the channel for downstream\n(base station to mobile device) transmissions; apart from these scheduled times, however,\nthe mobile device’s radio will be sleeping. If the discontinuous reception state might be considered a “light sleep,” the second\nsleep state—the Idle state—which follows even longer periods of 5 to 10 seconds of\ninactivity, might be thought of as a “deep sleep.” While in this deep sleep, the mobile\ndevice’s radio wakes up and monitors the channel even less frequently. Indeed, this sleep\nis so deep that if the mobile device moves into a new cell in the carrier’s network while\nsleeping, it need not inform the base station with which it was previous associated. Thus,\nwhen waking up periodically from this deep sleep, the mobile device will need to re-"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 979,
    "text": "establish an association with a (potentially new) base station in order to check for paging\nmessages broadcast by the MME to base stations nearby the base station with which the\nmobile was last associated. These control-plane paging messages, which are broadcast by\nthese base stations to all mobile devices in their cells, indicate which mobile devices\nshould fully wake up and re-establish a new data-plane connection to a base station (see\nFigure 7.18) in order to receive incoming packets. 7.4.5 The Global Cellular Network: A Network of Networks\nHaving now studied the 4G cellular network architecture, let’s take a step back at take a\nlook at how the global cellular network—itself a “network of networks” like the Internet\n—is organized. Figure 7.23 shows a user’s mobile smartphone connected via a 4G base station into\nits home network. The user’s home mobile network is operated by a cellular carrier such\nas Verizon, AT&T, T-Mobile, or Sprint in the United States; Orange in France; or SK\nTelecom in Korea. The user’s home network, in turn, is connected to the networks of\nother cellular carriers and to the global Internet, though one or more gateway routers in\nthe home network, as shown in Figure 7.23. The mobile networks themselves\ninterconnect with each other either via the public Internet or via an Internet Protocol\nPacket eXchange (IPX) Network [GSMA 2018a]. An IPX is a managed network\nspecifically for interconnecting cellular carriers, similar to Internet eXchange Points (see\nFigure 1.15) for peering among ISPs. From Figure 7.23, we can see that the global\ncellular network is indeed a “network of networks”—just like the Internet (recall Figure\n1.15 and Section 5.4). 4G networks can also peer with 3G cellular voice/data networks\nand earlier voice-only networks."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 980,
    "text": "Figure 7.23 ♦The global cellular data network: a network of networks. We’ll return shortly to additional 4G LTE topics—mobility management in Section\n7.6, and 4G security in Section 8.8.2—later, after developing the basic principles needed\nfor these topics. Let’s now take a quick look at the emerging 5G networks. 7.4.6 5G Cellular Networks\nThe ultimate wide-area data service would be one with ubiquitous gigabit connection\nspeeds, extremely low latency, and unrestricted limitations on the number of users and\ndevices that could be supported in any region. Such a service would open the door to all\nkinds of new applications, including pervasive augmented reality and virtual reality,\ncontrol of autonomous vehicles via wireless connections, control of robots in factories\nvia wireless connections, and replacement of residential access technologies, such as"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 981,
    "text": "DSL and cable, with fixed wireless Internet services (that is, residential wireless\nconnections from base stations to modems in homes). It is expected that 5G, for which progressively improved versions are likely to be\nrolled out in the 2020 decade, will make a big step towards achieving the goals of the\nultimate wide-area data service. It is predicted that 5G will provide roughly a 10x\nincrease in peak bitrate, a 10x decrease in latency, and a 100x increase in traffic capacity\nover 4G [Qualcomm 2019]. Principally, 5G refers to “5G NR (New Radio),” which is the standard adopted by\n3GPP. Other 5G technologies besides NR do exist, however. For example, Verizon’s\nproprietary 5G TF network operates on 28 and 39 GHz frequencies and is used only for\nfixed wireless Internet service, not in smartphones. 5G standards divide frequencies into two groups: FR1 (450 MHz–6 GHz) and FR2\n(24 GHz–52 GHz). Most early deployments will be in the FR1 space, although there are\nearly deployments as of 2020 in the FR2 space for fixed Internet residential access as\nmentioned just above. Importantly, the physical layer (that is, wireless) aspects of 5G are\nnot backward-compatible with 4G mobile communications systems such as LTE: in\nparticular, it can’t be delivered to existing smartphones by deploying base station\nupgrades or software updates. Therefore, in the transition to 5G, wireless carriers will\nneed to make substantial investments in physical infrastructure. FR2 frequencies are also known as millimeter wave frequencies. While millimeter\nwave frequencies allow for much faster data speeds, they come with two major\ndrawbacks:\n•\nMillimeter wave frequencies have much shorter range from base station to receivers. This makes millimeter wave technology unsuitable in rural areas and requires denser\ndeployments of base stations in urban areas. •\nMillimeter wave communication is highly susceptible to atmospheric interference. Nearby foliage and rain can cause problems for outdoor use. 5G is not one cohesive standard, but instead consists of three co-existing standards\n[Dahlman 2018]:\n•\neMBB (Enhanced Mobile Broadband). Initial deployments of 5G NR have focused\non eMBB, which provides for increased bandwidth for higher download and upload"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 982,
    "text": "speeds, as well as a moderate reduction in latency when compared to 4G LTE. eMBB\nenables rich media applications, such as mobile augmented reality and virtual reality,\nas well as mobile 4K resolution and 360° video streaming. •\nURLLC (Ultra Reliable Low-Latency Communications). URLLC is targeted towards\napplications that are highly latency-sensitive, such as factory automation and\nautonomous driving. URLLC is targeting latencies of  1msec. As of this writing,\ntechnologies that enable URLLC are still being standardized. •\nmMTC (Massive Machine Type Communications). mMTC is a narrowband access\ntype for sensing, metering, and monitoring applications. One priority for the design\nof 5G networks is to lower barriers for network connectivity for IoT devices. In\naddition to lowering latency, emerging technologies for 5G networks are focusing on\nreducing power requirements, making the use of IoT devices more pervasive than has\nbeen with 4G LTE. 5G and Millimeter Wave Frequencies\nMany 5G innovations will be a direct result of working in the millimeter wave\nfrequencies in the 24 GHz–52 GHz band. For example, these frequencies offer the\npotential of achieving 100x increase in capacity over 4G. To get some insight into this,\ncapacity can be defined as the product of three terms [Björnson 2017]:\ncapacity = cell density  ×  available spectrum  ×  spectral efficiency\nwhere cell density is in units of cells/km2, available spectrum is in units of Hertz, and\nspectral efficiency is a measure of how efficiently each base station can communicate\nwith users and is in units of bps/Hz/cell. By multiplying these units out, it is easy to see\nthat capacity is in units of bps/km2. For each of these three terms, the values will be\nlarger for 5G than for 4G:\n•\nBecause millimeter frequencies have much shorter range than 4G LTE frequencies,\nmore base stations are required, which in turn increases the cell density. •\nBecause 5G FR2 operates in a much larger frequency band (52 − 24 = 28 GHz) than\n4G LTE (up to about 2 GHz), it has more available spectrum. •\nWith regard to spectral efficiency, information theory says that if you want to double\nspectral efficiency, a 17-fold increase in power is needed [Björnson 2017]. Instead of"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 983,
    "text": "increasing power, 5G uses MIMO-technology (the same technology we encountered\nin our study of 802.11 networks in Section 7.3), which uses multiple antennas at each\nbase station. Rather than broadcasting signals in all directions, each MIMO antenna\nemploys beam forming and directs the signal at the user. MIMO technology allows a\nbase station to send to 10–20 users at the same time in the same frequency band. By increasing all three terms in the capacity equation, 5G is expected to provide a\n100x increase in capacity in urban areas. Similarly, owing to the much wider frequency\nband, 5G is expected to provide peak download rates of 1 Gbps or higher. Millimeter wave signals are, however, easily blocked by buildings and trees. Small\ncell stations are needed to fill in coverage gaps between base stations and users. In a\nhighly populous region, the distance between two small cells could vary from 10 to 100\nmeters [Dahlman 2018]. 5G Core Network\nThe 5G Core network is the data network that manages all of the 5G mobile voice, data\nand Internet connections. The 5G Core network is being redesigned to better integrate\nwith the Internet and cloud-based services, and also includes distributed servers and\ncaches across the network, thereby reducing latency. Network function virtualization (as\ndiscussed in Chapters 4 and 5), and network slicing for different applications and\nservices, will be managed in the core. The new 5G Core specification introduces major changes in the way mobile\nnetworks support a wide variety of services with varied performance. As in the case of\nthe 4G core network (recall Figures 7.17 and 7.18), the 5G core relays data traffic from\nend devices, authenticates devices, and manages device mobility. The 5G core also\ncontains all of the network elements that we encountered in Section 7.4.2—the mobile\ndevices, the cells, the base stations, and the Mobility Management Entity (now divided\ninto two sub-elements, as discussed below), the HSS, and the Serving and PDN\ngateways. Although the 4G and 5G core networks perform similar functions, there are some\nmajor differences in that the new 5G core architecture. The 5G Core is designed for\ncomplete control and user-plane separation (see Chapter 5). The 5G Core consists purely\nof virtualized software-based network functions. This new architecture will give"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 984,
    "text": "operators the flexibility to meet the diverse requirements of the different 5G applications. Some of the new 5G core network functions include [Rommer 2019]:\n•\nUser-Plane Function (UPF). Control and user-plane separation (see Chapter 5)\nallows packet processing to be distributed and pushed to the network edge. •\nAccess and Mobility Management Function (AMF). The 5G Core essentially\ndecomposes the 4G Mobility Management Entity (MME) into two functional\nelements: AMF and SMF. The AMF receives all the connection and session\ninformation from end-user equipment but only handles connection and mobility\nmanagement tasks. •\nSession Management Function (SMF). Session management is handled by the\nSession Management Function (SMF). The SMF is responsible for interacting with\nthe decoupled data plane. The SMF also performs IP address management and plays\nthe role of DHCP. As of this writing (2020), 5G is in its early stages of deployment, and many 5G\nstandards have yet to be finalized. Only time will tell whether 5G will become a\npervasive broadband wireless service, whether it will successfully compete with WiFi for\nindoor wireless service, whether it will become a critical component of factory\nautomation and the autonomous vehicle infrastructure, and whether it will take us a big\nstep forward toward the ultimate wide-area wireless service."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 985,
    "text": "7.5 Mobility Management: Principles\nHaving covered the wireless nature of the communication links in a\nwireless network, it’s now time to turn our attention to the mobility that\nthese wireless links enable. In the broadest sense, a mobile device is one\nthat changes its point of attachment into the network over time. Because the\nterm mobility has taken on many meanings in both the computer and\ntelephony worlds, it will serve us well first to carefully consider forms of\nmobility. 7.5.1 Device Mobility: a Network-layer Perspective\nFrom the network layer’s standpoint, a physically mobile device will\npresent a very different set of challenges to the network layer, depending on\nhow active the device is as it moves between points of attachment to the\nnetwork. At the one end of the spectrum, scenario (a) in Figure 7.24 is the\nmobile user who himself/herself physically moves between networks, but\npowers down the mobile device when moving. For example, a student\nmight disconnect from a wireless classroom network and power down\nhis/her device, head to the dining commons and connect to the wireless\naccess network there while eating, and then disconnect and power down\nfrom the dining commons network, walk to the library, and connect to the\nlibrary’s wireless network while studying. From a networking perspective,\nthis device is not mobile—it attaches to an access network and remains in\nthat access network while on. In this case, the device serially associates\nwith, and later disassociates from, each wireless access network\nencountered. This case of device (non-)mobility can be completely handled"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 986,
    "text": "using the networking mechanisms we’ve already studied in Sections 7.3 and\n7.4. In scenario (b) in Figure 7.24, the device is physically mobile but\nremains attached to the same access network. This device is also not mobile\nfrom a network-layer perspective. Additionally, if the device remains\nassociated with the same 802.11 AP or LTE base station, the device is not\neven mobile from a link-layer perspective. Figure 7.24 ♦Various degrees of mobility, from a network-layer\nperspective\nFrom a network standpoint, our interest in device mobility really starts\nwith case (c), where a device changes its access network (e.g., 802.11\nWLAN or LTE cell) while continuing to send and receiving IP datagrams,\nand while maintaining higher-level (e.g., TCP) connections. Here, the\nnetwork will need to provide handover—a transfer of responsibility for\nforwarding datagrams to/from one AP or base station to the mobile device\n—as the device moves among WLANs or among LTE cells. We’ll cover\nhandover in detail in Section 7.6. If the handover occurs within access\nnetworks belonging to a single network provider, that provider can\norchestrate handover on its own. When a mobile device roams between"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 987,
    "text": "multiple provider networks, as in scenario (d), the providers must\norchestrate handover together, which considerably complicates the\nhandover process. 7.5.2 Home Networks and Roaming on Visited\nNetworks\nAs we learned in our discussions of cellular 4G LTE networks in Section\n7.4.1, every subscriber has a “home” with some cellular provider. We\nlearned that the Home Subscriber Service (HSS) stores information about\neach of its subscribers, including a globally unique device ID (embedded in\na subscriber’s SIM card), information about services that the subscriber\nmay access, cryptographic keys to be used for communication, and\nbilling/charging information. When a device is connected to a cellular\nnetwork, other than its home network, that device is said to be roaming on\na visited network. When a mobile device attaches to, and roams on, a\nvisited network, coordination will be required between the home network\nand the visited network. The Internet does not have a similarly strong notion of a home network\nor a visited network. In practice, a student’s home network might be the\nnetwork operated by his/her school; for mobile professionals, their home\nnetwork might be their company network. The visited network might be the\nnetwork of a school or a company they are visiting. But there is no notion\nof a home/visited network deeply embedded in the Internet’s architecture. The Mobile IP protocol [Perkins 1998, RFC 5944], which we will cover\nbriefly in Section 7.6, was a proposal that strongly incorporated the notion\nof home/visited networks. But Mobile IP has seen limited deployment/use\nin practice. There are also activities underway that are built on top of the"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 988,
    "text": "existing IP infrastructure to provide authenticated network access across\nvisited IP networks. Eduroam [Eduroam 2020] is one such activity. The notion of a mobile device having a home network provides two\nimportant advantages: the home network provides a single location where\ninformation about that device can be found, and (as we will see) it can serve\nas a coordination point for communication to/from a roaming mobile\ndevice. To appreciate the potential value of the central point of information and\ncoordination, consider the human analogy of a 20-something adult Bob\nmoving out of the family home. Bob becomes mobile, living in a series of\ndormitories and apartments, and often changing addresses. If an old friend\nAlice wants to get in touch, how can Alice find the current address of Bob? One common way is to contact the family, since a mobile 20-something\nadult will often register his or her current address with the family (if for no\nother reason than so that the parents can send money to help pay the rent!). The family home becomes that unique location that others can go to as a\nfirst step in communicating with Bob. Additionally, later postal\ncommunication from Alice may be either indirect (e.g., with mail being sent\nfirst to Bob’s family home and then forwarded to Bob) or direct (e.g., with\nAlice using the address obtained from Bob’s parents to send mail directly to\nBob). 7.5.3 Direct and Indirect Routing to/from a Mobile\nDevice\nLet us now consider the conundrum faced by the Internet-connected host\n(that we will refer to as a correspondent) in Figure 7.25 wishing to\ncommunicate with a mobile device that might be located within that mobile"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 989,
    "text": "device’s cellular home network, or might be roaming in a visited network. In our development below, we’ll adopt a 4G/5G cellular network\nperspective, since these networks have such a long history of supporting\ndevice mobility. But as we’ll see, the fundamental challenges and basic\nsolution approaches for supporting device mobility are equally applicable in\nboth cellular networks and in the Internet. As shown in Figure 7.25, we’ll assume that the mobile device has a\nglobally unique identifier associated with it. In 4G, LTE cellular networks\n(see Section 7.4), this would be the International Mobile Subscriber Identity\n(IMSI) and an associated phone number, stored on a mobile device’s SIM\ncard. For mobile Internet users, this would be a permanent IP address in the\nIP address range of its home network, as in the case of the Mobile IP\narchitecture."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 990,
    "text": "Figure 7.25 ♦Elements of a mobile network architecture\nWhat approaches might be used in a mobile network architecture that\nwould allow a datagram sent by the correspondent to reach that mobile\ndevice? Three basic approaches can be identified and are discussed below. As we will see, the latter two of these are adopted in practice. Leveraging the Existing IP Address Infrastructure\nPerhaps the simplest approach to routing to a mobile device in a visited\nnetwork is to simply use the existing IP addressing infrastructure—to add\nnothing new to the architecture. What could be easier! Recall from our discussion of Figure 4.21 that an ISP uses BGP to\nadvertise routes to destination networks by enumerating the CIDRized\naddress ranges of reachable networks. A visited network could thus\nadvertise to all other networks that a particular mobile device is resident in\nits network simply by advertising a highly specific address—the mobile\ndevice’s full 32-bit IP permanent address—essentially informing other\nnetworks that it has the path to be used to forward datagrams to that mobile\ndevice. These neighboring networks would then propagate this routing\ninformation throughout the network as part of the normal BGP procedure of\nupdating routing information and forwarding tables. Since datagrams will\nalways be forwarded to the router advertising the most specific destination\nfor that address (see Section 4.3), all datagrams addressed to that mobile\ndevice will be forwarded to the visited network. If the mobile device leaves\none visited network and joins another, the new visited network can\nadvertise a new, highly specific route to the mobile device, and the old\nvisited network can withdraw its routing information regarding the mobile\ndevice."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 991,
    "text": "This solves two problems at once, and does so without making changes\nto the network-layer infrastructure! Other networks know the location of the\nmobile device, and it is easy to route datagrams to the mobile device, since\nthe forwarding tables will direct datagrams to the visited network. The killer\ndrawback, however, is that of scalability—network routers would have to\nmaintain forwarding table entries for potentially billions of mobile devices,\nand update a device’s entry each time it roams to a different network. Clearly, this approach would not work in practice. Some additional\ndrawbacks are explored in the problems at the end of this chapter. An alternative, more practical, approach (and one that has been adopted\nin practice) is to push mobility functionality from the network core to the\nnetwork edge—a recurring theme in our study of Internet architecture. A\nnatural way to do this is via the mobile device’s home network. In much the\nsame way that parents of the mobile 20-something adult track their child’s\nlocation, a mobility management entity (MME) in the mobile device’s home\nnetwork could track the visited network in which the mobile device resides. This information might reside in a database, shown as the HSS database in\nFigure 7.25. A protocol operating between the visited network and the home\nnetwork will be needed to update the network in which the mobile device\nresides. You might recall that we encountered the MME and HSS elements\nin our study of 4G LTE. We’ll reuse their element names here, since they\nare so descriptive, and also because they are pervasively deployed in 4G\nnetworks. Let’s next consider the visited network elements shown in Figure 7.25\nin more detail. The mobile device will clearly need an IP address in the\nvisited network. The possibilities here include using a permanent address\nassociated with the mobile device’s home network, allocating a new address\nin the address range of the visited network, or providing an IP address via"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 992,
    "text": "NAT (see Section 4.3.4). In the latter two cases, a mobile device has a\ntransient identifier (a newly allocated IP address) in addition to its\npermanent identifiers stored in the HSS in its home network. These cases\nare analogous to a writer addressing a letter to the address of the house in\nwhich our mobile 20-something adult is currently living. In the case of a\nNAT address, datagrams destined to the mobile device would eventually\nreach the NAT gateway router in the visited network, which would then\nperform NAT address translation and forward the datagram to the mobile\ndevice. We have now seen a number of elements of a solution to the\ncorrespondent’s dilemma in Figure 7.24: home and visited networks, the\nMME and HSS, and mobile device addressing. But how should datagrams\nbe addressed and forwarded to the mobile device? Since only the HSS (and\nnot network-wide routers) knows the location of the mobile device, the\ncorrespondent cannot simply address a datagram to the mobile device’s\npermanent address and send it into the network. Something more must be\ndone. Two approaches can be identified: indirect and direct routing. Indirect Routing to a Mobile Device\nLet’s again consider the correspondent that wants to send a datagram to a\nmobile device. In the indirect routing approach, the correspondent simply\naddresses the datagram to the mobile device’s permanent address and sends\nthe datagram into the network, blissfully unaware of whether the mobile\ndevice is resident in its home network or in a visited network; mobility is\nthus completely transparent to the correspondent. Such datagrams are first\nrouted, as usual, to the mobile device’s home network. This is illustrated in\nstep 1 in Figure 7.26."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 993,
    "text": "Figure 7.26 ♦Indirect routing to a mobile device\nLet’s now turn our attention to the HSS, which is responsible for\ninteracting with visited networks to track the mobile device’s location, and\nthe home network’s gateway router. One job of this gateway router is to be\non the lookout for an arriving datagram addressed to a device whose home\nis in that network, but that currently resides in a visited network. The home\nnetwork gateway intercepts this datagram, consults with the HSS to\ndetermine the visited network where the mobile device is resident, and\nforwards the datagram toward the visited network gateway router—step 2\nin Figure 7.26. The visited network gateway router then forwards the\ndatagram toward the mobile device—step 3 in Figure 7.26. If NAT"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 994,
    "text": "translation is used, as in Figure 7.26, the visited network gateway router\nperforms NAT translation. It is instructive to consider the rerouting at the home network in bit\nmore detail. Clearly, the home network gateway will need to forward the\narriving datagram to the gateway router in the visited network. On the other\nhand, it is desirable to leave the correspondent’s datagram intact, since the\napplication receiving the datagram should be unaware that the datagram\nwas forwarded via the home network. Both goals can be satisfied by having\nthe home gateway encapsulate the correspondent’s original complete\ndatagram within a new (larger) datagram. This larger datagram is then\naddressed and delivered to the visited network’s gateway router, which will\ndecapsulate the datagram—that is, remove the correspondent’s original\ndatagram from within the larger encapsulating datagram—and forward (step\n3 in Figure 7.26) the original datagram to the mobile device. The sharp\nreader will note that the encapsulation/decapsulation described here is\nprecisely the notion of tunneling, discussed in Section 4.3 in the context of\nIPv6; indeed, we also discussed the use of tunneling in the context of Figure\n7.18, when we introduced the 4G LTE data plane. Finally, let’s consider how the mobile device sends datagrams to the\ncorrespondent. In the context of Figure 7.26, the mobile device will clearly\nneed to forward the datagram through the visited gateway router, in order to\nperform NAT translation. But how then should the visited gateway router\nforward the datagram to the correspondent? As shown in Figure 7.26, there\nare two options here: (4a) the datagram could be tunneled back to the home\ngateway router, and sent to the correspondent from there, or (4b) the\ndatagram could be transmitted from the visited network directly to the\ncorrespondent—an approach known as local breakout [GSMA 2019a] in\nLTE."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 995,
    "text": "Let’s summarize our discussion of indirect routing by reviewing the\nnew network-layer functionality required to support mobility. •\nA mobile-device–to–visited-network association protocol. The mobile\ndevice will need to associate with the visited network, and will similarly\nneed to disassociate when leaving the visited network. •\nA visited-network–to–home-network-HSS registration protocol. The\nvisited network will need to register the mobile device’s location with\nthe HSS in the home network, and perhaps use information obtained\nfrom the HSS in performing device authentication. •\nA datagram tunneling protocol between in the home network gateway\nand the visited network gateway router. The sending side performs\nencapsulation and forwarding of the correspondent’s original datagram;\non the receiving side, the gateway router performs decapsulation, NAT\ntranslation, and forwarding of the original datagram to the mobile\ndevice. The previous discussion provides all the needed elements for a mobile\ndevice to maintain an ongoing connection with a correspondent as the\ndevice moves among networks. When a device roams from one visited\nnetwork to another, the new visited network information needs to be\nupdated in the home network HSS, and the home-gateway-router-to-visited-\ngateway-router tunnel endpoint needs to be moved. But will the mobile\ndevice see an interrupted flow of datagrams as it moves between networks? As long as the time between the mobile device disconnection from one\nvisited network and its attachment to the next visited network is small, few\ndatagrams will be lost. Recall from Chapter 3 that end-to-end connections\ncan experience datagram loss due to network congestion. Hence, occasional\ndatagram loss within a connection when a device moves between networks"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 996,
    "text": "is by no means a catastrophic problem. If loss-free communication is\nrequired, upper-layer mechanisms will recover from datagram loss, whether\nsuch loss results from network congestion or from device mobility. Our discussion above has been purposefully somewhat generic. An\nindirect routing approach is used in the mobile IP standard [RFC 5944], as\nwell as in 4G LTE networks [Sauter 2014]. Their details, in particular the\ntunneling procedures employed, differ just a bit from our generic discussion\nabove. Direct Routing to a Mobile Device\nThe indirect routing approach illustrated in Figure 7.26 suffers from an\ninefficiency known as the triangle routing problem—datagrams addressed\nto the mobile device must be forwarded first to the home network and then\nto the visited network, even when a much more efficient route exists\nbetween the correspondent and the roaming mobile device. In the worst\ncase, imagine a mobile user who is roaming on the same network that is the\nhome network for an overseas colleague who our mobile user is visiting. The two are sitting side-by-side and exchanging data. Datagrams between\nthe mobile user and his overseas colleague will be forwarded to the mobile\nuser’s home network and then back again to the visited network! Direct routing overcomes the inefficiency of triangle routing, but does\nso at the cost of additional complexity. In the direct routing approach,\nshown in Figure 7.27, the correspondent first discovers the visited network\nin which the mobile is resident. This is done by querying the HSS in the\nmobile device’s home network, assuming (as in the case of indirect routing)\nthat the mobile device’s visited network is registered in the HSS. This is\nshown as steps 1 and 2 in Figure 7.27. The correspondent then tunnels"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 997,
    "text": "datagrams from its network directly to the gateway router in the mobile\ndevice’s visited network. Figure 7.27 ♦Direct routing to a mobile device\nWhile direct routing overcomes the triangle routing problem, it\nintroduces two important additional challenges:\n•\nA mobile-user location protocol is needed for the correspondent to\nquery the HSS to obtain the mobile device’s visited network (steps 1\nand 2 in Figure 7.27). This is in addition to the protocol needed for the\nmobile device to register its location with its HSS."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 998,
    "text": "•\nWhen the mobile device moves from one visited network to another,\nhow will the correspondent know to now forward datagrams to the new\nvisited network? In the case of indirect routing, this problem was easily\nsolved by updating the HSS in the home network, and changing the\ntunnel endpoint to terminate at the gateway router of the new visited\nnetwork. However, with direct routing, this change in visited networks\nis not so easily handled, as the HSS is queried by the correspondent\nonly at the beginning of the session. Thus, additional protocol\nmechanisms would be required to proactively update the correspondent\neach time the mobile device moves. Two problems at the end of this\nchapter explore solutions to this problem."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 999,
    "text": "7.6 Mobility Management in Practice\nIn the previous section, we identified key fundamental challenges and\npotential solutions in developing a network architecture to support device\nmobility: the notions of home and visited networks; the home network’s\nrole as a central point of information and control for mobile devices\nsubscribed to that home network; control-plane functions needed by a home\nnetwork’s mobility management entity to track a mobile device roaming\namong visited networks; and data-plane approaches of direct and indirect\nrouting to enable a correspondent and a mobile device to exchange\ndatagrams. Let’s now look at how these principles are put into practice! In\nSection 7.6.1, we’ll study mobility management in 4G/5G networks; in\nSection 7.6.2, we’ll look at Mobile IP, which has been proposed for the\nInternet. 7.6.1 Mobility Management in 4G/5G Networks\nOur earlier study of 4G and emerging 5G architectures in Section 7.4\nacquainted us with all of the network elements that play a central role in\n4G/5G mobility management. Let’s now illustrate how those elements\ninteroperate with each other to provide mobility services in today’s 4G/5G\nnetworks [Sauter 2014; GSMA 2019b], which have their roots in earlier 3G\ncellular voice and data networks [Sauter 2014], and even earlier 2G voice-\nonly networks [Mouly 1992]. This will help us synthesize what we’ve\nlearned so far, allow us to introduce a few more advanced topics as well,\nand provide a lens into what might be in store for 5G mobility management."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1000,
    "text": "Let’s consider a simple scenario in which a mobile user (e.g., a\npassenger in a car), with a smartphone attaches to a visited 4G/5G network,\nbegins streaming a HD video from a remote server, and then moves from\nthe cell coverage of one 4G/5G base station to another. The four major steps\nin this scenario are shown in Figure 7.28:\n1. Mobile device and base station association. The mobile device\nassociates with a base station in the visited network. 2. Control-plane configuration of network elements for the mobile device. The visited and home networks establish control-plane state indicating\nthat the mobile device is resident in the visited network. 3. Data-plane configuration of forwarding tunnels for the mobile device. The visited network and the home network establish tunnels through\nwhich the mobile device and streaming server can send/receive IP\ndatagrams, using indirect routing through the home network’s Packet\nData Network gateway (P-GW). 4. Mobile device handover from one base station to another. The mobile\ndevice changes its point of attachment to the visited network, via\nhandover from one base station to another. Let’s now consider each of these four steps in more detail."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1001,
    "text": "Figure 7.28 ♦An example 4G/5G mobility scenario\n1. Base station association. Recall that in Section 7.4.2, we studied the\nprocedures by which a mobile device associates with a base station. We\nlearned that the mobile device listens on all frequencies for primary\nsignals being transmitted by base stations in its area. The mobile device\nacquires progressively more information about these base stations,\nultimately selecting the base station with which to associate, and\nbootstrapping a control-­signaling channel with that base station. As part\nof this association, the mobile device provides the base station with its\nInternational Mobile Subscriber Identity (IMSI), which uniquely\nidentifies the mobile device as well as its home network and other\nadditional subscriber information. 2. Control-plane configuration of LTE network elements for the\nmobile device.Once the mobile-device-to-base-station signaling channel\nhas been established, the base station can contact the MME in the visited\nnetwork. The MME will consult and configure a number of 4G/5G"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1002,
    "text": "elements in both the home and visited networks to establish state on\nbehalf of the mobile node:\n•\nThe MME will use to the IMSI and other information provided by\nthe mobile device to retrieve authentication, encryption, and\navailable network service information for that subscriber. That\ninformation might be in the MME’s local cache, retrieved from\nanother MME that the mobile device had recently contacted, or\nretrieved from the HSS in the mobile device’s home network. The\nmutual authentication process (which we will cover in more detail in\nSection 8.8) ensures that the visited network is sure about the\nidentity of the mobile device and that the device can authenticate the\nnetwork to which it is attaching. •\nThe MME informs the HSS in the mobile device’s home network\nthat the mobile device is now resident in the visited network, and the\nHSS updates its database. •\nThe base station and the mobile device select parameters for the\ndata-plane channel to be established between the mobile device and\nthe base station (recall that a control plane signaling channel is\nalready in operation). 3. Data-plane configuration of forwarding tunnels for the mobile\ndevice. The MME next configures the data plane for the mobile device,\nas shown in Figure 7.29. Two tunnels are established. One tunnel is\nbetween the base station and a Serving Gateway in the visited network. The second tunnel is between that Serving Gateway and the PDN\nGateway router in the mobile device’s home network. 4G LTE\nimplements this form of symmetric indirect routing—all traffic to/from\nthe mobile device will be tunneled through the device’s home network. 4G/5G tunnels use the GPRS Tunneling Protocol (GTP), specified in"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1003,
    "text": "[3GPP GTPv1-U 2019]. The Tunnel Endpoint ID (TEID) in the GTP\nheader indicates which tunnel a datagram belongs, allowing multiple\nflows to be multiplexed and de-multiplexed by GTP between tunnel\nendpoints. It is instructive to compare the configuration of tunnels in Figure\n7.29 (the case of mobile roaming in a visited network) with that of\nFigure 7.18 (the case of mobility only within the mobile device’s home\nnetwork). We see that in both cases, the Serving Gateway is co-resident\nin the same network as the mobile device, but PDN Gateway (which is\nalways the PDN Gateway in the mobile device’s home network) may be\nin a different network than the mobile device. This is precisely indirect\nrouting. An alternative to indirect routing, known as local breakout\n[GSMA 2019a] has been specified in which the Serving Gateway\nestablishes a tunnel to the PDN Gateway in the local, visited network. In\npractice, however, local breakout is not widely used [Sauter 2014]."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1004,
    "text": "Figure 7.29 ♦Tunneling in 4G/5G networks between the Serving\nGateway in the visited network and the PDN\ngateway in the home network\nOnce the tunnels have been configured and activated, the mobile\ndevice can now forward packets to/from the Internet via the PDN\ngateway in its home network! 4. Handover management. A handover occurs when a mobile device\nchanges its association from one base station to another. The handover\nprocess described below is the same, regardless of whether the mobile\ndevice is resident in its home network, or is roaming in a visited\nnetwork. As shown in Figure 7.30, datagrams to/from the device are initially\n(before handover) forwarded to the mobile through one base station\n(which we’ll refer to as the source base station), and after handover are\nrouted to the mobile device through another base station (which we’ll\nrefer to as the target base station). As we will see, a handover between\nbase stations results not only in the mobile device transmitting/receiving\nto/from a new base station but also in a change of the base-station side\nof the Serving-Gateway-to-base-station tunnel in Figure 7.29. In the\nsimplest case of handover, when the two base stations are near each\nother and in the same network, all changes occurring as a result of\nhandover are thus relatively local. In particular, the PDN gateway being\nused by the Serving Gateway remains blissfully unaware of device\nmobility. Of course, more complicated handoff scenarios will require the\nuse of more complex mechanisms [Sauter 2014; GSMA 2019a]. There may be several reasons for handover to occur. For example,\nthe signal between the current base station and the mobile may have\ndeteriorated to such an extent that communication is severely impaired."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1005,
    "text": "Or a cell may have become overloaded, handling a large amount of\ntraffic; handing over mobile devices to less congested nearby cells may\nalleviate this congestion. A mobile device periodically measures\ncharacteristics of a beacon signal from its current base station as well as\nsignals from nearby base stations that it can “hear.” These measurements\nare reported once or twice a second to the mobile device’s current\n(source) base station. Based on these measurements, the current loads of\nmobiles in nearby cells, and other factors, the source base station may\nchoose to initiate a handover. The 4G/5G standards do not specify a\nspecific algorithm to be used by a base station to determine whether or\nnot to perform handover, or which target base station to choose; this is\nan active area of research [Zheng 2008; Alexandris 2016]. Figure 7.30 illustrates the steps involved when a source base station\ndecides to hand over a mobile device to the target base station. Figure 7.30 ♦Steps in handing over a mobile device from the\nsource base station to the target base station"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1006,
    "text": "1. The current (source) base station selects the target base station, and\nsends a Handover Request message to the target base station. 2. The target base station checks whether it has the resources to support the\nmobile device and its quality of service requirements. If so, it pre-\nallocates channel resources (e.g., time slots) on its radio access network\nand other resources for that device. This pre-allocation of resources\nfrees the mobile device from having to go through the time-consuming\nbase-station association protocol discussed earlier, allowing handover to\nbe executed as fast as possible. The target base station replies to the\nsource base station with a Handover Request Acknowledge message,\ncontaining all the information at the target base station that the mobile\ndevice will need to associate with the new base station. 3. The source base station receives the Handover Request\nAcknowledgement message and informs the mobile device of the target\nbase station’s identity and channel access information. At this point, the\nmobile device can begin sending/receiving datagrams to/from the new\ntarget base station. From the mobile device’s point of view, handover is\nnow complete! However, there is still a bit of work to be done within the\nnetwork. 4. The source base station will also stop forwarding datagrams to the\nmobile device and instead forward any tunneled datagrams it receives to\nthe target base station, which will later forward these datagrams to the\nmobile device. 5. The target base station informs the MME that it (the target base station)\nwill be the new base station servicing the mobile device. The MME, in\nturn, signals to the Serving Gateway and the target base station to\nreconfigure the Serving-Gateway-to-base-station tunnel to terminate at\nthe target base station, rather than at the source base station."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 1007,
    "text": "6. The target base station confirms back to the source base station that the\ntunnel has been reconfigured, allowing the source base station to release\nresources associated with that mobile device. 7. At this point, the target base station can also begin delivering datagrams\nto the mobile device, including datagrams forwarded to the target base\nstation by the source base station during handover, as well as datagrams\nnewly arriving on the reconfigured tunnel from the Serving Gateway. It\ncan also forward outgoing datagrams received from the mobile device\ninto the tunnel to the Serving Gateway. The roaming configurations in today’s 4G LTE networks, such as that\ndiscussed above, will also be used in future emerging 5G networks [GSMA\n2019c]. Recall, however, from our discussion in Section 7.4.6 that the 5G\nnetworks will be denser, with significantly smaller cell sizes. This will\nmake handover an even more critically important network function. In\naddition, low handover latency will be critical for many real-time 5G\napplications. The migration of the cellular network control plane to the\nSDN framework that we studied earlier in Chapter 5 [GSMA 2018b;\nCondoluci 2018] promises to enable implementations of a higher-capacity,\nlower-latency 5G cellular network control plane. The application of SDN in\na 5G context is the subject of considerable research [Giust 2015; Ordonez-\nLucena 2017; Nguyen 2016]. 7.6.2 Mobile IP\nToday’s Internet does not have any widely deployed infrastructure that\nprovides the type of services for “on the go” mobile users that we\nencountered for 4G/5G cellular networks. But this is certainly not due to the\nlack of technical solutions for providing such services in an Internet setting!"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1009,
    "text": "The overall architecture and elements of Mobile IP are strikingly\nsimilar to that of cellular provider networks. There is a strong notion of a\nhome network, in which a mobile device has a permanent IP address, and\nvisited networks (known as “foreign” networks in Mobile IP), where the\nmobile device will be allocated a care-of-address. The home agent in\nMobile IP has a similar function to the LTE HSS: it tracks the location of a\nmobile device by receiving updates from foreign agents in foreign networks\nvisited by that mobile device, just as the HSS receives updates from\nMobility Management Entities (MMEs) in visited networks in which a 4G\nmobile device resides. And both 4G/5G and Mobile IP use indirect routing\nto a mobile node, using tunnels to connect the gateway routers in the home\nand visited/foreign networks. Table 7.3 summarizes the elements of the\nMobile IP architecture, along with a comparison with similar elements in\n4G/5G networks\nTable 7.3 ♦Commonalities between 4G/5G and Mobile IP\narchitectures\nThe mobile IP standard consists of three main pieces:\n•\nAgent discovery. Mobile IP defines the protocols used by a foreign\nagent to advertise its mobility services to a mobile device that wishes to\nattach to its network. Those services will include providing a care-of-\naddress to the mobile device for use in the foreign network, registration\nof the mobile device with the home agent in the mobile device’s home\nnetwork, and forwarding of datagrams to/from the mobile device,\namong other services. •\nRegistration with the home agent. Mobile IP defines the protocols used\nby the mobile device and/or foreign agent to register and deregister a\ncare-of-address with a mobile device’s home agent."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1011,
    "text": "7.7 Wireless and Mobility: Impact on Higher-Layer\nProtocols\nIn this chapter, we’ve seen that wireless networks differ significantly from\ntheir wired counterparts at both the link layer (as a result of wireless\nchannel characteristics such as fading, multipath, and hidden terminals) and\nat the network layer (as a result of mobile users who change their points of\nattachment to the network). But are there important differences at the\ntransport and application layers? It’s tempting to think that these differences\nwill be minor, since the network layer provides the same best-effort\ndelivery service model to upper layers in both wired and wireless networks. Similarly, if protocols such as TCP or UDP are used to provide transport-\nlayer services to applications in both wired and wireless networks, then the\napplication layer should remain unchanged as well. In one sense, our\nintuition is right—TCP and UDP can (and do) operate in networks with\nwireless links. On the other hand, transport protocols in general, and TCP in\nparticular, can sometimes have very different performance in wired and\nwireless networks, and it is here, in terms of performance, that differences\nare manifested. Let’s see why. Recall that TCP retransmits a segment that is either lost or corrupted on\nthe path between sender and receiver. In the case of mobile users, loss can\nresult from either network congestion (router buffer overflow) or from\nhandover (e.g., from delays in rerouting segments to a mobile’s new point\nof attachment to the network). In all cases, TCP’s receiver-to-sender ACK\nindicates only that a segment was not received intact; the sender is unaware\nof whether the segment was lost due to congestion, during handover, or due"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1012,
    "text": "to detected bit errors. In all cases, the sender’s response is the same—to\nretransmit the segment. TCP’s congestion-control response is also the same\nin all cases—TCP decreases its congestion window, as discussed in Section\n3.7. By unconditionally decreasing its congestion window, TCP implicitly\nassumes that segment loss results from congestion rather than corruption or\nhandover. We saw in Section 7.2 that bit errors are much more common in\nwireless networks than in wired networks. When such bit errors occur or\nwhen handover loss occurs, there’s really no reason for the TCP sender to\ndecrease its congestion window (and thus decrease its sending rate). Indeed,\nit may well be the case that router buffers are empty and packets are\nflowing along the end-to-end path unimpeded by congestion. Researchers realized in the early to mid 1990s that given high bit error\nrates on wireless links and the possibility of handover loss, TCP’s\ncongestion-control response could be problematic in a wireless setting. Three broad classes of approaches are possible for dealing with this\nproblem:\n•\nLocal recovery. Local recovery protocols recover from bit errors when\nand where (e.g., at the wireless link) they occur, for example, the 802.11\nARQ protocol we studied in Section 7.3, or more sophisticated\napproaches that use both ARQ and FEC [Ayanoglu 1995] that we saw in\nuse in 4G/5G networks in Section 7.4.2. •\nTCP sender awareness of wireless links. In the local recovery\napproaches, the TCP sender is blissfully unaware that its segments are\ntraversing a wireless link. An alternative approach is for the TCP sender\nand receiver to be aware of the existence of a wireless link, to\ndistinguish between congestive losses occurring in the wired network\nand corruption/loss occurring at the wireless link, and to invoke\ncongestion control only in response to congestive wired-network losses."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1013,
    "text": "[Liu 2003] investigates techniques for distinguishing between losses on\nthe wired and wireless segments of an end-to-end path. [Huang 2013]\nprovides insights on developing transport protocol mechanisms and\napplications that are more LTE-friendly. •\nSplit-connection approaches. In a split-connection approach [Bakre\n1995], the end-to-end connection between the mobile user and the other\nend point is broken into two transport-layer connections: one from the\nmobile host to the wireless access point, and one from the wireless\naccess point to the other communication end point (which we’ll assume\nhere is a wired host). The end-to-end connection is thus formed by the\nconcatenation of a wireless part and a wired part. The transport layer\nover the wireless segment can be a standard TCP connection [Bakre\n1995], or a specially tailored error recovery protocol on top of UDP. [Yavatkar 1994] investigates the use of a transport-layer selective repeat\nprotocol over the wireless connection. Measurements reported in [Wei\n2006] indicate that split TCP connections have been widely used in\ncellular data networks, and that significant improvements can indeed be\nmade through the use of split TCP connections. Our treatment of TCP over wireless links has been necessarily brief\nhere. ­In-depth surveys of TCP challenges and solutions in wireless networks\ncan be found in [Hanabali 2005; Leung 2006]. We encourage you to consult\nthe references for details of this ongoing area of research. Having considered transport-layer protocols, let us next consider the\neffect of wireless and mobility on application-layer protocols. Because of\nthe shared nature of the wireless spectrum, applications that operate over\nwireless links, particularly over cellular wireless links, must treat bandwidth\nas a scarce commodity. For example, a Web server serving content to a Web\nbrowser executing on a 4G smartphone will likely not be able to provide the"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1014,
    "text": "same image-rich content that it gives to a browser operating over a wired\nconnection. Although wireless links do provide challenges at the application\nlayer, the mobility they enable also makes possible a rich set of location-\naware and context-aware applications [Baldauf 2007]. More generally,\nwireless and mobile networks will continue to play a key role in realizing\nthe ubiquitous computing environments of the future [Weiser 1991]. It’s fair\nto say that we’ve only seen the tip of the iceberg when it comes to the\nimpact of wireless and mobile networks on networked applications and\ntheir protocols!"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1015,
    "text": "7.8 Summary\nWireless and mobile networks first revolutionized telephony and are now\nhaving an increasingly profound impact in the world of computer networks\nas well. With their anytime, anywhere, untethered access into the global\nnetwork infrastructure, they are not only making network access more\nubiquitous, they are also enabling an exciting new set of location-dependent\nservices. Given the growing importance of wireless and mobile networks,\nthis chapter has focused on the principles, common link technologies, and\nnetwork architectures for supporting wireless and mobile communication. We began this chapter with an introduction to wireless and mobile\nnetworks, drawing an important distinction between the challenges posed\nby the wireless nature of the communication links in such networks, and by\nthe mobility that these wireless links enable. This allowed us to better\nisolate, identify, and master the key concepts in each area. We focused first\non wireless communication, considering the characteristics of a wireless\nlink in Section 7.2. In Sections 7.3 and 7.4, we examined the link-level\naspects of the IEEE 802.11 (WiFi) wireless LAN standard, Bluetooth, and\n4G/5G cellular neworks. We then turned our attention to the issue of\nmobility. In Section 7.5, we identified several forms of mobility, with points\nalong this spectrum posing different challenges and admitting different\nsolutions. We considered the problems of locating and routing to a mobile\nuser, as well as approaches for handing over the mobile user who\ndynamically moves from one point of attachment to the network to another. We examined how these issues were addressed in 4G/5G networks and in\nthe Mobile IP standard. Finally, we considered the impact of wireless links"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1016,
    "text": "and mobility on transport-layer protocols and networked applications in\nSection 7.7. Although we have devoted an entire chapter to the study of wireless\nand mobile networks, an entire book (or more) would be required to fully\nexplore this exciting and rapidly expanding field. We encourage you to\ndelve more deeply into this field by consulting the many references\nprovided in this chapter."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1017,
    "text": "Homework Problems and Questions\nChapter 7 Review Questions\nSECTION 7.1\nR1. What does it mean for a wireless network to be operating in\n“infrastructure mode”? If the network is not in infrastructure mode,\nwhat mode of operation is it in, and what is the difference between\nthat mode of operation and infrastructure mode? R2. Both MANET and VANET are multi-hop infrastructure-less wireless\nnetworks. What is the difference between them? SECTION 7.2\nR3. What are the differences between the following types of wireless\nchannel impairments: path loss, multipath propagation, interference\nfrom other sources? R4. As a mobile node gets farther and farther away from a base station,\nwhat are two actions that a base station could take to ensure that the\nloss probability of a transmitted frame does not increase? SECTION 7.3\nR5. Describe the role of the beacon frames in 802.11. R6. An access point periodically sends beacon frames. What are the\ncontents of the beacon frames? R7. Why are acknowledgments used in 802.11 but not in wired Ethernet? R8. What is the difference between passive scanning and active scanning? R9. What are the two main purposes of a CTS frame?"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1018,
    "text": "R10. Suppose the IEEE 802.11 RTS and CTS frames were as long as the\nstandard DATA and ACK frames. Would there be any advantage to\nusing the CTS and RTS frames? Why or why not? R11. Section 7.3.4 discusses 802.11 mobility, in which a wireless station\nmoves from one BSS to another within the same subnet. When the\nAPs are interconnected with a switch, an AP may need to send a\nframe with a spoofed MAC address to get the switch to forward the\nframe properly. Why? R12. What is the difference between Bluetooth and Zigbee in terms of data\nrate? R13. What is the role of the base station in 4G/5G cellular architecture? With which other 4G/5G network elements (mobile device, MME,\nHSS, Serving Gateway Router, PDN Gateway Router) does it directly\ncommunicate with in the control plane? In the data plane? R14. What is an International Mobile Subscriber Identity (IMSI)? R15. What is the role of the Home Subscriber Service (HSS) in 4G/5G\ncellular architecture? With which other 4G/5G network elements\n(mobile device, base station, MME, Serving Gateway Router, PDN\nGateway Router) does it directly communicate with in the control\nplane? In the data plane? R16. What is the role of the Mobility Management Entity (MME) in\n4G/5G cellular architecture? With which other 4G/5G network\nelements (mobile device, base station, HSS, Serving Gateway Router,\nPDN Gateway Router) does it directly communicate with in the\ncontrol plane? In the data plane? R17. Describe the purpose of two tunnels in the data plane of the 4G/5G\ncellular architecture. When a mobile device is attached to its own\nhome network, at which 4G/5G network element (mobile device,"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1019,
    "text": "base station, HSS, MME, Serving Gateway Router, PDN Gateway\nRouter) does each end of each of the two tunnels terminate? R18. What are the three sublayers in the link layer in the LTE protocol\nstack? Briefly describe their functions. R19. Does the LTE wireless access network use FDMA, TDMA, or both? Explain your answer. R20. Describe the two possible sleep modes of a 4G/5G mobile device. In\neach of these sleep modes, will the mobile device remain associated\nwith the same base station between the time it goes to sleep and the\ntime it wakes up and first sends/receives a new datagram? R21. What is meant by a “visited network” and a “home network” in\n4G/5G cellular architecture? R22. List three important differences between 4G and 5G cellular\nnetworks. SECTION 7.5\nR23. What does it mean that a mobile device is said to be “roaming?”\nR24. What is meant by “hand over” of a network device? R25. What is the difference between direct and indirect routing of\ndatagrams to/from a roaming mobile host? R26. What does “triangle routing” mean? SECTION 7.6\nR27. Describe the similarity and differences in tunnel configuration when a\nmobile device is resident in its home network, versus when it is\nroaming in a visited network. R28. When a mobile device is handed over from one base station to\nanother in a 4G/5G network, which network element makes the\ndecision to initiate that handover? Which network element chooses"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1020,
    "text": "the target base station to which the mobile device will be handed\nover? R29. Describe how and when the forwarding path of datagrams entering\nthe visited network and destined to the mobile device changes before,\nduring, and after hand over. R30. Consider the following elements of the Mobile IP architecture: the\nhome network, foreign network permanent IP address, home agent,\nforeign agent, data plane forwarding, Access Point (AP), and WLANs\nat the network edge. What are the closest equivalent elements in the\n4G/5G cellular network architecture? SECTION 7.7\nR31. What are three approaches that can be used to avoid having a single\nwireless link degrade the performance of an end-to-end transport-\nlayer TCP connection? Problems\nP1. Consider the single-sender CDMA example in Figure 7.5. What\nwould be the sender’s output (for the 2 data bits shown) if the\nsender’s CDMA code were (1, 1, −1, 1, 1, −1, −1, 1)? P2. Consider sender 2 in Figure 7.6. What is the sender’s output to the\nchannel (before it is added to the signal from sender 1), Z  i,m? P3. After selecting the AP with which to associate, a wireless host sends\nan association request frame to the AP, and the AP responds with an ­-\nassociation response frame. Once associated with an AP, the host will\nwant to join the subnet (in the IP addressing sense of Section 4.4.2) to\nwhich the AP belongs. What does the host do next?"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1021,
    "text": "P4. If two CDMA senders have codes (1, 1, 1, −1, 1, −1, −1, −1) and (1,\n−1, 1, 1, 1, 1, 1, 1), would the corresponding receivers be able to\ndecode the data correctly? Justify. P5. Suppose there are two ISPs providing WiFi access in a particular café,\nwith each ISP operating its own AP and having its own IP address\nblock. a. Further suppose that by accident, each ISP has configured its AP\nto operate over channel 11. Will the 802.11 protocol completely\nbreak down in this situation? Discuss what happens when two\nstations, each associated with a different ISP, attempt to transmit\nat the same time. b. Now suppose that one AP operates over channel 1 and the other\nover channel 11. How do your answers change? P6. In step 4 of the CSMA/CA protocol, a station that successfully\ntransmits a frame begins the CSMA/CA protocol for a second frame\nat step 2, rather than at step 1. What rationale might the designers of\nCSMA/CA have had in mind by having such a station not transmit the\nsecond frame immediately (if the channel is sensed idle)? P7. Suppose an 802.11b station is configured to always reserve the\nchannel with the RTS/CTS sequence. Suppose this station suddenly\nwants to ­transmit 1,000 bytes of data, and all other stations are idle at\nthis time. Assume a ­transmission rate of 10 Mbps. Calculate the time\nrequired to transmit the frame and receive the acknowledgment as a\nfunction of SIFS and DIFS, ­ignoring propagation delay and assuming\nno bit errors. P8. Consider the scenario shown in Figure 7.31, in which there are four\nwireless nodes, A, B, C, and D. The radio coverage of the four nodes\nis shown via the shaded ovals; all nodes share the same frequency."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1022,
    "text": "When A transmits, it can only be heard/received by B; when B\ntransmits, both A and C can hear/receive from B; when C transmits,\nboth B and D can hear/receive from C; when D transmits, only C can\nhear/receive from D.\nSuppose now that each node has an infinite supply of messages that it\nwants to send to each of the other nodes. If a message’s destination is\nnot an immediate neighbor, then the message must be relayed. For\nexample, if A wants to send to D, a message from A must first be sent\nto B, which then sends the message to C, which then sends the\nmessage to D. Time is slotted, with a message ­transmission time\ntaking exactly one time slot, e.g., as in slotted Aloha. During a slot, a\nnode can do one of the following: (i) send a message, (ii) receive a\nmessage (if exactly one message is being sent to it), (iii) remain\nsilent. As always, if a node hears two or more simultaneous\ntransmissions, a collision occurs and none of the transmitted\nmessages are received successfully. You can assume here that there\nare no bit-level errors, and thus if exactly one message is sent, it will\nbe received correctly by those within the transmission radius of the\nsender. Figure 7.31 ♦Scenario for problem P8"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1023,
    "text": "a. Suppose now that an omniscient controller (i.e., a controller that\nknows the state of every node in the network) can command\neach node to do whatever it (the omniscient controller) wishes,\nthat is, to send a message, to receive a message, or to remain\nsilent. Given this omniscient controller, what is the maximum\nrate at which a data message can be transferred from C to A,\ngiven that there are no other messages between any other\nsource/destination pairs? b. Suppose now that A sends messages to B, and D sends messages\nto C. What is the combined maximum rate at which data\nmessages can flow from A to B and from D to C? c. Suppose now that A sends messages to B, and C sends messages\nto D. What is the combined maximum rate at which data\nmessages can flow from A to B and from C to D? d. Suppose now that the wireless links are replaced by wired links. Repeat questions (a) through (c) again in this wired scenario. e. Now suppose we are again in the wireless scenario, and that for\nevery data message sent from source to destination, the\ndestination will send an ACK message back to the source (e.g.,\nas in TCP). Also suppose that each ACK message takes up one\nslot. Repeat questions (a)–(c) above for this scenario. P9. Power is a precious resource in mobile devices, and thus the 802.11 ­-\nstandard provides power-management capabilities that allow 802.11\nnodes to ­minimize the amount of time that their sense, transmit, and\nreceive ­functions and other circuitry need to be “on.” In 802.11, a\nnode is able to ­explicitly alternate between sleep and wake states. Explain in brief how a node ­communicates with the AP to perform\npower management."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1024,
    "text": "P10. Consider the following idealized LTE scenario. The downstream\nchannel (see Figure 7.22) is slotted in time, across F frequencies. There are four nodes, A, B, C, and D, reachable from the base station\nat rates of 10 Mbps, 5 Mbps, 2.5 Mbps, and 1 Mbps, respectively, on\nthe downstream channel. These rates assume that the base station\nutilizes all time slots available on all F frequencies to send to just one\nstation. The base station has an infinite amount of data to send to each\nof the nodes, and can send to any one of these four nodes using any of\nthe F frequencies during any time slot in the ­downstream sub-frame. a. What is the maximum rate at which the base station can send to\nthe nodes, assuming it can send to any node it chooses during\neach time slot? Is your solution fair? Explain and define what\nyou mean by “fair.”\nb. If there is a fairness requirement that each node must receive an\nequal amount of data during each one second interval, what is\nthe average transmission rate by the base station (to all nodes)\nduring the downstream sub-frame? Explain how you arrived at\nyour answer. c. Suppose that the fairness criterion is that any node can receive at\nmost twice as much data as any other node during the sub-frame. What is the average transmission rate by the base station (to all\nnodes) during the sub-frame? Explain how you arrived at your\nanswer. P11. In Section 7.5, one proposed solution that allowed mobile users to\nmaintain their IP addresses as they moved among foreign networks\nwas to have a foreign network advertise a highly specific route to the\nmobile user and use the existing routing infrastructure to propagate\nthis information throughout the network. We identified scalability as"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1025,
    "text": "one concern. Suppose that when a mobile user moves from one\nnetwork to another, the new foreign network advertises a specific\nroute to the mobile user, and the old foreign network withdraws its\nroute. Consider how routing information propagates in a distance-\nvector algorithm (particularly for the case of interdomain routing\namong networks that span the globe). a. Will other routers be able to route datagrams immediately to the\nnew foreign network as soon as the foreign network begins\nadvertising its route? b. Is it possible for different routers to believe that different foreign\nnetworks contain the mobile user? c. Discuss the timescale over which other routers in the network\nwill eventually learn the path to the mobile users. P12. In 4G/5G networks, what effect will handoff have on end-to-end\ndelays of datagrams between the source and destination? P13. Consider a mobile device that powers on and attaches to an LTE\nvisited network A, and assume that indirect routing to the mobile\ndevice from its home network H is being used. Subsequently, while\nroaming, the device moves out of range of visited network A and\nmoves into range of an LTE visited network B. You will design a\nhandover process from a base station BS.A in visited network A to a\nbase station BS.B in visited network B. Sketch the series of steps that\nwould need to be taken, taking care to identify the network elements\ninvolved (and the networks to which they belong), to accomplish this\nhandover. Assume that following handover, the tunnel from the home\nnetwork to the visited network will terminate in visiting network B.\nP14. Consider again the scenario in Problem P13. But now assume that the\ntunnel from home network H to visited network A will continue to be"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1026,
    "text": "used. That is, visited network A will serve as an anchor point\nfollowing handover. (Aside: this is actually the process used for\nrouting circuit-switched voice calls to a roaming mobile phone in 2G\nGSM networks.) In this case, additional tunnel(s) will need to be built\nto reach the mobile device in its resident visited network B. Once\nagain, sketch the series of steps that would need to be taken, taking\ncare to identify the network elements involved (and the networks to\nwhich they belong), to accomplish this handover. What are one advantage and one disadvantage of this approach\nover the approach taken in your solution to Problem P13?"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1028,
    "text": "AN INTERVIEW WITH…\nDeborah Estrin\nCourtesy of Deborah Estrin\nDeborah Estrin is a Professor of Computer Science and\nAssociate Dean for Impact at Cornell Tech in New York City\nand a Professor of Public Health at Weill Cornell Medical\nCollege. She received her Ph.D. (1985) in Computer Science\nfrom M.I.T. and her B.S. (1980) from UC Berkeley. Estrin’s\nearly research focused on the design of network protocols,\nincluding multicast and inter-domain routing. In 2002 Estrin\nfounded the NSF-funded Science and Technology Center at\nUCLA, Center for Embedded Networked Sensing (CENS\nhttp://cens.ucla.edu.). CENS launched new areas of multi-\ndisciplinary computer systems research from sensor networks"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1029,
    "text": "for environmental monitoring, to participatory sensing and\nmobile health. As described in her 2013 TEDMED talk, she\nexplores how individuals can benefit from the pervasive data\nbyproducts of digital and IoT interactions for health and life\nmanagement. Professor Estrin is an elected member of the\nAmerican Academy of Arts and Sciences (2007), the National\nAcademy of Engineering (2009), and the National Academy\nof Medicine (2019). She is a Fellow of the IEEE, ACM, and\nAAAS. She was selected as the first ACM-W Athena Lecturer\n(2006), awarded the Anita Borg Institute’s Women of Vision\nAward for Innovation (2007), inducted into the WITI hall of\nfame (2008), received honorary doctorates from EPFL (2008)\nand Uppsala University (2011), and was selected as a\nMacArthur Fellow (2018). Please describe a few of the most exciting\nprojects you have worked on during your\ncareer. What were the biggest challenges? In the mid-90s at USC and ISI, I had the great\nfortune to work with the likes of Steve Deering,\nMark Handley, and Van Jacobson on the design of\nmulticast routing protocols (in particular, PIM). I\ntried to carry many of the architectural design\nlessons from multicast into the design of ecological\nmonitoring arrays, where for the first time I really\nbegan to take applications and multidisciplinary\nresearch seriously. The need for jointly innovating\nin the social and technological space is what"
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1032,
    "text": "said, new challenges have emerged from higher up\nin the stack. Machine Learning based systems and\nservices favor scale, particularly when they rely on\ncontinuous consumer engagement (clicks) for\nfinancial viability. The resulting information\necosystem has become far more monolithic than in\nearlier decades. This is a challenge for networking,\nthe Internet, and frankly our society. What people inspired you professionally? There are three people who come to mind. First,\nDave Clark, the secret sauce and under- sung hero\nof the Internet community. I was lucky to be\naround in the early days to see him act as the\n“organizing principle” of the IAB and Internet\ngovernance; the priest of rough consensus and\nrunning code. Second, Scott Shenker, for his\nintellectual brilliance, integrity, and persistence. I\nstrive for, but rarely attain, his clarity in defining\nproblems and solutions. He is always the first\nperson I e-mail for advice on matters large and\nsmall. Third, my sister Judy Estrin, who had the\ncreativity and commitment to spend the first half\nof her career bringing ideas and concepts to\nmarket; and now has the courage to study, write,\nand advise on how to rebuild it to support a\nhealthier democracy."
  },
  {
    "unit": "Unit 4",
    "topic": "Chapter 7",
    "source": "kurose",
    "page": 1033,
    "text": "What are your recommendations for\nstudents who want careers in computer\nscience and networking? First, build a strong foundation in your academic\nwork, balanced with any and every real- world\nwork experience you can get. As you look for a\nworking environment, seek opportunities in\nproblem areas you really care about and with smart\nteams that you can learn from and work with to\nbuild things that matter."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1034,
    "text": "Security in Computer\nNetworks\nWay back in Section 1.6, we described some of the more prevalent and\ndamaging classes of Internet attacks, including malware attacks, denial\nof service, sniffing, source masquerading, and message modification\nand deletion. Although we have since learned a tremendous amount\nabout computer networks, we still haven’t examined how to secure\nnetworks from those attacks. Equipped with our newly acquired\nexpertise in computer networking and Internet protocols, we’ll now\nstudy in-depth secure communication and, in particular, how computer\nnetworks can be defended from those nasty bad guys. Let us introduce Alice and Bob, two people who want to\ncommunicate and wish to do so “securely.” This being a networking\ntext, we should remark that Alice and Bob could be two routers that\nwant to exchange routing tables securely, a client and server that want\nto establish a secure transport connection, or two e-mail applications\nthat want to exchange secure e-mail—all case studies that we will\nconsider later in this chapter. Alice and Bob are well-known fixtures in\nthe security community, perhaps because their names are more fun\nthan a generic entity named “A” that wants to communicate securely\nwith \na \ngeneric \nentity \nnamed \n“B.” \nLove \naffairs, \nwartime\ncommunication, and business transactions are the commonly cited"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1035,
    "text": "human needs for secure communications; preferring the first to the\nlatter two, we’re happy to use Alice and Bob as our sender and\nreceiver, and imagine them in this first scenario. We said that Alice and Bob want to communicate and wish to do\nso “securely,” but what precisely does this mean? As we will see,\nsecurity (like love) is a many-splendored thing; that is, there are many\nfacets to security. Certainly, Alice and Bob would like for the contents\nof their communication to remain secret from an eavesdropper. They\nprobably would also like to make sure that when they are\ncommunicating, they are indeed communicating with each other, and\nthat if their communication is tampered with by an eavesdropper, that\nthis tampering is detected. In the first part of this chapter, we’ll cover\nthe fundamental cryptography techniques that allow for encrypting\ncommunication, authenticating the party with whom one is\ncommunicating, and ensuring message integrity. In the second part of this chapter, we’ll examine how the fundamental ­-\ncryptography principles can be used to create secure networking protocols. Once again taking a top-down approach, we’ll examine secure protocols in\neach of the (top four) layers, beginning with the application layer. We’ll\nexamine how to secure e-mail, how to secure a TCP connection, how to\nprovide blanket security at the network layer, and how to secure a wireless\nLAN. In the third part of this chapter we’ll consider operational security,\nwhich is about protecting organizational networks from attacks. In\nparticular, we’ll take a careful look at how firewalls and intrusion detection\nsystems can enhance the security of an organizational network."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1036,
    "text": "8.1 What Is Network Security? Let’s begin our study of network security by returning to our lovers, Alice\nand Bob, who want to communicate “securely.” What precisely does this\nmean? Certainly, Alice wants only Bob to be able to understand a message\nthat she has sent, even though they are communicating over an insecure\nmedium where an intruder (Trudy, the intruder) may intercept whatever is\ntransmitted from Alice to Bob. Bob also wants to be sure that the message\nhe receives from Alice was indeed sent by Alice, and Alice wants to make\nsure that the person with whom she is communicating is indeed Bob. Alice\nand Bob also want to make sure that the contents of their messages have not\nbeen altered in transit. They also want to be assured that they can\ncommunicate in the first place (i.e., that no one denies them access to the\nresources needed to communicate). Given these considerations, we can\nidentify the following desirable properties of secure communication. •\nConfidentiality. Only the sender and intended receiver should be able to\nunderstand the contents of the transmitted message. Because\neavesdroppers may intercept the message, this necessarily requires that\nthe message be somehow encrypted so that an intercepted message\ncannot be understood by an interceptor. This aspect of confidentiality is\nprobably the most commonly perceived meaning of the term secure\ncommunication. We’ll study cryptographic techniques for encrypting\nand decrypting data in Section 8.2. •\nMessage integrity. Alice and Bob want to ensure that the content of their\n­communication is not altered, either maliciously or by accident, in\ntransit. Extensions to the checksumming techniques that we"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1037,
    "text": "encountered in reliable transport and data link protocols can be used to\nprovide such message integrity. We will study message integrity in\nSection 8.3. •\nEnd-point authentication. Both the sender and receiver should be able\nto confirm the identity of the other party involved in the communication\n—to confirm that the other party is indeed who or what they claim to\nbe. Face-to-face human communication solves this problem easily by\nvisual recognition. When communicating entities exchange messages\nover a medium where they cannot see the other party, authentication is\nnot so simple. When a user wants to access an inbox, how does the mail\nserver verify that the user is the person he or she claims to be? We study\nend-point authentication in Section 8.4. •\nOperational security. Almost all organizations (companies, universities,\nand so on) today have networks that are attached to the public Internet. These networks therefore can potentially be compromised. Attackers\ncan attempt to deposit worms into the hosts in the network, obtain\ncorporate secrets, map the internal network configurations, and launch\nDoS attacks. We’ll see in Section 8.9 that operational devices such as\nfirewalls and intrusion detection systems are used to counter attacks\nagainst an organization’s network. A firewall sits between the\norganization’s network and the public network, controlling packet\naccess to and from the network. An intrusion detection system performs\n“deep packet ­inspection,” ­alerting the network administrators about\nsuspicious activity. Having established what we mean by network security, let’s next\nconsider exactly what information an intruder may have access to, and what\nactions can be taken by the intruder. Figure 8.1 illustrates the scenario. Alice, the sender, wants to send data to Bob, the receiver. In order to"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1038,
    "text": "exchange data securely, while meeting the requirements of confidentiality,\nend-point authentication, and message integrity, Alice and Bob will\nexchange control messages and data messages (in much the same way that\nTCP senders and receivers exchange control segments and data ­segments). All or some of these messages will typically be encrypted. As discussed in\nSection 1.6, an intruder can potentially perform\nFigure 8.1 ♦Sender, receiver, and intruder (Alice, Bob, and Trudy)\n•\neavesdropping—sniffing and recording control and data messages on\nthe ­channel. •\nmodification, insertion, or deletion of messages or message content. As we’ll see, unless appropriate countermeasures are taken, these\ncapabilities allow an intruder to mount a wide variety of security attacks:\nsnooping on communication (possibly stealing passwords and data),\nimpersonating another entity, hijacking an ongoing session, denying service\nto legitimate network users by overloading system resources, and so on. A\nsummary of reported attacks is maintained at the CERT Coordination\nCenter [CERT 2020]."
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 1039,
    "text": "Having established that there are indeed real threats loose in the\nInternet, what are the Internet equivalents of Alice and Bob, our friends\nwho need to communicate securely? Certainly, Bob and Alice might be\nhuman users at two end systems, for example, a real Alice and a real Bob\nwho really do want to exchange secure e-mail. They might also be\nparticipants in an electronic commerce transaction. For example, a real Bob\nmight want to transfer his credit card number securely to a Web server to\npurchase an item online. Similarly, a real Alice might want to interact with\nher bank online. The parties needing secure communication might\nthemselves also be part of the network infrastructure. Recall that the\ndomain name system (DNS, see Section 2.4) or routing daemons that\nexchange \nrouting \ninformation \n(see \nChapter \n5) \nrequire \nsecure\ncommunication between two parties. The same is true for network\nmanagement applications, a topic we examined in Chapter 5). An intruder\nthat could actively interfere with DNS lookups (as discussed in Section\n2.4), routing computations ­(Sections 5.3 and 5.4), or network management\nfunctions (Sections 5.5 and 5.7) could wreak havoc in the Internet. Having now established the framework, a few of the most important\ndefinitions, and the need for network security, let us next delve into\ncryptography. While the use of cryptography in providing confidentiality is\nself-evident, we’ll see shortly that it is also central to providing end-point\nauthentication and message integrity—making cryptography a cornerstone\nof network security."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1040,
    "text": "8.2 Principles of Cryptography\nAlthough cryptography has a long history dating back at least as far as Julius ­Caesar,\nmodern cryptographic techniques, including many of those used in the Internet, are based on\nadvances made in the past 30 years. Kahn’s book, The ­Codebreakers [Kahn 1967], and\nSingh’s book, The Code Book: The Science of Secrecy from Ancient Egypt to Quantum\nCryptography [Singh 1999], provide a fascinating look at the long history of cryptography. A complete discussion of cryptography itself requires a complete book [Bishop 2003;\nKaufman 2002; Schneier 2015] and so we only touch on the essential aspects of\ncryptography, particularly as they are practiced on the Internet. We also note that while our\nfocus in this section will be on the use of cryptography for confidentiality, we’ll see shortly\nthat cryptographic techniques are inextricably woven into authentication, message integrity,\nnonrepudiation, and more. Cryptographic techniques allow a sender to disguise data so that an intruder can gain no\ninformation from the intercepted data. The receiver, of course, must be able to recover the\noriginal data from the disguised data. Figure 8.2 illustrates some of the important\nterminology. Figure 8.2 ♦Cryptographic components"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1041,
    "text": "Suppose now that Alice wants to send a message to Bob. Alice’s message in its original\nform (e.g., “Bob, I love you. Alice”) is known as ­plaintext, or cleartext. Alice\nencrypts her plaintext message using an encryption algorithm so that the encrypted\nmessage, known as ciphertext, looks unintelligible to any intruder. Interestingly, in many\nmodern cryptographic systems, including those used in the Internet, the encryption\ntechnique itself is known—published, standardized, and available to everyone (e.g., [RFC\n1321; RFC 3447; RFC 2420; NIST 2001]), even a potential intruder! Clearly, if everyone\nknows the method for encoding data, then there must be some secret information that\nprevents an intruder from decrypting the transmitted data. This is where keys come in. In Figure 8.2, Alice provides a key, K , a string of numbers or characters, as input to the\nencryption algorithm. The encryption algorithm takes the key and the plaintext message, m,\nas input and produces ciphertext as output. The notation K (m) refers to the ciphertext form\n(encrypted using the key K ) of the plaintext message, m. The actual encryption algorithm\nthat uses key K  will be evident from the context. Similarly, Bob will provide a key, K , to\nthe decryption algorithm that takes the ciphertext and Bob’s key as input and produces the\noriginal plaintext as output. That is, if Bob receives an encrypted message K (m), he\ndecrypts it by computing K (K (m)) = m. In symmetric key systems, Alice’s and Bob’s keys\nare identical and are secret. In public key systems, a pair of keys is used. One of the keys is\nknown to both Bob and Alice (indeed, it is known to the whole world). The other key is\nknown only by either Bob or Alice (but not both). In the following two subsections, we\nconsider symmetric key and public key systems in more detail. 8.2.1 Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for example, taking\na piece of plaintext and then computing and substituting the appropriate ciphertext to create\nthe encrypted message. Before studying a modern key-based cryptographic system, let us\nfirst get our feet wet by studying a very old, very simple symmetric key algorithm attributed\nto Julius Caesar, known as the Caesar cipher (a cipher is a method for encrypting data). For English text, the Caesar cipher would work by taking each letter in the plaintext\nmessage and substituting the letter that is k letters later (allowing wraparound; that is, having\nthe letter z followed by the letter a) in the alphabet. For example, if k = 3, then the letter a in\nplaintext becomes d in ciphertext; b in plaintext becomes e in ciphertext, and so on."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1041,
    "text": "Suppose now that Alice wants to send a message to Bob. Alice’s message in its original\nform (e.g., “Bob, I love you. Alice”) is known as ­plaintext, or cleartext. Alice\nencrypts her plaintext message using an encryption algorithm so that the encrypted\nmessage, known as ciphertext, looks unintelligible to any intruder. Interestingly, in many\nmodern cryptographic systems, including those used in the Internet, the encryption\ntechnique itself is known—published, standardized, and available to everyone (e.g., [RFC\n1321; RFC 3447; RFC 2420; NIST 2001]), even a potential intruder! Clearly, if everyone\nknows the method for encoding data, then there must be some secret information that\nprevents an intruder from decrypting the transmitted data. This is where keys come in. In Figure 8.2, Alice provides a key, K , a string of numbers or characters, as input to the\nencryption algorithm. The encryption algorithm takes the key and the plaintext message, m,\nas input and produces ciphertext as output. The notation K (m) refers to the ciphertext form\n(encrypted using the key K ) of the plaintext message, m. The actual encryption algorithm\nthat uses key K  will be evident from the context. Similarly, Bob will provide a key, K , to\nthe decryption algorithm that takes the ciphertext and Bob’s key as input and produces the\noriginal plaintext as output. That is, if Bob receives an encrypted message K (m), he\ndecrypts it by computing K (K (m)) = m. In symmetric key systems, Alice’s and Bob’s keys\nare identical and are secret. In public key systems, a pair of keys is used. One of the keys is\nknown to both Bob and Alice (indeed, it is known to the whole world). The other key is\nknown only by either Bob or Alice (but not both). In the following two subsections, we\nconsider symmetric key and public key systems in more detail. 8.2.1 Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for example, taking\na piece of plaintext and then computing and substituting the appropriate ciphertext to create\nthe encrypted message. Before studying a modern key-based cryptographic system, let us\nfirst get our feet wet by studying a very old, very simple symmetric key algorithm attributed\nto Julius Caesar, known as the Caesar cipher (a cipher is a method for encrypting data). For English text, the Caesar cipher would work by taking each letter in the plaintext\nmessage and substituting the letter that is k letters later (allowing wraparound; that is, having\nthe letter z followed by the letter a) in the alphabet. For example, if k = 3, then the letter a in\nplaintext becomes d in ciphertext; b in plaintext becomes e in ciphertext, and so on. Here,\nthe value of k serves as the key."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1041,
    "text": "Suppose now that Alice wants to send a message to Bob. Alice’s message in its original\nform (e.g., “Bob, I love you. Alice”) is known as ­plaintext, or cleartext. Alice\nencrypts her plaintext message using an encryption algorithm so that the encrypted\nmessage, known as ciphertext, looks unintelligible to any intruder. Interestingly, in many\nmodern cryptographic systems, including those used in the Internet, the encryption\ntechnique itself is known—published, standardized, and available to everyone (e.g., [RFC\n1321; RFC 3447; RFC 2420; NIST 2001]), even a potential intruder! Clearly, if everyone\nknows the method for encoding data, then there must be some secret information that\nprevents an intruder from decrypting the transmitted data. This is where keys come in. In Figure 8.2, Alice provides a key, K , a string of numbers or characters, as input to the\nencryption algorithm. The encryption algorithm takes the key and the plaintext message, m,\nas input and produces ciphertext as output. The notation K (m) refers to the ciphertext form\n(encrypted using the key K ) of the plaintext message, m. The actual encryption algorithm\nthat uses key K  will be evident from the context. Similarly, Bob will provide a key, K , to\nthe decryption algorithm that takes the ciphertext and Bob’s key as input and produces the\noriginal plaintext as output. That is, if Bob receives an encrypted message K (m), he\ndecrypts it by computing K (K (m)) = m. In symmetric key systems, Alice’s and Bob’s keys\nare identical and are secret. In public key systems, a pair of keys is used. One of the keys is\nknown to both Bob and Alice (indeed, it is known to the whole world). The other key is\nknown only by either Bob or Alice (but not both). In the following two subsections, we\nconsider symmetric key and public key systems in more detail. 8.2.1 Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for example, taking\na piece of plaintext and then computing and substituting the appropriate ciphertext to create\nthe encrypted message. Before studying a modern key-based cryptographic system, let us\nfirst get our feet wet by studying a very old, very simple symmetric key algorithm attributed\nto Julius Caesar, known as the Caesar cipher (a cipher is a method for encrypting data). For English text, the Caesar cipher would work by taking each letter in the plaintext\nmessage and substituting the letter that is k letters later (allowing wraparound; that is, having\nthe letter z followed by the letter a) in the alphabet. For example, if k = 3, then the letter a in\nplaintext becomes d in ciphertext; b in plaintext becomes e in ciphertext, and so on. Here,\nthe value of k serves as the key. As an example, the plaintext message “bob, i love\nA\nA\nA\nA\nB\nA\nB\nA"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1041,
    "text": "Suppose now that Alice wants to send a message to Bob. Alice’s message in its original\nform (e.g., “Bob, I love you. Alice”) is known as ­plaintext, or cleartext. Alice\nencrypts her plaintext message using an encryption algorithm so that the encrypted\nmessage, known as ciphertext, looks unintelligible to any intruder. Interestingly, in many\nmodern cryptographic systems, including those used in the Internet, the encryption\ntechnique itself is known—published, standardized, and available to everyone (e.g., [RFC\n1321; RFC 3447; RFC 2420; NIST 2001]), even a potential intruder! Clearly, if everyone\nknows the method for encoding data, then there must be some secret information that\nprevents an intruder from decrypting the transmitted data. This is where keys come in. In Figure 8.2, Alice provides a key, K , a string of numbers or characters, as input to the\nencryption algorithm. The encryption algorithm takes the key and the plaintext message, m,\nas input and produces ciphertext as output. The notation K (m) refers to the ciphertext form\n(encrypted using the key K ) of the plaintext message, m. The actual encryption algorithm\nthat uses key K  will be evident from the context. Similarly, Bob will provide a key, K , to\nthe decryption algorithm that takes the ciphertext and Bob’s key as input and produces the\noriginal plaintext as output. That is, if Bob receives an encrypted message K (m), he\ndecrypts it by computing K (K (m)) = m. In symmetric key systems, Alice’s and Bob’s keys\nare identical and are secret. In public key systems, a pair of keys is used. One of the keys is\nknown to both Bob and Alice (indeed, it is known to the whole world). The other key is\nknown only by either Bob or Alice (but not both). In the following two subsections, we\nconsider symmetric key and public key systems in more detail. 8.2.1 Symmetric Key Cryptography\nAll cryptographic algorithms involve substituting one thing for another, for example, taking\na piece of plaintext and then computing and substituting the appropriate ciphertext to create\nthe encrypted message. Before studying a modern key-based cryptographic system, let us\nfirst get our feet wet by studying a very old, very simple symmetric key algorithm attributed\nto Julius Caesar, known as the Caesar cipher (a cipher is a method for encrypting data). For English text, the Caesar cipher would work by taking each letter in the plaintext\nmessage and substituting the letter that is k letters later (allowing wraparound; that is, having\nthe letter z followed by the letter a) in the alphabet. For example, if k = 3, then the letter a in\nplaintext becomes d in ciphertext; b in plaintext becomes e in ciphertext, and so on. Here,\nthe value of k serves as the key. As an example, the plaintext message “bob, i love\nA\nA\nA\nA\nB\nA\nB\nA"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1042,
    "text": "you. Alice” becomes “ere, l oryh brx. dolfh” in ciphertext. While the\nciphertext does indeed look like gibberish, it wouldn’t take long to break the code if you\nknew that the Caesar cipher was being used, as there are only 25 possible key values. An improvement on the Caesar cipher is the monoalphabetic cipher, which also\nsubstitutes one letter of the alphabet with another letter of the alphabet. ­However, rather than\nsubstituting according to a regular pattern (e.g., substitution with an offset of k for all\nletters), any letter can be substituted for any other letter, as long as each letter has a unique\nsubstitute letter, and vice versa. The substitution rule in Figure 8.3 shows one possible rule\nfor encoding plaintext. Figure 8.3 ♦A monoalphabetic cipher\nThe plaintext message “bob, i love you. Alice” becomes “nkn, s gktc\nwky. Mgsbc.” Thus, as in the case of the Caesar cipher, this looks like gibberish. A\nmonoalphabetic cipher would also appear to be better than the Caesar cipher in that there are\n26! (on the order of 10 ) possible pairings of letters rather than 25 possible pairings. A\nbrute-force approach of trying all 10  possible pairings would require far too much work to\nbe a feasible way of breaking the encryption algorithm and decoding the message. However,\nby statistical analysis of the plaintext language, for example, knowing that the letters e and t\nare the most frequently occurring letters in typical English text (accounting for 13 percent\nand 9 percent of letter occurrences), and knowing that particular two-and three-letter\noccurrences of letters appear quite often together (for example, “in,” “it,” “the,” “ion,”\n“ing,” and so forth) make it relatively easy to break this code. If the intruder has some\nknowledge about the possible contents of the message, then it is even easier to break the\ncode. For example, if Trudy the intruder is Bob’s wife and suspects Bob of having an affair\nwith Alice, then she might suspect that the names “bob” and “alice” appear in the text. If\nTrudy knew for certain that those two names appeared in the ciphertext and had a copy of\nthe example ciphertext message above, then she could immediately determine seven of the\n26 letter pairings, requiring 10  fewer possibilities to be checked by a brute-force method. 26"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1043,
    "text": "Indeed, if Trudy suspected Bob of having an affair, she might well expect to find some other\nchoice words in the message as well. When considering how easy it might be for Trudy to break Bob and Alice’s encryption\nscheme, one can distinguish three different scenarios, depending on what information the\nintruder has. •\nCiphertext-only attack. In some cases, the intruder may have access only to the\nintercepted ciphertext, with no certain information about the contents of the plaintext\nmessage. We have seen how statistical analysis can help in a ciphertext-only attack on\nan encryption scheme. •\nKnown-plaintext attack. We saw above that if Trudy somehow knew for sure that “bob”\nand “alice” appeared in the ciphertext message, then she could have determined the\n(plaintext, ciphertext) pairings for the letters a, l, i, c, e, b, and o. Trudy might also have\nbeen fortunate enough to have recorded all of the ciphertext transmissions and then\nfound Bob’s own decrypted version of one of the transmissions scribbled on a piece of\npaper. When an intruder knows some of the (plaintext, ciphertext) pairings, we refer to\nthis as a known-plaintext attack on the encryption scheme. •\nChosen-plaintext attack. In a chosen-plaintext attack, the intruder is able to choose the\nplaintext message and obtain its corresponding ciphertext form. For the simple\nencryption algorithms we’ve seen so far, if Trudy could get Alice to send the message,\n“The quick brown fox jumps over the lazy dog,” she could\ncompletely break the encryption scheme. We’ll see shortly that for more sophisticated\nencryption techniques, a chosen-plaintext attack does not necessarily mean that the\nencryption technique can be broken. Five hundred years ago, techniques improving on monoalphabetic encryption, known as\npolyalphabetic encryption, were invented. The idea behind ­polyalphabetic encryption is to\nuse multiple monoalphabetic ciphers, with a specific ­monoalphabetic cipher to encode a\nletter in a specific position in the plaintext message. Thus, the same letter, appearing in\ndifferent positions in the plaintext message, might be encoded differently. An example of a\npolyalphabetic encryption scheme is shown in Figure 8.4. It has two Caesar ciphers (with k\n= 5 and k = 19), shown as rows. We might choose to use these two Caesar ciphers, C  and\nC , in the repeating pattern C , C , C , C , C . That is, the first letter of plaintext is to be\nencoded using C , the second and third using C , the fourth using C , and the fifth using C . The pattern then repeats, with the sixth letter being encoded using C , the seventh with C ,\n2\n2\n1\n1\n1\n1"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1044,
    "text": "and so on. The plaintext message “bob, i love you.” is thus encrypted “ghu, n\netox dhz.” Note that the first b in the plaintext message is encrypted using C , while the\nsecond b is encrypted using C . In this example, the encryption and decryption “key” is the\nknowledge of the two Caesar keys (k = 5, k = 19) and the pattern C , C , C , C , C . Figure 8.4 ♦A polyalphabetic cipher using two Caesar ciphers\nBlock Ciphers\nLet us now move forward to modern times and examine how symmetric key encryption is\ndone today. We focus on block ciphers, which are used in many secure Internet protocols,\nincluding PGP (for secure e-mail), TLS (for securing TCP connections), and IPsec (for\nsecuring the network-layer transport). In a block cipher, the message to be encrypted is processed in blocks of k bits. For\nexample, if k = 64, then the message is broken into 64-bit blocks, and each block is\nencrypted independently. To encode a block, the cipher uses a one-to-one mapping to map\nthe k-bit block of cleartext to a k-bit block of ciphertext. Let’s look at an example. Suppose\nthat k = 3, so that the block cipher maps 3-bit inputs ­(cleartext) to 3-bit outputs (ciphertext). One possible mapping is given in Table 8.1. Notice that this is a one-to-one mapping; that is,\nthere is a different output for each input. This block cipher breaks the message up into 3-bit\nblocks and encrypts each block according to the above mapping. You should verify that the\nmessage 010110001111 gets encrypted into 101000111001. Table 8.1 ♦A specific 3-bit block cipher\nContinuing with this 3-bit block example, note that the mapping in Table 8.1 is just one\nmapping of many possible mappings. How many possible mappings are there? To answer\nthis question, observe that a mapping is nothing more than a permutation of all the possible\ninputs. There are 2  (= 8) possible inputs (listed under the input columns). These eight inputs\ncan be permuted in 8! = 40,320 different ways. Since each of these permutations specifies a\nmapping, there are 40,320 possible mappings. We can view each of these mappings as a key\n2\n2\n1\n3"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1045,
    "text": "—if Alice and Bob both know the mapping (the key), they can encrypt and decrypt the\nmessages sent between them. The brute-force attack for this cipher is to try to decrypt ciphtertext by using all\nmappings. With only 40,320 mappings (when k = 3), this can quickly be accomplished on a\ndesktop PC. To thwart brute-force attacks, block ciphers typically use much larger blocks,\nconsisting of k = 64 bits or even larger. Note that the number of possible mappings for a\ngeneral k-block cipher is 2 !, which is astronomical for even moderate values of k (such as k\n= 64). Although full-table block ciphers, as just described, with moderate values of k can\nproduce robust symmetric key encryption schemes, they are unfortunately difficult to\nimplement. For k = 64 and for a given mapping, Alice and Bob would need to maintain a\ntable with 2  input values, which is an infeasible task. Moreover, if Alice and Bob were to\nchange keys, they would have to each regenerate the table. Thus, a full-table block cipher,\nproviding predetermined mappings between all inputs and outputs (as in the example\nabove), is simply out of the question. Instead, block ciphers typically use functions that simulate randomly permuted tables. An example (adapted from [Kaufman 2002]) of such a function for k = 64 bits is shown in\nFigure 8.5. The function first breaks a 64-bit block into 8 chunks, with each chunk\nconsisting of 8 bits. Each 8-bit chunk is processed by an 8-bit to 8-bit table, which is of\nmanageable size. For example, the first chunk is processed by the table denoted by T . Next,\nthe 8 output chunks are reassembled into a 64-bit block. The positions of the 64 bits in the\nblock are then scrambled (permuted) to produce a 64-bit output. This output is fed back to\nthe 64-bit input, where another cycle begins. After n such cycles, the function provides a 64-\nbit block of ciphertext. The purpose of the rounds is to make each input bit affect most (if\nnot all) of the final output bits. (If only one round were used, a given input bit would affect\nonly 8 of the 64 output bits.) The key for this block cipher algorithm would be the eight\npermutation tables (assuming the scramble function is publicly known). k\n1"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1046,
    "text": "Figure 8.5 ♦An example of a block cipher\nToday there are a number of popular block ciphers, including DES (standing for Data\nEncryption Standard), 3DES, and AES (standing for Advanced Encryption Standard). Each\nof these standards uses functions, rather than predetermined tables, along the lines of Figure\n8.5 (albeit more complicated and specific to each cipher). Each of these algorithms also uses\na string of bits for a key. For example, DES uses 64-bit blocks with a 56-bit key. AES uses\n128-bit blocks and can operate with keys that are 128, 192, and 256 bits long. An\nalgorithm’s key determines the specific “mini-table” mappings and permutations within the\nalgorithm’s internals. The brute-force attack for each of these ciphers is to cycle through all\nthe keys, applying the decryption algorithm with each key. Observe that with a key length of\nn, there are 2  possible keys. NIST [NIST 2001] estimates that a machine that could crack\n56-bit DES in one second (that is, try all 2  keys in one second) would take approximately\n149 trillion years to crack a 128-bit AES key. Cipher-Block Chaining\nIn computer networking applications, we typically need to encrypt long messages or long\nstreams of data. If we apply a block cipher as described by simply chopping up the message\ninto k-bit blocks and independently encrypting each block, a subtle but important problem\noccurs. To see this, observe that two or more of the cleartext blocks can be identical. For\nn"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K ."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K . The astute reader will note that introducing randomness solves one problem but creates\nanother: namely, Alice must transmit twice as many bits as before."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K . The astute reader will note that introducing randomness solves one problem but creates\nanother: namely, Alice must transmit twice as many bits as before. Indeed, for each cipher\nbit, she must now also send a random bit, doubling the required bandwidth."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K . The astute reader will note that introducing randomness solves one problem but creates\nanother: namely, Alice must transmit twice as many bits as before. Indeed, for each cipher\nbit, she must now also send a random bit, doubling the required bandwidth. In order to have\nour cake and eat it too, block ciphers typically use a technique called Cipher Block\nChaining (CBC)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K . The astute reader will note that introducing randomness solves one problem but creates\nanother: namely, Alice must transmit twice as many bits as before. Indeed, for each cipher\nbit, she must now also send a random bit, doubling the required bandwidth. In order to have\nour cake and eat it too, block ciphers typically use a technique called Cipher Block\nChaining (CBC). The basic idea is to send only one random value along with the very first\nS\nS\nS\nS\nS"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1047,
    "text": "example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical\nblocks, a block cipher would, of course, produce the same ciphertext. An attacker could\npotentially guess the cleartext when it sees identical ciphertext blocks and may even be able\nto decrypt the entire message by identifying identical ciphtertext blocks and using\nknowledge about the underlying protocol structure [Kaufman 2002]. To address this problem, we can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. To explain this idea, let m(i)\ndenote the ith plaintext block, c(i) denote the ith ciphertext block, and a⊕b denote the\nexclusive-or (XOR) of two bit strings, a and b. (Recall that the 0 ⊕ 0 = 1 ⊕ 1 = 0 and 0 ⊕\n1 = 1 ⊕ 0 = 1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example,\n10101010 ⊕ 11110000 = 01011010.) Also, denote the block-cipher encryption algorithm\nwith key S as K . The basic idea is as follows. The sender creates a random k-bit number r(i)\nfor the ith block and calculates c(i ) = K (m(i) ⊕ r(i)). Note that a new k-bit random number\nis chosen for each block. The sender then sends c(1), r(1), c(2), r(2), c(3), r(3), and so on. Since the receiver receives c(i) and r(i), it can recover each block of the plaintext by\ncomputing m(i) = K (c(i)) ⊕ r(i). It is important to note that, although r(i) is sent in the clear\nand thus can be sniffed by Trudy, she cannot obtain the plaintext m(i), since she does not\nknow the key K . Also note that if two plaintext blocks m(i) and m(j) are the same, the\ncorresponding ciphertext blocks c(i) and c(j) will be different (as long as the random\nnumbers r(i) and r(j) are different, which occurs with very high probability). As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is\n010010010. If Alice encrypts this directly, without including the randomness, the resulting\nciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three\ncipher blocks is the same, she can correctly surmise that each of the three plaintext blocks\nare the same. Now suppose instead Alice generates the random blocks r(1) = 001, r(2) =\n111, and r(3) = 100 and uses the above technique to generate the ciphertext c(1) = 100, c(2)\n= 010, and c(3) = 000. Note that the three ciphertext blocks are different even though the\nplaintext blocks are the same. Alice then sends c(1), r(1), c(2), and r(2). You should verify\nthat Bob can obtain the original plaintext using the shared key K . The astute reader will note that introducing randomness solves one problem but creates\nanother: namely, Alice must transmit twice as many bits as before. Indeed, for each cipher\nbit, she must now also send a random bit, doubling the required bandwidth. In order to have\nour cake and eat it too, block ciphers typically use a technique called Cipher Block\nChaining (CBC). The basic idea is to send only one random value along with the very first\nS\nS\nS\nS\nS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1048,
    "text": "message, and then have the sender and receiver use the computed coded blocks in place of\nthe subsequent random number. Specifically, CBC operates as follows:\n1. Before encrypting the message (or the stream of data), the sender generates a random k-\nbit string, called the Initialization Vector (IV). Denote this initialization vector by c(0). The sender sends the IV to the receiver in cleartext. 2. For the first block, the sender calculates m(1) ⊕ c(0), that is, calculates the exclusive-or\nof the first block of cleartext with the IV. It then runs the result through the block-cipher\nalgorithm to get the corresponding ciphertext block; that is, c(1) = K (m(1) ⊕ c(0)). The\nsender sends the encrypted block c(1) to the receiver. 3. For the ith block, the sender generates the ith ciphertext block from c(i) = K (m(i) ⊕ c(i\n− 1)). Let’s now examine some of the consequences of this approach. First, the receiver will\nstill be able to recover the original message. Indeed, when the receiver receives c(i), it\ndecrypts it with K  to obtain s(i) = m(i) ⊕ c(i − 1); since the receiver also knows c(i − 1), it\nthen obtains the cleartext block from m(i) = s(i) ⊕ c(i − 1). Second, even if two cleartext\nblocks are identical, the corresponding ciphtertexts (almost always) will be different. Third,\nalthough the sender sends the IV in the clear, an intruder will still not be able to decrypt the\nciphertext blocks, since the intruder does not know the secret key, S. Finally, the sender only\nsends one overhead block (the IV), thereby negligibly increasing the bandwidth usage for\nlong messages (consisting of hundreds of blocks). As an example, let’s now determine the ciphertext for the 3-bit block cipher in Table 8.1\nwith plaintext 010010010 and IV = c(0) = 001. The sender first uses the IV to calculate c(1)\n= K (m(1) ⊕ c(0)) = 100. The sender then calculates c(2) = K (m(2) ⊕ c(1)) = K (010 ⊕\n100) = 000, and c(3) = K (m(3) ⊕ c(2)) = K (010 ⊕ 000) = 101. The reader should verify\nthat the receiver, knowing the IV and K  can recover the original plaintext. CBC has an important consequence when designing secure network protocols: we’ll\nneed to provide a mechanism within the protocol to distribute the IV from sender to\nreceiver. We’ll see how this is done for several protocols later in this chapter. 8.2.2 Public Key Encryption\nFor more than 2,000 years (since the time of the Caesar cipher and up to the 1970s),\nencrypted communication required that the two communicating parties share a common\nS\nS\nS\nS\nS\nS\nS\nS\nS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1049,
    "text": "secret—the symmetric key used for encryption and decryption. One difficulty with this\napproach is that the two parties must somehow agree on the shared key; but to do so in itself\nrequires secure communication. Perhaps the parties could first meet and agree on the key in\nperson (for example, two of Caesar’s centurions might meet at the Roman baths) and\nthereafter communicate with encryption. In a networked world, however, communicating\nparties may never meet and may never converse except over the network. Is it possible for two parties to communicate with encryption without having a shared\nsecret key that is known in advance? In 1976, Diffie and Hellman [Diffie 1976]\ndemonstrated an algorithm (known now as Diffie-Hellman Key Exchange) to do just that—a\nradically different and marvelously elegant approach toward secure communication that has\nled to the development of today’s public key cryptography systems. We’ll see shortly that\npublic key cryptography systems also have several wonderful properties that make them\nuseful not only for encryption, but for authentication and digital signatures as well. Interestingly, it has come to light that ideas similar to those in [Diffie 1976] and [RSA 1978]\nhad been independently developed in the early 1970s in a series of secret reports by\nresearchers at the Communications-Electronics Security Group in the United ­Kingdom\n[Ellis 1987]. As is often the case, great ideas can spring up independently in many places;\nfortunately, public key advances took place not only in private, but also in the public view,\nas well. The use of public key cryptography is conceptually quite simple. Suppose Alice wants\nto communicate with Bob. As shown in Figure 8.6, rather than Bob and Alice sharing a\nsingle secret key (as in the case of symmetric key systems), Bob (the recipient of Alice’s\nmessages) instead has two keys—a public key that is available to everyone in the world\n(including Trudy the intruder) and a private key that is known only to Bob. We will use the\nnotation K +\nB  and K −\nB  to refer to Bob’s public and private keys, respectively. In order to\ncommunicate with Bob, Alice first fetches Bob’s public key. Alice then encrypts her\nmessage, m, to Bob using Bob’s public key and a known (for example, standardized)\nencryption algorithm; that is, Alice computes K +\nB (m). Bob receives Alice’s encrypted\nmessage and uses his private key and a known (for example, standardized) decryption\nalgorithm to decrypt Alice’s encrypted message. That is, Bob computes K −\nB (K +\nB (m)). We\nwill see below that there are encryption/decryption algorithms and techniques for choosing\npublic and private keys such that K −\nB (K +\nB (m)) = m; that is, applying Bob’s public key,\nK +\nB , to a message, m (to get K +\nB (m)), and then applying Bob’s private key, K −\nB , to the\nencrypted version of m (that is, computing K −\nB (K +\nB (m))) gives back m. This is a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1049,
    "text": "secret—the symmetric key used for encryption and decryption. One difficulty with this\napproach is that the two parties must somehow agree on the shared key; but to do so in itself\nrequires secure communication. Perhaps the parties could first meet and agree on the key in\nperson (for example, two of Caesar’s centurions might meet at the Roman baths) and\nthereafter communicate with encryption. In a networked world, however, communicating\nparties may never meet and may never converse except over the network. Is it possible for two parties to communicate with encryption without having a shared\nsecret key that is known in advance? In 1976, Diffie and Hellman [Diffie 1976]\ndemonstrated an algorithm (known now as Diffie-Hellman Key Exchange) to do just that—a\nradically different and marvelously elegant approach toward secure communication that has\nled to the development of today’s public key cryptography systems. We’ll see shortly that\npublic key cryptography systems also have several wonderful properties that make them\nuseful not only for encryption, but for authentication and digital signatures as well. Interestingly, it has come to light that ideas similar to those in [Diffie 1976] and [RSA 1978]\nhad been independently developed in the early 1970s in a series of secret reports by\nresearchers at the Communications-Electronics Security Group in the United ­Kingdom\n[Ellis 1987]. As is often the case, great ideas can spring up independently in many places;\nfortunately, public key advances took place not only in private, but also in the public view,\nas well. The use of public key cryptography is conceptually quite simple. Suppose Alice wants\nto communicate with Bob. As shown in Figure 8.6, rather than Bob and Alice sharing a\nsingle secret key (as in the case of symmetric key systems), Bob (the recipient of Alice’s\nmessages) instead has two keys—a public key that is available to everyone in the world\n(including Trudy the intruder) and a private key that is known only to Bob. We will use the\nnotation K +\nB  and K −\nB  to refer to Bob’s public and private keys, respectively. In order to\ncommunicate with Bob, Alice first fetches Bob’s public key. Alice then encrypts her\nmessage, m, to Bob using Bob’s public key and a known (for example, standardized)\nencryption algorithm; that is, Alice computes K +\nB (m). Bob receives Alice’s encrypted\nmessage and uses his private key and a known (for example, standardized) decryption\nalgorithm to decrypt Alice’s encrypted message. That is, Bob computes K −\nB (K +\nB (m)). We\nwill see below that there are encryption/decryption algorithms and techniques for choosing\npublic and private keys such that K −\nB (K +\nB (m)) = m; that is, applying Bob’s public key,\nK +\nB , to a message, m (to get K +\nB (m)), and then applying Bob’s private key, K −\nB , to the\nencrypted version of m (that is, computing K −\nB (K +\nB (m))) gives back m. This is a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1050,
    "text": "remarkable result! In this manner, Alice can use Bob’s publicly available key to send a\nsecret message to Bob without either of them having to distribute any secret keys! We will\nsee shortly that we can interchange the public key and private key encryption and get the\nsame remarkable result––that is, K −\nB (+\nB(m)) = K +\nB (K −\nB (m)) = m.\nFigure 8.6 ♦Public key cryptography\nAlthough public-key cryptography is appealing, one concern immediately springs to\nmind. Since Bob’s encryption key is public, anyone can send an encrypted message to Bob,\nincluding Alice or someone pretending to be Alice. In the case of a single shared secret key,\nthe fact that the sender knows the secret key implicitly identifies the sender to the receiver. In the case of public key cryptography, however, this is no longer the case since anyone can\nsend an encrypted message to Bob using Bob’s publicly available key. A digital signature, a\ntopic we will study in Section 8.3, is needed to bind a sender to a message. RSA\nWhile there may be many algorithms that address these concerns, the RSA ­algorithm\n(named after its founders, Ron Rivest, Adi Shamir, and Leonard Adleman) has become\nalmost synonymous with public key cryptography. Let’s first see how RSA works and then\nexamine why it works. RSA makes extensive use of arithmetic operations using modulo-n arithmetic. So let’s\nbriefly review modular arithmetic. Recall that x mod n simply means the remainder of x\nwhen divided by n; so, for example, 19 mod 5 = 4. In modular arithmetic, one performs the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1051,
    "text": "usual operations of addition, multiplication, and exponentiation. However, the result of each\noperation is replaced by the integer remainder that is left when the result is divided by n.\nAdding and multiplying with modular arithmetic is facilitated with the following handy\nfacts:\nIt follows from the third fact that (α mod n)  mod n = α  mod n, which is an identity that we\nwill soon find very useful. Now suppose that Alice wants to send to Bob an RSA-encrypted message, as shown in\nFigure 8.6. In our discussion of RSA, let’s always keep in mind that a message is nothing\nbut a bit pattern, and every bit pattern can be uniquely represented by an integer number\n(along with the length of the bit pattern). For example, suppose a message is the bit pattern\n1001; this message can be represented by the decimal integer 9. Thus, when encrypting a\nmessage with RSA, it is equivalent to encrypting the unique integer number that represents\nthe message. There are two interrelated components of RSA:\n•\nThe choice of the public key and the private key\n•\nThe encryption and decryption algorithm\nTo generate the public and private RSA keys, Bob performs the following steps:\n1. Choose two large prime numbers, p and q. How large should p and q be? The larger the\nvalues, the more difficult it is to break RSA, but the longer it takes to perform the\nencoding and decoding. RSA Laboratories recommends that the product of p and q be on\nthe order of 1,024 bits. For a discussion of how to find large prime numbers, see\n[Caldwell 2020]. 2. Compute n = pq and z = (p – 1)(q – 1). 3. Choose a number, e, less than n, that has no common factors (other than 1) with z. (In\nthis case, e and z are said to be relatively prime.) The letter e is used since this value will\nbe used in encryption. 4. Find a number, d, such that ed − 1 is exactly divisible (that is, with no ­remainder) by z. The letter d is used because this value will be used in decryption. Put another way, given\n[(a mod n) + (b mod n)] mod n = (a + b) mod n\n[(a mod n)  − (b mod n)] mod n = (a  − b) mod n\n[(a mod n)  ⋅ (b mod n)] mod n = (a  ⋅ b) mod n\nd\nd"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1052,
    "text": "e, we choose d such that\ned mod z = 1\n5. The public key that Bob makes available to the world, K +\nB , is the pair of numbers (n, e);\nhis private key, K −\nB , is the pair of numbers (n, d). The encryption by Alice and the decryption by Bob are done as follows:\n•\nSuppose Alice wants to send Bob a bit pattern represented by the integer ­number m\n(with m < n). To encode, Alice performs the exponentiation m , and then computes the\ninteger remainder when m  is divided by n. In other words, the encrypted value, c, of\nAlice’s plaintext message, m, is\nc = me mod n\nThe bit pattern corresponding to this ciphertext c is sent to Bob. •\nTo decrypt the received ciphertext message, c, Bob computes\nm = cd mod n\nwhich requires the use of his private key (n, d). As a simple example of RSA, suppose Bob chooses p = 5 and q = 7. ­(Admittedly, these\nvalues are far too small to be secure.) Then n = 35 and z = 24. Bob chooses e = 5, since 5\nand 24 have no common factors. Finally, Bob chooses d = 29, since 5 · 29 – 1 (that is, ed –\n1) is exactly divisible by 24. Bob makes the two values, n = 35 and e = 5, public and keeps\nthe value d = 29 secret. Observing these two public values, suppose Alice now wants to send\nthe letters l, o, v, and e to Bob. Interpreting each letter as a number between 1 and 26 (with a\nbeing 1, and z being 26), Alice and Bob perform the encryption and decryption shown in\nTables 8.2 and 8.3, respectively. Note that in this example, we consider each of the four\nletters as a distinct message. A more realistic example would be to convert the four letters\ninto their 8-bit ASCII representations and then encrypt the integer corresponding to the\nresulting 32-bit bit pattern. (Such a realistic example generates numbers that are much too\nlong to print in a textbook!) Table 8.2 ♦Alice’s RSA encryption, e = 5, n = 35\nGiven that the “toy” example in Tables 8.2 and 8.3 has already produced some\nextremely large numbers, and given that we saw earlier that p and q should each be several\ne\ne"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1053,
    "text": "hundred bits long, several practical issues regarding RSA come to mind. How does one\nchoose large prime numbers? How does one then choose e and d? How does one perform\nexponentiation with large numbers? A discussion of these important issues is beyond the\nscope of this book; see [Kaufman 2002] and the references therein for details. Session Keys\nWe note here that the exponentiation required by RSA is a rather time-consuming process. As a result, RSA is often used in practice in combination with symmetric key cryptography. For example, if Alice wants to send Bob a large amount of encrypted data, she could do the\nfollowing. First Alice chooses a key that will be used to encode the data itself; this key is\nreferred to as a session key, and is denoted by K . Alice must inform Bob of the session key,\nsince this is the shared ­symmetric key they will use with a symmetric key cipher (e.g., with\nDES or AES). Alice encrypts the session key using Bob’s public key, that is, computes c =\n(K )  mod n. Bob receives the RSA-encrypted session key, c, and decrypts it to obtain the\nsession key, K . Bob now knows the session key that Alice will use for her encrypted data\ntransfer. Table 8.3 ♦Bob’s RSA decryption, d = 29, n = 35\nWhy Does RSA Work? RSA encryption/decryption appears rather magical. Why should it be that by applying the\nencryption algorithm and then the decryption algorithm, one recovers the original message? In order to understand why RSA works, again denote n = pq, where p and q are the large\nprime numbers used in the RSA algorithm. Recall that, under RSA encryption, a message (uniquely represented by an ­integer), m,\nis exponentiated to the power e using modulo-n arithmetic, that is,\nc = me mod n\nDecryption is performed by raising this value to the power d, again using modulo-n\narithmetic. The result of an encryption step followed by a decryption step is thus (m  mod\nn)  mod n. Let’s now see what we can say about this quantity. As mentioned earlier, one\nimportant property of modulo arithmetic is (a mod n)  mod n = a  mod n for any values a, n,\nand d. Thus, using a = m  in this property, we have\nS\nS e\nS\ne\nd\nd\nd\ne"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1054,
    "text": "(me mod n)d mod n = med mod n\nIt therefore remains to show that m  mod n = m. Although we’re trying to remove some\nof the magic about why RSA works, to establish this, we’ll need to use a rather magical\nresult from number theory here. Specifically, we’ll need the result that says if p and q are\nprime, n = pq, and z = (p – 1)(q – 1), then xy mod n is the same as x\n mod n [Kaufman\n2002]. Applying this result with x = m and y = ed we have\nmed mod n = m(ed mod z) mod n\nBut remember that we have chosen e and d such that ed mod z = 1. This gives us\nmed mod n = m1 mod n = m\nwhich is exactly the result we are looking for! By first exponentiating to the power of e (that\nis, encrypting) and then exponentiating to the power of d (that is, ­decrypting), we obtain the\noriginal value, m. Even more wonderful is the fact that if we first exponentiate to the power\nof d and then exponentiate to the power of e—that is, we reverse the order of encryption and\ndecryption, performing the decryption operation first and then applying the encryption\noperation—we also obtain the original value, m. This wonderful result follows immediately\nfrom the modular arithmetic:\n(md mod n)\ne mod n = mde mod n = med mod n = (me mod n)d mod n\nThe security of RSA relies on the fact that there are no known algorithms for quickly\nfactoring a number, in this case the public value n, into the primes p and q. If one knew p\nand q, then given the public value e, one could easily compute the secret key, d. On the other\nhand, it is not known whether or not there exist fast algorithms for factoring a number, and\nin this sense, the security of RSA is not guaranteed. With recent advances in quantum\ncomputing, and published fast factoring algorithms for quantum computers, there are\nconcerns that RSA may not be secure forever [MIT TR 2019]. But the practical realization\nof these algorithms still appears to be far in the future. Another popular public-key encryption algorithm is the Diffie-Hellman algorithm,\nwhich we will briefly explore in the homework problems. Diffie-Hellman is not as versatile\nas RSA in that it cannot be used to encrypt messages of arbitrary length; it can be used,\nhowever, to establish a symmetric session key, which is in turn used to encrypt messages. ed\n(y mod z)"
  },
  {
    "unit": "Unit 3",
    "topic": "Chapter 5",
    "source": "kurose",
    "page": 1055,
    "text": "8.3 Message Integrity and Digital Signatures\nIn the previous section, we saw how encryption can be used to provide\nconfidentiality to two communicating entities. In this section, we turn to the\nequally important cryptography topic of providing message integrity (also\nknown as message ­authentication). Along with message integrity, we will\ndiscuss two related topics in this section: digital signatures and end-point\nauthentication. We define the message integrity problem using, once again, Alice and\nBob. Suppose Bob receives a message (which may be encrypted or may be\nin plaintext) and he believes this message was sent by Alice. To authenticate\nthis message, Bob needs to verify:\n1. The message indeed originated from Alice. 2. The message was not tampered with on its way to Bob. We’ll see in Sections 8.4 through 8.7 that this problem of message integrity\nis a critical concern in just about all secure networking protocols. As a specific example, consider a computer network using a link-state\nrouting algorithm (such as OSPF) for determining routes between each pair\nof routers in the network (see Chapter 5). In a link-state algorithm, each\nrouter needs to broadcast a link-state message to all other routers in the\nnetwork. A router’s link-state message includes a list of its directly\nconnected neighbors and the direct costs to these neighbors. Once a router\nreceives link-state messages from all of the other routers, it can create a\ncomplete map of the network, run its least-cost routing algorithm, and\nconfigure its forwarding table. One relatively easy attack on the routing"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1056,
    "text": "algorithm is for Trudy to distribute bogus link-state messages with incorrect\nlink-state information. Thus, the need for message integrity—when router B\nreceives a link-state message from router A, router B should verify that\nrouter A actually created the message and, further, that no one tampered\nwith the message in transit. In this section, we describe a popular message integrity technique that\nis used by many secure networking protocols. But before doing so, we need\nto cover another important topic in cryptography—cryptographic hash\nfunctions. 8.3.1 Cryptographic Hash Functions\nAs shown in Figure 8.7, a hash function takes an input, m, and computes a\nfixed-size string H(m) known as a hash. The Internet checksum (Chapter 3)\nand CRCs (Chapter 6) meet this definition. A cryptographic hash function\nis required to have the following additional property:"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1057,
    "text": "Figure 8.7 ♦Hash functions\n•\nIt is computationally infeasible to find any two different messages x and\ny such that H(x) = H(y). Informally, this property means that it is computationally infeasible for\nan intruder to substitute one message for another message that is protected\nby the hash function. That is, if (m, H(m)) are the message and the hash of\nthe message created by the sender, then an intruder cannot forge the\ncontents of another message, y, that has the same hash value as the original\nmessage. Let’s convince ourselves that a simple checksum, such as the Internet\nchecksum, would make a poor cryptographic hash function. Rather than\nperforming 1s complement arithmetic (as in the Internet checksum), let us\ncompute a checksum by treating each character as a byte and adding the\nbytes together using 4-byte chunks at a time. Suppose Bob owes Alice\n$100.99 and sends an IOU to Alice consisting of the text string\n“IOU100.99BOB.” The ASCII representation (in hexadecimal notation)\nfor these letters is 49,4F,55,31,30,30,2E,39,39,42,4F,42. Figure 8.8 (top) shows that the 4-byte checksum for this message is B2\nC1 D2 AC. A slightly different message (and a much more costly one for\nBob) is shown in the bottom half of Figure 8.8. The messages\n“IOU100.99BOB” and “IOU900.19BOB” have the same checksum. Thus, this simple checksum algorithm violates the requirement above. Given the original data, it is simple to find another set of data with the same\nchecksum. Clearly, for security purposes, we are going to need a more\npowerful hash function than a checksum."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1058,
    "text": "Figure 8.8 ♦Initial message and fraudulent message have the\nsame checksum! The MD5 hash algorithm of Ron Rivest [RFC 1321] is in wide use\ntoday. It computes a 128-bit hash in a four-step process consisting of a\npadding step (adding a one followed by enough zeros so that the length of\nthe message satisfies certain conditions), an append step (appending a 64-\nbit representation of the message length before padding), an initialization of\nan accumulator, and a final looping step in which the message’s 16-word\nblocks are processed (mangled) in four rounds. For a description of MD5\n(including a C source code implementation) see [RFC 1321]. The second major hash algorithm in use today is the Secure Hash\nAlgorithm (SHA-1) [FIPS 1995]. This algorithm is based on principles\nsimilar to those used in the design of MD4 [RFC 1320], the predecessor to\nMD5. SHA-1, a US federal standard, is required for use whenever a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1059,
    "text": "cryptographic hash algorithm is needed for federal applications. It produces\na 160-bit message digest. The longer output length makes SHA-1 more\nsecure. 8.3.2 Message Authentication Code\nLet’s now return to the problem of message integrity. Now that we\nunderstand hash functions, let’s take a first stab at how we might perform\nmessage integrity:\n1. Alice creates message m and calculates the hash H(m) (for example,\nwith SHA-1). 2. Alice then appends H(m) to the message m, creating an extended\nmessage (m, H(m)), and sends the extended message to Bob. 3. Bob receives an extended message (m, h) and calculates H(m). If H(m) =\nh, Bob concludes that everything is fine. This approach is obviously flawed. Trudy can create a bogus message m´ in\nwhich she says she is Alice, calculate H(m´), and send Bob (m´, H(m´)). When Bob receives the message, everything checks out in step 3, so Bob\ndoesn’t suspect any funny ­business. To perform message integrity, in addition to using cryptographic hash\nfunctions, Alice and Bob will need a shared secret s. This shared secret,\nwhich is nothing more than a string of bits, is called the authentication\nkey. Using this shared secret, message integrity can be performed as\nfollows:\n1. Alice creates message m, concatenates s with m to create m + s, and\ncalculates the hash H(m + s) (for example, with SHA-1). H(m + s) is"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1060,
    "text": "called the message authentication code (MAC). 2. Alice then appends the MAC to the message m, creating an extended\nmessage (m, H(m + s)), and sends the extended message to Bob. 3. Bob receives an extended message (m, h) and knowing s, calculates the\nMAC H(m + s). If H(m + s) = h, Bob concludes that everything is fine. A summary of the procedure is shown in Figure 8.9. Readers should note\nthat the MAC here (standing for “message authentication code”) is not the\nsame MAC used in link-layer protocols (standing for “medium access\ncontrol”)! Figure 8.9 ♦Message authentication code (MAC)\nOne nice feature of a MAC is that it does not require an encryption\nalgorithm. Indeed, in many applications, including the link-state routing\nalgorithm described earlier, communicating entities are only concerned with\nmessage integrity and are not concerned with message confidentiality. Using a MAC, the entities can authenticate the messages they send to each"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1061,
    "text": "other without having to integrate complex encryption algorithms into the\nintegrity process. As you might expect, a number of different standards for MACs have\nbeen proposed over the years. The most popular standard today is HMAC,\nwhich can be used either with MD5 or SHA-1. HMAC actually runs data\nand the authentication key through the hash function twice [Kaufman 2002;\nRFC 2104]. There still remains an important issue. How do we distribute the shared\nauthentication key to the communicating entities? For example, in the link-\nstate routing algorithm, we would somehow need to distribute the secret\nauthentication key to each of the routers in the autonomous system. (Note\nthat the routers can all use the same authentication key.) A network\nadministrator could actually accomplish this by physically visiting each of\nthe routers. Or, if the network administrator is a lazy guy, and if each router\nhas its own public key, the network administrator could distribute the\nauthentication key to any one of the routers by encrypting it with the\nrouter’s public key and then sending the encrypted key over the network to\nthe router. 8.3.3 Digital Signatures\nThink of the number of the times you’ve signed your name to a piece of\npaper ­during the last week. You sign checks, credit card receipts, legal\ndocuments, and letters. Your signature attests to the fact that you (as\nopposed to someone else) have acknowledged and/or agreed with the\ndocument’s contents. In a digital world, one often wants to indicate the\nowner or creator of a document, or to signify one’s agreement with a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1062,
    "text": "document’s content. A digital signature is a cryptographic technique for\nachieving these goals in a digital world. Just as with handwritten signatures, digital signing should be done in a\nway that is verifiable and nonforgeable. That is, it must be possible to prove\nthat a document signed by an individual was indeed signed by that\nindividual (the signature must be verifiable) and that only that individual\ncould have signed the document (the signature cannot be forged). Figure 8.10 ♦Creating a digital signature for a document\nLet’s now consider how we might design a digital signature scheme. Observe that when Bob signs a message, Bob must put something on the\nmessage that is unique to him. Bob could consider attaching a MAC for the\nsignature, where the MAC is created by appending his key (unique to him)\nto the message, and then taking the hash. But for Alice to verify the\nsignature, she must also have a copy of the key, in which case the key\nwould not be unique to Bob. Thus, MACs are not going to get the job done\nhere."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1063,
    "text": "Recall that with public-key cryptography, Bob has both a public and\nprivate key, with both of these keys being unique to Bob. Thus, public-key\ncryptography is an excellent candidate for providing digital signatures. Let\nus now examine how it is done. Suppose that Bob wants to digitally sign a document, m. We can think\nof the document as a file or a message that Bob is going to sign and send. As shown in Figure 8.10, to sign this document, Bob simply uses his private\nkey, K −\nB , to compute K −\nB (m). At first, it might seem odd that Bob is using\nhis private key (which, as we saw in Section 8.2, was used to decrypt a\nmessage that had been encrypted with his public key) to sign a document. But recall that encryption and decryption are nothing more than\nmathematical operations (exponentiation to the power of e or d in RSA; see\nSection 8.2) and recall that Bob’s goal is not to scramble or obscure the\ncontents of the document, but rather to sign the document in a manner that\nis verifiable and nonforgeable. Bob’s digital signature of the document is\nK −\nB (m). Does the digital signature K −\nB (m) meet our requirements of being\nverifiable and nonforgeable? Suppose Alice has m and K −\nB (m). She wants\nto prove in court (being litigious) that Bob had indeed signed the document\nand was the only person who could have possibly signed the document. Alice takes Bob’s public key, K +\nB , and applies it to the digital signature,\nK −\nB (m), associated with the document, m. That is, she computes\nK +\nB (K −\nB (m)), and voilà, with a dramatic flurry, she produces m, which\nexactly matches the original document! Alice then argues that only Bob\ncould have signed the document, for the following reasons:\n•\nWhoever signed the message must have used the private key, K −\nB , in\ncomputing the signature K −\nB , such that K +\nB (K −\nB (m)) = m."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1064,
    "text": "•\nThe only person who could have known the private key, K −\nB , is Bob. Recall from our discussion of RSA in Section 8.2 that knowing the\npublic key, K +\nB , is of no help in learning the private key, K −\nB . Therefore, the only person who could know K −\nB  is the person who\ngenerated the pair of keys, (K +\nB , K −\nB ), in the first place, Bob. (Note that\nthis assumes, though, that Bob has not given K −\nB  to anyone, nor has\nanyone stolen K −\nB  from Bob.) It is also important to note that if the original document, m, is ever\nmodified to some alternate form, m´, the signature that Bob created for m\nwill not be valid for m´, since K +\nB (K −\nB (m)) does not equal m´. Thus, we\nsee that digital signatures also provide message integrity, allowing the\nreceiver to verify that the message was unaltered as well as the source of\nthe message. One concern with signing data by encryption is that encryption and\ndecryption are computationally expensive. Given the overheads of\nencryption and decryption, signing data via complete encryption/decryption\ncan be overkill. A more efficient approach is to introduce hash functions\ninto the digital signature. Recall from ­Section 8.3.2 that a hash algorithm\ntakes a message, m, of arbitrary length and computes a fixed-length\n“fingerprint” of the message, denoted by H(m). Using a hash function, Bob\nsigns the hash of a message rather than the message itself, that is, Bob\ncalculates K −\nB (H(m)). Since H(m) is generally much smaller than the\noriginal message m, the computational effort required to create the digital\nsignature is substantially reduced. In the context of Bob sending a message to Alice, Figure 8.11 provides\na summary of the operational procedure of creating a digital signature. Bob\nputs his original long message through a hash function. He then digitally\nsigns the resulting hash with his private key. The original message (in"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1065,
    "text": "cleartext) along with the digitally signed message digest (henceforth\nreferred to as the digital signature) is then sent to Alice. Figure 8.12\nprovides a summary of the operational procedure of the signature. Alice\napplies the sender’s public key to the message to obtain a hash result. Alice\nalso applies the hash function to the cleartext message to obtain a second\nhash result. If the two hashes match, then Alice can be sure about the\nintegrity and author of the message. Figure 8.11 ♦Sending a digitally signed message"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1066,
    "text": "Figure 8.12 ♦Verifying a signed message\nBefore moving on, let’s briefly compare digital signatures with MACs,\nsince they have parallels, but also have important subtle differences. Both\ndigital signatures and MACs start with a message (or a document). To\ncreate a MAC out of the message, we append an authentication key to the\nmessage, and then take the hash of the result. Note that neither public key\nnor symmetric key encryption is involved in creating the MAC. To create a\ndigital signature, we first take the hash of the message and then encrypt the\nmessage with our private key (using public key cryptography). Thus, a\ndigital signature is a “heavier” technique, since it requires an underlying\nPublic Key Infrastructure (PKI) with certification authorities as described"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1067,
    "text": "below. We’ll see in Section 8.4 that PGP—a popular secure e-mail system\n—uses digital signatures for message integrity. We’ve seen already that\nOSPF uses MACs for message integrity. We’ll see in Sections 8.5 and 8.6\nthat MACs are also used for popular transport-layer and network-layer\nsecurity protocols. Public Key Certification\nAn important application of digital signatures is public key certification,\nthat is, certifying that a public key belongs to a specific entity. Public key\ncertification is used in many popular secure networking protocols, including\nIPsec and TLS. To gain insight into this problem, let’s consider an Internet-commerce\nversion of the classic “pizza prank.” Alice is in the pizza delivery business\nand accepts orders over the Internet. Bob, a pizza lover, sends Alice a\nplaintext message that includes his home address and the type of pizza he\nwants. In this message, Bob also includes a digital signature (that is, a\nsigned hash of the original plaintext message) to prove to Alice that he is\nthe true source of the message. To verify the signature, Alice obtains Bob’s\npublic key (perhaps from a public key server or from the e-mail message)\nand checks the digital signature. In this manner she makes sure that Bob,\nrather than some adolescent prankster, placed the order. This all sounds fine until clever Trudy comes along. As shown in\nFigure 8.13, Trudy is indulging in a prank. She sends a message to Alice in\nwhich she says she is Bob, gives Bob’s home address, and orders a pizza. In\nthis message she also includes her (Trudy’s) public key, although Alice\nnaturally assumes it is Bob’s public key. Trudy also attaches a digital\nsignature, which was created with her own (Trudy’s) private key. After\nreceiving the message, Alice applies Trudy’s public key (thinking that it is"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1068,
    "text": "Bob’s) to the digital signature and concludes that the plaintext message was\nindeed created by Bob. Bob will be very surprised when the delivery person\nbrings a pizza with pepperoni and anchovies to his home! We see from this example that for public key cryptography to be useful,\nyou need to be able to verify that you have the actual public key of the\nentity (person, router, browser, and so on) with whom you want to\ncommunicate. For example, when Alice wants to communicate with Bob\nusing public key cryptography, she needs to verify that the public key that is\nsupposed to be Bob’s is indeed Bob’s. Binding a public key to a particular entity is typically done by a\nCertification Authority (CA), whose job is to validate identities and issue\ncertificates. A CA has the following roles:\n1. A CA verifies that an entity (a person, a router, and so on) is who it says\nit is. There are no mandated procedures for how certification is done. When dealing with a CA, one must trust the CA to have performed a\nsuitably rigorous identity verification. For example, if Trudy were able\nto walk into the Fly-by-Night CA and simply announce “I am Alice” and\nreceive certificates associated with the identity of Alice, then one\nshouldn’t put much faith in public keys certified by the Fly-by-Night\nCA. On the other hand, one might (or might not!) be more willing to\ntrust a CA that is part of a federal or state program. You can trust the\nidentity associated with a public key only to the extent to which you can\ntrust a CA and its identity verification techniques. What a tangled web\nof trust we spin! 2. Once the CA verifies the identity of the entity, the CA creates a\ncertificate that binds the public key of the entity to the identity. The\ncertificate contains the public key and globally unique identifying\ninformation about the owner of the public key (for example, a human"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1069,
    "text": "name or an IP address). The certificate is digitally signed by the CA. These steps are shown in Figure 8.14. Figure 8.13 ♦Trudy masquerades as Bob using public key\ncryptography"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1070,
    "text": "Figure 8.14 ♦Bob has his public key certified by the CA\nLet us now see how certificates can be used to combat pizza-ordering\npranksters, like Trudy, and other undesirables. When Bob places his order\nhe also sends his CA-signed certificate. Alice uses the CA’s public key to\ncheck the validity of Bob’s certificate and extract Bob’s public key. Both the International Telecommunication Union (ITU) and the IETF\nhave developed standards for CAs. ITU X.509 [ITU 2005a] specifies an\nauthentication service as well as a specific syntax for certificates. [RFC\n1422] describes CA-based key management for use with secure Internet e-\nmail. It is compatible with X.509 but goes beyond X.509 by establishing\nprocedures and conventions for a key management architecture. Table 8.4\ndescribes some of the important fields in a certificate. Table 8.4 ♦Selected fields in an X.509 and RFC 1422 public key"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1071,
    "text": "8.4 End-Point Authentication\nEnd-point authentication is the process of one entity proving its identity\nto another entity over a computer network, for example, a user proving its\nidentity to an e-mail server. As humans, we authenticate each other in many\nways: We recognize each ­other’s faces when we meet, we recognize each\nother’s voices on the telephone, we are authenticated by the customs official\nwho checks us against the picture on our passport. In this section, we consider how one party can authenticate another\nparty when the two are communicating over a network. We focus here on\nauthenticating a “live” party, at the point in time when communication is\nactually occurring. A concrete example is a user authenticating him or\nherself to an e-mail server. This is a subtly different problem from proving\nthat a message received at some point in the past did indeed come from that\nclaimed sender, as studied in Section 8.3. When performing authentication over the network, the communicating\nparties cannot rely on biometric information, such as a visual appearance or\na voiceprint. Indeed, we will see in our later case studies that it is often\nnetwork elements such as routers and client/server processes that must\nauthenticate each other. Here, authentication must be done solely on the\nbasis of messages and data exchanged as part of an authentication\nprotocol. Typically, an authentication protocol would run before the two\ncommunicating parties run some other protocol (for example, a reliable data\ntransfer protocol, a routing information exchange protocol, or an e-mail\nprotocol). The authentication protocol first establishes the identities of the\nparties to each ­other’s satisfaction; only after authentication do the parties\nget down to the work at hand."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1072,
    "text": "As in the case of our development of a reliable data transfer (rdt)\nprotocol in Chapter 3, we will find it instructive here to develop various\nversions of an authentication protocol, which we will call ap (authentication\nprotocol), and poke holes in each version as we proceed. (If you enjoy this\nstepwise evolution of a design, you might also enjoy [Bryant 1988], which\nrecounts a fictitious narrative between designers of an open-\nnetwork authentication system, and their discovery of the many subtle\nissues involved.) Let’s assume that Alice needs to authenticate herself to Bob. Perhaps the simplest authentication protocol we can imagine is one\nwhere Alice simply sends a message to Bob saying she is Alice. This\nprotocol is shown in Figure 8.15. The flaw here is obvious—there is no way\nfor Bob actually to know that the person sending the message “I am Alice”\nis indeed Alice. For example, Trudy (the intruder) could just as well send\nsuch a message. Figure 8.15 ♦Protocol ap1.0 and a failure scenario"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1073,
    "text": "Authentication Protocol ap2.0\nIf Alice has a well-known network address (e.g., an IP address) from which\nshe always communicates, Bob could attempt to authenticate Alice by\nverifying that the source address on the IP datagram carrying the\nauthentication message matches Alice’s well-known address. In this case,\nAlice would be authenticated. This might stop a very network-naive\nintruder from impersonating Alice, but it wouldn’t stop the determined\nstudent studying this book, or many others! From our study of the network and data link layers, we know that it is\nnot that hard (for example, if one had access to the operating system code\nand could build one’s own operating system kernel, as is the case with\nLinux and several other freely available operating systems) to create an IP\ndatagram, put whatever IP source address we want (for example, Alice’s\nwell-known IP address) into the IP datagram, and send the datagram over\nthe link-layer protocol to the first-hop router. From then on, the incorrectly\nsource-addressed datagram would be dutifully forwarded to Bob. This\napproach, shown in Figure 8.16, is a form of IP spoofing. IP spoofing can\nbe avoided if Trudy’s first-hop router is configured to forward only\ndatagrams containing Trudy’s IP source address [RFC 2827]. However, this\ncapability is not universally deployed or enforced. Bob would thus be\nfoolish to assume that Trudy’s network manager (who might be Trudy\nherself) had configured Trudy’s first-hop router to forward only\nappropriately addressed datagrams. Authentication Protocol ap3.0\nOne classic approach to authentication is to use a secret password. The\npassword is a shared secret between the authenticator and the person being\nauthenticated. Gmail, Facebook, telnet, FTP, and many other services use"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1074,
    "text": "password authentication. In protocol ap3.0, Alice thus sends her secret\npassword to Bob, as shown in Figure 8.17. Since passwords are so widely used, we might suspect that protocol\nap3.0 is fairly secure. If so, we’d be wrong! The security flaw here is clear. If Trudy eavesdrops on Alice’s communication, then she can learn Alice’s\npassword. Lest you think this is unlikely, consider the fact that when you\nTelnet to another machine and log in, the login password is sent\nunencrypted to the Telnet server. Someone connected to the Telnet client or\nserver’s LAN can possibly sniff (read and store) all packets transmitted on\nthe LAN and thus steal the login password. In fact, this is a well-known\napproach for stealing passwords (see, for example, [Jimenez 1997]). Such a\nthreat is obviously very real, so ap3.0 clearly won’t do. Figure 8.16 ♦Protocol ap2.0 and a failure scenario\nAuthentication Protocol ap3.1\nOur next idea for fixing ap3.0 is naturally to encrypt the password. By\nencrypting the password, we can prevent Trudy from learning Alice’s"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1075,
    "text": "password. If we assume that Alice and Bob share a symmetric secret key,\nK\n, then Alice can encrypt the password and send her identification\nmessage, “I am Alice,” and her encrypted password to Bob. Bob then\ndecrypts the password and, assuming the password is correct, authenticates\nAlice. Bob feels comfortable in authenticating Alice since Alice not only\nknows the password, but also knows the shared secret key value needed to\nencrypt the password. Let’s call this protocol ap3.1. While it is true that ap3.1 prevents Trudy from learning Alice’s\npassword, the use of cryptography here does not solve the authentication\nproblem. Bob is subject to a playback attack: Trudy need only eavesdrop\non Alice’s communication, record the encrypted version of the password,\nand play back the encrypted version of the password to Bob to pretend that\nshe is Alice. The use of an encrypted password in ap3.1 doesn’t make the\nsituation manifestly different from that of protocol ap3.0 in Figure 8.17. A−B"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1076,
    "text": "Figure 8.17 ♦Protocol ap3.0 and a failure scenario\nAuthentication Protocol ap4.0\nThe failure scenario in Figure 8.17 resulted from the fact that Bob could not\ndistinguish between the original authentication of Alice and the later\nplayback of Alice’s original authentication. That is, Bob could not tell if\nAlice was live (that is, was currently really on the other end of the\nconnection) or whether the messages he was receiving were a recorded\nplayback of a previous authentication of Alice. The very (very) observant\nreader will recall that the three-way TCP handshake protocol needed to\naddress the same problem—the server side of a TCP connection did not\nwant to accept a connection if the received SYN segment was an old copy\n(retransmission) of a SYN segment from an earlier connection. How did the\nTCP server side solve the problem of determining whether the client was"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1077,
    "text": "really live? It chose an initial sequence number that had not been used in a\nvery long time, sent that number to the client, and then waited for the client\nto respond with an ACK segment containing that number. We can adopt the\nsame idea here for authentication purposes. A nonce is a number that a protocol will use only once in a lifetime. That is, once a protocol uses a nonce, it will never use that number again. Our ap4.0 protocol uses a nonce as follows:\n1. Alice sends the message “I am Alice” to Bob. 2. Bob chooses a nonce, R, and sends it to Alice. 3. Alice encrypts the nonce using Alice and Bob’s symmetric secret key,\nK\n, and sends the encrypted nonce, K\n (R), back to Bob. As in\nprotocol ap3.1, it is the fact that Alice knows K\n and uses it to encrypt\na value that lets Bob know that the message he receives was generated\nby Alice. The nonce is used to ensure that Alice is live. 4. Bob decrypts the received message. If the decrypted nonce equals the\nnonce he sent Alice, then Alice is authenticated. Protocol ap4.0 is illustrated in Figure 8.18. By using the once-in-a-\nlifetime value, R, and then checking the returned value, K\n (R), Bob can\nbe sure that Alice is both who she says she is (since she knows the secret\nkey value needed to encrypt R) and live (since she has encrypted the nonce,\nR, that Bob just created). A−B\nA−B\nA−B\nA−B"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1078,
    "text": "Figure 8.18 ♦Protocol ap4.0 and a failure scenario\nThe use of a nonce and symmetric key cryptography forms the basis of\nap4.0. A natural question is whether we can use a nonce and public key\ncryptography (rather than symmetric key cryptography) to solve the\nauthentication problem. This issue is explored in the problems at the end of\nthe chapter."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1079,
    "text": "8.5 Securing E-Mail\nIn previous sections, we examined fundamental issues in network security,\nincluding symmetric key and public key cryptography, end-point\nauthentication, key distribution, message integrity, and digital signatures. We are now going to examine how these tools are being used to provide\nsecurity in the Internet. Interestingly, it is possible to provide security services in any of the top\nfour layers of the Internet protocol stack. When security is provided for a\nspecific application-layer protocol, the application using the protocol will\nenjoy one or more security services, such as confidentiality, authentication,\nor integrity. When security is provided for a transport-layer protocol, all\napplications that use that protocol enjoy the security services of the\ntransport protocol. When security is provided at the network layer on a\nhost-to-host basis, all transport-layer segments (and hence all application-\nlayer data) enjoy the security services of the network layer. When security\nis provided on a link basis, then the data in all frames traveling over the link\nreceive the security services of the link. In Sections 8.5 through 8.8, we examine how security tools are being\nused in the application, transport, network, and link layers. Being consistent\nwith the general structure of this book, we begin at the top of the protocol\nstack and discuss security at the application layer. Our approach is to use a\nspecific application, e-mail, as a case study for application-layer security. We then move down the protocol stack. We’ll examine the TLS protocol\n(which provides security at the transport layer), IPsec (which provides\nsecurity at the network layer), and the security of the IEEE 802.11 wireless\nLAN protocol."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1080,
    "text": "You might be wondering why security functionality is being provided\nat more than one layer in the Internet. Wouldn’t it suffice simply to provide\nthe security functionality at the network layer and be done with it? There\nare two answers to this question. First, although security at the network\nlayer can offer “blanket coverage” by encrypting all the data in the\ndatagrams (that is, all the transport-layer segments) and by authenticating\nall the source IP addresses, it can’t provide user-level security. For example,\na commerce site cannot rely on IP-layer security to authenticate a customer\nwho is purchasing goods at the commerce site. Thus, there is a need for\nsecurity functionality at higher layers as well as blanket coverage at lower\nlayers. Second, it is generally easier to deploy new Internet services,\nincluding security services, at the higher layers of the protocol stack. While\nwaiting for security to be broadly deployed at the network layer, which is\nprobably still many years in the future, many application developers “just\ndo it” and introduce security functionality into their favorite applications. A\nclassic example is Pretty Good Privacy (PGP), which provides secure e-\nmail (discussed later in this section). Requiring only client and server\napplication code, PGP was one of the first security technologies to be\nbroadly used in the Internet. 8.5.1 Secure E-Mail\nWe now use the cryptographic principles of Sections 8.2 through 8.3 to\ncreate a secure e-mail system. We create this high-level design in an\nincremental manner, at each step introducing new security services. When\ndesigning a secure e-mail system, let us keep in mind the racy example\nintroduced in Section 8.1—the love affair between Alice and Bob. Imagine"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1081,
    "text": "that Alice wants to send an e-mail message to Bob, and Trudy wants to\nintrude. Before plowing ahead and designing a secure e-mail system for Alice\nand Bob, we should consider which security features would be most\ndesirable for them. First and foremost is confidentiality. As discussed in\nSection 8.1, neither Alice nor Bob wants Trudy to read Alice’s e-mail\nmessage. The second feature that Alice and Bob would most likely want to\nsee in the secure e-mail system is sender authentication. In particular, when\nBob receives the message “I don’t love you anymore. I\nnever want to see you again. Formerly yours,\nAlice,” he would naturally want to be sure that the message came from\nAlice and not from Trudy. Another feature that the two lovers would\nappreciate is message integrity, that is, assurance that the message Alice\nsends is not modified while en route to Bob. Finally, the e-mail system\nshould provide receiver authentication; that is, Alice wants to make sure\nthat she is indeed sending the letter to Bob and not to someone else (for\nexample, Trudy) who is impersonating Bob. So let’s begin by addressing the foremost concern, confidentiality. The\nmost straightforward way to provide confidentiality is for Alice to encrypt\nthe message with symmetric key technology (such as DES or AES) and for\nBob to decrypt the message on receipt. As discussed in Section 8.2, if the\nsymmetric key is long enough, and if only Alice and Bob have the key, then\nit is extremely difficult for anyone else (including Trudy) to read the\nmessage. Although this approach is straightforward, it has the fundamental\ndifficulty that we discussed in Section 8.2—distributing a symmetric key so\nthat only Alice and Bob have copies of it. So we naturally consider an\nalternative approach—public key cryptography (using, for example, RSA). In the public key approach, Bob makes his public key publicly available"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1082,
    "text": "(e.g., in a public key server or on his personal Web page), Alice encrypts\nher message with Bob’s public key, and she sends the encrypted message to\nBob’s e-mail address. When Bob receives the message, he simply decrypts\nit with his private key. Assuming that Alice knows for sure that the public\nkey is Bob’s public key, this approach is an excellent means to provide the\ndesired confidentiality. One problem, however, is that public key encryption\nis relatively inefficient, particularly for long messages. To overcome the efficiency problem, let’s make use of a session key\n(discussed in Section 8.2.2). In particular, Alice (1) selects a random\nsymmetric session key, K , (2) encrypts her message, m, with the symmetric\nkey, (3) encrypts the symmetric key with Bob’s public key, K , (4)\nconcatenates the encrypted message and the encrypted symmetric key to\nform a “package,” and (5) sends the package to Bob’s e-mail address. The\nsteps are illustrated in Figure 8.19. (In this and the subsequent figures, the\ncircled “+” represents concatenation and the circled “−” represents\ndeconcatenation.) When Bob receives the package, he (1) uses his private\nkey, K , to obtain the symmetric key, K , and (2) uses the symmetric key K\nto decrypt the message m.\nHaving designed a secure e-mail system that provides confidentiality,\nlet’s now design another system that provides both sender authentication\nand message integrity. We’ll suppose, for the moment, that Alice and Bob\nare no longer concerned with confidentiality (they want to share their\nfeelings with everyone! ), and are concerned only about sender\nauthentication and message integrity. To accomplish this task, we use digital\nsignatures and message digests, as described in Section 8.3. Specifically,\nAlice (1) applies a hash function, H (e.g., MD5), to her message, m, to\nobtain a message digest, (2) signs the result of the hash function with her\nprivate key, K −\nA , to create a digital signature, (3) concatenates the original\nS\nB+\n−B\nS\nS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1083,
    "text": "(unencrypted) message with the signature to create a package, and (4) sends\nthe package to Bob’s e-mail address. When Bob receives the package, he\n(1) applies Alice’s public key, K +\nA , to the signed message digest and (2)\ncompares the result of this operation with his own hash, H, of the message. The steps are illustrated in Figure 8.20. As discussed in Section 8.3, if the\ntwo results are the same, Bob can be pretty confident that the message came\nfrom Alice and is unaltered. Figure 8.19 ♦Alice used a symmetric session key, K , to send a\nsecret e-mail to Bob\nS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1084,
    "text": "Figure 8.20 ♦Using hash functions and digital signatures to provide\nsender authentication and message integrity\nNow let’s consider designing an e-mail system that provides\nconfidentiality, sender authentication, and message integrity. This can be\ndone by combining the procedures in Figures 8.19 and 8.20. Alice first\ncreates a preliminary package, exactly as in Figure 8.20, that consists of her\noriginal message along with a digitally signed hash of the message. She\nthen treats this preliminary package as a message in itself and sends this\nnew message through the sender steps in Figure 8.19, creating a new\npackage that is sent to Bob. The steps applied by Alice are shown in Figure\n8.21. When Bob receives the package, he first applies his side of Figure\n8.19 and then his side of Figure 8.20. It should be clear that this design\nachieves the goal of providing confidentiality, sender authentication, and\nmessage integrity. Note that, in this scheme, Alice uses public key\ncryptography twice: once with her own private key and once with Bob’s\npublic key. Similarly, Bob also uses public key cryptography twice—once\nwith his private key and once with Alice’s public key. The secure e-mail design outlined in Figure 8.21 probably provides\nsatisfactory security for most e-mail users for most occasions. However,\nthere is still one important issue that remains to be addressed. The design in\nFigure 8.21 requires Alice to obtain Bob’s public key, and requires Bob to\nobtain Alice’s public key. The distribution of these public keys is a\nnontrivial problem. For example, Trudy might masquerade as Bob and give\nAlice her own public key while saying that it is Bob’s public key, enabling\nher to receive the message meant for Bob. As we learned in Section 8.3, a\npopular approach for securely distributing public keys is to certify the\npublic keys using a CA."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1085,
    "text": "Figure 8.21 ♦Alice uses symmetric key cyptography, public key\ncryptography, a hash function, and a digital signature\nto provide secrecy, sender authentication, and\nmessage integrity\n8.5.2 PGP\nWritten by Phil Zimmermann in 1991, Pretty Good Privacy (PGP) is a\nnice example of an e-mail encryption scheme [PGP 2020]. The PGP design\nis, in essence, the same as the design shown in Figure 8.21. Depending on\nthe version, the PGP software uses MD5 or SHA for calculating the\nmessage digest; CAST, triple-DES, or IDEA for symmetric key encryption;\nand RSA for the public key encryption. When PGP is installed, the software creates a public key pair for the\nuser. The public key can be posted on the user’s Web site or placed in a\npublic key server. The private key is protected by the use of a password. The password has to be entered every time the user accesses the private key. PGP gives the user the option of digitally signing the message, encrypting\nthe message, or both digitally signing and encrypting. Figure 8.22 shows a"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1086,
    "text": "PGP signed message. This message appears after the MIME header. The\nencoded data in the message is K −\nA (H(m)), that is, the digitally signed\nmessage digest. As we discussed above, in order for Bob to verify the\nintegrity of the message, he needs to have access to Alice’s public key. Figure 8.22 ♦A PGP signed message\nFigure 8.23 shows a secret PGP message. This message also appears\nafter the MIME header. Of course, the plaintext message is not included\nwithin the secret e-mail message. When a sender (such as Alice) wants both\nconfidentiality and integrity, PGP contains a message like that of Figure\n8.23 within the message of Figure 8.22. Figure 8.23 ♦A secret PGP message"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1087,
    "text": "PGP also provides a mechanism for public key certification, but the\nmechanism is quite different from the more conventional CA. PGP public\nkeys are certified by a web of trust. Alice herself can certify any\nkey/username pair when she believes the pair really belong together. In\naddition, PGP permits Alice to say that she trusts another user to vouch for\nthe authenticity of more keys. Some PGP users sign each other’s keys by\nholding key-signing parties. Users physically gather, exchange ­public keys,\nand certify each other’s keys by signing them with their private keys."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1088,
    "text": "8.6 Securing TCP Connections: TLS\nIn the previous section, we saw how cryptographic techniques can provide\nconfidentiality, data integrity, and end-point authentication to a specific\napplication, namely, e-mail. In this section, we’ll drop down a layer in the\nprotocol stack and examine how cryptography can enhance TCP with\nsecurity services, including confidentiality, data integrity, and end-point\nauthentication. This enhanced version of TCP is commonly known as\nTransport Layer Security (TLS), which has been standardized by the\nIETF [RFC 4346]. An earlier and similar version of this protocol is SSL\nversion 3. The SSL protocol was originally designed by Netscape, but the basic\nideas behind securing TCP had predated Netscape’s work (for example, see\nWoo [Woo 1994]). Since its inception, SSL and its successor TLS have\nenjoyed broad deployment. TLS is supported by all popular Web browsers\nand Web servers, and it is used by Gmail and essentially all Internet\ncommerce sites (including Amazon, eBay, and TaoBao). Hundreds of\nbillions of dollars are spent over TLS every year. In fact, if you have ever\npurchased anything over the Internet with your credit card, the\ncommunication between your browser and the server for this purchase\nalmost certainly went over TLS. (You can identify that TLS is being used\nby your browser when the URL begins with https: rather than http.) To understand the need for TLS, let’s walk through a typical Internet\ncommerce scenario. Bob is surfing the Web and arrives at the Alice\nIncorporated site, which is selling perfume. The Alice Incorporated site\ndisplays a form in which Bob is supposed to enter the type of perfume and\nquantity desired, his address, and his payment card number. Bob enters this"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1089,
    "text": "information, clicks on Submit, and expects to receive (via ordinary postal\nmail) the purchased perfumes; he also expects to receive a charge for his\norder in his next payment card statement. This all sounds good, but if no\nsecurity measures are taken, Bob could be in for a few surprises. •\nIf no confidentiality (encryption) is used, an intruder could intercept\nBob’s order and obtain his payment card information. The intruder\ncould then make purchases at Bob’s expense. •\nIf no data integrity is used, an intruder could modify Bob’s order,\nhaving him purchase ten times more bottles of perfume than desired. •\nFinally, if no server authentication is used, a server could display Alice\nIncorporated’s famous logo when in actuality the site maintained by\nTrudy, who is masquerading as Alice Incorporated. After receiving\nBob’s order, Trudy could take Bob’s money and run. Or Trudy could\ncarry out an identity theft by collecting Bob’s name, address, and credit\ncard number. TLS addresses these issues by enhancing TCP with confidentiality, data\nintegrity, server authentication, and client authentication. TLS is often used to provide security to transactions that take place\nover HTTP. However, because TLS secures TCP, it can be employed by any\napplication that runs over TCP. TLS provides a simple Application\nProgrammer Interface (API) with sockets, which is similar and analogous to\nTCP’s API. When an application wants to employ TLS, the application\nincludes SSL classes/libraries. As shown in Figure 8.24, although TLS\ntechnically resides in the application layer, from the developer’s ­perspective\nit is a transport protocol that provides TCP’s services enhanced with\nsecurity services."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1090,
    "text": "Figure 8.24 ♦Although TLS technically resides in the application\nlayer, from the developer’s perspective it is a transport-\nlayer protocol\n8.6.1 The Big Picture\nWe begin by describing a simplified version of TLS, one that will allow us\nto get a big-picture understanding of the why and how of TLS. We will refer\nto this simplified version of TLS as “almost-TLS.” After describing almost-\nTLS, in the next subsection we’ll then describe the real TLS, filling in the\ndetails. Almost-TLS (and TLS) has three phases: handshake, key derivation,\nand data transfer. We now describe these three phases for a communication\nsession between a client (Bob) and a server (Alice), with Alice having a\nprivate/public key pair and a certificate that binds her identity to her public\nkey. Handshake\nDuring the handshake phase, Bob needs to (a) establish a TCP connection\nwith Alice, (b) verify that Alice is really Alice, and (c) send Alice a master\nsecret key, which will be used by both Alice and Bob to generate all the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1091,
    "text": "symmetric keys they need for the TLS session. These three steps are shown\nin Figure 8.25. Note that once the TCP connection is established, Bob sends\nAlice a hello message. Alice then responds with her certificate, which\ncontains her public key. As discussed in Section 8.3, because the certificate\nhas been certified by a CA, Bob knows for sure that the public key in the\ncertificate belongs to Alice. Bob then generates a Master Secret (MS)\n(which will only be used for this TLS session), encrypts the MS with\nAlice’s public key to create the Encrypted Master Secret (EMS), and sends\nthe EMS to Alice. Alice decrypts the EMS with her private key to get the\nMS. After this phase, both Bob and Alice (and no one else) know the master\nsecret for this TLS session. Figure 8.25 ♦The almost-TLS handshake, beginning with a TCP\nconnection"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1092,
    "text": "Key Derivation\nIn principle, the MS, now shared by Bob and Alice, could be used as the\nsymmetric session key for all subsequent encryption and data integrity\nchecking. It is, however, generally considered safer for Alice and Bob to\neach use different cryptographic keys, and also to use different keys for\nencryption and integrity checking. Thus, both Alice and Bob use the MS to\ngenerate four keys:\n•\nE  = session encryption key for data sent from Bob to Alice\n•\nM  = session HMAC key for data sent from Bob to Alice, where\nHMAC [RFC 2104] is a standardized hashed message authentication\ncode (MAC) that we encountered in section 8.3.2\n•\nE  = session encryption key for data sent from Alice to Bob\n•\nM  = session HMAC key for data sent from Alice to Bob\nAlice and Bob each generate the four keys from the MS. This could be done\nby simply slicing the MS into four keys. (But in reality TLS it is a little\nmore complicated, as we’ll see.) At the end of the key derivation phase,\nboth Alice and Bob have all four keys. The two encryption keys will be\nused to encrypt data; the two HMAC keys will be used to verify the\nintegrity of the data. Data Transfer\nNow that Alice and Bob share the same four session keys (E , M , E , and\nM ), they can start to send secured data to each other over the TCP\nconnection. Since TCP is a byte-stream protocol, a natural approach would\nbe for TLS to encrypt application data on the fly and then pass the\nencrypted data on the fly to TCP. But if we were to do this, where would we\nB\nB\nA\nA\nB\nB\nA\nA"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1093,
    "text": "put the HMAC for the integrity check? We certainly do not want to wait\nuntil the end of the TCP session to verify the integrity of all of Bob’s data\nthat was sent over the entire session! To address this issue, TLS breaks the\ndata stream into records, appends an HMAC to each record for integrity\nchecking, and then encrypts the record+HMAC. To create the HMAC, Bob\ninputs the record data along with the key M  into a hash function, as\ndiscussed in Section 8.3. To encrypt the package record+HMAC, Bob uses\nhis session encryption key E . This encrypted package is then passed to\nTCP for transport over the Internet. Although this approach goes a long way, it still isn’t bullet-proof when\nit comes to providing data integrity for the entire message stream. In\nparticular, suppose Trudy is a woman-in-the-middle and has the ability to\ninsert, delete, and replace segments in the stream of TCP segments sent\nbetween Alice and Bob. Trudy, for example, could capture two segments\nsent by Bob, reverse the order of the segments, adjust the TCP sequence\nnumbers (which are not encrypted), and then send the two reverse-ordered\nsegments to Alice. Assuming that each TCP segment encapsulates exactly\none record, let’s now take a look at how Alice would process these\nsegments. 1. TCP running in Alice would think everything is fine and pass the two\nrecords to the TLS sublayer. 2. TLS in Alice would decrypt the two records. 3. TLS in Alice would use the HMAC in each record to verify the data\nintegrity of the two records. 4. TLS would then pass the decrypted byte streams of the two records to\nthe application layer; but the complete byte stream received by Alice\nwould not be in the correct order due to reversal of the records! B\nB"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1094,
    "text": "You are encouraged to walk through similar scenarios for when Trudy\nremoves segments or when Trudy replays segments. The solution to this problem, as you probably guessed, is to use\nsequence numbers. TLS does this as follows. Bob maintains a sequence\nnumber counter, which begins at zero and is incremented for each TLS\nrecord he sends. Bob doesn’t actually include a sequence number in the\nrecord itself, but when he calculates the HMAC, he includes the sequence\nnumber in the HMAC calculation. Thus, the HMAC is now a hash of the\ndata plus the HMAC key M  plus the current sequence number. Alice\ntracks Bob’s sequence numbers, allowing her to verify the data integrity of\na record by including the appropriate sequence number in the HMAC\ncalculation. This use of TLS sequence numbers prevents Trudy from\ncarrying out a woman-in-the-middle attack, such as reordering or replaying\nsegments. (Why?) TLS Record\nThe TLS record (as well as the almost-TLS record) is shown in Figure\n8.26. The record consists of a type field, version field, length field, data\nfield, and HMAC field. Note that the first three fields are not encrypted. The type field indicates whether the record is a handshake message or a\nmessage that contains application data. It is also used to close the TLS\nconnection, as discussed below. TLS at the receiving end uses the length\nfield to extract the TLS records out of the incoming TCP byte stream. The\nversion field is self-explanatory. B"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1095,
    "text": "Figure 8.26 ♦Record format for TLS\n8.6.2 A More Complete Picture\nThe previous subsection covered the almost-TLS protocol; it served to give\nus a basic understanding of the why and how of TLS. Now that we have a\nbasic understanding, we can dig a little deeper and examine the essentials of\nthe actual TLS protocol. In parallel to reading this description of the TLS\nprotocol, you are encouraged to complete the Wireshark TLS lab, available\nat the textbook’s Web site. TLS Handshake\nSSL does not mandate that Alice and Bob use a specific symmetric key\nalgorithm or a specific public-key algorithm. Instead, TLS allows Alice and\nBob to agree on the cryptographic algorithms at the beginning of the TLS\nsession, during the handshake phase. Additionally, during the handshake\nphase, Alice and Bob send nonces to each other, which are used in the\ncreation of the session keys (E , M , E , and M ). The steps of the real TLS\nhandshake are as follows:\n1. The client sends a list of cryptographic algorithms it supports, along\nwith a ­client nonce. 2. From the list, the server chooses a symmetric algorithm (for example,\nAES) and a public key algorithm (for example, RSA with a specific key\nB\nB\nA\nA"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1096,
    "text": "length), and HMAC algorithm (MD5 or SHA-1) along with the HMAC\nkeys. It sends back to the client its choices, as well as a certificate and a\nserver nonce. 3. The client verifies the certificate, extracts the server’s public key,\ngenerates a Pre-Master Secret (PMS), encrypts the PMS with the\nserver’s public key, and sends the encrypted PMS to the server. 4. Using the same key derivation function (as specified by the TLS\nstandard), the client and server independently compute the Master\nSecret (MS) from the PMS and nonces. The MS is then sliced up to\ngenerate the two encryption and two HMAC keys. Furthermore, when\nthe chosen symmetric cipher employs CBC (such as 3DES or AES),\nthen two Initialization Vectors (IVs)—one for each side of the\nconnection—are also obtained from the MS. Henceforth, all ­messages\nsent between client and server are encrypted and authenticated (with the\nHMAC). 5. The client sends the HMAC of all the handshake messages. 6. The server sends the HMAC of all the handshake messages. The last two steps protect the handshake from tampering. To see this,\nobserve that in step 1, the client typically offers a list of algorithms—some\nstrong, some weak. This list of algorithms is sent in cleartext, since the\nencryption algorithms and keys have not yet been agreed upon. Trudy, as a\nwoman-in-the-middle, could delete the stronger algorithms from the list,\nforcing the client to select a weak algorithm. To prevent such a tampering\nattack, in step 5, the client sends the HMAC of the concatenation of all the\nhandshake messages it sent and received. The server can compare this\nHMAC with the HMAC of the handshake messages it received and sent. If\nthere is an inconsistency, the server can terminate the connection. Similarly,"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1097,
    "text": "the server sends the HMAC of the handshake messages it has seen,\nallowing the client to check for inconsistencies. You may be wondering why there are nonces in steps 1 and 2. Don’t\nsequence numbers suffice for preventing the segment replay attack? The\nanswer is yes, but they don’t alone prevent the “connection replay attack.”\nConsider the following connection replay attack. Suppose Trudy sniffs all\nmessages between Alice and Bob. The next day, Trudy masquerades as Bob\nand sends to Alice exactly the same sequence of messages that Bob sent to\nAlice on the previous day. If Alice doesn’t use nonces, she will respond\nwith exactly the same sequence of messages she sent the previous day. Alice will not suspect any funny business, as each message she receives\nwill pass the integrity check. If Alice is an e-commerce server, she will\nthink that Bob is placing a second order (for exactly the same thing). On the\nother hand, by including a nonce in the protocol, Alice will send different\nnonces for each TCP session, causing the encryption keys to be different on\nthe two days. Therefore, when Alice receives played-back TLS records\nfrom Trudy, the records will fail the integrity checks, and the bogus e-\ncommerce transaction will not succeed. In summary, in TLS, nonces are\nused to defend against the “connection replay attack” and sequence\nnumbers are used to defend against replaying individual packets during an\nongoing session. Connection Closure\nAt some point, either Bob or Alice will want to end the TLS session. One\napproach would be to let Bob end the TLS session by simply terminating\nthe underlying TCP connection—that is, by having Bob send a TCP FIN\nsegment to Alice. But such a naive design sets the stage for the truncation\nattack whereby Trudy once again gets in the middle of an ongoing TLS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1098,
    "text": "session and ends the session early with a TCP FIN. If Trudy were to do this,\nAlice would think she received all of Bob’s data when ­actuality she only\nreceived a portion of it. The solution to this problem is to indicate in the\ntype field whether the record serves to terminate the TLS session. (Although the TLS type is sent in the clear, it is authenticated at the receiver\nusing the record’s HMAC.) By including such a field, if Alice were to\nreceive a TCP FIN before ­receiving a closure TLS record, she would know\nthat something funny was going on. This completes our introduction to TLS. We’ve seen that it uses many\nof the cryptography principles discussed in Sections 8.2 and 8.3. Readers\nwho want to explore TLS on yet a deeper level can read Rescorla’s highly\nreadable book on SSL/TLS [Rescorla 2001]."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1099,
    "text": "8.7 Network-Layer Security: IPsec and Virtual\nPrivate Networks\nThe IP security protocol, more commonly known as IPsec, provides\nsecurity at the network layer. IPsec secures IP datagrams between any two\nnetwork-layer entities, including hosts and routers. As we will soon\ndescribe, many institutions (corporations, government branches, non-profit\norganizations, and so on) use IPsec to create virtual private networks\n(VPNs) that run over the public Internet. Before getting into the specifics of IPsec, let’s step back and consider\nwhat it means to provide confidentiality at the network layer. With network-\nlayer confidentiality between a pair of network entities (for example,\nbetween two routers, between two hosts, or between a router and a host),\nthe sending entity encrypts the payloads of all the datagrams it sends to the\nreceiving entity. The encrypted payload could be a TCP segment, a UDP\nsegment, an ICMP message, and so on. If such a network-layer service were\nin place, all data sent from one entity to the other—including e-mail, Web\npages, TCP handshake messages, and management messages (such as\nICMP and SNMP)—would be hidden from any third party that might be\nsniffing the network. For this reason, network-layer security is said to\nprovide “blanket coverage.”\nIn addition to confidentiality, a network-layer security protocol could\npotentially provide other security services. For example, it could provide\nsource authentication, so that the receiving entity can verify the source of\nthe secured datagram. A network-layer security protocol could provide data\nintegrity, so that the receiving entity can check for any tampering of the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1100,
    "text": "datagram that may have occurred while the datagram was in transit. A\nnetwork-layer security service could also provide replay-attack prevention,\nmeaning that Bob could detect any duplicate datagrams that an attacker\nmight insert. We will soon see that IPsec indeed provides mechanisms for\nall these security services, that is, for confidentiality, source authentication,\ndata ­integrity, and replay-attack prevention. 8.7.1 IPsec and Virtual Private Networks (VPNs)\nAn institution that extends over multiple geographical regions often desires\nits own IP network, so that its hosts and servers can send data to each other\nin a secure and confidential manner. To achieve this goal, the institution\ncould actually deploy a stand-alone physical network—including routers,\nlinks, and a DNS ­infrastructure—that is completely separate from the public\nInternet. Such a disjoint network, dedicated to a particular institution, is\ncalled a private network. Not surprisingly, a private network can be very\ncostly, as the institution needs to purchase, install, and maintain its own\nphysical network infrastructure. Instead of deploying and maintaining a private network, many\ninstitutions today create VPNs over the existing public Internet. With a\nVPN, the institution’s inter-office traffic is sent over the public Internet\nrather than over a physically independent network. But to provide\nconfidentiality, the inter-office traffic is encrypted before it enters the public\nInternet. A simple example of a VPN is shown in Figure 8.27. Here the\ninstitution consists of a headquarters, a branch office, and traveling\nsalespersons that typically access the Internet from their hotel rooms. (There is only one salesperson shown in the figure.) In this VPN, whenever\ntwo hosts within headquarters send IP datagrams to each other or whenever"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1101,
    "text": "two hosts within the branch office want to communicate, they use good-old\nvanilla IPv4 (that is, without IPsec services). However, when two of the\ninstitution’s hosts communicate over a path that traverses the public\nInternet, the traffic is encrypted before it enters the Internet. Figure 8.27 ♦Virtual private network (VPN)\nTo get a feel for how a VPN works, let’s walk through a simple\nexample in the context of Figure 8.27. When a host in headquarters sends\nan IP datagram to a salesperson in a hotel, the gateway router in\nheadquarters converts the vanilla IPv4 datagram into an IPsec datagram and\nthen forwards this IPsec datagram into the Internet. This IPsec datagram\nactually has a traditional IPv4 header, so that the routers in the public\nInternet process the datagram as if it were an ordinary IPv4 datagram—to\nthem, the datagram is a perfectly ordinary datagram. But, as shown Figure\n8.27, the payload of the IPsec datagram includes an IPsec header, which is"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1102,
    "text": "used for IPsec processing; furthermore, the payload of the IPsec datagram is\nencrypted. When the IPsec datagram arrives at the salesperson’s laptop, the\nOS in the laptop decrypts the payload (and provides other security services,\nsuch as verifying data integrity) and passes the unencrypted payload to the\nupper-layer protocol (for example, to TCP or UDP). We have just given a high-level overview of how an institution can\nemploy IPsec to create a VPN. To see the forest through the trees, we have\nbrushed aside many important details. Let’s now take a closer look. 8.7.2 The AH and ESP Protocols\nIPsec is a rather complex animal—it is defined in more than a dozen RFCs. Two important RFCs are RFC 4301, which describes the overall IP security\narchitecture, and RFC 6071, which provides an overview of the IPsec\nprotocol suite. Our goal in this textbook, as usual, is not simply to re-hash\nthe dry and arcane RFCs, but instead take a more operational and pedagogic\napproach to describing the protocols. In the IPsec protocol suite, there are two principal protocols: the\nAuthentication Header (AH) protocol and the Encapsulation Security\nPayload (ESP) protocol. When a source IPsec entity (typically a host or a\nrouter) sends secure datagrams to a destination entity (also a host or a\nrouter), it does so with either the AH protocol or the ESP protocol. The AH\nprotocol provides source authentication and data integrity but does not\nprovide confidentiality. The ESP protocol provides source authentication,\ndata integrity, and confidentiality. Because confidentiality is often critical\nfor VPNs and other IPsec applications, the ESP protocol is much more\nwidely used than the AH protocol. In order to de-mystify IPsec and avoid\nmuch of its complication, we will henceforth focus exclusively on the ESP"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1103,
    "text": "protocol. Readers wanting to learn also about the AH protocol are\nencouraged to explore the RFCs and other online resources. 8.7.3 Security Associations\nIPsec datagrams are sent between pairs of network entities, such as between\ntwo hosts, between two routers, or between a host and router. Before\nsending IPsec datagrams from source entity to destination entity, the source\nand destination entities create a network-layer logical connection. This\nlogical connection is called a security association (SA). An SA is a simplex\nlogical connection; that is, it is unidirectional from source to destination. If\nboth entities want to send secure datagrams to each other, then two SAs\n(that is, two logical connections) need to be established, one in each\ndirection. For example, consider once again the institutional VPN in Figure 8.27. This institution consists of a headquarters office, a branch office and, say, n\ntraveling salespersons. For the sake of example, let’s suppose that there is\nbi-directional IPsec traffic between headquarters and the branch office and\nbi-directional IPsec traffic between headquarters and the salespersons. In\nthis VPN, how many SAs are there? To answer this question, note that there\nare two SAs between the headquarters gateway router and the branch-office\ngateway router (one in each direction); for each salesperson’s laptop, there\nare two SAs between the headquarters gateway router and the laptop (again,\none in each direction). So, in total, there are (2 + 2n) SAs. Keep in mind,\nhowever, that not all traffic sent into the Internet by the gateway routers or\nby the laptops will be IPsec secured. For example, a host in headquarters\nmay want to access a Web server (such as Amazon or Google) in the public"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1104,
    "text": "Internet. Thus, the gateway router (and the laptops) will emit into the\nInternet both vanilla IPv4 ­datagrams and secured IPsec datagrams. Figure 8.28 ♦Security association (SA) from R1 to R2\nLet’s now take a look “inside” an SA. To make the discussion tangible\nand ­concrete, let’s do this in the context of an SA from router R1 to router\nR2 in ­Figure 8.28. (You can think of Router R1 as the headquarters gateway\nrouter and Router R2 as the branch office gateway router from Figure 8.27.) Router R1 will maintain state information about this SA, which will\ninclude:\n•\nA 32-bit identifier for the SA, called the Security Parameter Index\n(SPI)\n•\nThe origin interface of the SA (in this case 200.168.1.100) and the\ndestination interface of the SA (in this case 193.68.2.23)\n•\nThe type of encryption to be used (for example, 3DES with CBC)\n•\nThe encryption key\n•\nThe type of integrity check (for example, HMAC with MD5)\n•\nThe authentication key"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1105,
    "text": "Whenever router R1 needs to construct an IPsec datagram for\nforwarding over this SA, it accesses this state information to determine how\nit should authenticate and encrypt the datagram. Similarly, router R2 will\nmaintain the same state information for this SA and will use this\ninformation to authenticate and decrypt any IPsec datagram that arrives\nfrom the SA. An IPsec entity (router or host) often maintains state information for\nmany SAs. For example, in the VPN example in Figure 8.27 with n\nsalespersons, the headquarters gateway router maintains state information\nfor (2 + 2n) SAs. An IPsec entity stores the state information for all of its\nSAs in its Security Association Database (SAD), which is a data structure\nin the entity’s OS kernel. 8.7.4 The IPsec Datagram\nHaving now described SAs, we can now describe the actual IPsec datagram. IPsec has two different packet forms, one for the so-called tunnel mode\nand the other for the so-called transport mode. The tunnel mode, being\nmore appropriate for VPNs, is more widely deployed than the transport\nmode. In order to further de-mystify IPsec and avoid much of its\ncomplication, we henceforth focus exclusively on the tunnel mode. Once\nyou have a solid grip on the tunnel mode, you should be able to easily learn\nabout the transport mode on your own. The packet format of the IPsec datagram is shown in Figure 8.29. You\nmight think that packet formats are boring and insipid, but we will soon see\nthat the IPsec datagram actually looks and tastes like a popular Tex-Mex\ndelicacy! Let’s examine the IPsec fields in the context of Figure 8.28. Suppose router R1 receives an ordinary IPv4 datagram from host"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 172",
    "source": "kurose",
    "page": 1106,
    "text": "172.16.1.17 (in the headquarters network) which is destined to host\n172.16.2.48 (in the branch-office network). Router R1 uses the ­following\nrecipe to convert this “original IPv4 datagram” into an IPsec datagram:\nFigure 8.29 ♦IPsec datagram format\n•\nAppends to the back of the original IPv4 datagram (which includes the\noriginal header fields!) an “ESP trailer” field\n•\nEncrypts the result using the algorithm and key specified by the SA\n•\nAppends to the front of this encrypted quantity a field called “ESP\nheader”; the resulting package is called the “enchilada”\n•\nCreates an authentication MAC over the whole enchilada using the\nalgorithm and key specified in the SA\n•\nAppends the MAC to the back of the enchilada forming the payload\n•\nFinally, creates a brand new IP header with all the classic IPv4 header\nfields (together normally 20 bytes long), which it appends before the\npayload\nNote that the resulting IPsec datagram is a bona fide IPv4 datagram,\nwith the traditional IPv4 header fields followed by a payload. But in this\ncase, the payload contains an ESP header, the original IP datagram, an ESP"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 172",
    "source": "kurose",
    "page": 1107,
    "text": "trailer, and an ESP authentication field (with the original datagram and ESP\ntrailer encrypted). The original IP datagram has 172.16.1.17 for the source\nIP address and 172.16.2.48 for the destination IP address. Because the IPsec\ndatagram includes the original IP datagram, these addresses are included\n(and encrypted) as part of the payload of the IPsec packet. But what about\nthe source and destination IP addresses that are in the new IP header, that is,\nin the left-most header of the IPsec datagram? As you might expect, they\nare set to the source and destination router interfaces at the two ends of the\ntunnels, namely, 200.168.1.100 and 193.68.2.23. Also, the protocol number\nin this new IPv4 header field is not set to that of TCP, UDP, or SMTP, but\ninstead to 50, designating that this is an IPsec datagram using the ESP\nprotocol. After R1 sends the IPsec datagram into the public Internet, it will pass\nthrough many routers before reaching R2. Each of these routers will process\nthe datagram as if it were an ordinary datagram—they are completely\noblivious to the fact that the datagram is carrying IPsec-encrypted data. For\nthese public Internet routers, because the destination IP address in the outer\nheader is R2, the ultimate destination of the datagram is R2. Having walked through an example of how an IPsec datagram is\nconstructed, let’s now take a closer look at the ingredients in the enchilada. We see in Figure 8.29 that the ESP trailer consists of three fields: padding;\npad length; and next header. Recall that block ciphers require the message\nto be encrypted to be an integer multiple of the block length. Padding\n(consisting of meaningless bytes) is used so that when added to the original\ndatagram (along with the pad length and next header fields), the resulting\n“message” is an integer number of blocks. The pad-length field indicates to\nthe receiving entity how much padding was inserted (and thus needs to be\nremoved). The next header identifies the type (e.g., UDP) of data contained"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 172",
    "source": "kurose",
    "page": 1108,
    "text": "in the payload-data field. The payload data (typically the original IP\ndatagram) and the ESP trailer are concatenated and then encrypted. Appended to the front of this encrypted unit is the ESP header, which is\nsent in the clear and consists of two fields: the SPI and the sequence\nnumber field. The SPI indicates to the receiving entity the SA to which the\ndatagram belongs; the receiving entity can then index its SAD with the SPI\nto determine the appropriate authentication/decryption algorithms and keys. The sequence number field is used to defend against replay attacks. The sending entity also appends an authentication MAC. As stated\nearlier, the sending entity calculates a MAC over the whole enchilada\n(consisting of the ESP header, the original IP datagram, and the ESP trailer\n—with the datagram and trailer being encrypted). Recall that to calculate a\nMAC, the sender appends a secret MAC key to the enchilada and then\ncalculates a fixed-length hash of the result. When R2 receives the IPsec datagram, R2 observes that the destination\nIP address of the datagram is R2 itself. R2 therefore processes the datagram. Because the protocol field (in the left-most IP header) is 50, R2 sees that it\nshould apply IPsec ESP processing to the datagram. First, peering into the\nenchilada, R2 uses the SPI to determine to which SA the datagram belongs. Second, it calculates the MAC of the enchilada and verifies that the MAC is\nconsistent with the value in the ESP MAC field. If it is, it knows that the\nenchilada comes from R1 and has not been tampered with. Third, it checks\nthe sequence-number field to verify that the datagram is fresh (and not a\nreplayed datagram). Fourth, it decrypts the encrypted unit using the\ndecryption algorithm and key associated with the SA. Fifth, it removes\npadding and extracts the original, vanilla IP datagram. And finally, sixth, it\nforwards the original datagram into the branch office network toward its"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1109,
    "text": "ultimate destination. Whew, what a complicated recipe, huh? Well no one\never said that preparing and unraveling an enchilada was easy! There is actually another important subtlety that needs to be addressed. It centers on the following question: When R1 receives an (unsecured)\ndatagram from a host in the headquarters network, and that datagram is\ndestined to some destination IP address outside of headquarters, how does\nR1 know whether it should be converted to an IPsec datagram? And if it is\nto be processed by IPsec, how does R1 know which SA (of many SAs in its\nSAD) should be used to construct the IPsec datagram? The problem is\nsolved as follows. Along with a SAD, the IPsec entity also maintains\nanother data structure called the Security Policy Database (SPD). The\nSPD indicates what types of datagrams (as a function of source IP address,\ndestination IP address, and protocol type) are to be IPsec processed; and for\nthose that are to be IPsec processed, which SA should be used. In a sense,\nthe information in a SPD indicates “what” to do with an arriving datagram;\nthe information in the SAD indicates “how” to do it. Summary of IPsec Services\nSo what services does IPsec provide, exactly? Let us examine these services\nfrom the perspective of an attacker, say Trudy, who is a woman-in-the-\nmiddle, sitting somewhere on the path between R1 and R2 in Figure 8.28. Assume throughout this ­discussion that Trudy does not know the\nauthentication and encryption keys used by the SA. What can and cannot\nTrudy do? First, Trudy cannot see the original datagram. If fact, not only is\nthe data in the original datagram hidden from Trudy, but so is the protocol\nnumber, the source IP address, and the destination IP address. For\ndatagrams sent over the SA, Trudy only knows that the datagram originated\nfrom 200.168.1.100 and is destined to 193.68.2.23. She does not know if it"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1110,
    "text": "is carrying TCP, UDP, or ICMP data; she does not know if it is carrying\nHTTP, SMTP, or some other type of application data. This confidentiality\nthus goes a lot farther than SSL. Second, suppose Trudy tries to tamper with\na datagram in the SA by flipping some of its bits. When this tampered\ndatagram arrives at R2, it will fail the integrity check (using the MAC),\nthwarting Trudy’s vicious attempts once again. Third, suppose Trudy tries\nto masquerade as R1, creating a IPsec datagram with source 200.168.1.100\nand destination 193.68.2.23. Trudy’s attack will be futile, as this datagram\nwill again fail the integrity check at R2. Finally, because IPsec includes\nsequence numbers, Trudy will not be able create a successful replay attack. In summary, as claimed at the beginning of this section, IPsec provides—\nbetween any pair of devices that process packets through the network layer\n—confidentiality, source authentication, data integrity, and replay-attack\nprevention. 8.7.5 IKE: Key Management in IPsec\nWhen a VPN has a small number of end points (for example, just two\nrouters as in Figure 8.28), the network administrator can manually enter the\nSA information (encryption/authentication algorithms and keys, and the\nSPIs) into the SADs of the endpoints. Such “manual keying” is clearly\nimpractical for a large VPN, which may consist of hundreds or even\nthousands of IPsec routers and hosts. Large, geographically distributed\ndeployments require an automated mechanism for creating the SAs. IPsec\ndoes this with the Internet Key Exchange (IKE) protocol, specified in RFC\n5996. IKE has some similarities with the handshake in SSL (see Section 8.6). Each IPsec entity has a certificate, which includes the entity’s public key."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1111,
    "text": "As with SSL, the IKE protocol has the two entities exchange certificates,\nnegotiate authentication and encryption algorithms, and securely exchange\nkey material for creating session keys in the IPsec SAs. Unlike SSL, IKE\nemploys two phases to carry out these tasks. Let’s investigate these two phases in the context of two routers, R1 and\nR2, in Figure 8.28. The first phase consists of two exchanges of message\npairs between R1 and R2:\n•\nDuring the first exchange of messages, the two sides use Diffie-\nHellman (see Homework Problems) to create a bi-directional IKE SA\nbetween the routers. To keep us all confused, this bi-directional IKE SA\nis entirely different from the IPsec SAs discussed in Section 8.6. The\nIKE SA provides an authenticated and encrypted channel between the\ntwo routers. During this first message-pair exchange, keys are\nestablished for encryption and authentication for the IKE SA. Also\nestablished is a master secret that will be used to compute IPSec SA\nkeys later in phase 2. Observe that during this first step, RSA public and\nprivate keys are not used. In particular, neither R1 nor R2 reveals its\nidentity by signing a message with its private key. •\nDuring the second exchange of messages, both sides reveal their\nidentity to each other by signing their messages. However, the identities\nare not revealed to a passive sniffer, since the messages are sent over\nthe secured IKE SA channel. Also during this phase, the two sides\nnegotiate the IPsec encryption and authentication algorithms to be\nemployed by the IPsec SAs. In phase 2 of IKE, the two sides create an SA in each direction. At the\nend of phase 2, the encryption and authentication session keys are\nestablished on both sides for the two SAs. The two sides can then use the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1112,
    "text": "SAs to send secured datagrams, as described in Sections 8.7.3 and 8.7.4. The primary motivation for having two phases in IKE is computational cost\n—since the second phase doesn’t involve any public-key cryptography, IKE\ncan generate a large number of SAs between the two IPsec entities with\nrelatively little computational cost."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1113,
    "text": "8.8 Securing Wireless LANs and 4G/5G Cellular\nNetworks\nSecurity is a particularly important concern in wireless networks, where the\nattacker can sniff frames by simply positioning a receiving device anywhere\nwithin the transmission range of the sender. This is true in both 802.11\nwireless LANs, as well as in 4G/5G cellular networks. In both settings,\nwe’ll see extensive use of the fundamental security techniques that we\nstudied earlier in this chapter, including the use of nonces for\nauthentication, cryptographic hashing for message integrity, derivation of\nshared symmetric keys for encrypting user-session data, and the extensive\nuse of the AES encryption standard. We will also see, as is also the case in\nwired Internet settings, that wireless security protocols have undergone\nconstant evolution, as researchers and hackers discover weaknesses and\nflaws in existing security protocols. In this section, we present a brief introduction to wireless security in\nboth 802.11(WiFi) and 4G/5G settings. For a more in-depth treatment, see\nthe highly readable 802.11 security books [Edney 2003; Wright 2015], the\nexcellent coverage of 3G/4G/5G security in [Sauter 2014], and recent\nsurveys [Zou 2016; Kohlios 2018]. 8.8.1 Authentication and Key Agreement in 802.11 ­-\nWireless LANs\nLet’s start our discussion of 802.11 security by identifying two (of many\n[Zou 2016]) critical security concerns that we’ll want an 802.11 network to"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1114,
    "text": "handle:\n•\nMutual authentication. Before a mobile device is allowed to fully attach\nto an access point and send datagrams to remote hosts, the network will\ntypically want to first authenticate the device—to verify the identity of\nthe mobile device attaching to the network, and to check that device’s\naccess privileges. Similarly, the mobile device will want to authenticate\nthe network to which it is attaching—to make sure that the network it is\njoining is truly the network to which it wants to attach. This two-way\nauthentication is known as mutual authentication. •\nEncryption. Since 802.11 frames will be exchanged over a wireless\nchannel that can be sniffed and manipulated by potential ne’er do-wells,\nit will be important to encrypt link-level frames carrying user-level data\nexchanged between the mobile device and the access point (AP). Symmetric key encryption is used in practice, since encryption and\ndecryption must be performed at high speeds. The mobile device and\nAP will need to derive the symmetric encryption and decryption keys to\nbe used. Figure 8.30 illustrates the scenario of a mobile device wishing to attach\nto an 802.11 network. We see the two usual network components that we\nencountered in our earlier study of 802.11 networks in Section 7.3—the\nmobile device and the AP. We also see a new architectural component, the\nauthentication server (AS) that will be responsible for authenticating the\nmobile device. The authentication server might be co-located in the AP, but\nmore typically and as shown in Figure 8.30, it is implemented as a separate\nserver that provides authentication services. For authentication, the AP\nserves as a pass-through device, relaying authentication and key derivation\nmessages between the mobile device and the authentication server. Such an"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1115,
    "text": "authentication server would typically provide authentication services for all\nAPs within its network. Figure 8.30 ♦Mutual authentication and encryption-key derivation\nin WPA\nWe can identify four distinct phases to the process of mutual\nauthentication and encryption-key derivation and use in Figure 8.30:\n1. Discovery. In the discovery phase, the AP advertises its presence and the\nforms of authentication and encryption that can be provided to the\nmobile device. The mobile device then requests the specific forms of\nauthentication and encryption that it desires. Although the device and"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1116,
    "text": "AP are already exchanging messages, the device has not yet been\nauthenticated nor does it have an encryption key for frame transmission\nover the wireless link, and so several more steps will be required before\nthe device can communicate securely through the AP. 2. Mutual authentication and shared symmetric key derivation. This is the\nmost critical step in “securing” the 802.11 channel. As we will see, this\nstep is greatly facilitated by assuming (which is true in practice in both\n802.11 and 4G/5G networks) that the authentication server and the\nmobile device already have a shared common secret before starting\nmutual authentication. In this step, the device and the authentication\nserver will use this shared secret along with nonces (to prevent relay\nattacks) and cryptographic hashing (to ensure message integrity) in\nauthenticating each other. They will also derive the shared session key\nto be used by the mobile device and the AP to encrypt frames\ntransmitted over the 802.11 wireless link. 3. Shared symmetric session key distribution. Since the symmetric\nencryption key is derived at the mobile device and the authentication\nserver, a protocol will be needed for the authentication server to inform\nthe AP of the shared symmetric session key. While this is rather\nstraightforward, it still is a necessary step. 4. Encrypted communication between mobile device and a remote host via\nthe AP. This communication happens as we saw earlier in Section 7.3.2,\nwith the link-layer frames sent between the mobile device and the AP\nbeing encrypted using the shared session key created and distributed by\nSteps 2 and 3. AES symmetric key cryptography, which we covered\nearlier in Section 8.2.1, is typically used in practice for\nencrypting/decrypting 802.11 frame data."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1118,
    "text": "knowing a shared secret key K\n (e.g., a password). One of their tasks will\nbe to derive a shared symmetric session-key, K\n, which will be used to\nencrypt/decrypt frames that are later transmitted between the mobile device\n(M) and the AP. Mutual authentication and shared symmetric session-key derivation\nare ­accomplished in the first two steps, a and b, of the four-way handshake\nshown in Figure 8.31. Steps c and d are used to derive a second key used\nfor group communication; see [Kohlios 2018; Zou 2016] for details. Figure 8.31 ♦The WPA2 four-way handshake\na. In this first step, the authentication server (AS) generates a nonce,\nNonce , and sends it to the mobile device. Recall from Section 8.4\nthat nonces are used to avoid playback attacks and prove the “liveness”\nof the other side being authenticated. AS-M\nM-AP\nAS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1119,
    "text": "b. The mobile device, M, receives the nonce, Nonce , from the AS and\ngenerates its own nonce, Nonce . The mobile device then generates the\nsymmetric shared session key, K\n, using Nonce , Nonce , the initial\nshared secret key K\n, its MAC address, and the MAC address of the\nAS. It then sends its nonce, Nonce , and an HMAC-signed (see Figure\n8.9) value that encodes Nonce  and the original shared secret. The AS receives this message from M. By looking at the HMAC-\nsigned version of the nonce it had just recently sent, Nonce , the\nauthentication server knows the mobile device is live; because the\nmobile device was able to encrypt using the shared secret key, K\n,\nthe AS also knows that the mobile device is indeed who it claims to be\n(i.e., a device that knows the shared initial secret). The AS has thus\nauthenticated the mobile device! The AS can also now perform the\nexact same computation as the mobile device to derive the shared\nsymmetric session-key, K\n, using the Nonce  it received, Nonce ,\nthe initial shared secret key K\n, its MAC address and the MAC\naddress of the mobile device. At this point both the mobile device and\nthe authentication server have computed the same shared symmetric\nkey, K\n, which will be used to encrypt/decrypt frames transmitted\nbetween the mobile device and the AP. The AS informs the AP of this\nkey value in Step 3 in Figure 8.30. WPA3 was released in June 2018 as an update to WPA2. The update\naddresses an attack on the four-way handshake protocol that could induce\nthe reuse of previously used nonces [Vanhoef 2017] but still permits the use\nof the four-way handshake as a legacy protocol and includes longer key\nlengths, among other changes [WiFi 2019]. AS\nM\nM-AP\nAS\nM\nAS-M\nM\nAS\nAS\nAS-M\nM-AP\nM\nAS\nAS-M\nM-AP"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1120,
    "text": "802.11 Security Messaging Protocols\nFigure 8.32 shows the protocols used to implement the 802.11 security\nframework discussed above. The Extensible Authentication Protocol (EAP)\n[RFC 3748] defines the end-to-end message formats used in a simple\nrequest/response mode of interaction between the mobile device and\nauthentication server, and are certified under WPA2. As shown in Figure\n8.32, EAP messages are encapsulated using EAPoL (EAP over LAN) and\nsent over the 802.11 wireless link. These EAP messages are then\ndecapsulated at the access point, and then re-encapsulated using the\nRADIUS protocol for transmission over UDP/IP to the authentication\nserver. While the RADIUS server and protocol [RFC 2865] are not\nrequired, they are de facto standard components. The recently standardized\nDIAMETER protocol [RFC 3588] is projected to eventually replace\nRADIUS in the future."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1121,
    "text": "Figure 8.32 ♦EAP is an end-to-end protocol. EAP messages are\nencapsulated using EAPoL over the wireless link\nbetween the mobile device and the access point, and\nusing RADIUS over UDP/IP between the access point\nand the authentication server\n8.8.2 Authentication and Key Agreement in 4G/5G\nCellular Networks\nIn this section, we describe mutual authentication and key-generation\nmechanisms in 4G/5G networks. Many of the approaches we’ll encounter\nhere parallel those that we just studied in 802.11 networks, with the notable\nexception that in 4G/5G ­networks, mobile devices may be attached to their\nhome network (i.e., the cellular carrier ­network to which they are\nsubscribed), or may be roaming on a visited network. In this latter case, the\nvisited and home networks will need to interact when authenticating a\nmobile device and generating encryption keys. Before continuing, you may\nwant to re-familiarize yourself with 4G/5G network architecture by re-\nreading Sections 7.4 and 7.7. The goals of mutual authentication and key generation are the same in\nthe 4G/5G setting as in the 802.11 setting. In order to encrypt the contents\nof frames being transmitted over the wireless channel, the mobile device\nand base station will need to derive a shared symmetric encryption key. In\naddition, the network to which the mobile device is attaching will need to\nauthenticate the device’s identity and check its access privileges. Similarly,\nthe mobile device will also want to authenticate the network to which it is\nattaching. While the network’s need to authenticate a mobile device may be\nobvious, the need for authentication in the reverse direction may not be so"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1122,
    "text": "clear. However, there are documented cases of ne’er-do-wells operating\nrogue cellular base stations that entice unsuspecting mobile devices to\nattach to the rogue network, exposing a device to a number of attacks [Li\n2017]. So, as in the case of 802.11 WLANs, a mobile device should\nexercise abundant caution when attaching to a cellular network! Figure 8.33 illustrates the scenario of mobile device attaching to a 4G\ncellular network. At the top of Figure 8.33, we see many of the 4G\ncomponents that we encountered earlier in Section 7.4—the mobile device\n(M), the base station (BS), the mobility management entity (MME) in the\nnetwork to which the mobile device wants to attach, and the home\nsubscriber service (HSS) in the mobile device’s home network. A\ncomparison of Figures 8.30 and 8.33 shows the similarities and differences\nbetween the 802.11 and 4G security settings. We again see a mobile device\nand a base station; the user session-key derived during network attachment,\nK\n, will be used to encrypt/decrypt frames transmitted over their wireless\nlink. The 4G MME and HSS together will play a role similar to that of the\nauthentication server in the 802.11 setting. Note that the HSS and the\nmobile device also share a common secret, K\n, known to both entities\nbefore authentication begins. This key is stored in the mobile device’s SIM\ncard, and in the HSS database in the mobile device’s home network. BS-M\nHSS-M"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1123,
    "text": "Figure 8.33 ♦Mutual authentication and key agreement in a 4G\nLTE cellular network\nThe 4G Authentication and Key Agreement (AKA) protocol consists of\nthe following steps:\na. Authentication request to HSS. When the mobile device first requests,\nvia a base station, to attach to the network, it sends an attach message\ncontaining its international mobile subscriber identity (IMSI) that is\nrelayed to the Mobility Management Entity (MME). The MME will\nthen send the IMSI and information about the visited network (shown\nas “VN info” in Figure 8.33) to the Home Subscriber Service (HSS) in\nthe device’s home network. In Section 7.4, we described how the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1124,
    "text": "MME is able to communicate with the HSS through the all-IP global\nnetwork of interconnected cellular networks. b. Authentication response from HSS. The HSS performs cryptographic ­-\noperations using the shared-in-advance secret key, K\n, to derive an\n­authentication token, auth_token, and an expected authentication\nresponse token, xres\n. auth_token contains information encrypted by\nthe HSS using K\n that will allow the mobile device to know that\nwhoever computed auth_token knows the secret key. For example,\nsuppose the HSS ­computes K\n(IMSI), that is, encrypts the device’s\nIMSI using K\n and sends that value as auth_token. When the\nmobile device receives that encrypted value and uses its secret key to\ndecrypt this value, that is, to ­compute K\n(K\n(IMSI)) = IMSI, it\nknows that the HSS that generated auth_token knows its secret key. The mobile device can thus authenticate the HSS. The expected authentication response token, xres\n, contains a value\nthat the mobile device will need to be able to compute (using K\n)\nand return to the MME to prove that it (the mobile device) knows the\nsecret key, thus authenticating the mobile device to the MME. Note that the MME only plays a middleman role here, receiving the\nauthentication response message, keeping xres\n for later use,\nextracting the authentication token and forwarding it to the mobile\ndevice. In particular it need not know, and will not learn, the secret\nkey, K\n. c. Authentication response from mobile device. The mobile device\nreceives auth_token and computes K\n(K\n(IMSI)) = IMSI, thus\nauthenticating the HSS. The mobile device then computes a value res\n—using its secret key to make the exact same cryptographic\nHSS-M\nHSS\nHSS-M\nHSS-M\nHSS-M\nHSS-M\nHSS-M\nHSS\nHSS-M\nHSS\nHSS-M\nHSS-M\nHSS-M\nM"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1125,
    "text": "calculation that the HSS had made to compute xres\n—and sends this\nvalue to the MME. d. Mobile device authentication. The MMS compares the mobile-\ncomputed value of res  with the HSS-computed value of xres\n. If\nthey match, the mobile device is authenticated, since the mobile has\nproven to the MME that it and the HSS both know the common secret\nkey. The MMS informs the base station and mobile device that mutual\nauthentication is complete, and sends the base station keys that will be\nused in step e.\ne. Data plane and control plane key derivation. The mobile device and\nthe base station will each determine the keys used for\nencrypting/decrypting their frame transmissions over the wireless\nchannel. Separate keys will be derived for data plane and control plane\nframe transmissions. The AES encryption algorithm that we saw in use\nin 802.11 networks is also used in 4G/5G networks. Our discussion above has focused on authentication and key agreement\nin 4G networks. Although much of the 4G security is being carried forward\ninto 5G, there are some important changes:\n•\nFirst, note that in our discussion above that it is the MME in the visited\nnetwork that makes the authentication decision. A significant change\nunderway in 5G network security is to allow authentication services to\nbe provided by the home network, with the visited network playing an\neven smaller middleman role. While the visited network may still reject\nan authentication from a mobile device, it is up to the home network to\naccept the authentication request in this new 5G scenario. •\n5G networks will support the Authentication and Key Agreement\n(AKA) protocol described above, as well as two new additional\nHSS\nM\nHSS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1126,
    "text": "protocols for authentication and key agreement. One of these, known as\nAKA’, is closely related to the 4G AKA protocol. It also uses the\nshared-in-advance secret key, K\n. However, since it uses the EAP\nprotocol that we encountered earlier in Figure 8.33 in the context of\n802.11 authentication, 5G AKA’ has different message flows than that\nof 4G AKA. The second new 5G protocol is meant for an IoT\nenvironment, and does not require a shared-in-advance secret key. •\nAn additional change in 5G is to use public key cryptography\ntechniques to encrypt a device’s permanent identity (i.e., its IMSI) so\nthat it is never transmitted in cleartext. In this section, we have only briefly overviewed mutual authentication and\nkey agreement in 4G /5G networks. As we have seen, they make extensive\nuse of the security techniques that we studied earlier in this chapter. More\ndetails on 4G/5G security can be found in [3GPP SAE 2019; Cable Labs\n2019; Cichonski 2017]. HSS-M"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1127,
    "text": "8.9 Operational Security: Firewalls and Intrusion\nDetection Systems\nWe’ve seen throughout this chapter that the Internet is not a very safe place\n—bad guys are out there, wreaking all sorts of havoc. Given the hostile\nnature of the Internet, let’s now consider an organization’s network and the\nnetwork administrator who administers it. From a network administrator’s\npoint of view, the world divides quite neatly into two camps—the good\nguys (who belong to the organization’s network, and who should be able to\naccess resources inside the organization’s network in a relatively\nunconstrained manner) and the bad guys (everyone else, whose access to\nnetwork resources must be carefully scrutinized). In many organizations,\nranging from medieval castles to modern corporate office buildings, there is\na single point of entry/exit where both good guys and bad guys entering and\nleaving the organization are security-checked. In a castle, this was done at a\ngate at one end of the drawbridge; in a corporate building, this is done at the\nsecurity desk. In a computer network, when traffic entering/leaving a\nnetwork is security-checked, logged, dropped, or forwarded, it is done by\noperational devices known as firewalls, intrusion detection systems (IDSs),\nand intrusion prevention systems (IPSs). 8.9.1 Firewalls\nA firewall is a combination of hardware and software that isolates an\norganization’s internal network from the Internet at large, allowing some\npackets to pass and blocking others. A firewall allows a network"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1128,
    "text": "administrator to control access between the outside world and resources\nwithin the administered network by managing the traffic flow to and from\nthese resources. A firewall has three goals:\n•\nAll traffic from outside to inside, and vice versa, passes through the\nfirewall. Figure 8.34 shows a firewall, sitting squarely at the boundary\nbetween the administered network and the rest of the Internet. While\nlarge organizations may use multiple levels of firewalls or distributed\nfirewalls [Skoudis 2006], locating a firewall at a single access point to\nthe network, as shown in Figure 8.34, makes it easier to manage and\nenforce a security-access policy. •\nOnly authorized traffic, as defined by the local security policy, will be\nallowed to pass. With all traffic entering and leaving the institutional\nnetwork passing through the firewall, the firewall can restrict access to\nauthorized traffic. •\nThe firewall itself is immune to penetration. The firewall itself is a\ndevice connected to the network. If not designed or installed properly, it\ncan be compromised, in which case it provides only a false sense of\nsecurity (which is worse than no firewall at all!). Cisco and Check Point are two of the leading firewall vendors today. You\ncan also easily create a firewall (packet filter) from a Linux box using\niptables (public-domain software that is normally shipped with Linux). Furthermore, as discussed in Chapters 4 and 5, firewalls are now frequently\nimplemented in routers and controlled remotely using SDNs. Firewalls can be classified in three categories: traditional packet\nfilters, stateful filters, and application gateways. We’ll cover each of\nthese in turn in the following subsections."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1129,
    "text": "Traditional Packet Filters\nAs shown in Figure 8.34, an organization typically has a gateway router\nconnecting its internal network to its ISP (and hence to the larger public\nInternet). All traffic leaving and entering the internal network passes\nthrough this router, and it is at this router where packet filtering occurs. A\npacket filter examines each datagram in isolation, determining whether the\ndatagram should be allowed to pass or should be dropped based on\nadministrator-specific rules. Filtering decisions are typically based on:\nFigure 8.34 ♦Firewall placement between the administered network\nand the outside world\n•\nIP source or destination address\n•\nProtocol type in IP datagram field: TCP, UDP, ICMP, OSPF, and so on"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1130,
    "text": "•\nTCP or UDP source and destination port\n•\nTCP flag bits: SYN, ACK, and so on\n•\nICMP message type\n•\nDifferent rules for datagrams leaving and entering the network\n•\nDifferent rules for the different router interfaces\nA network administrator configures the firewall based on the policy of\nthe organization. The policy may take user productivity and bandwidth\nusage into account as well as the security concerns of an organization. Table\n8.5 lists a number of possible polices an organization may have, and how\nthey would be addressed with a packet filter. For example, if the\norganization doesn’t want any incoming TCP connections except those for\nits public Web server, it can block all incoming TCP SYN segments except\nTCP SYN segments with destination port 80 and the destination IP address\ncorresponding to the Web server. If the organization doesn’t want its users\nto monopolize access bandwidth with Internet radio applications, it can\nblock all not-critical UDP traffic (since Internet radio is often sent over\nUDP). If the organization doesn’t want its internal network to be mapped\n(tracerouted) by an outsider, it can block all ICMP TTL expired messages\nleaving the organization’s network. Table 8.5 ♦Policies and corresponding filtering rules for an\norganization’s network 130.207/16 with Web server at\n130.207.244.203\nA filtering policy can be based on a combination of addresses and port\nnumbers. For example, a filtering router could forward all Telnet datagrams\n(those with a port number of 23) except those going to and coming from a\nlist of specific IP addresses. This policy permits Telnet connections to and\nfrom hosts on the allowed list. Unfortunately, basing the policy on external"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1131,
    "text": "addresses provides no protection against datagrams that have had their\nsource addresses spoofed. Filtering can also be based on whether or not the TCP ACK bit is set. This trick is quite useful if an organization wants to let its internal clients\nconnect to external servers but wants to prevent external clients from\nconnecting to internal servers. Recall from Section 3.5 that the first segment\nin every TCP connection has the ACK bit set to 0, whereas all the other\nsegments in the connection have the ACK bit set to 1. Thus, if an\norganization wants to prevent external clients from initiating connections to\ninternal servers, it simply filters all incoming segments with the ACK bit set\nto 0. This policy kills all TCP connections originating from the outside, but\npermits connections originating internally. Firewall rules are implemented in routers with access control lists, with\neach router interface having its own list. An example of an access control\nlist for an organization 222.22/16 is shown in Table 8.6. This access control\nlist is for an interface that connects the router to the organization’s external\nISPs. Rules are applied to each datagram that passes through the interface\nfrom top to bottom. The first two rules together allow internal users to surf\nthe Web: The first rule allows any TCP packet with destination port 80 to\nleave the organization’s network; the second rule allows any TCP packet\nwith source port 80 and the ACK bit set to enter the organization’s network. Note that if an external source attempts to establish a TCP connection with\nan internal host, the connection will be blocked, even if the source or\ndestination port is 80. The second two rules together allow DNS packets to\nenter and leave the organization’s network. In summary, this rather\nrestrictive access control list blocks all traffic except Web traffic initiated\nfrom within the organization and DNS traffic. [CERT Filtering 2012]"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 4",
    "source": "kurose",
    "page": 1132,
    "text": "provides a list of recommended port/protocol packet filterings to avoid a\nnumber of well-known security holes in existing network applications. Readers with sharp memories may recall we encountered access control\nlists similar to Table 8.6 when we studied generalized forwarding in Section\n4.4.3 of Chapter 4. Indeed, we provided an example there of how\ngeneralized forwarding rules can be used to build a packet-filtering firewall. Table 8.6 ♦An access control list for a router interface\nStateful Packet Filters\nIn a traditional packet filter, filtering decisions are made on each packet in\nisolation. Stateful filters actually track TCP connections, and use this\nknowledge to make ­filtering decisions. To understand stateful filters, let’s reexamine the access control list in\nTable 8.6. Although rather restrictive, the access control list in Table 8.6\nnevertheless allows any packet arriving from the outside with ACK = 1 and\nsource port 80 to get through the filter. Such packets could be used by\nattackers in attempts to crash internal systems with malformed packets,\ncarry out denial-of-service attacks, or map the internal network. The naive\nsolution is to block TCP ACK packets as well, but such an approach would\nprevent the organization’s internal users from surfing the Web. Stateful filters solve this problem by tracking all ongoing TCP\nconnections in a connection table. This is possible because the firewall can\nobserve the beginning of a new connection by observing a three-way\nhandshake (SYN, SYNACK, and ACK); and it can observe the end of a\nconnection when it sees a FIN packet for the connection. The firewall can\nalso (conservatively) assume that the connection is over when it hasn’t seen\nany activity over the connection for, say, 60 seconds. An example\nconnection table for a firewall is shown in Table 8.7. This connection table"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1133,
    "text": "indicates that there are currently three ongoing TCP connections, all of\nwhich have been initiated from within the organization. Additionally, the\nstateful filter includes a new column, “check connection,” in its access\ncontrol list, as shown in Table 8.8. Note that Table 8.8 is identical to the\naccess control list in Table 8.6, except now it indicates that the connection\nshould be checked for two of the rules. Table 8.7 ♦Connection table for stateful filter\nLet’s walk through some examples to see how the connection table and\nthe extended access control list work hand-in-hand. Suppose an attacker\nattempts to send a malformed packet into the organization’s network by\nsending a datagram with TCP source port 80 and with the ACK flag set. Further suppose that this packet has source port number 12543 and source\nIP address 150.23.23.155. When this packet reaches the firewall, the\nfirewall checks the access control list in Table 8.7, which indicates that the\nconnection table must also be checked before permitting this packet to enter\nthe organization’s network. The firewall duly checks the connection table,\nsees that this packet is not part of an ongoing TCP connection, and rejects\nthe packet. As a second example, suppose that an internal user wants to surf\nan external Web site. Because this user first sends a TCP SYN segment, the\nuser’s TCP connection gets recorded in the connection table. When the Web\nserver sends back packets (with the ACK bit necessarily set), the firewall\nchecks the table and sees that a corresponding connection is in progress. The firewall will thus let these packets pass, thereby not interfering with the\ninternal user’s Web surfing activity. Table 8.8 ♦Access control list for stateful filter\nApplication Gateway"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1134,
    "text": "In the examples above, we have seen that packet-level filtering allows an\norganization to perform coarse-grain filtering on the basis of the contents of\nIP and TCP/UDP headers, including IP addresses, port numbers, and\nacknowledgment bits. But what if an organization wants to provide a Telnet\nservice to a restricted set of internal users (as opposed to IP addresses)? And\nwhat if the organization wants such privileged users to authenticate\nthemselves first before being allowed to create Telnet sessions to the\noutside world? Such tasks are beyond the capabilities of traditional and\nstateful filters. Indeed, information about the identity of the internal users is\napplication-layer data and is not included in the IP/TCP/UDP headers. To have finer-level security, firewalls must combine packet filters with\napplication gateways. Application gateways look beyond the IP/TCP/UDP\nheaders and make policy decisions based on application data. An\napplication gateway is an application-specific server through which all\napplication data (inbound and outbound) must pass. Multiple application\ngateways can run on the same host, but each gateway is a separate server\nwith its own processes. To get some insight into application gateways, let’s design a firewall\nthat allows only a restricted set of internal users to Telnet outside and\nprevents all external clients from Telneting inside. Such a policy can be\naccomplished by implementing a combination of a packet filter (in a router)\nand a Telnet application gateway, as shown in Figure 8.35. The router’s\nfilter is configured to block all Telnet connections except those that\noriginate from the IP address of the application gateway. Such a filter\nconfiguration forces all outbound Telnet connections to pass through the\napplication gateway. Consider now an internal user who wants to Telnet to\nthe outside world. The user must first set up a Telnet session with the\napplication gateway. An application running in the gateway, which listens"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1135,
    "text": "for incoming Telnet sessions, prompts the user for a user ID and password. When the user supplies this information, the application gateway checks to\nsee if the user has permission to Telnet to the outside world. If not, the\nTelnet connection from the internal user to the gateway is terminated by the\ngateway. If the user has permission, then the gateway (1) prompts the user\nfor the host name of the external host to which the user wants to connect,\n(2) sets up a Telnet session between the gateway and the external host, and\n(3) relays to the external host all data arriving from the user, and relays to\nthe user all data arriving from the external host. Thus, the Telnet application\ngateway not only performs user authorization but also acts as a Telnet\nserver and a Telnet client, relaying information between the user and the\nremote Telnet server. Note that the filter will permit step 2 because the\ngateway initiates the Telnet connection to the outside world."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1136,
    "text": "Figure 8.35 ♦Firewall consisting of an application gateway and a\nfilter\nANONYMITY AND PRIVACY\nSuppose you want to visit a controversial Web site (for example, a political activist site)\nand you (1) don’t want to reveal your IP address to the Web site, (2) don’t want your\nlocal ISP (which may be your home or office ISP) to know that you are visiting the site,\nand (3) don’t want your local ISP to see the data you are exchanging with the site. If\nyou use the traditional approach of connecting directly to the Web site without any\nencryption, you fail on all three counts. Even if you use SSL, you fail on the first two\ncounts: Your source IP address is presented to the Web site in every datagram you"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1137,
    "text": "send; and the destination address of every packet you send can easily be sniffed by\nyour local ISP. To obtain privacy and anonymity, you can instead use a combination of a trusted proxy\nserver and SSL, as shown in Figure 8.36. With this approach, you first make an SSL\nconnection to the trusted proxy. You then send, into this SSL connection, an HTTP\nrequest for a page at the desired site. When the proxy receives the SSL-encrypted\nHTTP request, it decrypts the request and forwards the cleartext HTTP request to the\nWeb site. The Web site then responds to the proxy, which in turn forwards the\nresponse to you over SSL. Because the Web site only sees the IP address of the\nproxy, and not of your client’s address, you are indeed obtaining anonymous access to\nthe Web site. And because all traffic between you and the proxy is encrypted, your\nlocal ISP cannot invade your privacy by logging the site you visited or recording the\ndata you are exchanging. Many companies today (such as proxify\n.com) make available such proxy services. Figure 8.36 ♦Providing anonymity and privacy with a proxy\nOf course, in this solution, your proxy knows everything: It knows your IP address and\nthe IP address of the site you’re surfing; and it can see all the traffic in ­cleartext\nexchanged between you and the Web site. Such a solution, therefore, is only as good\nas the trustworthiness of the proxy. A more robust approach, taken by the TOR"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1138,
    "text": "anonymizing and privacy service, is to route your traffic through a series of non-­-\ncolluding proxy servers [TOR 2020]. In particular, TOR allows independent ­individuals\nto contribute proxies to its proxy pool. When a user connects to a server using TOR,\nTOR randomly chooses (from its proxy pool) a chain of three proxies and routes all\ntraffic between client and server over the chain. In this manner, assuming the proxies\ndo not collude, no one knows that communication took place between your IP address\nand the target Web site. Furthermore, although cleartext is sent between the last proxy\nand the server, the last proxy doesn’t know what IP address is sending and receiving\nthe cleartext. Internal networks often have multiple application gateways, for\nexample, gateways for Telnet, HTTP, FTP, and e-mail. In fact, an\norganization’s mail server (see Section 2.3) and Web cache are application\ngateways. Application gateways do not come without their disadvantages. First, a\ndifferent application gateway is needed for each application. Second, there\nis a performance penalty to be paid, since all data will be relayed via the\ngateway. This becomes a concern particularly when multiple users or\napplications are using the same gateway machine. Finally, the client\nsoftware must know how to contact the gateway when the user makes a\nrequest, and must know how to tell the application gateway what external\nserver to connect to. 8.9.2 Intrusion Detection Systems\nWe’ve just seen that a packet filter (traditional and stateful) inspects IP,\nTCP, UDP, and ICMP header fields when deciding which packets to let pass\nthrough the firewall. However, to detect many attack types, we need to"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1139,
    "text": "perform deep packet inspection, that is, look beyond the header fields and\ninto the actual application data that the packets carry. As we saw in Section\n8.9.1, application gateways often do deep packet inspection. But an\napplication gateway only does this for a specific application. Clearly, there is a niche for yet another device—a device that not only\nexamines the headers of all packets passing through it (like a packet filter),\nbut also ­performs deep packet inspection (unlike a packet filter). When such\na device observes a ­suspicious packet, or a suspicious series of packets, it\ncould prevent those packets from entering the organizational network. Or,\nbecause the activity is only deemed as suspicious, the device could let the\npackets pass, but send alerts to a network administrator, who can then take a\ncloser look at the traffic and take appropriate actions. A device that\ngenerates alerts when it observes potentially malicious traffic is called an\nintrusion detection system (IDS). A device that filters out suspicious\ntraffic is called an intrusion prevention system (IPS). In this section we\nstudy both ­systems—IDS and IPS—together, since the most interesting\ntechnical aspect of these systems is how they detect suspicious traffic (and\nnot whether they send alerts or drop packets). We will henceforth\ncollectively refer to IDS systems and IPS systems as IDS systems. An IDS can be used to detect a wide range of attacks, including\nnetwork mapping (emanating, for example, from nmap), port scans, TCP\nstack scans, DoS bandwidth-flooding attacks, worms and viruses, OS\nvulnerability attacks, and application vulnerability attacks. (See Section 1.6\nfor a survey of network attacks.) Today, thousands of organizations employ\nIDS systems. Many of these deployed systems are proprietary, marketed by\nCisco, Check Point, and other security equipment vendors. But many of the\ndeployed IDS systems are public-domain systems, such as the immensely\npopular Snort IDS system (which we’ll discuss shortly)."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1140,
    "text": "An organization may deploy one or more IDS sensors in its\norganizational network. Figure 8.37 shows an organization that has three\nIDS sensors. When multiple sensors are deployed, they typically work in\nconcert, sending information about suspicious traffic activity to a central\nIDS processor, which collects and integrates the information and sends\nalarms to network administrators when deemed appropriate. In Figure 8.37,\nthe organization has partitioned its network into two regions: a high-\nsecurity region, protected by a packet filter and an application gateway and\nmonitored by IDS sensors; and a lower-security region—referred to as the\ndemilitarized zone (DMZ)—which is protected only by the packet filter,\nbut also monitored by IDS sensors. Note that the DMZ includes the\norganization’s servers that need to communicate with the outside world,\nsuch as its public Web server and its authoritative DNS server."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1141,
    "text": "Figure 8.37 ♦An organization deploying a filter, an application\ngateway, and IDS sensors\nYou may be wondering at this stage, why multiple IDS sensors? Why\nnot just place one IDS sensor just behind the packet filter (or even\nintegrated with the packet filter) in Figure 8.37? We will soon see that an\nIDS not only needs to do deep packet inspection, but must also compare\neach passing packet with tens of thousands of “signatures”; this can be a\nsignificant amount of processing, particularly if the organization receives\ngigabits/sec of traffic from the Internet. By placing the IDS sensors further\ndownstream, each sensor sees only a fraction of the organization’s traffic,\nand can more easily keep up. Nevertheless, high-performance IDS and IPS\nsystems are available today, and many organizations can actually get by\nwith just one sensor located near its access router. IDS systems are broadly classified as either signature-based systems\nor ­anomaly-\nbased systems. A signature-based IDS maintains an extensive database of\nattack signatures. Each signature is a set of rules pertaining to an intrusion\nactivity. A signature may simply be a list of characteristics about a single\npacket (e.g., source and destination port numbers, protocol type, and a\nspecific string of bits in the packet payload), or may relate to a series of\npackets. The signatures are normally created by skilled network security\nengineers who research known attacks. An organization’s network\nadministrator can customize the signatures or add its own to the database. Operationally, a signature-based IDS sniffs every packet passing by it,\ncomparing each sniffed packet with the signatures in its database. If a\npacket (or series of packets) matches a signature in the database, the IDS\ngenerates an alert. The alert could be sent to the network administrator in an"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1142,
    "text": "e-mail message, could be sent to the network management system, or could\nsimply be logged for future inspection. Signature-based IDS systems, although widely deployed, have a\nnumber of limitations. Most importantly, they require previous knowledge\nof the attack to generate an accurate signature. In other words, a signature-\nbased IDS is completely blind to new attacks that have yet to be recorded. Another disadvantage is that even if a signature is matched, it may not be\nthe result of an attack, so that a false alarm is generated. Finally, because\nevery packet must be compared with an extensive collection of signatures,\nthe IDS can become overwhelmed with processing and actually fail to\ndetect many malicious packets. An anomaly-based IDS creates a traffic profile as it observes traffic in\nnormal operation. It then looks for packet streams that are statistically\nunusual, for example, an inordinate percentage of ICMP packets or a\nsudden exponential growth in port scans and ping sweeps. The great thing\nabout anomaly-based IDS systems is that they don’t rely on previous\nknowledge about existing attacks—that is, they can potentially detect new,\nundocumented attacks. On the other hand, it is an extremely challenging\nproblem to distinguish between normal traffic and statistically unusual\ntraffic. To date, most IDS deployments are primarily signature-based,\nalthough some include some anomaly-based features. Snort\nSnort is a public-domain, open source IDS with hundreds of thousands of\nexisting deployments [Snort 2012; Koziol 2003]. It can run on Linux,\nUNIX, and Windows platforms. It uses the generic sniffing interface\nlibpcap, which is also used by Wireshark and many other packet sniffers. It"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1143,
    "text": "can easily handle 100 Mbps of traffic; for installations with gibabit/sec\ntraffic rates, multiple Snort sensors may be needed. To gain some insight into Snort, let’s take a look at an example of a\nSnort signature:\nalert icmp $EXTERNAL_NET any -> $HOME_NET any\n(msg:”ICMP PING NMAP”; dsize: 0; itype: 8;)\nThis signature is matched by any ICMP packet that enters the organization’s\nnetwork ($HOME_NET) from the outside ($EXTERNAL_NET), is of type 8\n(ICMP ping), and has an empty payload (dsize = 0). Since nmap (see\nSection 1.6) generates ping packets with these specific characteristics, this\nsignature is designed to detect nmap ping sweeps. When a packet matches\nthis signature, Snort generates an alert that includes the message “ICMP\nPING NMAP”. Perhaps what is most impressive about Snort is the vast community of\nusers and security experts that maintain its signature database. Typically\nwithin a few hours of a new attack, the Snort community writes and\nreleases an attack signature, which is then downloaded by the hundreds of\nthousands of Snort deployments distributed around the world. Moreover,\nusing the Snort signature syntax, network administrators can tailor the\nsignatures to their own organization’s needs by either modifying existing\nsignatures or creating entirely new ones."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1144,
    "text": "8.10 Summary\nIn this chapter, we’ve examined the various mechanisms that our secret\nlovers, Bob and Alice, can use to communicate securely. We’ve seen that\nBob and Alice are interested in confidentiality (so they alone are able to\nunderstand the contents of a transmitted message), end-point authentication\n(so they are sure that they are talking with each other), and message\nintegrity (so they are sure that their messages are not altered in transit). Of\ncourse, the need for secure communication is not confined to secret lovers. Indeed, we saw in Sections 8.5 through 8.8 that security can be used in\nvarious layers in a network architecture to protect against bad guys who\nhave a large arsenal of possible attacks at hand. The first part of this chapter presented various principles underlying\nsecure communication. In Section 8.2, we covered cryptographic techniques\nfor encrypting and decrypting data, including symmetric key cryptography\nand public key cryptography. DES and RSA were examined as specific case\nstudies of these two major classes of cryptographic techniques in use in\ntoday’s networks. In Section 8.3, we examined two approaches for providing message\nintegrity: message authentication codes (MACs) and digital signatures. The\ntwo approaches have a number of parallels. Both use cryptographic hash\nfunctions and both techniques enable us to verify the source of the message\nas well as the integrity of the message itself. One important difference is\nthat MACs do not rely on encryption whereas digital signatures require a\npublic key infrastructure. Both techniques are extensively used in practice,\nas we saw in Sections 8.5 through 8.8. Furthermore, digital signatures are\nused to create digital certificates, which are important for verifying the"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1145,
    "text": "validity of public keys. In Section 8.4, we ­examined endpoint authentication\nand introduced nonces to defend against the replay attack. In Sections 8.5 through 8.8 we examined several security networking\nprotocols that enjoy extensive use in practice. We saw that symmetric key\ncryptography is at the core of PGP, SSL, IPsec, and wireless security. We\nsaw that public key cryptography is crucial for both PGP and TLS. We saw\nthat PGP uses digital signatures for message integrity, whereas TLS and\nIPsec use MACs. We also explored security in wireless networks, including\nWiFi networks and 4G/5G cellular networks. Having now an understanding\nof the basic principles of cryptography, and having studied how these\nprinciples are actually used, you are now in position to design your own\nsecure network protocols! Armed with the techniques covered in Sections 8.2 through 8.8, Bob\nand Alice can communicate securely. But confidentiality is only a small part\nof the network security picture. As we learned in Section 8.9, increasingly,\nthe focus in network security has been on securing the network\ninfrastructure against a potential onslaught by the bad guys. In the latter part\nof this chapter, we thus covered firewalls and IDS systems which inspect\npackets entering and leaving an organization’s network."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1146,
    "text": "Homework Problems and Questions\nChapter 8 Review Questions\nSECTION 8.1\nR1. Operational devices such as firewalls and intrusion detection systems\nare used to counter attacks against an organization’s network. What is\nthe basic difference between a firewall and an intrusion detection\nsystem? R2. Internet entities (routers, switches, DNS servers, Web servers, user\nend systems, and so on) often need to communicate securely. Give\nthree specific example pairs of Internet entities that may want secure\ncommunication. SECTION 8.2\nR3. The encryption technique itself is known—published, standardized,\nand available to everyone, even a potential intruder. Then where does\nthe security of an encryption technique come from? R4. What is the difference between known plaintext attack and chosen\nplaintext attack? R5. Consider a 16-block cipher. How many possible input blocks does\nthis cipher have? How many possible mappings are there? If we view\neach mapping as a key, then how many possible keys does this cipher\nhave? R6. Suppose N people want to communicate with each of N − 1 other\npeople using symmetric key encryption. All communication between\nany two people, i and j, is visible to all other people in this group of"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1147,
    "text": "N, and no other person in this group should be able to decode their\ncommunication. How many keys are required in the system as a\nwhole? Now suppose that public key encryption is used. How many\nkeys are required in this case? R7. Suppose n = 1,000, a = 1,017, and b = 1,006. Use an identity of\nmodular arithmetic to calculate in your head (a · b) mod n.\nR8. Suppose you want to encrypt the message 10010111 by encrypting\nthe decimal number that corresponds to the message. What is the\ndecimal number? SECTIONS 8.3-8.4\nR9. In what way does a hash provide a better message integrity check\nthan a checksum (such as the Internet checksum)? R10. Can you “decrypt” a hash of a message to get the original message? Explain your answer. R11. Consider a variation of the MAC algorithm (Figure 8.9) where the\nsender sends (m, H(m) + s), where H(m) + s is the concatenation of\nH(m) and s. Is this variation flawed? Why or why not? R12. What does it mean for a signed document to be verifiable and\nnonforgeable? R13. In the link-state routing algorithm, we would somehow need to\ndistribute the secret authentication key to each of the routers in the\nautonomous system. How do we distribute the shared authentication\nkey to the communicating entities? R14. Name two popular secure networking protocols in which public key\ncertification is used. R15. Suppose Alice has a message that she is ready to send to anyone who\nasks. Thousands of people want to obtain Alice’s message, but each\nwants to be sure of the integrity of the message. In this context, do"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1148,
    "text": "you think a MAC-based or a digital-signature-based integrity scheme\nis more suitable? Why? R16. What is the purpose of a nonce in an end-point authentication\nprotocol? R17. What does it mean to say that a nonce is a once-in-a-lifetime value? In whose lifetime? R18. Is the message integrity scheme based on HMAC susceptible to\nplayback attacks? If so, how can a nonce be incorporated into the\nscheme to remove this susceptibility? SECTIONS 8.5-8.8\nR19. What is the de facto e-mail encryption scheme? What does it use for\nauthentication and message integrity? R20. In the TLS record, there is a field for TLS sequence numbers. True or\nfalse? R21. What is the purpose of the random nonces in the TLS handshake? R22. Suppose an TLS session employs a block cipher with CBC. True or\nfalse: The server sends to the client the IV in the clear. R23. Suppose Bob initiates a TCP connection to Trudy who is pretending\nto be Alice. During the handshake, Trudy sends Bob Alice’s\ncertificate. In what step of the TLS handshake algorithm will Bob\ndiscover that he is not communicating with Alice? R24. Consider sending a stream of packets from Host A to Host B using\nIPsec. Typically, a new SA will be established for each packet sent in\nthe stream. True or false? R25. Suppose that TCP is being run over IPsec between headquarters and\nthe branch office in Figure 8.28. If TCP retransmits the same packet,\nthen the two corresponding packets sent by R1 packets will have the\nsame sequence number in the ESP header. True or false?"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1149,
    "text": "R26. Is there a fixed encryption algorithm in SSL? R27. Consider WEP for 802.11. Suppose that the data is 10001101 and the\nkeystream is 01101010. What is the resulting ciphertext? SECTION 8.9\nR28. Stateful packet filters maintain two data structures. Name them and\nbriefly describe what they do. R29. Consider a traditional (stateless) packet filter. This packet filter may\nfilter packets based on TCP flag bits as well as other header fields. True or false? R30. In a traditional packet filter, each interface can have its own access\ncontrol list. True or false? R31. Why must an application gateway work in conjunction with a router\nfilter to be effective? R32. Signature-based IDSs and IPSs inspect into the payloads of TCP and\nUDP segments. True or false? Problems\nP1. Using the monoalphabetic cipher in Figure 8.3, encode the message\n“This is a secret message.”\nP2. Show that Trudy’s known-plaintext attack, in which she knows the\n(ciphertext, plaintext) translation pairs for seven letters, reduces the\nnumber of possible substitutions to be checked in the example in\nSection 8.2.1 by approximately 10 . P3. Consider the polyalphabetic system shown in Figure 8.4. Will a\nchosen-plaintext attack that is able to get the plaintext encoding of the\nmessage “The quick brown fox jumps over the lazy dog.” be\nsufficient to decode all messages? Why or why not?"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1150,
    "text": "P4. Consider the block cipher in Figure 8.5. Suppose that each block\ncipher T  simply reverses the order of the eight input bits (so that, for\nexample, 11110000 becomes 00001111). Further suppose that the 64-\nbit scrambler does not modify any bits (so that the output value of the\nmth bit is equal to the input value of the mth bit). (a) With n = 3 and\nthe original 64-bit input equal to 10100000 repeated eight times, what\nis the value of the output? (b) Repeat part (a) but now change the last\nbit of the original 64-bit input from a 0 to a 1. (c) Repeat parts (a) and\n(b) but now suppose that the 64-bit scrambler inverses the order of the\n64 bits. P5. Encode the plaintext 000001011111 with the 3-bit block cipher in\nTable 8.1 and IV = c(0) = 001. Then show that the receiver can\ndecode the ciphertext, ­knowing IV and K . P6. The ciphertext for the 3-bit block cipher in Table 8.1 with plaintext\n010010010 and IV = c(0) = 001 becomes:\nc(1) = K (m(1) ⊕ c(0)) = K (010 ⊕ 001) = K (011) = 100,\nc(2) = K (m(2) ⊕ c(1)) = K (010 ⊕ 100) = K (110) = 000, and\nc(3) = K (m(3) ⊕ c(2)) = K (010 ⊕ 000) = K (010) = 101. P7. a. Using RSA, choose p = 5 and q = 7, and encode the numbers 12,\n19, and 27 separately. Apply the decryption algorithm to the\nencrypted version to recover the original plaintext message. b. Choose p and q of your own and encrypt 1834 as one message\nm.\nP8. Consider RSA with p = 7 and q = 13.\na. What are n and z? b. Let e be 17. Why is this an acceptable choice for e? c. Find d such that de = 1 (mod z). i\nS\nS\nS\nS\nS\nS\nS\nS\nS\nS"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1151,
    "text": "d. Encrypt the message m = 9 using the key (n, e). Let c denote the\ncorresponding ciphertext. Show all work. P9. In this problem, we explore the Diffie-Hellman (DH) public-key\nencryption algorithm, which allows two entities to agree on a shared\nkey. The DH algorithm makes use of a large prime number p and\nanother large number g less than p. Both p and g are made public (so\nthat an attacker would know them). In DH, Alice and Bob each\nindependently choose secret keys, S  and S , respectively. Alice then\ncomputes her public key, T , by raising g to S  and then taking mod p.\nBob similarly computes his own public key T  by raising g to S  and\nthen taking mod p. Alice and Bob then exchange their public keys\nover the Internet. Alice then calculates the shared secret key S by\nraising T  to S  and then taking mod p. Similarly, Bob calculates the\nshared key S' by raising T  to S  and then taking mod p.\na. Prove that, in general, Alice and Bob obtain the same symmetric\nkey, that is, prove S = S'. b. With p = 11 and g = 2, suppose Alice and Bob choose private\nkeys S  = 5 and S  = 12, respectively. Calculate Alice’s and\nBob’s public keys, T  and T . Show all work. c. Following up on part (b), now calculate S as the shared\nsymmetric key. Show all work. d. Provide a timing diagram that shows how Diffie-Hellman can be\nattacked by a man-in-the-middle. The timing diagram should\nhave three vertical lines, one for Alice, one for Bob, and one for\nthe attacker Trudy. P10. Suppose Alice wants to communicate with Bob using symmetric key\ncryptography using a session key K . In Section 8.2, we learned how\npublic-key cryptography can be used to distribute the session key\nA\nB\nA\nA\nB\nB\nB\nA\nA\nB\nA\nB\nA\nB\nS"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1152,
    "text": "from Alice to Bob. In this problem, we explore how the session key\ncan be distributed—without public key cryptography—using a key\ndistribution center (KDC). The KDC is a server that shares a unique\nsecret symmetric key with each registered user. For Alice and Bob,\ndenote these keys by K\n and K\n. Design a scheme that uses the\nKDC to distribute K  to Alice and Bob. Your scheme should use three\nmessages to distribute the session key: a message from Alice to the\nKDC; a message from the KDC to Alice; and finally a message from\nAlice to Bob. The first message is K\n (A, B). Using the notation,\nK\n, K\n, S, A, and B answer the following questions. a. What is the second message? b. What is the third message? P11. Compute a third message, different from the two messages in Figure\n8.8, that has the same checksum as the messages in Figure 8.8. P12. The sender can mix some randomness into the ciphertext so that\nidentical plaintext blocks produce different ciphertext blocks. But for\neach cipher bit, the sender must now also send a random bit, doubling\nthe required ­bandwidth. Is there any way around this? P13. In the BitTorrent P2P file distribution protocol (see Chapter 2), the\nseed breaks the file into blocks, and the peers redistribute the blocks\nto each other. Without any protection, an attacker can easily wreak\nhavoc in a torrent by masquerading as a benevolent peer and sending\nbogus blocks to a small subset of peers in the torrent. These\nunsuspecting peers then redistribute the bogus blocks to other peers,\nwhich in turn redistribute the bogus blocks to even more peers. Thus,\nit is critical for BitTorrent to have a mechanism that allows a peer to\nverify the integrity of a block, so that it doesn’t redistribute bogus\nblocks. Assume that when a peer joins a torrent, it initially gets a\nA-KDC\nB-KDC\nS\nA-KDC\nA-KDC\nB-KDC"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1153,
    "text": ".torrent file from a fully trusted source. Describe a simple scheme\nthat allows peers to verify the integrity of blocks. P14. Solving factorization in polynomial time implies breaking the RSA ­-\ncryptosystem. Is the converse true? P15. Consider our authentication protocol in Figure 8.18 in which Alice\nauthenticates herself to Bob, which we saw works well (i.e., we found\nno flaws in it). Now suppose that while Alice is authenticating herself\nto Bob, Bob must authenticate himself to Alice. Give a scenario by\nwhich Trudy, pretending to be Alice, can now authenticate herself to\nBob as Alice. (Hint: Consider that the sequence of operations of the\nprotocol, one with Trudy initiating and one with Bob initiating, can be\narbitrarily interleaved. Pay particular attention to the fact that both\nBob and Alice will use a nonce, and that if care is not taken, the same\nnonce can be used maliciously.) P16. A natural question is whether we can use a nonce and public key\ncryptography to solve the end-point authentication problem in Section\n8.4. Consider the following natural protocol: (1) Alice sends the\nmessage “I am Alice” to Bob. (2) Bob chooses a nonce, R, and\nsends it to Alice. (3) Alice uses her private key to encrypt the nonce\nand sends the resulting value to Bob. (4) Bob applies Alice’s public\nkey to the received message. Thus, Bob computes R and authenticates\nAlice. a. Diagram this protocol, using the notation for public and private\nkeys employed in the textbook. b. Suppose that certificates are not used. Describe how Trudy can\nbecome a “woman-in-the-middle” by intercepting Alice’s\nmessages and then ­pretending to be Alice to Bob."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1154,
    "text": "P17. Figure 8.21 shows the operations that Alice must perform with PGP to\nprovide confidentiality, authentication, and integrity. Diagram the\ncorresponding operations that Bob must perform on the package\nreceived from Alice. P18. Suppose Alice wants to send an e-mail to Bob. Bob has a public-\nprivate key pair (K +\nB , K −\nB ), and Alice has Bob’s certificate. But Alice\ndoes not have a public, private key pair. Alice and Bob (and the entire\nworld) share the same hash function H(·). a. In this situation, is it possible to design a scheme so that Bob can\nverify that Alice created the message? If so, show how with a\nblock diagram for Alice and Bob. b. Is it possible to design a scheme that provides confidentiality for\nsending the message from Alice to Bob? If so, show how with a\nblock diagram for Alice and Bob. P19. Consider the Wireshark output below for a portion of an SSL session. a. Is Wireshark packet 112 sent by the client or server? b. What is the server’s IP address and port number? c. Assuming no loss and no retransmissions, what will be the\nsequence number of the next TCP segment sent by the client? d. How many SSL records does Wireshark packet 112 contain? e. Does packet 112 contain a Master Secret or an Encrypted Master\nSecret or neither? f. Assuming that the handshake type field is 1 byte and each length\nfield is 3 bytes, what are the values of the first and last bytes of\nthe Master Secret (or Encrypted Master Secret)? g. The client encrypted handshake message takes into account how\nmany SSL records?"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1155,
    "text": "h. The server encrypted handshake message takes into account how\nmany SSL records? P20. In Section 8.6.1, it is shown that without sequence numbers, Trudy (a\nwoman-in-the middle) can wreak havoc in a TLS session by\ninterchanging TCP segments. Can Trudy do something similar by\ndeleting a TCP segment? What does she need to do to succeed at the\ndeletion attack? What effect will it have? (Wireshark screenshot reprinted by permission of the\nWireshark Foundation.) P21. A router’s link-state message includes a list of its directly connected\nneighbors and the direct costs to these neighbors. Once a router\nreceives link-state messages from all of the other routers, it can create"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1156,
    "text": "a complete map of the network, run its least-cost routing algorithm,\nand configure its forwarding table. One relatively easy attack on the\nrouting algorithm is for the attacker to distribute bogus linkstate\nmessages with incorrect link-state information. How can this be\nprevented? P22. The following true/false questions pertain to Figure 8.28.\na. When a host in 172.16.1/24 sends a datagram to an Amazon.com\nserver, the router R1 will encrypt the datagram using IPsec. b. When a host in 172.16.1/24 sends a datagram to a host in\n172.16.2/24, the router R1 will change the source and destination\naddress of the IP datagram. c. Suppose a host in 172.16.1/24 initiates a TCP connection to a\nWeb server in 172.16.2/24. As part of this connection, all\ndatagrams sent by R1 will have protocol number 50 in the left-\nmost IPv4 header field. d. Consider sending a TCP segment from a host in 172.16.1/24 to a\nhost in 172.16.2/24. Suppose the acknowledgment for this\nsegment gets lost, so that TCP resends the segment. Because\nIPsec uses sequence numbers, R1 will not resend the TCP\nsegment. P23. When Bob signs a message, Bob must put something on the message\nthat is unique to him. Bob could consider attaching a MAC for the\nsignature, where the MAC is created by appending his key (unique to\nhim) to the message, and then taking the hash. Will it cause any\nproblem when Alice would try verification? P24. Provide a filter table and a connection table for a stateful firewall that\nis as restrictive as possible but accomplishes the following:"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 222",
    "source": "kurose",
    "page": 1157,
    "text": "a. Allows all internal users to establish Telnet sessions with\nexternal hosts. b. Allows external users to surf the company Web site at\n222.22.0.12.\nc. But otherwise blocks all inbound and outbound traffic. The internal network is 222.22/16. In your solution, suppose\nthat the connection table is currently caching three connections,\nall from inside to outside. You’ll need to invent appropriate IP\naddresses and port numbers. P25. Suppose Alice wants to visit the Web site activist.com using a TOR-\nlike ­service. This service uses two non-colluding proxy servers,\nProxy1 and Proxy2. Alice first obtains the certificates (each\ncontaining a public key) for Proxy1 and Proxy2 from some central\nserver. Denote K +\n1 ( ), K +\n2 ( ), K −\n1 ( ), and K−\n2 ( ) for the\nencryption/decryption with public and private RSA keys. a. Using a timing diagram, provide a protocol (as simple as\npossible) that enables Alice to establish a shared session key S\nwith Proxy1. Denote S (m) for encryption/decryption of data m\nwith the shared key S . b. Using a timing diagram, provide a protocol (as simple as\npossible) that allows Alice to establish a shared session key S\nwith Proxy2 without revealing her IP address to Proxy2. c. Assume now that shared keys S  and S  are now established. Using a timing diagram, provide a protocol (as simple as\npossible and not using public-key cryptography) that allows\nAlice to request an html page from activist.com without\nrevealing her IP address to Proxy2 and without revealing to\n1\n2\n2"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 222",
    "source": "kurose",
    "page": 1158,
    "text": "Proxy1 which site she is visiting. Your diagram should end with\nan HTTP request arriving at activist.com."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1159,
    "text": "Wireshark Lab: SSL\nIn this lab (available from the book Web site), we investigate the Secure\nSockets Layer (SSL) protocol. Recall from Section 8.6 that SSL is used for\nsecuring a TCP connection, and that it is extensively used in practice for\nsecure Internet transactions. In this lab, we will focus on the SSL records\nsent over the TCP connection. We will attempt to delineate and classify\neach of the records, with a goal of understanding the why and how for each\nrecord. We investigate the various SSL record types as well as the fields in\nthe SSL messages. We do so by analyzing a trace of the SSL records sent\nbetween your host and an e-commerce server."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1160,
    "text": "IPsec Lab\nIn this lab (available from the book Web site), we will explore how to create\nIPsec SAs between linux boxes. You can do the first part of the lab with two\nordinary linux boxes, each with one Ethernet adapter. But for the second\npart of the lab, you will need four linux boxes, two of which having two\nEthernet adapters. In the second half of the lab, you will create IPsec SAs\nusing the ESP protocol in the tunnel mode. You will do this by first\nmanually creating the SAs, and then by having IKE create the SAs."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1161,
    "text": "AN INTERVIEW WITH…\nSteven M. Bellovin\nCourtesy of Steven Bellovin\nSteven M. Bellovin joined the faculty at Columbia University\nafter many years at the Network Services Research Lab at\nAT&T Labs Research in Florham Park, New Jersey. His focus\nis on networks, security, and why the two are incompatible. In\n1995, he was awarded the Usenix Lifetime Achievement\nAward for his work in the creation of Usenet, the first\nnewsgroup exchange network that linked two or more\ncomputers and allowed users to share information and join in\ndiscussions. Steve is also an elected member of the National\nAcademy of Engineering. He received his BA from Columbia"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1162,
    "text": "University and his PhD from the University of North Carolina\nat Chapel Hill. What led you to specialize in the\nnetworking security area? This is going to sound odd, but the answer is\nsimple: It was fun. My background was in ­systems\nprogramming and systems administration, which\nleads fairly naturally to security. And I’ve always\nbeen interested in communications, ranging back\nto part-time systems ­programming jobs when I was\nin college. My work on security continues to be\nmotivated by two things—a desire to keep\ncomputers useful, which means that their function\ncan’t be corrupted by attackers, and a desire to\nprotect privacy. What was your vision for Usenet at the\ntime that you were developing it? And\nnow? We originally viewed it as a way to talk about\ncomputer science and computer programming\naround the country, with a lot of local use for\nadministrative matters, for-sale ads, and so on. In\nfact, my original prediction was one to two\nmessages per day, from 50 to 100 sites at the most"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1163,
    "text": "—ever. However, the real growth was in people-\nrelated topics, including—but not limited to—\nhuman interactions with computers. My favorite\nnewsgroups, over the years, have been things like\nrec.woodworking, as well as sci.crypt. To some extent, netnews has been displaced by\nthe Web. Were I to start designing it today, it would\nlook very different. But it still excels as a way to\nreach a very broad audience that is interested in the\ntopic, without having to rely on particular Web\nsites. Has anyone inspired you professionally? In what ways? Professor Fred Brooks—the founder and original\nchair of the computer science department at the\nUniversity of North Carolina at Chapel Hill, the\nmanager of the team that developed the IBM S/360\nand OS/360, and the author of The Mythical Man-\nMonth—was a tremendous influence on my career. More than anything else, he taught outlook and\ntrade-offs—how to look at problems in the context\nof the real world (and how much messier the real\nworld is than a theorist would like), and how to\nbalance competing interests in designing a\nsolution. Most computer work is engineering—the\nart of making the right trade-offs to satisfy many\ncontradictory objectives."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1164,
    "text": "What is your vision for the future of\nnetworking and security? Thus far, much of the security we have has come\nfrom isolation. A firewall, for example, works by\ncutting off access to certain machines and services. But we’re in an era of increasing connectivity—it’s\ngotten harder to isolate things. Worse yet, our\nproduction systems require far more separate\npieces, interconnected by networks. Securing all\nthat is one of our biggest challenges. What would you say have been the\ngreatest advances in security? How much\nfurther do we have to go? At least scientifically, we know how to do\ncryptography. That’s been a big help. But most\nsecurity problems are due to buggy code, and that’s\na much harder problem. In fact, it’s the oldest\nunsolved problem in computer science, and I think\nit will remain that way. The challenge is figuring\nout how to secure systems when we have to build\nthem out of insecure components. We can already\ndo that for reliability in the face of hardware\nfailures; can we do the same for security? Do you have any advice for students\nabout the Internet and networking"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 8",
    "source": "kurose",
    "page": 1165,
    "text": "security? Learning the mechanisms is the easy part. Learning how to “think paranoid” is harder. You\nhave to remember that probability distributions\ndon’t apply—the attackers can and will find\nimprobable conditions. And the details matter—a\nlot."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 36",
    "source": "kurose",
    "page": 1167,
    "text": "[3GPP PDCP 2019] 3GPP, “Packet Data Convergence Protocol (PDCP)\nSpecification,” 3GPP Technical Specification 36.323 version 15.4.0, 2019. [3GPP RLCP 2018] 3GPP, “Radio Link Control (RLC) protocol\nspecification,” 3GPP Technical Specification 25.322 version 15.0.0, 2018. [3GPP SAE 2019] 3GPP, “System Architecture Evolution (SAE); Security\narchitecture,” Technical Specification 33.401, version 15.9.0, October\n2019.”\n[Abramson 1970] N. Abramson, “The Aloha System—Another Alternative\nfor Computer Communications,” Proc. 1970 Fall Joint Computer\nConference, AFIPS Conference, p. 37, 1970. [Abramson 1985] N. Abramson, “Development of the Alohanet,” IEEE\nTransactions on Information Theory, Vol. IT-31, No. 3 (Mar. 1985), pp. 119–123. [Abramson 2009] N. Abramson, “The Alohanet—Surfing for Wireless\nData,” IEEE Communications Magazine, Vol. 47, No. 12, pp. 21–25. [Adhikari 2011a] V. K. Adhikari, S. Jain, Y. Chen, Z. L. Zhang,\n“Vivisecting YouTube: An Active Measurement Study,” Technical Report,\nUniversity of Minnesota, 2011. [Adhikari 2012] V. K. Adhikari, Y. Gao, F. Hao, M. Varvello, V. Hilt, M.\nSteiner, Z. L. Zhang, “Unreeling Netflix: Understanding and Improving\nMulti-CDN Movie Delivery,” Technical Report, University of Minnesota,\n2012. [Afanasyev 2010] A. Afanasyev, N. Tilley, P. Reiher, L. Kleinrock, “Host-\nto-Host Congestion Control for TCP,” IEEE Communications Surveys &\nTutorials, Vol. 12, No. 3, pp. 304–342. [Agarwal 2009] S. Agarwal, J. Lorch, “Matchmaking for Online Games\nand Other Latency-sensitive P2P Systems,” Proc. 2009 ACM SIGCOMM."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 36",
    "source": "kurose",
    "page": 1168,
    "text": "[Ager 2012] B. Ager, N. Chatzis, A. Feldmann, N. Sarrar, S. Uhlig, W.\nWillinger, “Anatomy of a Large European ISP,” Proc. 2012 ACM\nSIGCOMM. [Akamai 2020] Akamai homepage, http://www.akamai.com\n[Akella 2003] A. Akella, S. Seshan, A. Shaikh, “An Empirical Evaluation\nof Wide-Area Internet Bottlenecks,” Proc. 2003 ACM Internet\nMeasurement Conference (Miami, FL, Nov. 2003). [Akhshabi 2011] S. Akhshabi, A. C. Begen, C. Dovrolis, “An Experimental\nEvaluation of Rate-Adaptation Algorithms in Adaptive Streaming over\nHTTP,” Proc. 2011 ACM Multimedia Systems Conf. [Akhshabi 2011] S. Akhshabi, C. Dovrolis, “The evolution of layered\nprotocol stacks leads to an hourglass-shaped architecture,” Proceedings\n2011 ACM SIGCOMM, pp. 206–217. [Akyildiz 2010] I. Akyildiz, D. Gutierrex-Estevez, E. Reyes, “The\nEvolution to 4G Cellular Systems, LTE Advanced,” Physical\nCommunication, Elsevier, 3 (2010), pp. 217–244. [Albitz 1993] P. Albitz and C. Liu, DNS and BIND, O’Reilly & Associates,\nPetaluma, CA, 1993. [Alexandris 2016] K. Alexandris, N. Nikaein, R. Knopp and C. Bonnet,\n“Analyzing X2 handover in LTE/LTE-A,” 2016 14th International\nSymposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless\nNetworks (WiOpt), Tempe, AZ, pp. 1–7. [Alizadeh 2010] M. Alizadeh, A. Greenberg, D. Maltz, J. Padhye, P. Patel,\nB. Prabhakar, S. Sengupta, M. Sridharan. “Data center TCP (DCTCP),”\nProc. 2010 ACM SIGCOMM Conference, ACM, New York, NY, USA, pp. 63–74."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 36",
    "source": "kurose",
    "page": 1169,
    "text": "[Alizadeh 2013] M. Alizadeh, S. Yang, M. Sharif, S. Katti, N. McKeown,\nB. Prabhakar, S. Shenker, “pFabric: Minimal Near-Optimal Datacenter\nTransport,” Proc. 2013 ACM SIGCOMM Conference. [Alizadeh 2014] M. Alizadeh, T. Edsall, S. Dharmapurikar, K. Chu, A.\nFingerhut, V. T. Lam, F. Matus, R. Pan, N. Yadav, G. Varghese , “CONGA:\nDistributed Congestion-Aware Load Balancing for Datacenters,” Proc. 2014 ACM SIGCOMM Conference. [Allman 2011] E. Allman, “The Robustness Principle Reconsidered:\nSeeking a Middle Ground,” Communications of the ACM, Vol. 54, No. 8\n(Aug. 2011), pp. 40–45. [Almers 2007] P. Almers, et al., “Survey of Channel and Radio Propagation\nModels for Wireless MIMO Systems,” Journal on Wireless\nCommunications and Networking, 2007. [Amazon 2014] J. Hamilton, “AWS: Innovation at Scale, YouTube video,\nhttps://www.youtube.com/watch?v=JIQETrFC_SQ\n[Anderson 1995] J. B. Andersen, T. S. Rappaport, S. Yoshida, “Propagation\nMeasurements and Models for Wireless Communications Channels,” IEEE\nCommunications Magazine, (Jan. 1995), pp. 42–49. [Appenzeller 2004] G. Appenzeller, I. Keslassy, N. McKeown, “Sizing\nRouter Buffers,” Proc. 2004 ACM SIGCOMM Conference (Portland, OR,\nAug. 2004). [Arkko 2012] J. Arkko, “Analysing IP Mobility Protocol Deployment\nDifficulties,” 83rd IETF meeting, March, 2012. [ASO-ICANN 2020] The Address Supporting Organization homepage,\nhttp://www.aso.icann.org\n[AT&T 2019] A, Fuetsch, “From Next-Gen to Now: SDN, White Box and\nOpen Source Go Mainstream,”"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1170,
    "text": "https://about.att.com/innovationblog/2019/09/sdn_white_box_and_open_so\nurce_go_mainstream.html\n[Atheros 2020] Atheros Communications Inc., “Atheros AR5006 WLAN\nChipset Product Bulletins,”\nhttp://www.atheros.com/pt/AR5006Bulletins.htm\n[Ayanoglu 1995] E. Ayanoglu, S. Paul, T. F. La Porta, K. K. Sabnani, R. D.\nGitlin, “AIRMAIL: A Link-Layer Protocol for Wireless Networks,” ACM\nACM/Baltzer Wireless Networks Journal, 1: 47–60, Feb. 1995. [Bakre 1995] A. Bakre, B. R. Badrinath, “I-TCP: Indirect TCP for Mobile\nHosts,” Proc. 1995 Int. Conf. on Distributed Computing Systems (ICDCS)\n(May 1995), pp. 136–143. [Baldauf 2007] M. Baldauf, S. Dustdar, F. Rosenberg, “A Survey on\nContext-Aware Systems,” Int. J. Ad Hoc and Ubiquitous Computing, Vol. 2,\nNo. 4 (2007), pp. 263–277. [Baran 1964] P. Baran, “On Distributed Communication Networks,” IEEE\nTransactions on Communication Systems, Mar. 1964. Rand Corporation\nTechnical report with the same title (Memorandum RM-3420-PR, 1964). http://www.rand.org/publications/RM/RM3420/\n[Bardwell 2004] J. Bardwell, “You Believe You Understand What You\nThink I Said . . . The Truth About 802.11 Signal and Noise Metrics: A\nDiscussion Clarifying Often-Misused 802.11 WLAN Terminologies,”\nhttp://www.connect802.com/download/techpubs/2004/you_believe_D1002\n01.pdf\n[Barford 2009] P. Barford, N. Duffield, A. Ron, J. Sommers, “Network\nPerformance Anomaly Detection and Localization,” Proc. 2009 IEEE\nINFOCOM (Apr. 2009)."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1171,
    "text": "[Beck 2019] M. Beck, “On the hourglass model,” Commun. ACM, Vol. 62,\nNo. 7 (June 2019), pp. 48–57. [Beheshti 2008] N. Beheshti, Y. Ganjali, M. Ghobadi, N. McKeown, G.\nSalmon, “Experimental Study of Router Buffer Sizing,” Proc. ACM Internet\nMeasurement Conference (Oct. 2008, Vouliagmeni, Greece). [Bender 2000] P. Bender, P. Black, M. Grob, R. Padovani, N.\nSindhushayana, A. Viterbi, “CDMA/HDR: A Bandwidth-Efficient High-\nSpeed Wireless Data Service for Nomadic Users,” IEEE Commun. Mag.,\nVol. 38, No. 7 (July 2000), pp. 70–77. [Berners-Lee 1989] T. Berners-Lee, CERN, “Information Management: A\nProposal,” Mar. 1989, May 1990.\nhttp://www.w3.org/History/1989/proposal.html\n[Berners-Lee 1994] T. Berners-Lee, R. Cailliau, A. Luotonen, H. Frystyk\nNielsen, A. Secret, “The World-Wide Web,” Communications of the ACM,\nVol. 37, No. 8 (Aug. 1994), pp. 76–82. [Bertsekas 1991] D. Bertsekas, R. Gallagher, Data Networks, 2nd Ed.,\nPrentice Hall, Englewood Cliffs, NJ, 1991. [Biersack 1992] E. W. Biersack, “Performance Evaluation of Forward\nError Correction in ATM Networks,” Proc. 1999 ACM SIGCOMM\nConference (Baltimore, MD, Aug. 1992), pp. 248–257. [BIND 2020] Internet Software Consortium page on BIND,\nhttp://www.isc.org/bind.html\n[Bisdikian 2001] C. Bisdikian, “An Overview of the Bluetooth Wireless\nTechnology,” IEEE Communications Magazine, No. 12 (Dec. 2001), pp. 86–94. [Bishop 2003] M. Bishop, Computer Security: Art and Science, Boston:\nAddison Wesley, Boston MA, 2003."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1172,
    "text": "[Bishop 2004] M. Bishop, Introduction to Computer Security, Addison-\nWesley, 2004. [Björnson 2017] E. Björnson, J. Hoydis, L. Sanguinetti, Massive MIMO\nNetworks: Spectral, Energy, and Hardware Efficiency, Now Publishers,\n2017. [Black 1995] U. Black, ATM Volume I: Foundation for Broadband\nNetworks, Prentice Hall, 1995. [Bluetooth 2020] The Bluetooth Special Interest Group,\nhttp://www.bluetooth.com/\n[Blumenthal 2001] M. Blumenthal, D. Clark, “Rethinking the Design of\nthe Internet: The End-to-end Arguments vs. the Brave New World,” ACM\nTransactions on Internet Technology, Vol. 1, No. 1 (Aug. 2001), pp. 70–\n109. [Bochman 1984] G. V. Bochmann, C. A. Sunshine, “Formal Methods in\nCommunication Protocol Design,” IEEE Transactions on Communications,\nVol. 28, No. 4 (Apr. 1980) pp. 624–631. [Bosshart 2013] P. Bosshart, G. Gibb, H. Kim, G. Varghese, N. McKeown,\nM. Izzard, F. Mujica, M. Horowitz, “Forwarding Metamorphosis: Fast\nProgrammable Match-Action Processing in Hardware for SDN,” Proc. 2013 SIGCOMM Conference, pp. 99–110. [Bosshart 2014] P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown, J.\nRexford, C. Schlesinger, D. Talayco, A. Vahdat, G. Varghese, D. Walker,\n“P4: Programming Protocol-Independent Packet Processors,” Proc. 2014\nACM SIGCOMM Conference, pp. 87–95. [Bottger 2018] T. Böttger, F. Cuadrado, G. Tyson, I. Castro, S. Uhlig, Open\nconnect everywhere: A glimpse at the internet ecosystem through the lens of\nthe Netflix CDN, Proc. 2018 ACM SIGCOMM Conference."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1173,
    "text": "[Brakmo 1995] L. Brakmo, L. Peterson, “TCP Vegas: End to End\nCongestion Avoidance on a Global Internet,” IEEE Journal of Selected\nAreas in Communications, Vol. 13, No. 8 (Oct. 1995), pp. 1465–1480. [Bryant 1988] B. Bryant, “Designing an Authentication System: A\nDialogue in Four Scenes,” http://web.mit.edu/kerberos/www/dialogue.html\n[Bush 1945] V. Bush, “As We May Think,” The Atlantic Monthly, July\n1945. http://www.theatlantic.com/unbound/flashbks/computer/bushf.htm\n[Byers 1998] J. Byers, M. Luby, M. Mitzenmacher, A. Rege, “A Digital\nFountain Approach to Reliable Distribution of Bulk Data,” Proc. 1998 ACM\nSIGCOMM Conference (Vancouver, Canada, Aug. 1998), pp. 56–67. [Cable Labs 2019] Cable Labs, “A Comparative Introduction to 4G and 5G\nAuthentication,” https://www.cablelabs.com/insights/a-comparative-\nintroduction-to-4g-and-5g-authentication\n[Caesar 2005b] M. Caesar, D. Caldwell, N. Feamster, J. Rexford, A.\nShaikh, J. van der Merwe, “Design and implementation of a Routing\nControl Platform,” Proc. Networked Systems Design and Implementation\n(May 2005). [Caesar 2005b] M. Caesar, J. Rexford, “BGP Routing Policies in ISP\nNetworks,” IEEE Network Magazine, Vol. 19, No. 6 (Nov. 2005). [CAIDA 2020] Center for Applied Internet Data Analysis, www.caida.org\n[Caldwell 2020] C. Caldwell, “The Prime Pages,”\nhttp://www.utm.edu/research/primes/prove\n[Cardwell 2017] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, V.\nJacobson. “BBR: congestion-based congestion control,” Commun. ACM,\nVol. 60, No. 2 (Jan. 2017), pp. 58–66. [Casado 2007] M. Casado, M. Freedman, J. Pettit, J. Luo, N. McKeown, S.\nShenker, “Ethane: Taking Control of the Enterprise,” Proc. 2007 ACM"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 96",
    "source": "kurose",
    "page": 1174,
    "text": "SIGCOMM Conference, New York, pp. 1–12. See also IEEE/ACM Trans. Networking, Vol. 17, No. 4 (Aug. 2007), pp. 270–1283. [Casado 2009] M. Casado, M. Freedman, J. Pettit, J. Luo, N. Gude, N.\nMcKeown, S. Shenker, “Rethinking Enterprise Network Control,”\nIEEE/ACM Transactions on Networking (ToN), Vol. 17, No. 4 (Aug. 2009),\npp. 1270–1283. [Casado 2014] M. Casado, N. Foster, A. Guha, “Abstractions for Software-\nDefined Networks,” Communications of the ACM, Vol. 57, No. 10, (Oct.\n2014), pp. 86–95. [Cerf 1974] V. Cerf, R. Kahn, “A Protocol for Packet Network\nInterconnection,” IEEE Transactions on Communications Technology, Vol. COM-22, No. 5, pp. 627–641. [CERT 2001–09] CERT, “Advisory 2001–09: Statistical Weaknesses in\nTCP/IP Initial Sequence Numbers,” http://www.cert.org/advisories/CA-\n2001-09.html\n[CERT 2003–04] CERT, “CERT Advisory CA-2003-04 MS-SQL Server\nWorm,” http://www.cert.org/advisories/CA-2003-04.html\n[CERT 2020] The CERT division of the Software Engineering Institute,\nhttps://www.sei.cmu.edu/about/divisions/cert, 2020\n[CERT Filtering 2012] CERT, “Packet Filtering for Firewall Systems,”\nhttp://www.cert.org/tech_tips/packet_filtering.html\n[Cert SYN 1996] CERT, “Advisory CA-96.21: TCP SYN Flooding and IP\nSpoofing Attacks,” http://www.cert.org/advisories/CA-1998-01.html\n[Chandra 2007] T. Chandra, R. Greisemer, J. Redstone, “Paxos Made Live:\nan Engineering Perspective,” Proc. of 2007 ACM Symposium on Principles\nof Distributed Computing (PODC), pp. 398–407."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 96",
    "source": "kurose",
    "page": 1175,
    "text": "[Chao 2011] C. Zhang, P. Dunghel, D. Wu, K. W. Ross, “Unraveling the\nBitTorrent Ecosystem,” IEEE Transactions on Parallel and Distributed\nSystems, Vol. 22, No. 7 (July 2011). [Chen 2011] Y. Chen, S. Jain, V. K. Adhikari, Z. Zhang, “Characterizing\nRoles of Front-End Servers in End-to-End Performance of Dynamic\nContent Distribution,” Proc. 2011 ACM Internet Measurement Conference\n(Berlin, Germany, Nov. 2011). [Chiu 1989] D. Chiu, R. Jain, “Analysis of the Increase and Decrease\nAlgorithms for Congestion Avoidance in Computer Networks,” Computer\nNetworks and ISDN Systems, Vol. 17, No. 1, pp. 1–14. http://www.cs.wustl.edu/~jain/papers/cong_av.htm\n[Christiansen 2001] M. Christiansen, K. Jeffay, D. Ott, F. D. Smith,\n“Tuning Red for Web Traffic,” IEEE/ACM Transactions on Networking,\nVol. 9, No. 3 (June 2001), pp. 249–264. [Cichonski 2017] J. Cichonski, J. Franklin, M. Bartock, Guide to LTE\nSecurity, NIST Special Publication 800–187, Dec. 2017. [Cisco 2012] Cisco 2012, Data Centers, http://www.cisco.com/go/dce\n[Cisco 2020] Cisco Visual Networking Index: Forecast and Trends, 2017–\n2022 White Paper. [Cisco 6500 2020] Cisco Systems, “Cisco Catalyst 6500 Architecture White\nPaper,” http://www.cisco.com/c/en/us/products/collateral/switches/catalyst-\n6500-series-switches/prod_white_paper0900aecd80673385.html\n[Cisco 7600 2020] Cisco Systems, “Cisco 7600 Series Solution and Design\nGuide,”\nhttp://www.cisco.com/en/US/products/hw/routers/ps368/prod_technical_ref\nerence09186a0080092246.html"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1177,
    "text": "[Clark 1997] D. Clark, “ Interoperation, open interfaces and protocol\narchitecture,” in The Unpredictable Certainty, The National Academies\nPress, 1997, pp. 133–144. [Clark 2005] D. Clark, J. Wroclawski, K. R. Sollins, R. Braden, “Tussle in\ncyberspace: defining tomorrow’s internet,” IEEE/ACM Trans. Networking,\nVol. 13, No. 3 (June 2005), pp. 462–475. [Clos 1953] C. Clos, “A study of non-blocking switching networks,” Bell\nSystem Technical Journal, Vol. 32, No. 2 (Mar. 1953), pp. 406–424. [Cohen 2003] B. Cohen, “Incentives to Build Robustness in BitTorrent,”\nFirst Workshop on the Economics of Peer-to-Peer Systems, Berkeley, CA,\nJune 2003. [Colbach 2017] G. Colbach, Wireless Technologies: An introduction to\nBluetooth and WiFi, 2017. [Condoluci 2018] M. Condoluci, T. Mahmoodi,, “Softwarization and\nvirtualization in 5G mobile networks: Benefits, trends and challenges,”\nComputer Networks, Vol. 146 (2018), pp. 65–84. [Cormen 2001] T. H. Cormen, Introduction to Algorithms, 2nd Ed., MIT\nPress, Cambridge, MA, 2001. [Crow 1997] B. Crow, I. Widjaja, J. Kim, P. Sakai, “IEEE 802.11 Wireless\nLocal Area Networks,” IEEE Communications Magazine (Sept. 1997), pp. 116–126. [Cusumano 1998] M. A. Cusumano, D. B. Yoffie, Competing on Internet\nTime: Lessons from Netscape and Its Battle with Microsoft, Free Press, New\nYork, NY, 1998. [Czyz 2014] J. Czyz, M. Allman, J. Zhang, S. Iekel-Johnson, E. Osterweil,\nM. Bailey, “Measuring IPv6 Adoption,” Proc. ACM SIGCOMM 2014\nConference, ACM, New York, NY, USA, pp. 87–98."
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1178,
    "text": "[Dahlman 2018] E. Dahlman, S. Parkvall, J. Skold, 5G NR: The Next\nGeneration Wireless Access Technology, Academic Press, 2018. [DAM 2020] Digital Attack Map, http://www.digitalattackmap.com\n[Davie 2000] B. Davie and Y. Rekhter, MPLS: Technology and\nApplications, Morgan Kaufmann Series in Networking, 2000. [DEC 1990] Digital Equipment Corporation, “In Memoriam: J. C. R.\nLicklider 1915–1990,” SRC Research Report 61, Aug. 1990.\nhttp://www.memex.org/licklider.pdf\n[DeClercq 2002] J. DeClercq, O. Paridaens, “Scalability Implications of\nVirtual Private Networks,” IEEE Communications Magazine, Vol. 40, No. 5\n(May 2002), pp. 151–157. [Demers 1990] A. Demers, S. Keshav, S. Shenker, “Analysis and\nSimulation of a Fair Queuing Algorithm,” Internetworking: Research and\nExperience, Vol. 1, No. 1 (1990), pp. 3–26. [dhc 2020] IETF Dynamic Host Configuration working group homepage,\nhttps://datatracker.ietf.org/wg/dhc/about/\n[Diffie 1976] W. Diffie, M. E. Hellman, “New Directions in Cryptography,”\nIEEE Transactions on Information Theory, Vol IT-22 (1976), pp. 644–654. [Diggavi 2004] S. N. Diggavi, N. Al-Dhahir, A. Stamoulis, R. Calderbank,\n“Great Expectations: The Value of Spatial Diversity in Wireless Networks,”\nProceedings of the IEEE, Vol. 92, No. 2 (Feb. 2004). [Dilley 2002] J. Dilley, B. Maggs, J. Parikh, H. Prokop, R. Sitaraman, B.\nWeihl, “Globally Distributed Content Delivery,” IEEE Internet Computing\n(Sept.–Oct. 2002). [Dmitiropoulos 2007] X. Dmitiropoulos, D. Krioukov, M. Fomenkov, B.\nHuffaker, Y. Hyun, K. C. Claffy, G. Riley, “AS Relationships: Inference and"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1180,
    "text": "(HotSDN ’13). ACM, New York, NY, USA, pp. 13–18. [Facebook 2014] A. Andreyev, “Introducing Data Center Fabric, the Next-\nGeneration Facebook Data Center Network,”\nhttps://code.facebook.com/posts/360346274145943/introducing-data-\ncenter-fabric-the-next-generation-facebook-data-center-network\n[Faloutsos 1999] C. Faloutsos, M. Faloutsos, P. Faloutsos, “What Does the\nInternet Look Like? Empirical Laws of the Internet Topology,” Proc. 1999\nACM SIGCOMM Conference (Boston, MA, Aug. 1999). [Farrington 2010] N. Farrington, G. Porter, S. Radhakrishnan, H. Bazzaz,\nV. Subramanya, Y. Fainman, G. Papen, A. Vahdat, “Helios: A Hybrid\nElectrical/Optical Switch Architecture for Modular Data Centers,” Proc. 2010 ACM SIGCOMM Conference. [Faulhaber 2012] G. Faulhaber, “The Economics of Network Neutrality:\nAre ‘Prophylactic’ Remedies to Nonproblems Needed?,” Regulation, Vol. 34, No. 4, p. 18, Winter 2011–2012. [FB 2014] Facebook, “Introducing data center fabric, the next-generation\nFacebook data center network.” https://engineering.fb.com/production-\nengineering/introducing-data-center-fabric-the-next-generation-facebook-\ndata-center-network/\n[FB 2019] Facebook, “Reinventing Facebook’s Data Center Network,”\nhttps://engineering.fb.com/data-center-engineering/f16-minipack/\n[FCC 2008] US Federal Communications Commission, Memorandum\nOpinion and Order: Formal Complaint of Free Press and Public\nKnowledge Against Comcast Corporation for Secretly Degrading Peer-to-\nPeer Applications, FCC 08-083. [FCC 2015] US Federal Communications Commission, Protecting and\nPromoting the Open Internet, Report and Order on Remand, Declaratory"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1181,
    "text": "Ruling, and Order, GN Docket No. 14-28. (March 12, 2015),\nhttps://apps.fcc.gov/edocs_public/attachmatch/FCC-15-24A1.pdf\n[FCC 2017] Restoring Internet Freedom, Declaratory Ruling, Report and\nOrder and Order, WC Docket No. 17-108, December 14, 2017.\nhttps://transition.fcc.gov/Daily_Releases/Daily_Business/2018/db0105/FC\nC-17-166A1.pdf\n[Feamster 2004] N. Feamster, H. Balakrishnan, J. Rexford, A. Shaikh, K.\nvan der Merwe, “The Case for Separating Routing from Routers,” ACM\nSIGCOMM Workshop on Future Directions in Network Architecture, Sept.\n2004. [Feamster 2004] N. Feamster, J. Winick, J. Rexford, “A Model for BGP\nRouting for Network Engineering,” Proc. 2004 ACM SIGMETRICS\nConference (New York, NY, June 2004). [Feamster 2005] N. Feamster, H. Balakrishnan, “Detecting BGP\nConfiguration Faults with Static Analysis,” NSDI (May 2005). [Feamster 2013] N. Feamster, J. Rexford, E. Zegura, “The Road to SDN,”\nACM Queue, Volume 11, Issue 12, (Dec. 2013). [Feamster 2018] N. Feamster, J. Rexford, “Why (and How) Networks\nShould Run Themselves,” Proc. 2018 ACM Applied Networking Research\nWorkshop (ANRW ’18). [Feldmeier 1995] D. Feldmeier, “Fast Software Implementation of Error\nDetection Codes,” IEEE/ACM Transactions on Networking, Vol. 3, No. 6\n(Dec. 1995), pp. 640–652. [Fiber Broadband 2020] Fiber Broadband Association\nhttps://www.fiberbroadband.org/\n[Fielding 2000] R. Fielding, “Architectural Styles and the Design of\nNetwork-based Software Architectures,” 2000. PhD Thesis, UC Irvine,"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1182,
    "text": "2000. [FIPS 1995] Federal Information Processing Standard, “Secure Hash\nStandard,” FIPS Publication 180-1. http://www.itl.nist.gov/fipspubs/fip180-\n1.htm\n[Floyd 1999] S. Floyd, K. Fall, “Promoting the Use of End-to-End\nCongestion Control in the Internet,” IEEE/ACM Transactions on\nNetworking, Vol. 6, No. 5 (Oct. 1998), pp. 458–472. [Floyd 2000] S. Floyd, M. Handley, J. Padhye, J. Widmer, “Equation-Based\nCongestion Control for Unicast Applications,” Proc. 2000 ACM SIGCOMM\nConference (Stockholm, Sweden, Aug. 2000). [Floyd 2016] S. Floyd, “"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1183,
    "text": "Apr. 2000). [Fortz 2002] B. Fortz, J. Rexford, M. Thorup, “Traffic Engineering with\nTraditional IP Routing Protocols,” IEEE Communication Magazine, Vol. 40, No. 10 (Oct. 2002). [Frost 1994] J. Frost, “BSD Sockets: A Quick and Dirty Primer,”\nhttp://world.std.com/~jimf/papers/sockets/sockets.html\n[Gao 2001] L. Gao, J. Rexford, “Stable Internet Routing Without Global\nCoordination,” IEEE/ACM Transactions on Networking, Vol. 9, No. 6 (Dec.\n2001), pp. 681–692. [Garfinkel 2003] S. Garfinkel, “The End of End-to-End?,” MIT\nTechnology Review, July 2003. [Gauthier 1999] L. Gauthier, C. Diot, and J. Kurose, “End-to-End\nTransmission Control Mechanisms for Multiparty Interactive Applications\non the Internet,” Proc. 1999 IEEE INFOCOM (New York, NY, Apr. 1999). [Gieben 2004] M. Gieben, “DNSSEC,” The Internet Protocol Journal, 7\n[2] (June 2004), http://ipj.dreamhosters.com/internet-protocol-\njournal/issues/back-issues/\n[Giust 2015] F. Giust, L. Cominardi and C. J. Bernardos, “Distributed\nmobility management for future 5G networks: overview and analysis of\nexisting approaches,” in IEEE Communications Magazine, Vol. 53, No. 1,\npp. 142–149, January 2015. [Goldsmith 2005] A. Goldsmith, Wireless Communications, Cambridge\nUniversity Press, 2005. [Goodman 1997] David J. Goodman, Wireless Personal Communications\nSystems, Prentice-Hall, 1997. [Google CDN 2020] Google Data Center Locations\nhttps://cloud.google.com/cdn/docs/locations"
  },
  {
    "unit": "Unit 5",
    "topic": "Chapter 14",
    "source": "kurose",
    "page": 1184,
    "text": "[Google IPv6 2020] Google Inc. “IPv6 Statistics,”\nhttps://www.google.com/intl/en/ipv6/statistics.html\n[Google Locations 2020] Google data centers. http://www.google.com/corporate/datacenter/locations.html\n[Goralski 1999] W. Goralski, Frame Relay for High-Speed Networks, John\nWiley, New York, 1999. [Greenberg 2009a] A. Greenberg, J. Hamilton, D. Maltz, P. Patel, “The\nCost of a Cloud: Research Problems in Data Center Networks,” ACM\nComputer Communications Review (Jan. 2009). [Greenberg 2009b] A. Greenberg, N. Jain, S. Kandula, C. Kim, P. Lahiri,\nD. Maltz, P. Patel, S. Sengupta, “VL2: A Scalable and Flexible Data Center\nNetwork,” Proc. 2009 ACM SIGCOMM Conference. [Greenberg 2015] A. Greenberg, “SDN for the Cloud,” 2015 ACM\nSIGCOMM Conference 2015 Keynote Address,\nhttp://conferences.sigcomm.org/sigcomm/2015/pdf/papers/keynote.pdf\n[GSMA 2018a] GSM Association, “Guidelines for IPX Provider\nnetworks,” Document IR.34, Version 14.0, August 2018. [GSMA 2018b] GSM Association, “Migration from Physical to Virtual\nNetwork Functions: Best Practices and Lessons Learned,” July 2019. [GSMA 2019a] GSM Association, “LTE and EPC Roaming Guidelines,”\nDocument IR.88, June 2019. [GSMA 2019b] GSM Association, “IMS Roaming, Interconnection and\nInterworking Guidelines,” Document IR.65, April 2019. [GSMA 2019c] GSM Association, “5G Implementation Guidelines,” July\n2019. [Gude 2008] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N.\nMcKeown, and S. Shenker, “NOX: Towards an Operating System for"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1185,
    "text": "Networks,” ACM SIGCOMM Computer Communication Review, July 2008. [Guo 2009] C. Guo, G. Lu, D. Li, H. Wu, X. Zhang, Y. Shi, C. Tian, Y.\nZhang, S. Lu, “BCube: A High Performance, Server-centric Network\nArchitecture for Modular Data Centers,” Proc. 2009 ACM SIGCOMM\nConference. [Guo 2016] C. Guo, H. Wu, Z. Deng, G. Soni, J. Ye, J. Padhye, M.\nLipshteyn, “RDMA over Commodity Ethernet at Scale,” Proc. 2016 ACM\nSIGCOMM Conference. [Gupta 2001] P. Gupta, N. McKeown, “Algorithms for Packet\nClassification,” IEEE Network Magazine, Vol. 15, No. 2 (Mar./Apr. 2001),\npp. 24–32. [Gupta 2014] A. Gupta, L. Vanbever, M. Shahbaz, S. Donovan, B.\nSchlinker, N. Feamster, J. Rexford, S. Shenker, R. Clark, E. Katz-Bassett,\n“SDX: A Software Defined Internet Exchange, “ Proc. 2014 ACM\nSIGCOMM Conference (Aug. 2014), pp. 551–562. [Ha 2008] S. Ha, I. Rhee, L. Xu, “CUBIC: A New TCP-Friendly High-\nSpeed TCP Variant,” ACM SIGOPS Operating System Review, 2008. [Halabi 2000] S. Halabi, Internet Routing Architectures, 2nd Ed., Cisco\nPress, 2000. [Hamzeh 2015] B. Hamzeh, M. Toy, Y. Fu and J. Martin, “DOCSIS 3.1:\nscaling broadband cable to Gigabit speeds,” IEEE Communications\nMagazine, Vol. 53, No. 3, pp. 108–113, March 2015. [Hanabali 2005] A. A. Hanbali, E. Altman, P. Nain, “A Survey of TCP over\nAd Hoc Networks,” IEEE Commun. Surveys and Tutorials, Vol. 7, No. 3\n(2005), pp. 22–36. [He 2015] K. He , E. Rozner , K. Agarwal , W. Felter , J. Carter , A. Akella,\n“Presto: Edge-based Load Balancing for Fast Datacenter Networks,” Proc."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1186,
    "text": "2015 ACM SIGCOMM Conference. [Heidemann 1997] J. Heidemann, K. Obraczka, J. Touch, “Modeling the\nPerformance of HTTP over Several Transport Protocols,” IEEE/ACM\nTransactions on Networking, Vol. 5, No. 5 (Oct. 1997), pp. 616–630. [Held 2001] G. Held, Data Over Wireless Networks: Bluetooth, WAP, and\nWireless LANs, McGraw-Hill, 2001. [Holland 2001] G. Holland, N. Vaidya, V. Bahl, “A Rate-Adaptive MAC\nProtocol for Multi-Hop Wireless Networks,” Proc. 2001 ACM Int. Conference of Mobile Computing and Networking (Rome, Italy, July 2001). [Hollot 2002] C.V. Hollot, V. Misra, D. Towsley, W. Gong, “Analysis and\nDesign of Controllers for AQM Routers Supporting TCP Flows,” IEEE\nTransactions on Automatic Control, Vol. 47, No. 6 (June 2002), pp. 945–\n959. [Hong 2012] C.Y. Hong, M. Caesar, P. B. Godfrey, “Finishing Flows\nQuickly with Preemptive Scheduling,” Proc. 2012 ACM SIGCOMM\nConference. [Hong 2013] C. Hong, S, Kandula, R. Mahajan, M.Zhang, V. Gill, M.\nNanduri, R. Wattenhofer, “Achieving High Utilization with Software-driven\nWAN,” Proc. ACM SIGCOMM Conference (Aug. 2013), pp.15–26. [Hong 2018] C. Hong et al., “B4 and after: managing hierarchy,\npartitioning, and asymmetry for availability and scale in Google’s software-\ndefined WAN,” Proc. 2018 ACM SIGCOMM Conference, pp. 74–87. [HTTP/3 2020] M. Bishop. Ed, “Hypertext Transfer Protocol Version 3\n(HTTP/3),” Internet Draft draft-ietf-quic-http-23, expires March 15, 2020. [Huang 2002] C. Haung, V. Sharma, K. Owens, V. Makam, “Building\nReliable MPLS Networks Using a Path Protection Mechanism,” IEEE\nCommunications Magazine, Vol. 40, No. 3 (Mar. 2002), pp. 156–162."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 3",
    "source": "kurose",
    "page": 1187,
    "text": "[Huang 2008] C. Huang, J. Li, A. Wang, K. W. Ross, “Understanding\nHybrid CDN-P2P: Why Limelight Needs Its Own Red Swoosh,” Proc. 2008 NOSSDAV, Braunschweig, Germany. [Huang 2013] J. Huang, F. Qian, Y. Guo, Yu. Zhou, Q. Xu, Z. Mao, S. Sen,\nO. Spatscheck, “An in-depth study of LTE: effect of network protocol and\napplication behavior on performance,” Proc. 2013 ACM SIGCOMM\nConference. [Huitema 1998] C. Huitema, IPv6: The New Internet Protocol, 2nd Ed.,\nPrentice Hall, Englewood Cliffs, NJ, 1998. [Huston 1999a] G. Huston, “Interconnection, Peering, and Settlements—\nPart I,” The Internet Protocol Journal, Vol. 2, No. 1 (Mar. 1999). [Huston 2004] G. Huston, “NAT Anatomy: A Look Inside Network\nAddress Translators,” The Internet Protocol Journal, Vol. 7, No. 3 (Sept.\n2004). [Huston 2008b] G. Huston, G. Michaelson, “IPv6 Deployment: Just where\nare we?” http://www.potaroo.net/ispcol/2008-04/ipv6.html\n[Huston 2011a] G. Huston, “A Rough Guide to Address Exhaustion,” The\nInternet Protocol Journal, Vol. 14, No. 1 (Mar. 2011). [Huston 2011b] G. Huston, “Transitioning Protocols,” The Internet\nProtocol Journal, Vol. 14, No. 1 (Mar. 2011). [Huston 2012] G. Huston, “A Quick Primer on Internet Peering and\nSettlements,” April 2012, http://www.potaroo.net/ispcol/2012-\n04/interconnection-primer.html\n[Huston 2017] G. Huston, “BBR, the new kid on the TCP block,”\nhttps://blog.apnic.net/2017/05/09/bbr-new-kid-tcp-block/\n[Huston 2017] G. Huston, “An Opinion in Defence of NAT,”\nhttps://www.potaroo.net/ispcol/2017-09/natdefence.html"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1189,
    "text": "[IEEE 802.3 2020] IEEE, “IEEE 802.3 CSMA/CD (Ethernet),”\nhttp://grouper.ieee.org/groups/802/3/\n[IEEE 802.5 2012] IEEE, IEEE 802.5 homepage,\nhttp://www.ieee802.org/5/www8025org/\n[IEEE 802.11 2020] IEEE 802.11 Wireless Local Area Networks, the\nWorking Group for WLAN Standards, http://www.ieee802.org/11/\n[IETF 2020] Internet Engineering Task Force homepage,\nhttp://www.ietf.org\n[IETF QUIC2020] Internet Engineering Task Force, QUIC Working\nGroup, https://datatracker.ietf.org/wg/quic/about/\n[Intel 2020] Intel Corp., “Intel 710 Ethernet Adapter,”\nhttp://www.intel.com/content/www/us/en/ethernet-products/converged-\nnetwork-adapters/ethernet-xl710.html\n[ISC 2020] Internet Systems Consortium homepage, http://www.isc.org\n[ITU 2005a] International Telecommunication Union, “ITU-T X.509, The\nDirectory: Public-key and attribute certificate frameworks” (Aug. 2005). [ITU 2014] ITU, “G.fast broadband standard approved and on the market,”\nhttp://www.itu.int/net/pressoffice/press_releases/2014/70.aspx\n[ITU 2020] The ITU homepage, http://www.itu.int/\n[Iyer 2008] S. Iyer, R. R. Kompella, N. McKeown, “Designing Packet\nBuffers for Router Line Cards,” IEEE/ACM Transactions on Networking,\nVol. 16, No. 3 (June 2008), pp. 705–717. [Jacobson 1988] V. Jacobson, “Congestion Avoidance and Control,” Proc. 1988 ACM SIGCOMM Conference (Stanford, CA, Aug. 1988), pp. 314–\n329. [Jain 1986] R. Jain, “A Timeout-Based Congestion Control Scheme for\nWindow Flow-Controlled Networks,” IEEE Journal on Selected Areas in"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1190,
    "text": "Communications SAC-4, 7 (Oct. 1986). [Jain 1989] R. Jain, “A Delay-Based Approach for Congestion Avoidance\nin Interconnected Heterogeneous Computer Networks,” ACM SIGCOMM\nComputer Communications Review, Vol. 19, No. 5 (1989), pp. 56–71. [Jain 1994] R. Jain, FDDI Handbook: High-Speed Networking Using Fiber\nand Other Media, Addison-Wesley, Reading, MA, 1994. [Jain 1996] R. Jain. S. Kalyanaraman, S. Fahmy, R. Goyal, S. Kim,\n“Tutorial Paper on ABR Source Behavior,” ATM Forum/96-1270, Oct.\n1996. http://www.cse.wustl.edu/~jain/atmf/ftp/atm96-1270.pdf\n[Jain 2013] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh,\nS.Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U. Hölzle, S. Stuart, A,\nVahdat, “B4: Experience with a Globally Deployed Software Defined\nWan,” Proc. 2013 ACM SIGCOMM Conference, pp. 3–14. [Jimenez 1997] D. Jimenez, “Outside Hackers Infiltrate MIT Network,\nCompromise Security,” The Tech, Vol. 117, No. 49 (Oct. 1997), p. 1,\nhttp://www-tech.mit.edu/V117/N49/hackers.49n.html\n[Juniper MX2020 2020] Juniper Networks, “MX2020 and MX2010 3D\nUniversal Edge Routers,” https://www.juniper.net/us/en/products-\nservices/routing/mx-series/mx2020/\n[Kaaranen 2001] H. Kaaranen, S. Naghian, L. Laitinen, A. Ahtiainen, V.\nNiemi, Networks: Architecture, Mobility and Services, New York: John\nWiley & Sons, 2001. [Kahn 1967] D. Kahn, The Codebreakers: The Story of Secret Writing, The\nMacmillan Company, 1967. [Kahn 1978] R. E. Kahn, S. Gronemeyer, J. Burchfiel, R. Kunzelman,\n“Advances in Packet Radio Technology,” Proc. IEEE, Vol. 66, No. 11 (Nov.\n1978), pp. 1468–1496."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1192,
    "text": "Throughput-Delay Characteristics,” IEEE Transactions on\nCommunications, Vol. 23, No. 12 (Dec. 1975), pp. 1400–1416. [Kleinrock 1976] L. Kleinrock, Queuing Systems, Vol. 2, John Wiley, New\nYork, 1976. [Kleinrock 2004] L. Kleinrock, “The Birth of the Internet,”\nhttp://www.lk.cs.ucla.edu/LK/Inet/birth.html\n[Kleinrock 2018] L. Kleinrock, “Internet congestion control using the\npower metric: Keep the pipe just full, but no fuller,” Ad Hoc Networks, Vol. 80, 2018, pp. 142–157. [Kohler 2006] E. Kohler, M. Handley, S. Floyd, “DDCP: Designing DCCP:\nCongestion Control Without Reliability,” Proc. 2006 ACM SIGCOMM\nConference (Pisa, Italy, Sept. 2006). [Kohlios 2018] C. Kohlios, T. Hayajneh, “A Comprehensive Attack Flow\nModel and Security Analysis for Wi-Fi and WPA3,” Electronics, Vol. 7, No. 11, 2018. [Kolding 2003] T. Kolding, K. Pedersen, J. Wigard, F. Frederiksen, P.\nMogensen, “High Speed Downlink Packet Access: WCDMA Evolution,”\nIEEE Vehicular Technology Society News (Feb. 2003), pp. 4–10. [Koponen 2010] T. Koponen, M. Casado, N. Gude, J. Stribling, L.\nPoutievski, M. Zhu, R. Ramanathan, Y. Iwata, H. Inoue, T. Hama, S.\nShenker, “Onix: A Distributed Control Platform for Large-Scale Production\nNetworks,” 9th USENIX conference on Operating systems design and\nimplementation (OSDI’10), pp. 1–6. [Koponen 2011] T. Koponen, S. Shenker, H. Balakrishnan, N. Feamster, I.\nGanichev, A. Ghodsi, P. B. Godfrey, N. McKeown, G. Parulkar, B.\nRaghavan, J. Rexford, S. Arianfar, D. Kuptsov, “Architecting for\nInnovation,” ACM Computer Communications Review, 2011."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1194,
    "text": "[Labrador 1999] M. Labrador, S. Banerjee, “Packet Dropping Policies for\nATM and IP Networks,” IEEE Communications Surveys, Vol. 2, No. 3\n(Third Quarter 1999), pp. 2–14. [Lacage 2004] M. Lacage, M.H. Manshaei, T. Turletti, “IEEE 802.11 Rate\nAdaptation: A Practical Approach,” ACM Int. Symposium on Modeling,\nAnalysis, and Simulation of Wireless and Mobile Systems (MSWiM)\n(Venice, Italy, Oct. 2004). [Lakhina 2005] A. Lakhina, M. Crovella, C. Diot, “Mining Anomalies\nUsing Traffic Feature Distributions,” Proc. 2005 ACM SIGCOMM\nConference. [Lakshman 1997] T. V. Lakshman, U. Madhow, “The Performance of\nTCP/IP for Networks with High Bandwidth-Delay Products and Random\nLoss,” IEEE/ACM Transactions on Networking, Vol. 5, No. 3 (1997), pp. 336–350. [Lakshman 2004] T. V. Lakshman, T. Nandagopal, R. Ramjee, K. Sabnani,\nT. Woo, “The SoftRouter Architecture,” Proc. 3nd ACM Workshop on Hot\nTopics in Networks (Hotnets-III), Nov. 2004. [Lam 1980] S. Lam, “A Carrier Sense Multiple Access Protocol for Local\nNetworks,” Computer Networks, Vol. 4 (1980), pp. 21–32. [Lamport 1989] L. Lamport, “The Part-Time Parliament,” Technical\nReport 49, Systems Research Center, Digital Equipment Corp., Palo Alto,\nSept. 1989. [Lampson 1983] Lampson, Butler W. “Hints for computer system design,”\nACM SIGOPS Operating Systems Review, Vol. 17, No. 5, 1983. [Lampson 1996] B. Lampson, “How to Build a Highly Available System\nUsing Consensus,” Proc. 10th International Workshop on Distributed"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1195,
    "text": "Algorithms (WDAG ’96), Özalp Babaoglu and Keith Marzullo (Eds. ),\nSpringer-Verlag, pp. 1–17. [Langley 2017] A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic, D.\nZhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, J. Bailey, J. Dorfman, J.\nRoskind, J. Kulik, P. Westin, R. Tenneti, R. Shade, R. Hamilton, V. Vasiliev,\nW. Chang, Z. Shi, “The QUIC Transport Protocol: Design and Internet-\nScale Deployment,” Proc. 2017 ACM SIGCOMM Conference. [Lawton 2001] G. Lawton, “Is IPv6 Finally Gaining Ground?” IEEE\nComputer Magazine (Aug. 2001), pp. 11–15. [Leighton 2009] T. Leighton, “Improving Performance on the Internet,”\nCommunications of the ACM, Vol. 52, No. 2 (Feb. 2009), pp. 44–51. [Leiner 1998] B. Leiner, V. Cerf, D. Clark, R. Kahn, L. Kleinrock, D.\nLynch, J. Postel, L. Roberts, S. Woolf, “A Brief History of the Internet,”\nhttp://www.isoc.org/internet/history/brief.html\n[Leung 2006] K. Leung, V. O. K. Li, “TCP in Wireless Networks: Issues,\nApproaches, and Challenges,” IEEE Commun. Surveys and Tutorials, Vol. 8, No. 4 (2006), pp. 64–79. [Levin 2012] D. Levin, A. Wundsam, B. Heller, N. Handigol, A. Feldmann,\n“Logically Centralized? : State Distribution Trade-offs in Software Defined\nNetworks,” Proc. First Workshop on Hot Topics in Software Defined\nNetworks (Aug. 2012), pp. 1–6. [Li 2004] L. Li, D. Alderson, W. Willinger, J. Doyle, “A First-Principles\nApproach to Understanding the Internet’s Router-Level Topology,” Proc. 2004 ACM SIGCOMM Conference (Portland, OR, Aug. 2004). [Li 2007] J. Li, M. Guidero, Z. Wu, E. Purpus, T. Ehrenkranz, “BGP\nRouting Dynamics Revisited.” ACM Computer Communication Review\n(Apr. 2007)."
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1196,
    "text": "[Li 2015] S. Q. Li, “Building Softcom Ecosystem Foundation,” Open\nNetworking Summit, 2015. [Li 2017] Z. Li, W. Wang, C. Wilson, J. Chen, C. Qian, T. Jung, L. Zhang,\nK. Liu, X.Li, Y. Liu, “FBS-Radar: Uncovering Fake Base Stations at Scale\nin the Wild,” ISOC Symposium on Network and Distributed System Security\n(NDSS), February 2017. [Li 2018] Z. Li, D. Levin, N. Spring, B. Bhattacharjee, “Internet anycast:\nperformance, problems, & potential,” Proc. 2018 ACM SIGCOMM\nConference, pp. 59–73. [Lin 2001] Y. Lin, I. Chlamtac, Wireless and Mobile Network Architectures,\nJohn Wiley and Sons, New York, NY, 2001. [Liogkas 2006] N. Liogkas, R. Nelson, E. Kohler, L. Zhang, “Exploiting\nBitTorrent for Fun (but Not Profit),” 6th International Workshop on Peer-\nto-Peer Systems (IPTPS 2006). [Liu 2003] J. Liu, I. Matta, M. Crovella, “End-to-End Inference of Loss\nNature in a Hybrid Wired/Wireless Environment,” Proc. WiOpt’03:\nModeling and Optimization in Mobile, Ad Hoc and Wireless Networks. [Locher 2006] T. Locher, P. Moor, S. Schmid, R. Wattenhofer, “Free Riding\nin BitTorrent is Cheap,” Proc. ACM HotNets 2006 (Irvine CA, Nov. 2006). [Madhyastha 2017] H. Madhyastha, “A Case Against Net Neutrality,”\nIEEE Spectrum, Dec. 2017, https://spectrum.ieee.org/tech-\ntalk/telecom/internet/a-case-against-net-neutrality\n[Mahdavi 1997] J. Mahdavi, S. Floyd, “TCP-Friendly Unicast Rate-Based\nFlow Control,” unpublished note (Jan. 1997). [Mao 2002] Z. Mao, C. Cranor, F. Douglis, M. Rabinovich, O. Spatscheck,\nJ. Wang, “A Precise and Efficient Evaluation of the Proximity Between Web"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1197,
    "text": "Clients and Their Local DNS Servers,” 2002 USENIX Annual Technical\nConference, pp. 229–242. [Mathis 1997] M. Mathis, J. Semke, J. Mahdavi, T. Ott, T. 1997, “The\nmacroscopic behavior of the TCP congestion avoidance algorithm,” ACM\nSIGCOMM Computer Communication Review, 27(3): pp. 67–82. [MaxMind 2020] http://www.maxmind.com/app/ip-location\n[McKeown 1997a] N. McKeown, M. Izzard, A. Mekkittikul, W. Ellersick,\nM. Horowitz, “The Tiny Tera: A Packet Switch Core,” IEEE Micro\nMagazine (Jan.–Feb. 1997). [McKeown 1997b] N. McKeown, “A Fast Switched Backplane for a\nGigabit Switched Router,” Business Communications Review, Vol. 27, No. 12. http://tiny-tera.stanford.edu/~nickm/papers/cisco_fasts_wp.pdf\n[McKeown 2008] N. McKeown, T. Anderson, H. Balakrishnan, G.\nParulkar, L. Peterson, J. Rexford, S. Shenker, J. Turner. 2008. OpenFlow:\nEnabling Innovation in Campus Networks. SIGCOMM Comput. Commun. Rev. 38, 2 (Mar. 2008), pp. 69–74. [McQuillan 1980] J. McQuillan, I. Richer, E. Rosen, “The New Routing\nAlgorithm for the Arpanet,” IEEE Transactions on Communications, Vol. 28, No. 5 (May 1980), pp. 711–719. [Metcalfe 1976] R. M. Metcalfe, D. R. Boggs. “Ethernet: Distributed\nPacket Switching for Local Computer Networks,” Communications of the\nAssociation for Computing Machinery, Vol. 19, No. 7 (July 1976), pp. 395–\n404. [Meyers 2004] A. Myers, T. Ng, H. Zhang, “Rethinking the Service Model:\nScaling Ethernet to a Million Nodes,” ACM Hotnets Conference, 2004. [Mijumbi 2016] R. Mijumbi, J. Serrat, J. Gorricho, N. Bouten, F. De Turck\nand R. Boutaba, “Network Function Virtualization: State-of-the-Art and"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1198,
    "text": "Research Challenges,” IEEE Communications Surveys & Tutorials, Vol. 18,\nNo. 1, pp. 236–262, 2016. [MIT TR 2019] MIT Technology Review, “How a quantum computer\ncould break 2048-bit RSA encryption in 8 hours,” May 2019,\nhttps://www.technologyreview.com/s/613596/how-a-quantum-computer-\ncould-break-2048-bit-rsa-encryption-in-8-hours/\n[Mittal 2015] R. Mittal, V. Lam, N. Dukkipati, E. Blem, H. Wassel, M.\nGhobadi, A. Vahdat, Y. Wang, D. Wetherall, D. Zats, “TIMELY: RTT-based\nCongestion Control for the Datacenter,” Proc. 2015 ACM SIGCOMM\nConference, pp. 537–550. [Mockapetris 1988] P. V. Mockapetris, K. J. Dunlap, “Development of the\nDomain Name System,” Proc. 1988 ACM SIGCOMM Conference\n(Stanford, CA, Aug. 1988). [Mockapetris 2005] P. Mockapetris, Sigcomm Award Lecture, video\navailable at http://www.postel.org/sigcomm\n[Molinero-Fernandez 2002] P. Molinaro-Fernandez, N. McKeown, H.\nZhang, “Is IP Going to Take Over the World (of Communications)?” Proc. 2002 ACM Hotnets. [Molle 1987] M. L. Molle, K. Sohraby, A. N. Venetsanopoulos, “Space-\nTime Models of Asynchronous CSMA Protocols for Local Area Networks,”\nIEEE Journal on Selected Areas in Communications, Vol. 5, No. 6 (1987),\npp. 956–968. [Moshref 2016] M. Moshref, M. Yu, R, Govindan, A. Vahdat, “Trumpet:\nTimely and Precise Triggers in Data Centers,” Proc. 2016 ACM SIGCOMM\nConference. [Motorola 2007] Motorola, “Long Term Evolution (LTE): A Technical\nOverview,”"
  },
  {
    "unit": "Unit 2",
    "topic": "Chapter 19",
    "source": "kurose",
    "page": 1199,
    "text": "http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Soluti\nons/Service%20Providers/Wireless%20Operators/LTE/_Document/Static%\n20Files/6834_MotDoc_New.pdf\n[Mouly 1992] M. Mouly, M. Pautet, The GSM System for Mobile\nCommunications, Cell and Sys, Palaiseau, France, 1992. [Moy 1998] J. Moy, OSPF: Anatomy of An Internet Routing Protocol,\nAddison-Wesley, Reading, MA, 1998. [Mysore 2009] R. N. Mysore, A. Pamboris, N. Farrington, N. Huang, P.\nMiri, S. Radhakrishnan, V. Subramanya, A. Vahdat, “PortLand: A Scalable\nFault-Tolerant Layer 2 Data Center Network Fabric,” Proc. 2009 ACM\nSIGCOMM Conference. [Nahum 2002] E. Nahum, T. Barzilai, D. Kandlur, “Performance Issues in\nWWW Servers,” IEEE/ACM Transactions on Networking, Vol 10, No. 1\n(Feb. 2002). [Narayan 2018] A. Narayan, F. Cangialosi, D. Raghavan, P. Goyal, S.\nNarayana, R. Mittal, M. Alizadeh, H. Balakrishnan, “Restructuring endpoint\ncongestion control,” Proc. ACM SIGCOMM 2018 Conference, pp. 30–43. [Netflix Open Connect 2020] Netflix Open Connect CDN, 2016,\nhttps://openconnect.netflix.com/\n[Netflix Video 1] Designing Netflix’s Content Delivery System, D.\nFulllager, 2014, https://www.youtube.com/watch?v=LkLLpYdDINA\n[Netflix Video 2] Scaling the Netflix Global CDN, D. Temkin, 2015,\nhttps://www.youtube.com/watch?v=tbqcsHg-Q_o\n[Neumann 1997] R. Neumann, “Internet Routing Black Hole,” The Risks\nDigest: Forum on Risks to the Public in Computers and Related Systems,\nVol. 19, No. 12 (May 1997). http://catless.ncl.ac.uk/Risks/19.12.html#subj1.1"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1200,
    "text": "[Neville-Neil 2009] G. Neville-Neil, “Whither Sockets?” Communications\nof the ACM, Vol. 52, No. 6 (June 2009), pp. 51–55. [Nguyen 2016] T. Nguyen, C. Bonnet and J. Harri, “SDN-based distributed\nmobility management for 5G networks,” 2016 IEEE Wireless\nCommunications and Networking Conference, Doha, 2016, pp. 1–7. [Nichols 2012] K. Nichols, V. Jacobson. Controlling Queue Delay. ACM\nQueue, Vol. 10, No. 5, May 2012. [Nicholson 2006] A Nicholson, Y. Chawathe, M. Chen, B. Noble, D.\nWetherall, “Improved Access Point Selection,” Proc. 2006 ACM Mobisys\nConference (Uppsala Sweden, 2006). [Nielsen 1997] H. F. Nielsen, J. Gettys, A. Baird-Smith, E.\nPrud’hommeaux, H. W. Lie, C. Lilley, “Network Performance Effects of\nHTTP/1.1, CSS1, and PNG,” W3C Document, 1997 (also appears in Proc. 1997 ACM SIGCOM Conference (Cannes, France, Sept 1997), pp. 155–\n166. [NIST 2001] National Institute of Standards and Technology, “Advanced\nEncryption Standard (AES),” Federal Information Processing Standards\n197, Nov. 2001, http://csrc.nist.gov/publications/fips/fips197/fips-197.pdf\n[NIST IPv6 2020] US National Institute of Standards and Technology,\n“Estimating IPv6 & DNSSEC Deployment SnapShots,” http://fedv6-\ndeployment.antd.nist.gov/snap-all.html\n[Nmap 2020] Nmap homepage, https://nmap.org\n[Nonnenmacher 1998] J. Nonnenmacher, E. Biersak, D. Towsley, “Parity-\nBased Loss Recovery for Reliable Multicast Transmission,” IEEE/ACM\nTransactions on Networking, Vol. 6, No. 4 (Aug. 1998), pp. 349–361. [Noormohammadpour 2018] M. Noormohammadpour, C. Raghavendra,\nCauligi, “Datacenter Traffic Control: Understanding Techniques and Trade-"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1201,
    "text": "offs,” IEEE Communications Surveys & Tutorials, Vol. 20 (2018), pp. 1492–1525. [Nygren 2010] Erik Nygren, Ramesh K. Sitaraman, and Jennifer Sun, “The\nAkamai Network: A Platform for High-performance Internet Applications,”\nSIGOPS Oper. Syst. Rev. 44, 3 (Aug. 2010), pp. 2–19. [ONF 2020] Open Networking Foundation, Specification,\nhttps://www.opennetworking.org/software-defined-standards/specifications/\n[ONOS 2020] ONOS, https://onosproject.org/collateral/\n[OpenDaylight 2020] OpenDaylight, https://www.opendaylight.org/\n[OpenDaylight 2020] OpenDaylight, https://www.opendaylight.org/what-\nwe-do/current-release/sodium\n[OpenSignal 2019] Opensignal, https://www.opensignal.com/\n[Ordonez-Lucena 2017] J. Ordonez-Lucena, P. Ameigeiras, D. Lopez, J. J.\nRamos-Munoz, J. Lorca and J. Folgueira, “Network Slicing for 5G with\nSDN/NFV: Concepts, Architectures, and Challenges,” IEEE\nCommunications Magazine, Vol. 55, No. 5, pp. 80–87, May 2017. [Osterweil 2012] E. Osterweil, D. McPherson, S. DiBenedetto, C.\nPapadopoulos, D. Massey, “Behavior of DNS Top Talkers,” Passive and\nActive Measurement Conference, 2012. [P4 2020] P4 Language Consortium, https://p4.org/\n[Padhye 2000] J. Padhye, V. Firoiu, D. Towsley, J. Kurose, “Modeling TCP\nReno Performance: A Simple Model and Its Empirical Validation,”\nIEEE/ACM Transactions on Networking, Vol. 8, No. 2 (Apr. 2000), pp. 133–145. [Padhye 2001] J. Padhye, S. Floyd, “On Inferring TCP Behavior,” Proc. 2001 ACM SIGCOMM Conference (San Diego, CA, Aug. 2001)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1202,
    "text": "[Palat 2009] S. Palat, P. Godin, “The LTE Network Architecture: A\nComprehensive Tutorial,” in LTE—The UMTS Long Term Evolution: From\nTheory to Practice. Also available as a standalone Alcatel white paper. [Panda 2013] A. Panda, C. Scott, A. Ghodsi, T. Koponen, S. Shenker,\n“CAP for Networks,” Proc. 2013 ACM HotSDN Conference, pp. 91–96. [Parekh 1993] A. Parekh, R. Gallagher, “A Generalized Processor Sharing\nApproach to Flow Control in Integrated Services Networks: The Single-\nNode Case,” IEEE/ACM Transactions on Networking, Vol. 1, No. 3 (June\n1993), pp. 344–357. [Partridge 1998] C. Partridge, et al. “A Fifty Gigabit per second IP\nRouter,” IEEE/ACM Transactions on Networking, Vol. 6, No. 3 (Jun. 1998),\npp. 237–248. [Patel 2013] P. Patel, D. Bansal, L. Yuan, A. Murthy, A. Greenberg, D.\nMaltz, R. Kern, H. Kumar, M. Zikos, H. Wu, C. Kim, N. Karri, “Ananta:\nCloud Scale Load Balancing,” Proc. 2013 ACM SIGCOMM Conference. [Pathak 2010] A. Pathak, Y. A. Wang, C. Huang, A. Greenberg, Y. C. Hu, J.\nLi, K. W. Ross, “Measuring and Evaluating TCP Splitting for Cloud\nServices,” Passive and Active Measurement (PAM) Conference (Zurich,\n2010). [Peering DB 2020] “The Interconnection Database,”\nhttps://www.peeringdb.com/\n[Peha 2006] J. Peha, “The Benefits and Risks of Mandating Network\nNeutrality, and the Quest for a Balanced Policy,” Proc. 2006\nTelecommunication Policy Research Conference (TPRC),\nhttps://ssrn.com/abstract=2103831\n[Perkins 1994] A. Perkins, “Networking with Bob Metcalfe,” The Red\nHerring Magazine (Nov. 1994)."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1204,
    "text": "[Qazi 2013] Z. Qazi, C. Tu, L. Chiang, R. Miao, V. Sekar, M. Yu,\n“SIMPLE-fying Middlebox Policy Enforcement Using SDN,” Proc. ACM\nSIGCOMM Conference (Aug. 2013), pp. 27–38. [Quic 2020] https://quicwg.org/\n[QUIC-recovery 2020] J. Iyengar, Ed.,I. Swett, Ed., “QUIC Loss Detection\nand Congestion Control,” Internet Draft draft-ietf-quic-recovery-latest,\nApril 20, 2020. [Quittner 1998] J. Quittner, M. Slatalla, Speeding the Net: The Inside Story\nof Netscape and How It Challenged Microsoft, Atlantic Monthly Press,\n1998. [Quova 2020] www.quova.com\n[Raiciu 2010] C. Raiciu, C. Pluntke, S. Barre, A. Greenhalgh, D. Wischik,\nM. Handley, “Data Center Networking with Multipath TCP,” Proc. 2010\nACM SIGCOMM Conference. [Ramakrishnan 1990] K. K. Ramakrishnan, R. Jain, “A Binary Feedback\nScheme for Congestion Avoidance in Computer Networks,” ACM\nTransactions on Computer Systems, Vol. 8, No. 2 (May 1990), pp. 158–181. [Raman 2007] B. Raman, K. Chebrolu, “Experiences in Using WiFi for\nRural Internet in India,” IEEE Communications Magazine, Special Issue on\nNew Directions in Networking Technologies in Emerging Economies (Jan.\n2007). [Ramjee 1994] R. Ramjee, J. Kurose, D. Towsley, H. Schulzrinne,\n“Adaptive Playout Mechanisms for Packetized Audio Applications in Wide-\nArea Networks,” Proc. 1994 IEEE INFOCOM. [Rescorla 2001] E. Rescorla, SSL and TLS: Designing and Building Secure\nSystems, Addison-Wesley, Boston, 2001. [RFC 001] S. Crocker, “Host Software,” RFC 001 (the very first RFC! )."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1205,
    "text": "[RFC 768] J. Postel, “User Datagram Protocol,” RFC 768, Aug. 1980. [RFC 791] J. Postel, “Internet Protocol: DARPA Internet Program Protocol\nSpecification,” RFC 791, Sept. 1981. [RFC 792] J. Postel, “Internet Control Message Protocol,” RFC 792, Sept.\n1981. [RFC 793] J. Postel, “Transmission Control Protocol,” RFC 793, Sept.\n1981. [RFC 801] J. Postel, “NCP/TCP Transition Plan,” RFC 801, Nov. 1981. [RFC 826] D. C. Plummer, “An Ethernet Address Resolution Protocol—or\n— Converting Network Protocol Addresses to 48-bit Ethernet Address for\nTransmission on Ethernet Hardware,” RFC 826, Nov. 1982. [RFC 829] V. Cerf, “Packet Satellite Technology Reference Sources,” RFC\n829, Nov. 1982. [RFC 854] J. Postel, J. Reynolds, “TELNET Protocol Specification,” RFC\n854, May 1993. [RFC 950] J. Mogul, J. Postel, “Internet Standard Subnetting Procedure,”\nRFC 950, Aug. 1985. [RFC 959] J. Postel and J. Reynolds, “File Transfer Protocol (FTP),” RFC\n959, Oct. 1985. [RFC 1034] P. V. Mockapetris, “Domain Names—Concepts and Facilities,”\nRFC 1034, Nov. 1987. [RFC 1035] P. Mockapetris, “Domain Names—Implementation and\nSpecification,” RFC 1035, Nov. 1987. [RFC 1071] R. Braden, D. Borman, and C. Partridge, “Computing the\nInternet Checksum,” RFC 1071, Sept. 1988. [RFC 1122] R. Braden, “Requirements for Internet Hosts—Communication\nLayers,” RFC 1122, Oct. 1989."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1206,
    "text": "[RFC 1191] J. Mogul, S. Deering, “Path MTU Discovery,” RFC 1191, Nov.\n1990. [RFC 1320] R. Rivest, “The MD4 Message-Digest Algorithm,” RFC 1320,\nApr. 1992. [RFC 1321] R. Rivest, “The MD5 Message-Digest Algorithm,” RFC 1321,\nApr. 1992. [RFC 1422] S. Kent, “Privacy Enhancement for Internet Electronic Mail:\nPart II: Certificate-Based Key Management,” RFC 1422. [RFC 1546] C. Partridge, T. Mendez, W. Milliken, “Host Anycasting\nService,” RFC 1546, 1993. [RFC 1584] J. Moy, “Multicast Extensions to OSPF,” RFC 1584, Mar. 1994. [RFC 1633] R. Braden, D. Clark, S. Shenker, “Integrated Services in the\nInternet Architecture: an Overview,” RFC 1633, June 1994. [RFC 1752] S. Bradner, A. Mankin, “The Recommendations for the IP\nNext Generation Protocol,” RFC 1752, Jan. 1995. [RFC 1918] Y. Rekhter, B. Moskowitz, D. Karrenberg, G. J. de Groot, E.\nLear, “Address Allocation for Private Internets,” RFC 1918, Feb. 1996. [RFC 1930] J. Hawkinson, T. Bates, “Guidelines for Creation, Selection,\nand Registration of an Autonomous System (AS),” RFC 1930, Mar. 1996. [RFC 1945] T. Berners-Lee, R. Fielding, H. Frystyk, “Hypertext Transfer\nProtocol—HTTP/1.0,” RFC 1945, May 1996. [RFC 1958] B. Carpenter, “Architectural Principles of the Internet,” RFC\n1958, June 1996. [RFC 2003] C. Perkins, “IP Encapsulation Within IP,” RFC 2003, Oct.\n1996."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1207,
    "text": "[RFC 2004] C. Perkins, “Minimal Encapsulation Within IP,” RFC 2004,\nOct. 1996. [RFC 2018] M. Mathis, J. Mahdavi, S. Floyd, A. Romanow, “TCP\nSelective Acknowledgment Options,” RFC 2018, Oct. 1996. [RFC 2104] H. Krawczyk, M. Bellare, R. Canetti, “HMAC: Keyed-\nHashing for Message Authentication,” RFC 2104, Feb. 1997. [RFC 2131] R. Droms, “Dynamic Host Configuration Protocol,” RFC\n2131, Mar. 1997. [RFC 2136] P. Vixie, S. Thomson, Y. Rekhter, J. Bound, “Dynamic Updates\nin the Domain Name System,” RFC 2136, Apr. 1997. [RFC 2328] J. Moy, “OSPF Version 2,” RFC 2328, Apr. 1998. [RFC 2420] H. Kummert, “The PPP Triple-DES Encryption Protocol\n(3DESE),” RFC 2420, Sept. 1998. [RFC 2460] S. Deering, R. Hinden, “Internet Protocol, Version 6 (IPv6)\nSpecification,” RFC 2460, Dec. 1998. [RFC 2578] K. McCloghrie, D. Perkins, J. Schoenwaelder, “Structure of\nManagement Information Version 2 (SMIv2),” RFC 2578, Apr. 1999. [RFC 2579] K. McCloghrie, D. Perkins, J. Schoenwaelder, “Textual\nConventions for SMIv2,” RFC 2579, Apr. 1999. [RFC 2580] K. McCloghrie, D. Perkins, J. Schoenwaelder, “Conformance\nStatements for SMIv2,” RFC 2580, Apr. 1999. [RFC 2581] M. Allman, V. Paxson, W. Stevens, “TCP Congestion Control,”\nRFC 2581, Apr. 1999. [RFC 2663] P. Srisuresh, M. Holdrege, “IP Network Address Translator\n(NAT) Terminology and Considerations,” RFC 2663. [RFC 2702] D. Awduche, J. Malcolm, J. Agogbua, M. O’Dell, J. McManus,\n“Requirements for Traffic Engineering Over MPLS,” RFC 2702, Sept."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1208,
    "text": "1999. [RFC 2827] P. Ferguson, D. Senie, “Network Ingress Filtering: Defeating\nDenial of Service Attacks which Employ IP Source Address Spoofing,”\nRFC 2827, May 2000. [RFC 2865] C. Rigney, S. Willens, A. Rubens, W. Simpson, “Remote\nAuthentication Dial In User Service (RADIUS),” RFC 2865, June 2000. [RFC 2992] C. Hopps, “Analysis of an Equal-Cost Multi-Path Algorithm,”\nRFC 2992, Nov 2000. [RFC 3007] B. Wellington, “Secure Domain Name System (DNS)\nDynamic Update,” RFC 3007, Nov. 2000. [RFC 3022] P. Srisuresh, K. Egevang, “Traditional IP Network Address\nTranslator (Traditional NAT),” RFC 3022, Jan. 2001. [RFC 3031] E. Rosen, A. Viswanathan, R. Callon, “Multiprotocol Label\nSwitching Architecture,” RFC 3031, Jan. 2001. [RFC 3032] E. Rosen, D. Tappan, G. Fedorkow, Y. Rekhter, D. Farinacci,\nT. Li, A. Conta, “MPLS Label Stack Encoding,” RFC 3032, Jan. 2001. [RFC 3168] K. Ramakrishnan, S. Floyd, D. Black, “The Addition of\nExplicit Congestion Notification (ECN) to IP,” RFC 3168, Sept. 2001. [RFC 3209] D. Awduche, L. Berger, D. Gan, T. Li, V. Srinivasan, G.\nSwallow, “RSVP-TE: Extensions to RSVP for LSP Tunnels,” RFC 3209,\nDec. 2001. [RFC 3232] J. Reynolds, “Assigned Numbers: RFC 1700 Is Replaced by an\nOn-line Database,” RFC 3232, Jan. 2002. [RFC 3234] B. Carpenter, S. Brim, “Middleboxes: Taxonomy and Issues,”\nRFC 3234, Feb. 2002. [RFC 3261] J. Rosenberg, H. Schulzrinne, G. Carmarillo, A. Johnston, J.\nPeterson, R. Sparks, M. Handley, E. Schooler, “SIP: Session Initiation"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1209,
    "text": "Protocol,” RFC 3261, July 2002. [RFC 3272] J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B.\nChristian, W. S. Lai, “Overview and Principles of Internet Traffic\nEngineering,” RFC 3272, May 2002. [RFC 3286] L. Ong, J. Yoakum, “An Introduction to the Stream Control\nTransmission Protocol (SCTP),” RFC 3286, May 2002. [RFC 3346] J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B.\nChristian, W. S. Lai, “Applicability Statement for Traffic Engineering with\nMPLS,” RFC 3346, Aug. 2002. [RFC 3390] M. Allman, S. Floyd, C. Partridge, “Increasing TCP’s Initial\nWindow,” RFC 3390, Oct. 2002. [RFC 3410] J. Case, R. Mundy, D. Partain, “Introduction and Applicability\nStatements for Internet Standard Management Framework,” RFC 3410,\nDec. 2002. [RFC 3439] R. Bush, D. Meyer, “Some Internet Architectural Guidelines\nand Philosophy,” RFC 3439, Dec. 2003. [RFC 3447] J. Jonsson, B. Kaliski, “Public-Key Cryptography Standards\n(PKCS) #1: RSA Cryptography Specifications Version 2.1,” RFC 3447,\nFeb. 2003. [RFC 3468] L. Andersson, G. Swallow, “The Multiprotocol Label\nSwitching (MPLS) Working Group Decision on MPLS Signaling\nProtocols,” RFC 3468, Feb. 2003. [RFC 3469] V. Sharma, Ed., F. Hellstrand, Ed, “Framework for Multi-\nProtocol Label Switching (MPLS)-based Recovery,” RFC 3469, Feb. 2003.\nftp://ftp.rfc-editor.org/in-notes/rfc3469.txt\n[RFC 3535] J. Schönwälder, “Overview of the 2002 IAB Network\nManagement Workshop,” RFC 3535, May 2003."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1210,
    "text": "[RFC 3550] H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson, “RTP: A\nTransport Protocol for Real-Time Applications,” RFC 3550, July 2003. [RFC 3588] P. Calhoun, J. Loughney, E. Guttman, G. Zorn, J. Arkko,\n“Diameter Base Protocol,” RFC 3588, Sept. 2003. [RFC 3746] L. Yang, R. Dantu, T. Anderson, R. Gopal, “Forwarding and\nControl Element Separation (ForCES) Framework,” Internet, RFC 3746,\nApr. 2004. [RFC 3748] B. Aboba, L. Blunk, J. Vollbrecht, J. Carlson, H. Levkowetz,\nEd., “Extensible Authentication Protocol (EAP),” RFC 3748, June 2004. [RFC 4022] R. Raghunarayan, Ed., “Management Information Base for the\nTransmission Control Protocol (TCP),” RFC 4022, March 2005. [RFC 4033] R. Arends, R. Austein, M. Larson, D. Massey, S. Rose, “DNS\nSecurity Introduction and Requirements, RFC 4033, March 2005. [RFC 4113] B. Fenner, J. Flick, “Management Information Base for the\nUser Datagram Protocol (UDP),” RFC 4113, June 2005. [RFC 4213] E. Nordmark, R. Gilligan, “Basic Transition Mechanisms for\nIPv6 Hosts and Routers,” RFC 4213, Oct. 2005. [RFC 4271] Y. Rekhter, T. Li, S. Hares, Ed., “A Border Gateway Protocol 4\n(BGP-4),” RFC 4271, Jan. 2006. [RFC 4291] R. Hinden, S. Deering, “IP Version 6 Addressing\nArchitecture,” RFC 4291, Feb. 2006. [RFC 4293] S. Routhier, Ed., “Management Information Base for the\nInternet Protocol (IP),” RFC 4293, April 2006. [RFC 4340] E. Kohler, M. Handley, S. Floyd, “Datagram Congestion\nControl Protocol (DCCP),” RFC 4340, Mar. 2006. [RFC 4346] T. Dierks, E. Rescorla, “The Transport Layer Security (TLS)\nProtocol Version 1.1,” RFC 4346, Apr. 2006."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1211,
    "text": "[RFC 4514] K. Zeilenga, Ed., “Lightweight Directory Access Protocol\n(LDAP): String Representation of Distinguished Names,” RFC 4514, June\n2006. [RFC 4632] V. Fuller, T. Li, “Classless Inter-domain Routing (CIDR): The\nInternet Address Assignment and Aggregation Plan,” RFC 4632, Aug. 2006. [RFC 4960] R. Stewart, ed., “Stream Control Transmission Protocol,” RFC\n4960, Sept. 2007. [RFC 4987] W. Eddy, “TCP SYN Flooding Attacks and Common\nMitigations,” RFC 4987, Aug. 2007. [RFC 5128] P. Srisuresh, B. Ford, D. Kegel, “State of Peer-to-Peer (P2P)\nCommunication across Network Address Translators (NATs),” March 2008,\nRFC 5128. [RFC 5246] T. Dierks, E. Rescorla, “The Transport Layer Security (TLS)\nProtocol, Version 1.2,” RFC 5246, Aug. 2008. [RFC 5277] S. Chisholm H. Trevino, “NETCONF Event Notifications,”\nRFC 5277, July 2008. [RFC 5321] J. Klensin, “Simple Mail Transfer Protocol,” RFC 5321, Oct.\n2008. [RFC 5389] J. Rosenberg, R. Mahy, P. Matthews, D. Wing, “Session\nTraversal Utilities for NAT (STUN),” RFC 5389, Oct. 2008. [RFC 5681] M. Allman, V. Paxson, E. Blanton, “TCP Congestion Control,”\nRFC 5681, Sept. 2009. [RFC 5944] C. Perkins, Ed., “IP Mobility Support for IPv4, Revised,” RFC\n5944, Nov. 2010. [RFC 6020] M. Bjorklund, “YANG—A Data Modeling Language for the\nNetwork Configuration Protocol (NETCONF),” RFC 6020, Oct. 2010."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1212,
    "text": "[RFC 6241] R. Enns, M. Bjorklund, J. Schönwälder, A. Bierman, “Network\nConfiguration Protocol (NETCONF),” RFC 6241, June 2011. [RFC 6265] A Barth, “HTTP State Management Mechanism,” RFC 6265,\nApr. 2011. [RFC 6298] V. Paxson, M. Allman, J. Chu, M. Sargent, “Computing TCP’s\nRetransmission Timer,” RFC 6298, June 2011. [RFC 6582] T. Henderson, S. Floyd, A. Gurtov, Y. Nishida, “The NewReno\nModification to TCP’s Fast Recovery Algorithm,” RFC 6582, April 2012. [RFC 6733] V. Fajardo, J. Arkko, J. Loughney, G. Zorn, “Diameter Base\nProtocol,” RFC 6733, Oct. 2012. [RFC 7020] R. Housley, J. Curran, G. Huston, D. Conrad, “The Internet\nNumbers Registry System,” RFC 7020, Aug. 2013. [RFC 7094] D. McPherson, D. Oran, D. Thaler, E. Osterweil,\n“Architectural Considerations of IP Anycast,” RFC 7094, Jan. 2014. [RFC 7230] R. Fielding, Ed., J. Reschke, “Hypertext Transfer Protocol\n(HTTP/1.1): Message Syntax and Routing,” RFC 7230, June 2014. [RFC 7232] R. Fielding, Ed., J. Reschke, Ed., “Hypertext Transfer Protocol\n(HTTP/1.1): Conditional Requests,” RFC 7232, June 2014. [RFC 7234] R. Fielding, Ed., M. Nottingham, Ed., J. Reschke, Ed.,\n“Hypertext Transfer Protocol (HTTP/1.1): Caching,” RFC 7234, June 2014. [RFC 7323] D. Borman, S. Braden, V. Jacobson, R. Scheffenegger, “TCP\nExtensions for High Performance,” RFC 7323, Sept. 2014. [RFC 7540] M. Belshe, R. Peon, M. Thomson (Eds), “Hypertext Transfer\nProtocol Version 2 (HTTP/2),” RFC 7540, May 2015. [RFC 8033] R. Pan, P. Natarajan, F. Baker, G. White, “Proportional Integral\nController Enhanced (PIE): A Lightweight Control Scheme to Address the\nBufferbloat Problem,” RFC 8033, Feb. 2017."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 1",
    "source": "kurose",
    "page": 1213,
    "text": "[RFC 8034] G. White, R. Pan, “Active Queue Management (AQM) Based\non Proportional Integral Controller Enhanced (PIE) for Data-Over-Cable\nService Interface Specifications (DOCSIS) Cable Modems,” RFC 8034,\nFeb. 2017. [RFC 8257] S. Bensley, D. Thaler, P. Balasubramanian, L. Eggert, G. Judd,\n“Data Center TCP (DCTCP): TCP Congestion Control for Data Centers,\nRFC 8257, October 2017. [RFC 8312] L. Xu, S. Ha, A. Zimmermann,L. Eggert, R. Scheffenegger,\n“CUBIC for Fast Long-Distance Networks,” RFC 8312, Feb. 2018. [Richter 2015] P. Richter, M. Allman, R. Bush, V. Paxson, “A Primer on\nIPv4 Scarcity,” ACM SIGCOMM Computer Communication Review, Vol. 45, No. 2 (Apr. 2015), pp. 21–32. [Roberts 1967] L. Roberts, T. Merril, “Toward a Cooperative Network of\nTime-Shared Computers,” AFIPS Fall Conference (Oct. 1966). [Rom 1990] R. Rom, M. Sidi, Multiple Access Protocols: Performance and\nAnalysis, Springer-Verlag, New York, 1990. [Rommer 2019] S. Rommer, P. Hedman, M. Olsson, L. Frid, S. Sultana, C.\nMulligan, 5G Core Networks: Powering Digitalization, Academic Press,\n2019. [Root Servers 2020] Root Servers home page, http://www.root-servers.org/\n[Roy 2015] A. Roy, H.i Zeng, J. Bagga, G. Porter, A. Snoeren, “Inside the\nSocial Network’s (Datacenter) Network,” Proc. 2015 ACM SIGCOMM\nConference, pp. 123–137. [RSA 1978] R. Rivest, A. Shamir, L. Adelman, “A Method for Obtaining\nDigital Signatures and Public-key Cryptosystems,” Communications of the\nACM, Vol. 21, No. 2 (Feb. 1978), pp. 120–126."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1215,
    "text": "[Schwartz 1977] M. Schwartz, Computer-Communication Network Design\nand Analysis, Prentice-Hall, Englewood Cliffs, NJ, 1997. [Schwartz 1980] M. Schwartz, Information, Transmission, Modulation,\nand Noise, McGraw Hill, New York, NY 1980. [Schwartz 1982] M. Schwartz, “Performance Analysis of the SNA Virtual\nRoute Pacing Control,” IEEE Transactions on Communications, Vol. 30,\nNo. 1 (Jan. 1982), pp. 172–184. [Scourias 2012] J. Scourias, “Overview of the Global System for Mobile\nCommunications: GSM.” http://www.privateline.com/PCS/GSM0.html\n[Segaller 1998] S. Segaller, Nerds 2.0.1, A Brief History of the Internet, TV\nBooks, New York, 1998. [Serpanos 2011] D. Serpanos, T. Wolf, Architecture of Network Systems,\nMorgan Kaufmann Publishers, 2011. [Shacham 1990] N. Shacham, P. McKenney, “Packet Recovery in High-\nSpeed Networks Using Coding and Buffer Management,” Proc. 1990 IEEE\nInfocom (San Francisco, CA, Apr. 1990), pp. 124–131. [Shaikh 2001] A. Shaikh, R. Tewari, M. Agrawal, “On the Effectiveness of\nDNS-based Server Selection,” Proc. 2001 IEEE INFOCOM. [Sherry 2012] J. Sherry, S. Hasan, C. Scott, A. Krishnamurthy, S.\nRatnasamy, V. Sekar, “Making middleboxes someone else’s problem:\nnetwork processing as a cloud service,” Proc. 2012 ACM SIGCOMM\nConference. [Singh 1999] S. Singh, The Code Book: The Evolution of Secrecy from\nMary, Queen of Scotsto Quantum Cryptography, Doubleday Press, 1999. [Singh 2015] A. Singh et al., “Jupiter Rising: A Decade of Clos Topologies\nand Centralized Control in Google’s Datacenter Network,” Proc. 2015 ACM\nSIGCOMM Conference, pp. 183–197."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1217,
    "text": "[Stewart 1999] J. Stewart, BGP4: Interdomain Routing in the Internet,\nAddison-Wesley, 1999. [Stone 1998] J. Stone, M. Greenwald, C. Partridge, J. Hughes,\n“Performance of Checksums and CRC’s Over Real Data,” IEEE/ACM\nTransactions on Networking, Vol. 6, No. 5 (Oct. 1998), pp. 529–543. [Stone 2000] J. Stone, C. Partridge, “When Reality and the Checksum\nDisagree,” Proc. 2000 ACM SIGCOMM Conference (Stockholm, Sweden,\nAug. 2000). [Strayer 1992] W. T. Strayer, B. Dempsey, A. Weaver, XTP: The Xpress\nTransfer Protocol, Addison-Wesley, Reading, MA, 1992. [Stubblefield 2002] A. Stubblefield, J. Ioannidis, A. Rubin, “Using the\nFluhrer, Mantin, and Shamir Attack to Break WEP,” Proceedings of 2002\nNetwork and Distributed Systems Security Symposium (2002), pp. 17–22. [Subramanian 2000] M. Subramanian, Network Management: Principles\nand Practice, Addison-Wesley, Reading, MA, 2000. [Subramanian 2002] L. Subramanian, S. Agarwal, J. Rexford, R. Katz,\n“Characterizing the Internet Hierarchy from Multiple Vantage Points,”\nProc. 2002 IEEE INFOCOM. [Sundaresan 2006] K. Sundaresan, K. Papagiannaki, “The Need for Cross-\nlayer Information in Access Point Selection,” Proc. 2006 ACM Internet\nMeasurement Conference (Rio De Janeiro, Oct. 2006). [Sunshine 1978] C. Sunshine, Y. Dalal, “Connection Management in\nTransport Protocols,” Computer Networks, North-Holland, Amsterdam,\n1978. [Tan 2006] K. Tan, J. Song, Q. Zhang and M. Sridharan, “A Compound\nTCP Approach for High-Speed and Long Distance Networks,” Proc. 2006\nIEEE INFOCOM."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1218,
    "text": "[Tariq 2008] M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, M. Ammar,\n“Answering What-If Deployment and Configuration Questions with\nWISE,” Proc. 2008 ACM SIGCOMM Conference (Aug. 2008). [Teixeira 2006] R. Teixeira, J. Rexford, “Managing Routing Disruptions in\nInternet Service Provider Networks,” IEEE Communications Magazine Vol. 44, No. 3 (Mar. 2006) pp. 160–165. [Think 2012] Technical History of Network Protocols, “Cyclades,”\nhttp://www.cs.utexas.edu/users/chris/think/Cyclades/index.shtml\n[Tian 2012] Y. Tian, R. Dey, Y. Liu, K. W. Ross, “China’s Internet:\nTopology Mapping and Geolocating,” IEEE INFOCOM Mini-Conference\n2012 (Orlando, FL, 2012). [TLD list 2020] TLD list maintained by Wikipedia,\nhttps://en.wikipedia.org/wiki/List_of_Internet_top-level_domains\n[Tobagi 1990] F. Tobagi, “Fast Packet Switch Architectures for Broadband\nIntegrated Networks,” Proc. IEEE, Vol. 78, No. 1 (Jan. 1990), pp. 133–167. [TOR 2020] Tor: Anonymity Online, http://www.torproject.org\n[Torres 2011] R. Torres, A. Finamore, J. R. Kim, M. M. Munafo, S. Rao,\n“Dissecting Video Server Selection Strategies in the YouTube CDN,” Proc. 2011 Int. Conf. on Distributed Computing Systems. [Tourrilhes 2014] J. Tourrilhes, P. Sharma, S. Banerjee, J. Petit, “SDN and\nOpenflow Evolution: A Standards Perspective,” IEEE Computer Magazine,\nNov. 2014, Vol. 47, No. 11, pp. 22–29. [Turner 1988] J. S. Turner, “Design of a Broadcast packet switching\nnetwork,” IEEE Transactions on Communications, Vol. 36, No. 6 (June\n1988), pp. 734–743. [Turner 2012] B. Turner, “2G, 3G, 4G Wireless Tutorial,”\nhttp://blogs.nmscommunications.com/communications/2008/10/2g-3g-4g-"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1219,
    "text": "wireless-tutorial.html\n[van der Berg 2008] R. van der Berg, “How the ’Net Works: An\nIntroduction to Peering and Transit,”\nhttp://arstechnica.com/guides/other/peering-and-transit.ars\n[van der Merwe 1998] J. van der Merwe, S. Rooney, I. Leslie, S. Crosby,\n“The Tempest: A Practical Framework for Network Programmability,”\nIEEE Network, Vol. 12, No. 3 (May 1998), pp. 20–28. [Vanhoef 2017] M. Vanhoef, F. Piessens, “ Key Reinstallation Attacks:\nForcing Nonce Reuse in WPA2,” 2017 ACM SIGSAC Conference on\nComputer and Communications Security (CCS ’17), pp. 1313–1328. [Varghese 1997] G. Varghese, A. Lauck, “Hashed and Hierarchical Timing\nWheels: Efficient Data Structures for Implementing a Timer Facility,”\nIEEE/ACM Transactions on Networking, Vol. 5, No. 6 (Dec. 1997), pp. 824–834. [Vasudevan 2005] S. Vasudevan, C. Diot, J. Kurose, D. Towsley,\n“Facilitating Access Point Selection in IEEE 802.11 Wireless Networks,”\nProc. 2005 ACM Internet Measurement Conference, (San Francisco CA,\nOct. 2005). [Venkataramani 2014] A. Venkataramani, J. Kurose, D. Raychaudhuri, K.\nNagaraja, M. Mao, S. Banerjee, “MobilityFirst: A Mobility-Centric and\nTrustworthy Internet Architecture,” ACM Computer Communication\nReview, July 2014. [Villamizar 1994] C. Villamizar, C. Song. “High Performance TCP in\nANSNET,” ACM SIGCOMM Computer Communications Review, Vol. 24,\nNo. 5 (1994), pp. 45–60. [Viterbi 1995] A. Viterbi, CDMA: Principles of Spread Spectrum\nCommunication, Addison-Wesley, Reading, MA, 1995."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1220,
    "text": "[Vixie 2009] P. Vixie, “What DNS Is Not,” Communications of the ACM,\nVol. 52, No. 12 (Dec. 2009), pp. 43–47. [Wakeman 1992] I. Wakeman, J. Crowcroft, Z. Wang, D. Sirovica, “Is\nLayering Harmful (remote procedure call),” IEEE Network, Vol. 6, No. 1\n(Jan. 1992), pp. 20–24. [Waldrop 2007] M. Waldrop, “Data Center in a Box,” Scientific American\n(July 2007). [Walfish 2004] M. Walfish, J. Stribling, M. Krohn, H. Balakrishnan, R.\nMorris, S. Shenker, “Middleboxes No Longer Considered Harmful,”\nUSENIX OSDI 2004 San Francisco, CA, December 2004. [Wang 2011] Z. Wang, Z. Qian, Q. Xu, Z. Mao, M. Zhang, “An untold\nstory of middleboxes in cellular networks,” Proc. 2011 ACM SIGCOMM\nConference. [Wei 2006] D. X. Wei, C. Jin, S. H. Low and S. Hegde, “FAST TCP:\nMotivation, Architecture, Algorithms, Performance,” IEEE/ACM\nTransactions on Networking, Vol. 14, No. 6, pp. 1246–1259, Dec. 2006. [Wei 2006] W. Wei, C. Zhang, H. Zang, J. Kurose, D. Towsley, “Inference\nand Evaluation of Split-Connection Approaches in Cellular Data\nNetworks,” Proc. Active and Passive Measurement Workshop (Adelaide,\nAustralia, Mar. 2006). [Weiser 1991] M. Weiser, “The Computer for the Twenty-First Century,”\nScientific American (Sept. 1991): 94–10. http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html\n[Wifi 2019] The WiFi Alliance, “WPA3™ Security Considerations\nOverview,” April 2019. [WiFi 2020] The WiFi Alliance, https://www.wi-fi.org/"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1221,
    "text": "[Williams 1993] R. Williams, “A Painless Guide to CRC Error Detection\nAlgorithms,” http://www.ross.net/crc/crcpaper.html\n[Wireshark 2020] Wireshark homepage, http://www.wireshark.org\n[Wischik 2005] D. Wischik, N. McKeown, “Part I: Buffer Sizes for Core\nRouters,” ACM SIGCOMM Computer Communications Review, Vol. 35,\nNo. 3 (July 2005). [Woo 1994] T. Woo, R. Bindignavle, S. Su, S. Lam, “SNP: an interface for\nsecure network programming,” Proc. 1994 Summer USENIX (Boston, MA,\nJune 1994), pp. 45–58. [Wright 2015] J. Wright, J., Hacking Exposed Wireless, McGraw-Hill\nEducation, 2015. [Wu 2005] J. Wu, Z. M. Mao, J. Rexford, J. Wang, “Finding a Needle in a\nHaystack: Pinpointing Significant BGP Routing Changes in an IP\nNetwork,” Proc. USENIX NSDI (2005). [W3Techs] World Wide Web Technology Surveys, 2020.\nhttps://w3techs.com/technologies/details/ce-http2/all/all. [Xanadu 2012] Xanadu Project homepage, http://www.xanadu.com/\n[Xiao 2000] X. Xiao, A. Hannan, B. Bailey, L. Ni, “Traffic Engineering\nwith MPLS in the Internet,” IEEE Network (Mar./Apr. 2000). [Xu 2004] L. Xu, K Harfoush, I. Rhee, “Binary Increase Congestion\nControl (BIC) for Fast Long-Distance Networks,” IEEE INFOCOM 2004,\npp. 2514–2524. [Yang 2014] P. Yang, J. Shao, W. Luo, L. Xu, J. Deogun, Y. Lu, “TCP\ncongestion avoidance algorithm identification,” IEEE/ACM Trans. Netw. Vol. 22, No. 4 (Aug. 2014), pp. 1311–1324. [Yavatkar 1994] R. Yavatkar, N. Bhagwat, “Improving End-to-End\nPerformance of TCP over Mobile Internetworks,” Proc. Mobile 94"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1222,
    "text": "Workshop on Mobile Computing Systems and Applications (Dec. 1994). [YouTube 2009] YouTube 2009, Google container data center tour, 2009. [Yu 2004] Yu, Fang, H. Katz, Tirunellai V. Lakshman. “Gigabit Rate Packet\nPattern-Matching Using TCAM,” Proc. 2004 Int. Conf. Network Protocols,\npp. 174–183. [Yu 2011] M. Yu, J. Rexford, X. Sun, S. Rao, N. Feamster, “A Survey of\nVLAN Usage in Campus Networks,” IEEE Communications Magazine,\nJuly 2011. [Zegura 1997] E. Zegura, K. Calvert, M. Donahoo, “A Quantitative\nComparison of Graph-based Models for Internet Topology,” IEEE/ACM\nTransactions on Networking, Vol. 5, No. 6, (Dec. 1997). See also\nhttp://www.cc.gatech.edu/projects/gtitm for a software package that\ngenerates networks with a transit-stub structure. [Zhang 2007] L. Zhang, “A Retrospective View of NAT,” The IETF\nJournal, Vol. 3, No. 2 (Oct. 2007). [Zheng 2008] N. Zheng and J. Wigard, “On the Performance of Integrator\nHandover Algorithm in LTE Networks,” 2008 IEEE 68th Vehicular\nTechnology Conference, Calgary, BC, 2008, pp. 1–5. [Zhu 2015] Y. Zhu, H. Eran, D. Firestone, D. Firestone, C. Guo, M.\nLipshteyn, Y. Liron, J. Padhye, S. Raindel Mohamad, H. Yahia, M. Zhang,\nJ. Padhye, “Congestion Control for Large-Scale RDMA Deployments,”\nProc. 2015 ACM SIGCOMM Conference. [Zilberman 2019] N. Zilberman, G. Bracha, G. Schzukin. “Stardust:\nDivide and conquer in the data center network,” 2019 USENIX Symposium\non Networked Systems Design and Implementation. [Zink 2009] M. Zink, K. Suh, Y. Gu, J. Kurose, “Characteristics of\nYouTube Network Traffic at a Campus Network—Measurements, Models,"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1223,
    "text": "and Implications,” Computer Networks, Vol. 53, No. 4, pp. 501–514, 2009. [Zou 2016] Y. Zou, J. Zhu, X. Wang, L. Hanzo, “A Survey on Wireless\nSecurity: Technical Challenges, Recent Advances, and Future Trends,”\nProceedings of the IEEE, Vol. 104, No. 9, 2016."
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1224,
    "text": "Index\nA\nAbramson, Norman, 91, 500\naccess and mobility management function (AMF), 608\naccess control lists, 700\naccess networks, 42–48, 438\ncable, 44–45, 93\nDSL, 43–44, 93\nenterprise, 46–47\nEthernet, 46–47\nFTTH, 45–46, 93\n3G, 48\n4G, 48\n5G, 48\n5G cellular networks, 46\n5G fixed wireless, 46\nHFC, 45\nLTE, 48\nWiFi, 46–47\naccess points (AP), 574\nin infrastructure LANs, 574\nMAC addresses, 574\nmobility between, 587"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1225,
    "text": "power management and, 590\nscanning for, 577\nSSID, 575\nWiFi, 480\nwireless LANs, 563\nACK (positive acknowledgments), 234–238\ncorrupted, 236\nDHCP, 374\nduplicate, 238, 273\nin 802.11 RTC/CTS system, 590\nTCP generation recommendation, 274\nACK bit, 260\nTCP, 700\nack clocking, 331\nACK frames, 582\nacknowledged segments, 295\nacknowledgments\ncumulative, 248, 262\nnegative, 234–238, 265\npiggybacked, 265\npositive, 234–238, 273, 374\nTCP, 261–263, 276\nacknowledgment number, 261–263\npiggybacked, 265\nTelnet and, 263–265\nacknowledgment number field, 260\nACK received events, 269, 270\nactive optical networks (AONs), 46"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1226,
    "text": "active queue management (AQM), 352\nactive scanning, 576\nadapters\n802.11, 563\nARP query and, 512\nCSMA/CD operation and, 515\ndatagram transmission and, 516\nerror detection in, 482\nEthernet frames and, 524\nframes, 494\njabbering, 524\nMAC addresses, 508\nmonitors, 502\nmotherboard chipset, 483\nnetwork, 483\nadaptive congestion control, 227\nadditive-increase, multiplicative-decrease (AIMD), 301\nfairness of, 306–309\naddress aggregation, 368\naddresses. See also IP addresses; MAC addresses\nanycast, 378\nbroadcast, 510\ncare-of, 623, 624\nforeign, 623\nIEEE 802.11 wireless LAN, 584–586\nIP broadcast, 370, 372–373\nLAN, 508\nMAC, 574"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1227,
    "text": "mobile node, 623\nobtaining with DHCP, 371–374\npermanent, 160\nphysical, 508\nrealm with private, 374\nSIP, 123\ntemporary IP, 371\naddressing, 363–374\nclassful, 367–368\nIP, 216\nIPv4, 363–374\nlink-layer, 483, 508–514\nmobility management and, 596\nsubnet, 366\naddress lease time, 373\nAddress Resolution Protocol (ARP), 510\nMAC address, 508–513\npacket, 512\ntable, 512\nAddress Supporting Organization of ICANN, 370–371\nad hoc networks, 564\nmobile, 565\nvehicular, 565\nAdleman, Leonard, 650\nadministrative autonomy, 426\nAdvanced Research Projects Agency (ARPA), 89, 405\nAES (Advanced Encryption Standard), 645\nagent discovery, 624"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1228,
    "text": "aging time, 523\nAH protocol. See Authentication Header protocol\nAIMD. See additive-increase, multiplicative-decrease\nAkamai, 142, 155\naliasing\nhost, 154\nmail server, 154\nAlibaba Cloud, 94\nALOHAnet, 89, 91, 500\nALOHA protocol, 498\ncarrier sense multiple access (CSMA), 499–501\ncarrier sense multiple access with collision detection (CSMA/CD), 501–\nefficiency, 497\npure, 551\nslotted, 496–498\nsuccessful slot, 497\nalternating-bit protocol, 241, 242\nAlto computers, 518\nAmazon, 93\ncloud services, 535, 536\nDNS vulnerabilities, 165\nvideo streaming, 173\nAndreessen, Marc, 92\nAndroid devices, 48\nanomaly-based systems, 707\nanonymity, 704–705\nanycast address, 378"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1229,
    "text": "AONs. See active optical networks\nApache Web server, 223\nAPI. See Application Programming Interface\napplication architecture, 114\napplication delay, 73\napplication gateways, 698\napplication layer, 80, 111\napplication-layer message, 83\napplication-layer protocols, 124\nDNS, 80\nFTP, 80\nHTTP, 80\nSkype, 124\nSMTP, 80\napplication-level transport reliability, 227–228\nApplication Programming Interface (API), 117\napplication protocols, well-known, 218–219\napplications. See also multimedia applications; network applications\nbandwidth-sensitive, 119\ncontrol, 444–446\ndelays, 73\ndistributed, 35\nelastic, 120\nloss-tolerant, 119\nmultimedia, 226\nnetwork, 112–125\nnetwork-service, 450\nSDN control, 444–446"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1230,
    "text": "APs. See access points\nAQM. See active queue management\narchitectural evolution from 2G to 3G to 4G, 598–599\nARP. See Address Resolution Protocol\nARPA. See Advanced Research Projects Agency\nARPAnet, 258\nALOHAnet connection to, 89\nCerf on, 405\ndevelopment of, 89–92\nrouting algorithms, 413, 420\nARP packet, 583\nARP protocol, 545\nARP query, 545\nARP reply, 545\nARP table, 512\nARQ (Automatic Repeat reQuest) protocols, 234\nASN. See autonomous system number\nAS numbers. See autonomous system number\nAS-PATH, 433, 435\nASs. See autonomous systems\nassociate, 533\nassociations\nIEEE 802.11 wireless LAN, 575–578\nsecurity, 683–685\nAtheros AR5006, 483\nATM\ncongestion control, 292\ndelay and bandwidth guarantees, 340"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1231,
    "text": "frame-relay and, 532\nSDN and, 449\nATM Available Bite Rate (ABR), 292\ncongestion control, 292\nAT&T, 62, 410, 476\nauthentication, 428\nend-point, 87–88, 639\n4G/5G cellular networks, 694–697\n4G LTE cellular networks, 596, 694–697\nMD5, 428\nmutual, 690\nin OSPF, 428\nsender, 639\nshared common secret, 691\nsimple, 428\nwireless LANs, 690\nAuthentication and Key Agreement (AKA) protocol\n4G, 695\nAuthentication Header (AH) protocol, 683\nauthentication key, 657\nauthentication protocol, 666–669\nauthentication server (AS), 690\nauthoritative DNS servers, 157, 546\nautonomous system number (ASN), 426\nautonomous systems (ASs), 426\nin BGP route advertisement, 430–432\nhierarchy within, 428–429\niBGP connections within, 431"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1232,
    "text": "routing between, 425–429, 439, 450\navailability zones, 542\naverage throughput, 74\nAzure, 94\nB\nB4, 410, 447\nbackbone providers, 438\nbackoff\nbinary exponential, 503\nrandom, 580\nbandwidth, 58–59\nATM guarantees, 340\nbest-effort service and, 340\nchannel, 603\ncongestion control and, 295\nDoS, 706\ndownstream, 602\nfairness and, 306–309\nflooding, 85\nFM radio, 58\nguaranteed minimal, 339–340\nmemory, 347\nprobing, 295, 301\nwireless, 576\nBaran, Paul, 89\nbase HTML file, 126\nbase station, 563, 593, 594\nbasic service set (BSS), 574"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1233,
    "text": "BBN, 89\nBBR. See TCP BBR\nbeacon frames, 546\nbeam forming, 607\nBellman-Ford equation, 418–419\nBellovin, Steven M., 719\nBER. See bit error rate\nBerners-Lee, Tim, 92\nbest-effort delivery services, 216\nbest-effort services, 340\nBGP, 546. See also Border Gateway Protocol\nbidirectional data transfer, 232\nbinary exponential backoff algorithm, 503\nbind(), 219\nbit error rate (BER), 567\nbit errors\ndata transfer over channel with, 233–238\ndata transfer over lossy channel with, 238–241\nbit-level error detection and correction, 484\nBITNET, 91\nBitTorrent\nchunks, 170\nDHT, 173\nfile distribution with, 171\noptimistically unchoked, 172\nrarest first, 172\ntorrent, defined, 170\ntracker, 171"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1234,
    "text": "unchoked, 172\nblades, 535\nblock ciphers\n3-bit, 645\nfull-table, 645\nk-bit block, 644\nBluetooth\nas cable replacement technology, 590\nneighbor discovery problem, 592\npaging, 592\npiconet, 591\nself-organizing, 592\nstandards, transmission rates, and range, 564\nBoggs, David, 515\nBorder Gateway Protocol (BGP), 407, 413, 420, 429–441, 546\nattributes, 432–433\nconnection, 431\ndetermining best routes, 432–436\nin Google SDN, 447\nhot potato routing, 434–435\ninternal BGP, 431–432\nIP-anycast implementation with, 436–437\noutside-AS destinations, 434\nrole of, 429–430\nroute attributes, 433\nroute information advertisement, 430–432\nroute-selection algorithm, 435–436\nrouting policy, 437–440"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1235,
    "text": "routing tables, 435–436\nborder routers, 428–429, 536\nbotnets, 85\nbottleneck link, 75\nTCP fairness and, 306–308\nbounded delay, 339\nbright line rules, 358\nbroadband Internet, 93\nbroadcast\nin ALOHA, 91\nEthernet as, 519\nforwarding to, 387\nlink, 491\nlink-state, 413, 425\nMAC address, 510\nmultiple access protocols, 492\nin OSPF, 427–428\npacket sniffing and, 87\nbroadcast address, 510\nIP, 370, 372–373\nMAC, 510\nbroadcast link, 491\nbroadcast media, 331\nbroadcast storms, 526\nBrooks, Fred, 719\nbrowsers, 92, 126\nBS. See base station\nbufferbloat, 354"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1236,
    "text": "buffered distributors, 520\nbuffering, 353–354\nbuffer overflows, congestion causing, 290–291\nbuffers\nfinite, 288\ninfinite, 286\noutput, 54\nreceive, 259, 277, 278\nsend, 259\nsizing for routers, 353\nTCP, 130\nBush, Vannevar, 92\nbus, switching via, 348\nC\nCA. See Certification Authority\ncable Internet access, 44–45, 93\ncable modem termination system (CMTS), 45\ncaching, 331\nDNS, 160\npull, 181\npush, 182\nWeb, 135, 138\nCaesar cipher, 642, 644\ncanonical hostname, 154\ncare-of address (COA), 623, 624\ncarrier sense multiple access (CSMA), 499–501\ncarrier sense multiple access with collision detection (CSMA/CD), 501–504\nefficiency, 504"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1237,
    "text": "carrier sensing, 499\nCBC. See Cipher Block Chaining\nCDMA. See code division multiple access\nCDNs. See Content Distribution Networks\ncell location tracking, 597\ncells, 593\ncellular networks\n3G, 48\n4G, 48\n5G, 48\n4G/5G, transmission rates and range, 564\nLTE, 48\ncellular telephony, 48\ncentralized routing algorithm, 412\nin LS algorithm, 414\ncentral office (CO), 43–44\nCerf, Vinton, 91, 258, 405–406\ncertificate, 662\nCertification Authority (CA), 662\nchannel partitioning protocols, 493\nCDMA, 495\nFDM, 493–494\nTDM, 493–494\nchannel propagation delay, 501\nchannels\nwith bit errors, 233–240\nIEEE 802.11 wireless LAN, 575–578\nlossy, 238–241"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1238,
    "text": "perfectly reliable, 232–233\nsatellite radio, 51\nterrestrial radio, 51\nchannel utilization, 243\nchecksum field, 260\nchecksumming methods, 488\nchecksums\ncorrupted ACK and NAK packet detection, 236\nIPv4 headers, 362–363\nUDP, 228–230\nChina Telecom, 410\nChina Unicom, 410\nchipping rate, 569\nchoke packets, 292\nchosen-plaintext attack, 643\nchunks, 170\nCIDR. See Classless Interdomain Routing\nCipher Block Chaining (CBC), 646\nciphertext, 641\nciphertext-only attack, 643\ncircuit, 57\ncircuit switching, 57–61\npacket switching versus, 60–61\nCisco, 34, 93\nCisco Catalyst 6500 Series, 346\nswitching bus, 348\nCisco Catalyst 7600 Series, 346\nswitching fabric, 349"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1239,
    "text": "Cisco Catalyst 8500 Series, switching fabric, 348\nCisco CRS, switching strategy, 349\nCisco 12000 series, switching fabric, 348–349\nClark, Jim, 92\nclassful addressing, 367–368\nClassless Interdomain Routing (CIDR), 366–367, 544\n“class” of traffic, 358\ncleartext, 641\nClear to Send (CTS) control frame, 581\nclient process, 257\nclients, 41, 116\nclient-server architecture, 114\ncloud computing, 41, 94, 535\ncloud services, response time of, 299\ncluster selection strategy, 179\nCMTS. See cable modem termination system\nCO. See central office\nCOA. See care-of address\ncoaxial cable, 50\ncode division multiple access (CDMA), 495, 562, 569–572\ncollide, 492\ncollisions\ndetection, 499\nelimination of, 524\n3Com, 518\nCOMCAST, 410\nCommand Line Interface (CLI), 457–458\ncommunication"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1240,
    "text": "secure, 638\ncommunication layer, SDN, 444\ncommunication links, 34\nCompound TCP (CTPC), 306\ncomputational complexity, of LS algorithm, 416\ncomputer networks, 32\ngraph model of, 410–411\nhistory of, 88–94\nthroughput in, 73–76\nconditional GET, 142\nconfidentiality, 638, 670\nconfiguration data, 456\ncongestion\nbuffer overflows from, 290–291\ncauses and costs of, 285–291\ndelays from, 287\nlost segments and, 295\nmultihop paths and, 289–291\nretransmission and, 288–289\nrouters and, 286–291\nthroughput and, 286–291\ncongestion avoidance, 297–298\ncongestion control, 216, 277\nABR, 227\nadaptive, 227\nAIMD, 301\napproaches to, 292–293\nbandwidth and, 295"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1241,
    "text": "end-to-end, 292\nnetwork-assisted, 292, 293\nprinciples of, 285–293\nTCP, 293–309\ncongestion window, 294, 300\nCongestion Window Reduced (CWR) bit, 304\nconnection flooding, 85\nconnectionless demultiplexing, 219–220\nconnectionless multiplexing, 219–220\nconnectionless transport, 224–230\nconnection management, TCP, 279–283, 285\nconnection-oriented and secure, 310–311\nconnection-oriented demultiplexing, 220–223\nconnection-oriented multiplexing, 220–223\nconnection-oriented transport, 257–285\nconnection requests, 221\nconnection state, 226\nContent Distribution Networks (CDNs), 142, 175\nbring home, 176\ncluster selection strategies, 179\nDNS redirects user’s request to, 178\nenter deep, 176\ngeographically closest, 179\nGoogle, 177\nIP-anycast and, 436–437\nNetflix, 180–182\noperation, 176\nprivate, 176"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1242,
    "text": "real-time measurements, 179\nthird-party, 176\nuploading versions to, 180\nYouTube, 182\ncontent ingestion, 180\ncontent processing, 180\ncontent provider networks, 64\ncontrol packets, 342\ncontrol plane, 333, 343, 407\nSDN, 441–450\nconvergence, routing algorithm speed of, 425\ncookies, 135–138\nSYN, 284\ncost reduction, 539–540\ncountdown timer, 240\nCRC. See cyclic redundancy check\ncrossbar switches, 348–349\ncryptographic hash function, 655–656\ncryptography\ncomponents, 641\nprinciples of, 640–654\npublic-key, 649\nCSMA. See carrier sense multiple access\nCSMA with collision avoidance, 578\nCSNET, 91\nCTS. See Clear to Send\nCUBIC. See TCP CUBIC\ncumulative acknowledgment, 248, 262"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1243,
    "text": "customer, 62\ncwnd, 294, 296–301\nCyclades, 90\ncyclic redundancy check (CRC), 489–491\ncodes, 489, 517\nerror-detection techniques, 489–491\nIEEE 802.11 wireless LAN, 583–584\nD\nDARPA. See Defense Advanced Research Projects Agency\nDASH. See Dynamic Adaptive Streaming over HTTP\ndata, 456\ndata center, 114\ncost reduction, 539–540\nhardware modularity and customization, 541–542\nphysical constraints, 541\nSDN control and management, 540\nvirtualization, 540–541\ndata center network design, 536\ndata center networking\ndata center architectures, 535–539\ntrends in, 539–542\ndata center networks, 535\nData Center Quantized Congestion Notification (DCQCN), 305\ndata centers, 41\nData Center TCP (DCTCP), 304, 309\nData Encryption Standard (DES), 645\nDatagram Congestion Control Protocol (DCCP), 304\ndatagrams, 81, 215"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1244,
    "text": "indirect routing of, 624\ninspecting, 376\nIPv4 format, 361–363\nIPv6 format, 378–380\nNAT and, 376\nnetwork-layer, 83\nreassembly of, 380\ntransmission, 516\ndata-over-cable service interface specifications (DOCSIS), 505–507\ndata plane, 333, 394\n4G, 614\ngeneralized forwarding and SDN, 383–390\nIP, 360–383\nrouters, 341–360\nSDN and, 442, 448–449\ndata received events, 269, 270\nDavies, Donald, 89\nDCCP. See Datagram Congestion Control Protocol\nDCTCP. See Data Center TCP\nDDoS. See distributed DoS\ndecentralized routing algorithm, 412–413\ndecryption, 653\ndecryption algorithm, 641\ndeep packet inspection (DPI), 390, 639, 705\nDefense Advanced Research Projects Agency (DARPA), 90, 91, 405\ndelayed-based congestion control, 305–306\ndelays\napplication, 73"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1245,
    "text": "bounded, 339\nin end systems, 73\nend-to-end, 71–73\nnetwork congestion and, 287\nnodal, 66\nnodal processing, 65\nin packet-switched networks, 65–76\nprocessing, 66\npropagation, 65, 67–69\nqueuing, 54–55, 65, 66, 69–71, 287\nin shared medium, 73\ntotal nodal, 65\ntransmission, 65–69\ntypes of, 65–69\ndeletion, message content, 640\ndemilitarized zone (DMZ), 706\ndemultiplexing, 217–224, 544\nconnectionless, 219–220\nconnection-oriented, 220–223\ntransport-layer, 216\ndenial-of-service (DoS)\nattacks, 85–86\ndistributed, 86, 87\nSYN floods for, 284\ndestination-based forwarding, 343–346\ndestination port number, 260\ndestination port number field, 218\nDeutsche Telecom, 410"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1246,
    "text": "device statistics, 456\nDHCP. See Dynamic Host Configuration Protocol\nDHCP ACK message, 374, 544\nDHCP discover message, 372\nDHCP offer message, 372–373\nDHCP request message, 374, 543\nDHT. See Distributed Hast Table\nDiffie-Hellman algorithm, 654\nDIFS. See Distributed Inter-frame Space\nDigital Attack Map, 85\ndigital ethernet, 518\ndigital signatures, 658–661\ndigital subscriber line (DSL), 43–44, 93\ndigital subscriber line access multiplexer (DSLAM), 43–44\nDijkstra’s algorithm, 413, 420\nin OSPF, 426\ndirect routing, 615\ndistance-vector algorithm (DV algorithm), 418–425\ndecentralization, 420\nlink-cost changes and link failure, 422–424\nLS compared with, 424–425\nmessage complexity, 424–425\npoisoned reverse, 424\nrobustness, 425\nspeed of convergence, 425\ndistant centralized database, 156\ndistributed applications, 35\ndistributed DoS (DDoS), 86"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1247,
    "text": "Distributed Hast Table (DHT), 173\nDistributed Inter-frame Space (DIFS), 580\ndistribution time, 168\nDMZ. See demilitarized zone\nDNS. See domain name system\nDNS protocol, 545\nDNS query message, 545\nDNS reply message, 546\nDNS resource record, 546\nDOCSIS. See Data-Over-Cable Service Interface Specifications\nDOCSIS 2.0, 45\ndomain names, 440\ndomain name system (DNS), 80, 153\nadditional section, 164\nanswer section, 164\nand ARP, 544–545\nauthoritative servers, 157\nauthority section, 164\ncaching, 160\ndistant centralized database, 156\ndistributed, hierarchical database, 156–160\nheader section, 163\nhierarchy, 157\ninteraction, 159\nInternet presence and, 440–441\nintra-domain routing, 545–546\nIP-anycast in, 436–437\niterative queries, 160"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 2",
    "source": "kurose",
    "page": 1248,
    "text": "local server, 158\nmaintenance, 156\nmessages, 163\noperation of, 155–161\npeer-to-peer file distribution, 166–173\nquestion section, 163\nrecords insertion, 164\nrecursive queries, 160\nresource records (RRs), 161\nroot servers, 157\nservers, 153\nservers in 2020, 158\nservices provided by, 153–155\nsingle point of failure, 156\ntop-level domain (TLD), 156, 157\ntraffic volume, 156\nUDP usage by, 225\nvulnerabilities, 165\ndotted-decimal notation, 364\nDPI. See deep packet inspection\ndrop, packet, 71\ndropping\nOpenFlow, 387\npackets, strategies for, 352\ndrop-tail, 352\nDSL. See digital subscriber line\nDSLAM. See digital subscriber line access multiplexer\nduplicate ACKs, 238, 273"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1249,
    "text": "duplicate data packets, 240\nduplicate packets, 236\nDV algorithm. See distance-vector algorithm\nDynamic Adaptive Streaming over HTTP (DASH), 174\nDynamic Host Configuration Protocol (DHCP), 371–374\naddress obtainment with, 371–374\nmessages, 372–373\nmobile nodes and, 374\nNAT and, 374\ndynamic routing algorithms, 413\nE\nEAP. See Extensible Authentication Protocol\neavesdropping, 640\ne-Bay, 93\neBGP. See external BGP\nEC2, 94\nECE. See Explicit Congestion Notification Echo\necho request, 453\nECN. See Explicit Congestion Notification\nedge routers, 342\nefficiency\nALOHA protocol, 497\nCSMA/CD, 504\n802.11. See IEEE 802.11\nEIGRP protocol, 426\nelastic applications, 120\ne-mail\ncomponents, 146"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1250,
    "text": "high-level view of, 147\nin internet, 146\nmail access protocols, 151–152\nmail message formats, 151\nPGP, 673–674\nprotocols, 152\nsecure, 670–673\nSMTP, 80, 147–150\nencapsulation, 82–84\nEncapsulation Security Payload (ESP) protocol, 683\nencrypted, 638\nencryption\npublic key, 642, 648–654\nsymmetric key, 642–648\nencryption algorithm, 641\nend-end principle, 229\nend-point authentication, 87–88, 639, 664–666\nend systems, 32, 34, 39–41\ndelay in, 73\nend-to-end argument, 393\nend-to-end congestion control, 292\nend-to-end connection, 57\nend-to-end delay, 71–73\nenhanced mobile broadband (eMBB), 606\neNode-B, 595\nentity body, 133\nEqual Cost Multi Path (ECMP), 539\nerror checking, UDP checksums and, 228–230"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1251,
    "text": "error-correction techniques, 482, 484, 485\nerror detection, 234\nerror-detection techniques, 482, 484, 485\nchecksumming methods, 488\ncyclic redundancy check (CRC), 489–491\nparity checks, 486–488\nESP. See Encapsulation Security Payload\nEstimatedRTT, 266\nEstrin, Deborah, 633\nEthane project, 449–450\nEthernet, 35, 46–47, 392\nbuffered distributors, 520\nchallenges, 514\ndevelopment of, 91\nframe, 543\nframe structure, 516–518\ngigabit, 520\ninstallations, 515\nMTU, 259\npacket sniffing, 87\nstandards, 519\ntechnologies, 518–521\nevent-based programming, 249\nEWMA. See exponential weighted moving average\nExplicit Congestion Notification (ECN), 304–305\nExplicit Congestion Notification Echo (ECE), 305\nexponential weighted moving average (EWMA), 266\nextended FSM, 248"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1252,
    "text": "extensible authentication protocol (EAP), 693–694\nexternal BGP (eBGP), 431\nF\nFacebook, 666\nFacetime, video conferencing, 111\nfading, 569\nfairness\nof AIMD, 306–309\nparallel TCP connections and, 309\nTCP and, 306–309\nUDP and, 308–309\nfast recovery, 298–300\nfast retransmit, 273–275\nFCFS. See first-come-first-served\nFDM. See frequency-division multiplexing\nFEC. See forward error correction\nFeynman, Richard, 332\nFHSS. See frequency-hopping spread spectrum\nfiber optics, 93\nin cable systems, 44–45\nphysical media, 50\nfiber to the home (FTTH), 45–46, 93\nFIFO. See first-in-first-out\n5G, 48\n5G cellular networks, 46\n5G fixed wireless, 46\nfiltering, 521\nlink-layer switches, 521–522"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1253,
    "text": "filters\nstateful, 698\ntraditional packet, 698\nFIN bit, 261\nfinite-state machine (FSM), 232\nfor data transfer over channel with bit errors, 234–240\nfor data transfer over lossy channel with bit errors, 240–241\nfor data transfer over perfectly reliable channel, 232–233\nextended, 248\nfor GBN protocol, 246–248\nTCP congestion control, 297, 298\nfirewalls, 377, 383\napplication gateways, 698\nstateful filters, 698\ntraditional packet filters, 698\nfirst-come-first-served (FCFS), 355\nfirst-in-first-out (FIFO), 355–356\n5G cellular networks, 605\ncore network, 607–608\neMBB, 606\nFR2 frequencies, 606\nmillimeter wave frequencies, 606\nand millimeter wave frequencies, 606–607\nmMTC, 606\nstandards, 606\nURLLC, 606\n5G Core network, 607\nflag days, 381"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1254,
    "text": "flag field, 260\nflow, 378\nflow-based forwarding, 441–442\nflow-control service, 276\nflow control, TCP, 276–278\nflow table, 384\nmatch-plus-action, 449\nSDN, 444\nwildcards in, 386\nforward error correction (FEC), 488\nforwarding, 60, 334, 341, 521\nto broadcast, 387\ndestination-based, 343–346\nflow-based, 441–442\ngeneralized, 343, 383–390\nlink-layer switches, 521–522\nlongest prefix matching rule, 345, 368\nOpenFlow, 387\npackets, 336\nSDN, 441–442\nforwarding plane, 342–343\nforwarding tables, 55–56, 336, 337\nin input processing, 345–346\nline cards, 345\nin LS algorithm, 415–416\nmatch-plus-action, 384\nprefixes, 345\nrouters, 336, 337"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1255,
    "text": "in SDN, 342, 344\n4G LTE cellular networks\nauthentication, 596\nbase station, 594–595\ncell location tracking, 597\nelements of, 595\nfunctions, 597\nhome subscriber server (HSS), 595\nmobile device, 594\nmobility management entity (MME), 596\nnetwork attachment, 602–603\nnetwork of networks, 604–605\npacket data network gateway, 595\npath setup, 596\npower management, 603–604\nprotocols stacks, 600–601\nradio access network, 601–602\nserving gateway, 595\n4G, 48\nfragmentation, 380\nframes, 82\nACK, 582\nbeacon, 576\nCTS, 581\nEthernet, 543\nIEEE 802.11 wireless LAN, 583–586\nlink-layer, 83\ntime, 494"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1256,
    "text": "VLANs, 530\nframing, 482\nfrequency-division multiplexing (FDM), 58–59, 493–494\nfrequency-hopping spread spectrum (FHSS), 591\nFSM. See finite-state machine\nFTP protocol, 80\nFTTH. See fiber to the home\nfull-duplex service, 257\nfully connected topology, 541\nG\ngateway router, 430\ngateways, 343\nGBN protocol. See Go-Back-N (GBN) protocol\nGE Information Services, 90\ngeneralized forwarding, 343, 383–390\naction, 386–387\nmatch, 385–386\nmatch-plus-action, 387–390\ngenerator, 489\ngeostationary satellites, 51\n4G/5G cellular networks\nauthentication and key agreement, 694–697\nsecurity, 689\nGigabit Ethernet, 520\nGithub, 165\nGlobal Positioning System (GPS), 588\nGo-Back-N (GBN) protocol, 245–250\nevents, 248"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1257,
    "text": "TCP as, 276\nGoogle, 41, 93, 306, 310\nCDN infrastructure, 177\nprivate network, 64, 94, 410\nSDN use by, 410, 447\nvideo streaming, 173\nGoogle Chrome browser\nQUIC protocol, 226\ngraph, 410\ngraph algorithms, 413\nGreenberg, Albert, 558\nguaranteed delivery, 339\nguaranteed delivery with bounded delay, 339\nguaranteed minimal bandwidth, 339–340\nguided media, 49\nH\nHandley, Mark, 633\nhandoff, 564\nhandover, 564, 609\nhandover management, 620\nhandshaking\nTCP three-way, 258, 280–281\nTLS, 676\nhash functions\nchecksum, 655–656\ncryptographic, 655–656\ndigital signatures using, 660\nMD5, 656"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1258,
    "text": "SHA-1, 656\nheader length field, 260\nheader lines, 131, 133\nheaders, 362–363\nAH protocol, 683\nDNS, 163\nIPv4, 361–362\nhead-of-the-line blocking (HOL blocking), 144, 350\nHELLO message, 428\nHeterogeneous links, 524\nHFC. See hybrid fiber coax\nhidden terminal problem, 569\nhierarchical architectures, 537–539\nwithin ASs, 428–429\nhigh-speed wireless Internet access, 93\nHMAC, 658\nHOL blocking. See head-of-the-line blocking\nhome agent\nin mobile IP, 623\nregistration with, 624\nhome network, 604, 610\nHome Subscriber Server (HSS), 595, 609\nhop limit, 380\nHost\naliasing, 154\nhost addresses, obtaining with DHCP, 371–374\nhost aliasing, 154\nhostname, 153"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1259,
    "text": "hosts, 32, 40, 41\nhot potato routing, 434–435\nhourglass, Internet Protocol, 392–393\nHTML, development of, 92\nHTTP\nmanifest file, 175\nTCP and, 546–547\nHTTP GET message, 546\nHTTP request, 544\nHTTP response, 547\nhub, 515\nhybrid fiber coax (HFC), 44–45\nHyperText Transfer Protocol (HTTP), 80, 92, 126\nconditional GET, 142–143\nHTTP/2, 143–144\nHTTP/3, 146\nHTTP/2 framing, 144–145\nICMP and, 453\nmessage format, 131–135\nwith non-persistent connections, 128–130\noverview of, 126–128\nwith persistent connections, 130–131\nports, 223–224\nQuick UDP Internet Connections, 311–312\nrequest message, 131–133\nrequest-response behavior, 127\nresponse message, 133–135\nresponse message prioritization, 145"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1260,
    "text": "server, manifest file, 175\nserver pushing, 145\nstateless protocol, 128\nuser-server interaction, 135–138\nweb and, 125–126\nweb caching, 138–142\nI\nIANA, 378\niBGP. See internal BGP\nIBM, 90\nICANN. See Internet Corporation for Assigned Names and Numbers\nICMP. See Internet Control Message Protocol\nIEEE 802.11ac, 573\nIEEE 802.11ax, 573\nIEEE 802.11b, 573\nIEEE 802.11g, 573\nIEEE 802 LAN/MAN Standards Committee, 35\nIEEE 802.11n, 573\nIEEE 802.11 wireless LAN, 47, 573\naddress fields, 584–586\nadvanced features in, 589–590\narchitecture, 574–578\nchannels and association, 575–578\nclear to send (CTS) control frame, 581\ncollision avoidance, 582\nduration, 586\nframe control fields, 586\nframes, 583–586"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1261,
    "text": "hidden terminals, dealing with, 581–583\nlink-layer acknowledgments, 579\nMAC protocol, 578–583\nmobility in same IP subnet, 586–588\npayload and CRC fields, 583–584\npersonal area networks, 590–592\nas point-to-point link, 583\npower management, 590\npublic access, 93\nrate adaptation, 589–590\nrequest to send (RTS) control, 581\nsequence number, 586\nstandards, 573\nIETF. See Internet Engineering Task Force\nIKE. See Internet Key Exchange\nIKE SA, 688\nIMAP. See Internet Mail Access Protocol\nindirect routing approach, 613\ninformation propagation, 331\ninfrastructure mode, 564\ninfrastructure wireless LANs, 574\nInitialization Vector (IV), 647\nin-order packet delivery, 339\ninput port, 342\ninput port processing, 344–346\nforwarding tables in, 345–346\ninput queuing, 350\ninsertion, message content, 640"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1262,
    "text": "instantaneous throughput, 73\nIntel Ethernet, 518\nintelligent software agents, 109\ninter-area routing, 428–429\ninter-autonomous system routing protocol, 429, 439\ninterconnection networks\nswitching via, 348–349\ninter-domain protocol, 546\ninterface, 364\nSDN controller, 444–445\nsocket, 36\ninternal BGP (iBGP), 431–432\ninternal router, 430\nInternational Mobile Subscriber Identity (IMSI), 594\nInternational Telecommunication Union (ITU), 663\nInternet. See also access networks\narchitectural principles of, 391\nbest-effort service in, 340\nbroadband, 93\nCerf on, 405–406\ncommercialization of, 92\ncomponents of, 32–35\nDNS and presence on, 440–441\nenterprise access, 46–47\nhistory of, 88–94\nhome access, 43–46\nnetwork core, 52\nnetwork edges, 39–41"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1263,
    "text": "network layer, 340\nobtaining presence on, 440–441\nregistries, 370\nrouter self-synchronization, 417\nrouting algorithms used in, 413\nas service infrastructure, 35–37\ntransport layer, 215–217\nInternet applications, transport protocols used by, 227\nInternet checksum, 488\nInternet-connected smartphones, 93\nInternet Control Message Protocol (ICMP), 453–455, 461\nIPv6 and, 455\nmessage types, 454\nInternet Corporation for Assigned Names and Numbers (ICANN), 164, 370,\nInternet Engineering Task Force (IETF), 35, 377\nInternet Exchange Points (IXPs), 63–64\ninternet key exchange (IKE) protocol, 688\nInternet Mail Access Protocol (IMAP), 152\nInternet Protocol (IP), 35, 81, 405\nICMP and, 453\nmobile, 622–624\nservice model, 216\nstack for, 80\ntotal annual traffic using, 34\ntransition to, 91\nInternet Protocol Packet eXchange (IPX) Network, 605\nInternet registrars, 440"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1264,
    "text": "Internet Service Providers (ISPs), 34–35\naccess, 62\nbackbone, 438\nAS configurations, 426\nglobal transit, 62\nmulti-home, 63\nmulti-homed access, 438\npeering agreements among, 438–439\nPoP, 63\nrouting among, 429–441\nInternet standards, 35\nInternet Systems Consortium, 374\nInternet telephony, 123\ninternetworking, 89–91\nintra-autonomous system routing, 425–429, 439\nSDN in, 450\nintruder, security attacks, 640\nintrusion detection system (IDS), 377, 639, 705–708\nintrusion prevention systems (IPSs), 377, 706\nIntserv, 340\nIP. See Internet Protocol\nIP addresses, 92, 118, 153, 363–374, 378\nbroadcast, 370, 372–373\nclasses of, 367–368\nDHCP, 371–374\nInternet presence and, 440\nIPv4, 363–374\nIPv6, 378"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1265,
    "text": "NAT and, 374–376\nobtaining blocks of, 370–371\ntemporary, 371\nIP-anycast, 436–437\nIP datagram, 543\nIP forwarding table, 544\nIP fragmentation, 380\nIPv6, 380\niPhones, 48\nIP hourglass, 392–393\nIPsec, 681–683\nIPsec datagram, 685–687\nIP spoofing, 87–88\nIPSs. See intrusion prevention systems\nIP traffic, volume of, 34\nIPv4\naddressing, 363–374\ndatagram format, 361–363\ntransitioning to IPv6 from, 381–383\nIPv6, 377\nadoption of, 381–382\ndatagram format, 378–380\nICMP, 455\ntransitioning to, 381–383\ntunneling, 381–382\nIPX, 420\nIS-IS, 426, 447, 546\nISO IDRP, 420"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1266,
    "text": "ISPs. See Internet Service Providers\niterative queries, 160\nITU. See International Telecommunication Union\nIV. See Initialization Vector\nIXPs. See Internet Exchange Points\nJ\njabbering adapters, 524\nJacobson, Van, 331–332\nJuniper MX2020, 342\nK\nKahn, Bob, 405, 406\nKahn, Robert\nARPAnet development and, 89–91\nTCP/IP creation and, 258\nKarels, Mike, 331\nkey, 641\nkey agreement\n4G/5G cellular networks, 694–697\nKleinrock, Leonard, 89, 108–110, 405\nknown-plaintext attack, 643\nL\nlabel-switched router, 533\nLampson, Butler, 386\nLAN. See local area network\nLAN address, 508\nlayered architectures, 77–82"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1267,
    "text": "encapsulation, 82–84\nlayers, 79\nlayer 4 switching, 343\nlayer 5 switching, 343\nleast-cost path, 412\nBellman-Ford equation for, 418–419\nin LS algorithm, 414–416\nLEO satellites. See low-earth orbiting satellites\nLevel 3 Communications, 62\nLicklider, J. C. R., 89\nline cards\nforwarding tables in, 345\ninput and output ports, 342\nprocessing on, 348\nline speeds, queuing and, 349–350\nlink access, 482\nlink capacity\nbuffer sizing and, 353\nnetwork congestion and, 287\nlink failure, 422–424\nlink layer, 81–82\nbroadcast, 482\ncable internet access, 505–507\nimplementation locations, 483–484\nnetwork as, 531–534\nnetwork types, 491–493\nservices provided by, 482–483\nwireless host vs. server, 481"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1268,
    "text": "link-layer acknowledgment scheme, 579\nlink-layer frame, 83, 480\nlink-layer switches, 34, 53, 341\ndestination address lookup in, 346\nfiltering, 521–522\nforwarding, 521–522\nproperties of, 524–525\nvs. routers, 525–527\nself-learning, 523–524\nlinks, 480\nlink-state algorithms (LS algorithms), 412–417, 420\ncentralized routing algorithm, 414\ncomputational complexity of, 416\nDV compared with, 424–425\nforwarding tables, 415–416\nmessage complexity, 424–425\noscillations in, 416–417\nOSPF, 426\nrobustness, 425\nspeed of convergence, 425\nsteps of, 414–415\nlink-state broadcast, 413\nerroneous, 425\nlink virtualization, 531\ndialup modem connection, 531\nmultiprotocol label switching (MPLS), 532–534\nlink weights, in OSPF, 427\nLinux, Snort, 708"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1269,
    "text": "load balancing, 536–537\nload balancing packets, 383\nload distribution, 154\nload-insensitive algorithms, 413\nload-sensitive algorithm, 413\nlocal area network (LAN), 46–47. See also virtual local area networks;\nwireless LANs\nlocal area networks\nswitched, 507–531\nlocal breakout, 614, 620\nLocal DNS Server (LDNS), 158, 178\nlocal preference, 435\nlogical communication, 212\nlogically centralized control, 409–410\nlogically centralized routing controllers, 338\nlongest prefix matching rule, 345, 368\nLong-Term Evolution (LTE), 48\nlookup algorithms, 346\nloss-tolerant applications, 119\nlossy channels, 238–241\nlost, packet, 71\nlost segments, 295\nlow-earth orbiting (LEO) satellites, 51\nLS algorithms. See link-state algorithms\nLTE. See Long-Term Evolution\nM\nMAC. See message authentication code\nMAC addresses, 508"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1270,
    "text": "and ARP, 508–513\nsubnets, 513–514\nmail servers, 146\naliasing, 154\nmalware, 84–85\nself-replicating, 85\nmanaged device, 456\nmanaged objects, 461\nManagement Information Base (MIB), 458–462\nmanaging server, 456\nMANETs. See mobile ad hoc networks\nmanifest file, HTTP, 175\nmassive machine type communications (mMTC), 606\nmatch-plus-action, 346\nforwarding table, 384\nin generalized forwarding, 383–384\nOpenFlow, 387–390\nmatch-plus-action flow tables, 449\nmaximum segment size (MSS), 259\nnegotiating, 260\nmaximum transmission unit (MTU), 259, 465–466\nMD5 authentication, 428\nMD5 hash algorithm, 656\nmedium access control (MAC), 601\nmemory\naccess times, 346\nbandwidth of, 347\nswitching via, 347–348"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1271,
    "text": "message authentication code (MAC), 656–658\nbroadcast address, 510\ndigital signatures, 658–661\nmessage integrity, 638–639, 654–664, 670\nmessage queue, 147\nmessages, 53, 80\napplication-layer, 83\ncomplexity in LS algorithms, 424–425\nDHCP, 372–373\nHELLO, 428\nOpenFlow, 449\nport-status, 449\nsource quench, 453–454\nMetcalfe,Bob, 515, 518\nMIB. See Management Information Base\nMicrosoft, 93\nprivate network, 94\nMicrosoft Research, 410\nMicrosoft’s Azure, 94\nmiddleboxes, 340, 376, 390–391\nmillimeter wave frequencies, 606\nMinitel, 92\nMME. See Mobility Management Entity\nmobile ad hoc networks (MANETs), 565\nmobile devices, 593, 594\nmobile-device-to-PDN-gateway data path configuration, 603\nmobile nodes, DHCP and, 374\nMobility management"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1272,
    "text": "device mobility, 608–609\ndirect and indirect routing to/from a mobile device, 610–611\ndirect routing to mobile device, 615–616\nin 4G/5G networks, 617–622\nhome networks and roaming on visited networks, 609–610\nindirect routing to mobile device, 613–615\nIP address infrastructure, 611–613\nmobile IP, 622–624\nin practice, 617–624\nwireless and, 624–626\nmobility management entity (MME), 596, 603\nmodification, message content, 640\nmodify-field action, 387\nmonoalphabetic cipher, 642\nMosaic Communications, 92\nMOSPF. See multicast OSPF\nMP3, 75\nmulticast OSPF (MOSPF), 428\nmulticast routing in OSPF, 428\nmulti-home, 63\nmulti-homed access ISP, 438\nMulti-hop, infrastructure-based networks, 565\nMulti-hop, infrastructure-less networks, 565\nmultihop path, 289–291\nmultimedia applications\nTCP use by, 226\nUDP use by, 226–227\nmultipath propagation, 566"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1273,
    "text": "multiple access problem, 491\nmultiple access protocols, 492\nmultiple same-cost paths, in OSPF, 428\nmultiplexing, 217–224\nconnectionless, 219–220\nconnection-oriented, 220–223\ntransport-layer, 216\nmultiprotocol label switching (MPLS) networks, 531–534\nmutual authentication, 603, 689\nN\nNAK (negative acknowledgments), 234–238\ncorrupted, 236\nnarrow waist, 392, 393\nNASA, 406\nNAT. See network address translation; network address translator\nNational Physical Laboratory, 89\nNAT translation table, 376\nNAT traversal, 376\nNCP. See network-control protocol\nNCS. See network control server\nnegative acknowledgments, 234\nneighbor, 411\nneighboring peers, 171\nNelson, Ted, 92\nNetflix\nCDN and, 180–182\ncomponents, 181\nDNS vulnerabilities, 165"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1274,
    "text": "video streaming, 173, 180\nnet neutrality, 357–358\nNetscape Communications, 92–93\nnetwork adapter, 483, 484\nnetwork address translation (NAT), 374–376, 383, 390\nnetwork address translator (NAT), 346\nnetwork applications principles, 112–125\nnetwork-assisted congestion control, 292, 293\nnetwork attachment, 602\nNetwork Configuration Protocol (NETCONF), 458, 462–466\nmanaged network devices, 462\nMTU, 465–466\noperations, 464\nsession, 463\nXML format, 464–465\nnetwork control functions, in SDN, 442\nnetwork-control protocol (NCP), 89, 91\nnetwork control server (NCS), 447\nnetwork core, 52\ncircuit switching, 57–61\nnetwork of networks, 61–64\npacket switching, 53–56, 60–61\nnetwork functions virtualization (NFV), 391, 450\nNetwork Information Base (NIB), 447\nnetwork infrastructure, 565\nnetwork interface controller (NIC), 483\nnetwork layer, 81. See also control plane; data plane\nbest-effort service, 340"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1275,
    "text": "forwarding and routing, 334–339\nsecurity, 340\nservices, 339–340\ntransport layer relationship to, 212–215\nnetwork-layer datagram, 83\nnetwork-layer security\nAH protocols, 683\nESP protocols, 683\ninternet key exchange (IKE) protocol, 688\nIPsec, 681–683\nIPsec datagram, 685–687\nsecurity associations, 683–685\nvirtual private networks (VPNs), 681–683\nnetwork management, 455–466\ndefining, 455\nframework for, 456–458\nnetwork management agent, 456\nnetwork management protocol, 457\nnetwork managers, 456\nnetwork of networks, 61–64, 91\nnetwork operations center (NOC), 456\nnetwork prefix, 366\nnetwork protocols, 38–39\nnetworks. See also access networks; cellular networks; Internet; local area\nnetwork; wireless networks\nattacks against, 84–88\ncellular, 48\ncontent provider, 64"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1276,
    "text": "edges, 39–41\npacket-radio, 89\npacket-satellite, 89\nprivate, 64, 94, 374, 410\nprogrammable, 442\nproliferation of, 91–92\nproprietary, 89–91\nprovider, 438\nthroughput in, 73–76\nnetwork security, 638–640\nnetwork service model, 339–340\nNEXT-HOP, 433–435\nNFV. See network functions virtualization\nNIB. See Network Information Base\nNIST, 381\nnmap, 222, 285\nNOC. See network operations center\nnodal delay, 66\nnodal processing delay, 65\nnode, 480\nnon-blocking switches, 348\nnonce, 668\nnon-persistent connections, 128\nnon-preemptive priority queuing, 357\nNovell IPX, 420\nNOX controller, 446, 450\nNSFNET, 91, 92\nnslookup program, 164"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1277,
    "text": "NTT, 62\nO\nOC. See Optical Carrier standard\nODL’s Basic Network Functions, 450\nOFA. See Open Flow Agent\nOFC. See Open Flow Controller\nOFDM. See orthogonal frequency division multiplexing\noffered load, 288\nOLT. See optical line terminator\none-bit even parity, 486\nONIX SDN controller, 447\nONOS, 446, 450, 452–453\nONT. See optical network terminator\nOpenDaylight, 446, 450–451\nOpenDaylight controller, 451\nOpenDaylight Lithium, 450\nOpenFlow, 444, 446–449\naction, 387\nflow table, 384\nmatch, 385–386\nmatch-plus-action, 387–390\nOpen Flow Agent (OFA), 447\nOpen Flow Controller (OFC), 447\nOpen Shortest Path First (OSPF), 407, 413, 426–429, 546\nauthentication in, 428\nbroadcast in, 427–428\nDijkstra’s algorithm, 426\nlink weights, 427"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1278,
    "text": "multicast, 428\nsecurity and, 428\nsubnets, 426\noperational data, 456\noperational security, 639\nIDSs, 377\nOptical Carrier standard (OC), 50\noptical line terminator (OLT), 46\noptical network terminator (ONT), 46\noptions field, 260\northogonal frequency division multiplexing (OFDM), 601\nOSPF. See Open Shortest Path First\nout-of-order packets, 249\noutput buffer, 54\noutput port, 342\nforwarding to, 346\noutput port processing, 349\noutput queue, 54\noutput queuing, 351–353\noutside-AS destinations, 434\nOVSDB, 451\nP\npacket data convergence, 600\nPacket Data Network Gateway (P-GW), 595\npacket-dropping strategies, 352\npacket filtering, 699\npacket header overhead, 226\npacket headers"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1279,
    "text": "routing and, 336, 337\npacket loss, 55, 71, 349\npacket-marking strategies, 352\npacket-radio networks, 89\npackets, 34, 53\nchoke, 292\ncontrol, 342\ndeep inspection of, 377, 390\nduplicate, 236\nduplicate data, 240\nforwarding, 336\nin-order delivery of, 339\nout-of-order, 249\npacket-satellite networks, 89\npacket scheduler, 353\npacket scheduling\nFIFO, 355–356\npriority queuing, 356–357, 359\nround robin, 359–360\nWFQ, 359–360\npacket sniffer, 87, 106\npacket-switched networks, delays in, 65–76\npacket switches, 34, 53, 341\npacket switching, 53–57, 108\ncircuit switching versus, 60–61\ndevelopment of, 88–89\nstore-and-forward, 53–54\npaging, 597"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1280,
    "text": "pairwise communication, 331\nparallel TCP connections, fairness and, 309\nparity bit, 486\nparity checks, 486–488\npassive optical networks (PONs), 46\npassive scanning, 576\npath loss, 566\npaths, 34, 411\nleast-cost, 412, 414–416, 418–419\nmultihop, 289–291\nmultiple same-cost, 428\nshortest, 412\nPaxos, 447\npayload field, 83\nPDUs. See protocol data units\npeering agreements, 438–439\npeers, 63\npeer-to-peer (P2P) architecture, 114, 167–170\nBitTorrent, 170–173\nchunks, 170\nDHT, 173\nfile distribution with, 171\noptimistically unchoked, 172\nrarest first, 172\ntorrent, defined, 170\ntracker, 171\nunchoked, 172\nper-connection throughput, 286–287"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1281,
    "text": "performance enhancement, 390\nper-router control, 408–410, 466\npersistent connections, 128\nPGP. See Pretty Good Privacy\nP-GW. See Packet Data Network Gateway\nPhotobell, 108\nphysical address, 508\nphysical layer, 82\nphysical media, 48–51\ncoaxial cable, 50\nfiber optics, 50\nsatellite radio, 51\nterrestrial radio, 51\ntwisted-pair copper wire, 49–50\nphysical medium, 49\npiconets, 591\npiggybacked acknowledgments, 265\nping, 453\npipelined reliable data transfer protocols, 241, 243–245\npipelining, 245\nTCP, 267\nplaintext, 641, 642\nplayback attack, 668\nplug-and-play, 371\nplug-and-play devices, 524\npoints of presence (PoPs), 63\npoint-to-point connections, 257\npoint-to-point link, 491"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1282,
    "text": "Point-to-Point Protocol (PPP)\nMTU, 259\npoisoned reverse, 424\npolling protocol, 504\npolls, 504\npolyalphabetic encryption, 643, 644\npolynomial codes, 489\nPONs. See passive optical networks\nPoPs. See points of presence\nport numbers, 118, 184, 219–220\nNAT and, 374–376\nsocket, 219–220\nwell-known, 218\nport scanning, 222\nport-status message, 449\npositive acknowledgments, 234\nPouzin, Louis, 90\nPPP. See Point-to-Point Protocol\npreamble, 517\nprefix, 345, 346, 366–368\nPretty Good Privacy (PGP), 673–674\nPrim’s algorithm, 413\npriority queuing, 355–357, 359\nnon-preemptive, 357\nprivacy, 704–705\nprivate key, 649\nprivate networks, 64, 94, 374, 410\nprocesses, 115"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1283,
    "text": "server, 257\ntransport layer protocols connecting, 212\nprocessing delay, 66\nprogrammable network, 442\npropagation delay, 65, 67–69\nproprietary networks, 89–91\nprotocol data units (PDUs), 459, 460\nprotocol layering, 79–80\nprotocols, 35, 39. See also specific protocols\ndefining, 37–39\nnetwork, 38–39\nrouting, 55–56\nprotocol stack, 80\nprovider, 62\nprovider networks, 438\nproxy server, 138\nPSH bit, 261\npublic-key, 649\npublic key certification, 662–664\npublic key encryption, 642, 648–654\nPublic Key Infrastructure (PKI), 661\npull protocol, 181\npure ALOHA protocol, 551\npush protocol, 182\nPython\nport numbers, 219\nUDP connections, 219\nQ"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1284,
    "text": "QoS. See quality of service\nquality of service, 597\nnon-default, 379\nqueuing delays, 54–55, 66, 69–71\nnetwork congestion and, 287\nqueuing\ndelays, 65\nFIFO, 355–356\ninput, 350\nline speed and, 349–350\nnon-preemptive priority, 357\noutput, 351–353\npriority, 355–357, 359\nround-robin, 355, 359–360\nin routers, 349–354\ntraffic load and, 349\ntransmission rate and, 349–350\nWFQ, 359–360\nwork-conserving, 359\nQuick UDP Internet Connections (QUIC), 310–312\nconnection-oriented and secure, 310–311\nHTTP, 311–312\nstreams, 311\nTCP-friendly congestion-controlled data transfer, 311\nQUIC protocol, 226, 227\nR\nradio link control, 600\nRand Institute, 89"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1285,
    "text": "random access protocols, 493, 495\nRandom Early Detection (RED), 352\nRCP. See Routing Control Platform\nrealm with private addresses, 374\nreal-time conversational applications. See Voice-over-IP\nreassembly, IPv6 datagram, 380\nreceive buffer, 277, 278\nreceiver authentication, 639, 670\nreceiver feedback, 234\nreceive window, 260, 277, 278\nrecursive queries, 160, 161\nRED. See Random Early Detection\nregional ISP, 62–63\nregistrar, 440\nregistries, 370\nreliable data transfer, 119, 216, 255–256\nimplementing, 330\nover channel with bit errors, 233–238\nover lossy channel with bit errors, 238–241\nover perfectly reliable channel, 232–233\nprinciples of, 230–256\nservice implementation for, 231, 232\nservice model for, 230, 231\nTCP, 268–376\nreliable data transfer protocol, 230\nbuilding, 232–241\npipelined, 241, 243–245\nreliable data transfer service, 268"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1286,
    "text": "reliable delivery, 482\nreliable, TCP-friendly congestion-controlled data transfer, 311\nreliable transport protocol, 330\nremote procedure call (RPC), 462\nrepeater, 519\nrequest line, 131\nrequests for comments (RFCs), 35\nRequest to Send (RTS) control frame, 581\nresponse time, cloud service performance, 299\nretransmission, 234\ncongestion and, 288–289\nduplicate packets from, 236\nfast, 273–275\nrandom access protocols, 495\nsequence numbers for handling, 236–237\nslotted ALOHA protocol, 496–498\nTCP timeout interval for, 266–267\nTCP timer management for, 268–269\ntime-based, 240–241\nRexford, Jennifer, 476\nRFC 1422 public key, 664\nRFCs. See requests for comments\nRIP, 413, 420, 546\nRivest, Ron, 650\nroaming, 610\nRoberts, Lawrence, 89\nrobustness, LS and DV algorithms, 425\nroot DNS servers, 157"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1287,
    "text": "round-robin queuing, 355, 359–360\nround-trip time (RTT), 129\nbuffer sizing and, 353\nTCP estimation for, 265–268\nTCP Reno throughput, 303\nTCP variable tracking, 294\nroute, 34, 432\nBGP, 433\nBGP selection algorithm for, 435–436\nroute aggregation, 368\nroute information, advertising in BGP, 430–432\nrouters, 34, 53, 341, 383\narchitecture of, 341\nborder, 428–429, 536\nbuffer sizing, 353\ncomponents of, 341–344\ncongestion and, 286–291\ndata plane, 341–360\ndestination-based forwarding, 343–346\nedge, 342\nforwarding plane, 342–343\nforwarding tables, 336, 337\ngateway, 430\ninput port processing, 344–346\ninternal, 430\nNAT-enabled, 374–376\noutput port processing, 349\nper-router control, 408–410"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1288,
    "text": "queuing in, 349–354\nself-synchronization, 417\nswitching fabric, 347–349\nroute summarization, 368\nroutine, node, 474–475\nrouting, 336, 337\namong ISPs, 429–441\nhot potato, 434–435\ninter-area, 428–429\nintra-ASs, 425–429, 439, 450\nlink weights in, 427\nlogically centralized, 338\nmulticast, 428\nprogramming assignment, 474–475\nrouting algorithms, 336, 337, 410–425\nARPAnet, 413, 420\ncentralized, 412, 414\nconvergence speed, 425\ndecentralized, 412–413\ndistance-vector, 418–425\ndynamic, 413\nlink-state, 413–417\nload sensitivity, 413\nstatic, 413\nrouting controllers\nlogically centralized, 338\nSDN and, 339\nRouting Control Platform (RCP), 476"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1289,
    "text": "routing loop, 423\nrouting policy, BGP, 437–440\nrouting processor, 342\nrouting protocols, 55–56\nrouting tables, 420\nBGP, 435–436\nRSA algorithm, 650–652\ncomponents of, 650\nencryption/decryption, 653\nRST bit, 260\nRTT. See round-trip time\nrwnd, 294\nS\nSA. See security association\nSAD. See Security Association Database\nSAL. See Service Abstraction Layer\nSampleRTT, 266\nsatellite radio channels, 51\nScantlebury, Roger, 89\nSCTP. See Stream Control Transmission Protocol\nSDN. See software-defined networking\nSDN control and management, 540\nSDN controller, 444–446\nsecure communication, 638\nSecure Hash Algorithm (SHA-1), 656\nsecure shell (SSH) connection, 457\nsecurity\ndatagram inspection, 377"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1290,
    "text": "firewalls, 377, 383\nIDSs, 377\nnetwork, 638–640\nnetwork layer, 340\noperational, 418, 639\nOSPF and, 428\nSYN flood attacks, 284\nsecurity association (SA), 683\nSecurity Association Database (SAD), 684\nsecurity associations, 683–685\nSecurity Parameter Index (SPI), 684\nSecurity Policy Database (SPD), 687\nsecurity services, 390\nsegments, 81, 212, 215\nacknowledged, 295\nlost, 295\nmaximum size, 259, 260\nTCP, 259\nTCP structure, 260–265\ntransport-layer, 83\nUDP structure, 228\nselective acknowledgment, 276\nselective repeat (SR), 245, 250–256\nevents and actions, 252\noperation of, 253\nTCP as, 276\nwindow size, 254, 255\nself-clocking, 295"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1291,
    "text": "self-learning, 523, 544\nlink-layer switches, 523–524\nself-replicating malware, 85\nself-synchronization, 417\nsend buffer, 259\nsender authentication, 639, 670\nsending rate, 288\nsequence number, 236\nin GBN protocol, 245–246\nin pipelined protocols, 245\nretransmission handling with, 236–237\nin SR protocol, 251, 254\nTCP, 261–263\nfor TCP segment, 262\nTelnet and, 263–265\nsequence number field, 260\nsequence number for segment, 262\nserver, 116\nservers, 41\nmanaging, 456\nnetwork control, 447\nprocesses, 257\nweb, 92, 223–224\nService Abstraction Layer (SAL), 450–451\nService Level Agreements (SLAs), 456\nservice model, 79\nIP, 216\nnetwork, 339–340"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1292,
    "text": "reliable data transfer, 230, 231\nservices, 79\nflow-control, 276\nfull-duplex, 257\nlayering, 79\nnetwork layer, 339–340\nTCP, 216\nunreliable, 216\nservice set identifier (SSID), 575\nServing Gateway (S-GW), 595\nsession key, 652\nsession management function (SMF), 608\nS-GW. See Serving Gateway\nSHA-1. See Secure Hash Algorithm\nShamir, Adi, 650\nshared medium, 50\ndelays in, 73\nshortest path, 412\nShort Inter-frame Spacing (SIFS), 579\nSIFS. See Short Inter-frame Spacing\nsignal-to-noise ratio (SNR), 566\nsignature-based systems, 707\nsilent periods, 59\nsimple authentication, 428\nSimple Mail Transfer Protocol (SMTP), 80, 146–150\nSimple Network Management Protocol (SNMP), 451, 458–462\nSimple Network Management Protocol version 3 (SNMPv3), 458–461\nsingle-hop, infrastructure-based networks, 565"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1293,
    "text": "single-hop, infrastructure-less networks, 565\nSkype\napplication-layer protocols, 124\ninternet telephony, 123\nSlammer worm, 222\nSLAs. See Service Level Agreements\nsleep modes, 603–604\nsliding-window protocol, 246\nslow start, 296–297\nsmall cell stations, 607\nsmall office, home office (SOHO), subnets, 374\nsmart spaces, 109\nSMI. See Structure of Management Information\nSMTP. See Simple Mail Transfer Protocol\nSNA, 90\nsniffing, 87, 106\nSNMP. See Simple Network Management Protocol\nSnort, 708\nSNR. See signal-to-noise ratio\nsocial networks, 94\nsocket interface, 36\nsocket programming\nport numbers, 219–220\nwith TCP, 189–195\ntypes of, 182, 183\nwith UDP, 184–189\nsockets, 117, 217\nport numbers, 219–220"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1294,
    "text": "simultaneous, 222\nwelcoming, 221\nsoftware agents, 109\nsoftware-defined networking (SDN), 334, 339, 477\narchitecture of, 443\ncontrol applications, 444–446\ncontrol plane, 343, 441–450\ndata plane, 442, 448–449\nforwarding tables in, 342, 344\ngeneralized forwarding and, 383–390\nkey characteristics of, 441–442\nlink state change in, 448–449\nlogically centralized control in, 409–410\npacket forwarding and, 340\nrouting component, 466\nrouting processor responsibilities in, 342\nsource port number, 260\nsource port number field, 218\nsource quench message, 453–454\nspanning layer, 392\nSPD. See Security Policy Database\nSPI. See Security Parameter Index\nSpotify\nDNS vulnerabilities, 165\nSprint, 62\nSR. See selective repeat\nSRI. See Stanford Research Institute\nSSID. See Service Set Identifier"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1295,
    "text": "ssthresh, 297–300\nStanford Research Institute (SRI), 89, 108\nstateless protocol, 128\nstate-management layer, SDN, 444\nstatic routing algorithms, 413\nstatus line, 133\nstop-and-wait protocols, 235, 243, 244\nstore-and-forward transmission, 53–54\nStream Control Transmission Protocol (SCTP), 311\nstreaming\ncontent distribution networks, 175–179\nDASH, 174–175\nHTTP streaming, 174–175\ninternet video, 173–174\nstreams, 311\nStructure of Management Information (SMI), 459\nsubnet mask, 365\nsubnets, 364–368, 513–514\nobtaining blocks of IP addresses, 370–371\nin OSPF, 426\nSOHO, 374\nSWAN, 410\nswitch\ntop of rack, 535\nswitches, 343\ncrossbar, 348–349\nlink-layer, 34, 53, 341, 346\nnon-blocking, 348"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1296,
    "text": "switches vs. routers, 525–527\nswitching, 341\nin destination-based forwarding, 346\ntechniques for, 347–349\nswitching fabric, 342\nbus, 348\ncrossbar, 347–349\ninterconnection network, 348–349\nmemory, 347–348\nqueuing and speed of, 349–350\nswitch poisoning, 525\nswitch table, 521\nsymmetric key encryption, 642–648\nblock ciphers, 644–646\nCaesar cipher, 642\nchosen-plaintext attack, 643\nCipher Block Chaining (CBC), 647\nciphertext-only attack, 643\nin IPsec, 644\nknown-plaintext attack, 643\nmonoalphabetic cipher, 642\nin PGP, 644\npolyalphabetic encryption, 643, 644\nin TLS, 644\nSYNACK segment, 279, 283\nSYN bit, 261\nSYN cookies, 284\nSYN flood attack, 284"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1297,
    "text": "T\nTag Protocol Identifier (TPID), 529\ntaking-turns protocols, 493, 504–505\nTCAMs. See Ternary Content Addressable Memories\nTCP. See Transmission Control Protocol\nTCP BBR, 306\nTCP congestion-control algorithm, 295–300\nTCP connection, 121\nTCP CUBIC, 301–303, 309\nTCP-friendly congestion-controlled data transfer, 311\nTCP/IP, 35, 258\nTCP Reno, 300–303\nTCP segments, 259\nTCP socket, 544, 546\nTCP splitting, 299\nTCP states, 281–283\nTCP SYN, 546\nTCP Tahoe, 300, 301\nTCP Vegas, 305–306\nTDM. See time-division multiplexing\ntelco. See telephone company\nTelenet, 89\ntelephone company (telco), 43\nTelnet, 263–265, 457\ntemporary IP addresses, 371\nTernary Content Addressable Memories (TCAMs), 346\nterrestrial radio channels, 51\n3G, 48"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1298,
    "text": "Third Generation Partnership Program, 382\nthree-way handshake, 258, 280–281, 546\nthroughput, 73–76\naverage, 74\ncongestion and, 286–291\ninstantaneous, 73\nper-connection, 286–287\nTCP Reno, 303\ntier-1 ISPs, 62–63\nTikTok\nvideo streaming, 173\ntime-based retransmission, 240–241\ntime-division multiplexing (TDM), 58–60, 493–494\ntime frames, 494\ntimeout events\nin GBN protocol, 248\nin SR protocol, 252\nTCP, 266–267, 269, 270\ntimeout intervals\ndoubling, 271–273\nTCP, 266–267, 271–273\ntime slots, 494\ntime-to-live (TTL), 362\ntoken, 505\ntoken-passing protocol, 505\nTomlinson, Ray, 89\ntop-down approach, 80\ntop-level domain (TLD), 156, 157"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1299,
    "text": "Top of Rack (TOR) switch, 535\ntorrent, 170\nTOR switch. See Top of Rack switch\nTOS. See type of service\ntotal nodal delay, 65\nTPID. See Tag Protocol Identifier\nTraceroute, 71–73, 454–455\ntraffic engineering, 427, 534\ntraffic intensity, 69\ntraffic load, queuing and, 349\ntraffic volume, DNS, 156\nTransmission Control Protocol (TCP)\nACK generation recommendation, 274\nacknowledgment number, 261–263\nclassic congestion control, 293–303\nclient-server application using, 192\nclosing connection, 280–281\ncongestion avoidance, 297–298\ncongestion-control algorithm, 295–300\ncongestion control in, 293–309\ncongestion window, 294, 300\nconnection, 257–260\nconnection management, 279–283, 285\nconnection requests, 221\ncubic, 301–303\ncumulative acknowledgment, 262\ndemultiplexing, 220–223\ndevelopment of, 91"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1300,
    "text": "establishing connection, 279–280\nexploring, 330\nfairness and, 306–309\nfast recovery, 298–300\nfast retransmit, 273–275\nflow control, 276–278\nfull-duplex service, 257\nhandshake protocol, 668\nmultimedia applications using, 226\nparallel connection fairness, 309\npipelining, 267\npoint-to-point connections, 257\nreceive window, 277, 278\nreliable data transfer, 268–376\nretransmission timeout interval, 266–267\nRTT estimation, 265–268\nsecuring connections, 674–676\nsegment structure, 260–265\nselective acknowledgment, 276\nself-clocking, 295\nsequence number, 261–263\nservices provided by, 216\nsimultaneous connection sockets, 222\nslow start, 296–297\nsocket programming with, 189–195 (see also socket programming)\nsteady-state behavior of, 303\nTCPClient.py, 191–193\nTCPServer.py, 193–195"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1301,
    "text": "three-way handshake, 258, 280–281\nthroughput, 303\ntimeout events, 266–267, 269, 270\ntimeout intervals, 266–267, 271–273\ntimer management, 268–269\ntransition to, 91–92\ntransport-layer functionality, 309–312\nvariables, 294, 297, 300\nWeb servers and, 223–224\ntransmission delay, 65–69\ntransmission rate, 34\nqueuing and, 349–350\ntransparent, 521\ntransport layer, 80–81\nin Internet, 215–217\nnetwork layer relationship to, 212–215\ntransport-layer functionality, 309–312\ntransport-layer multiplexing and demultiplexing, 216\ntransport-layer protocols (TCP), 212, 482\nand HTTP, 546–547\nTransport Layer Security (TLS), 122, 462, 674–675\nconnection closure, 680\ndata transfer, 677\nhandshake phase, 676, 679–680\nkey derivation, 677\nrecord, 678\ntransport-layer segment, 83\ntransport mode, 685"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1302,
    "text": "triangle routing problem, 615\ntrunking, VLAN, 529\nTTL. See time-to-live\ntunnel, 381\ntunnel endpoint identifier (TEID), 601\ntunneling, 381\ntunnel mode, 685\ntwisted-pair copper wire, 49–50\nTwitter\nDNS vulnerabilities, 165\ntwo-dimensional even parity, 487\ntwo-dimensional parity scheme, 487\nTymnet, 90\ntype of service (TOS), 362\nU\nubiquitous WiFi, 593\nUCLA, 108, 405\nUDP. See User Datagram Protocol\nUDP segment, 543\nultra reliable low-latency communications (URLLC), 606\nundetected bit errors, 485\nunguided media, 49\nunidirectional data transfer, 232\nUNIX, Snort, 708\nunreliable services, 216\nunshielded twisted pair (UTP), 49\nURG bit, 261\nurgent data pointer field, 261"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1303,
    "text": "user agents, 146\nUser Datagram Protocol (UDP), 215, 216, 224–230\nadvantages of, 225–226\nchecksum, 228–230\nclient-server application using, 185\nconnectionless nature of, 225\nDNS using, 225\nexploring, 330\nfairness and, 308–309\nmultimedia applications using, 226–227\nmultiplexing and demultiplexing, 219–220\nreliability with, 227–228\nsegment structure, 228\nsocket programming with, 184–189\nUDPClient.py, 186–188\nUDPServer.py, 188–189\nUser Equipment (UE), 594\nuser-plane function (UPF), 608\nutilization, 243\nUTP. See unshielded twisted pair\nV\nVANET. See vehicular ad hoc network\nvehicular ad hoc network (VANET), 565\nvideo\nfrom remote server, 617\nstreaming, 606\nvideo streaming\ncontent distribution networks, 175–179"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1304,
    "text": "DASH, 174–175\nHTTP streaming, 174–175\ninternet video, 173–174\nvirtualization, 540–541\nvirtual local area networks (VLANs), 528\ninefficient use of switches, 528\nlack of traffic isolation, 527–528\noriginal ethernet frame, 530\nsingle switch with two, 528\ntag, 529\ntrunking, 529\ntwo switches with two, 530\nusers management, 528\nvirtual private networks (VPNs), 534, 681–683\nvisited network, 610\nVLANs. See virtual local area networks\nVoice-over-IP (VoIP), 65, 73, 356, 358\nVoIP. See Voice-over-IP\nVPNs. See virtual private networks\nvulnerability attacks, 85\nW\nWeb browsers, 92–93, 126\nconditional GET, 142\nparallel connections, 309\nWeb cache, 138\nweb client-server interaction, 546–547\nWeb page, 126\nWeb servers, 92, 126, 306"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1305,
    "text": "TCP and, 223–224\nweighted fair queuing (WFQ), 359–360\nwelcoming socket, 221\nwell-known application protocols, 218–219\nwell-known port numbers, 218\nwell-know service, 358\nWFQ. See weighted fair queuing\nwide-area wireless Internet access, 48\nWiFi, 34, 35, 47, 392, 573. See also IEEE 802.11 wireless LAN\naddress fields, 584–586\nadvanced features in, 589–590\narchitecture, 574–578\nchannels and association, 575–578\nclear to send (CTS) control frame, 581\ncollision avoidance, 582\nduration, 586\nenterprise usage of, 46–47\nframe control fields, 586\nframes, 583–586\nhidden terminals, dealing with, 581–583\nlink-layer acknowledgments, 579\nMAC protocol, 578–583\nmobility in same IP subnet, 586–588\npacket sniffing, 87\npayload and CRC fields, 583–584\npersonal area networks, 590–592\nas point-to-point link, 583\npower management, 590"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1306,
    "text": "public access, 93\nrate adaptation, 589–590\nrequest to send (RTS) control, 581\nsequence number, 586\nstandards, 573\ntransmission rates and range, 564\nwide-area wireless versus, 48\nWiFi jungle, 576\nWiFi Positioning System (WPS), 588\nWiFi wireless router, 46\nwildcards, in flow table entries, 386\nwindow scaling factor, 260\nwindow size, 246\nin SR, 254, 255\nWindows platforms\nSnort, 708\nwireless and mobile devices, 109\nwireless communication link, 562\nwireless host, 562\nwireless LANs, 47\nencryption, 689\nencryption-key derivation, 690\nfour-way handshake, 692\nmutual authentication, 690\nsecurity, 689–694\nsecurity messaging protocols, 693–694\nshared symmetric session key derivation, 691\n802.11 wireless LANs. See IEEE 802.11 wireless LAN"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1307,
    "text": "wireless mesh networks, 565\nwireless networks\nCDMA, 569–572\nelements, 562, 563\nlinks and network characteristics, 566–569\nmesh, 565\npacket sniffing, 87\ntransmission rates and range, 564\nWiFi, 572–593\nwireless personal area networks (WPANs), 591\nWireshark, 87, 106–107\nTCP, 330\nwork-conserving queuing, 359\nworms, 222\nWPANs. See wireless personal area networks\nX\nX.509, 664\nXerox\nethernet, 518\nX.25 protocol suite, 92\nXTP, 488\nY\nYahoo, 93\nYANG, 458, 466\nYouTube, 306\nCDN and, 182\nvideo streaming, 173"
  },
  {
    "unit": "Unit 1",
    "topic": "Chapter 802",
    "source": "kurose",
    "page": 1308,
    "text": "Z\nzeroconf, 371\nZimmerman, Phil, 673"
  }
]